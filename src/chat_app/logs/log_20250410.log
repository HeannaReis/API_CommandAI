2025-04-10 08:35:16,000 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 08:35:16,005 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 08:35:16,007 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 08:35:16,009 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 08:35:16,010 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 08:35:16,012 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 08:35:16,014 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 08:35:16,020 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 08:35:16,023 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 08:35:16,027 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 08:35:16,029 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 08:35:16,035 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 08:35:16,040 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 08:35:16,045 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 08:35:16,047 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 08:35:16,981 [INFO] Modelo Gemini 'gemini-2.0-flash-exp' inicializado com sucesso.
2025-04-10 08:41:56,618 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 08:41:56,619 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 08:41:56,621 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 08:41:56,622 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 08:41:56,624 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 08:41:56,625 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 08:41:56,626 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 08:41:56,627 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 08:41:56,629 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 08:41:56,630 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 08:41:56,631 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 08:41:56,633 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 08:41:56,634 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 08:41:56,635 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 08:41:56,636 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 08:41:57,476 [INFO] Modelo Gemini 'gemini-2.0-flash-exp' inicializado com sucesso.
2025-04-10 08:53:39,597 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 08:53:39,599 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 08:53:39,601 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 08:53:39,604 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 08:53:39,605 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 08:53:39,608 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 08:53:39,610 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 08:53:39,613 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 08:53:39,615 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 08:53:39,617 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 08:53:39,618 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 08:53:39,620 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 08:53:39,622 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 08:53:39,624 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 08:53:39,625 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 08:53:39,736 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 08:53:39,737 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 08:53:39,739 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 08:53:39,741 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 08:53:39,743 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 08:53:39,745 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 08:53:39,748 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 08:53:39,751 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 08:53:39,753 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 08:53:39,755 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 08:53:39,757 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 08:53:39,759 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 08:53:39,760 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 08:53:39,763 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 08:53:39,765 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 08:53:39,769 [INFO] Enviando para IA - Prompt (sem imagem): Voc√™ √© um assistente inteligente utilizado em um chat com IA, que recebe c√≥digos de uma aplica√ß√£o completa de chat, como voc√™ funciona e tudo que 
√© programado para fazer no seu contexto.

Seu objetivo √©:
- Analisar todo o contexto e aprender com ele.
- Analisar a Pergunta do Usu√°rio.
- Identificar se possui rela√ß√£o com o contexto.
- Se houver rela√ß√£o com o c√≥digo do contexto responder a pergunta sobre o c√≥digo sempre seguindo boas pr√°ticas:
    - Analisar o c√≥digo-fonte contido no projeto enviado
    - Identificar melhorias em legibilidade, performance e seguran√ßa
    - Sugerir pr√°ticas recomendadas de design e arquitetura
    - Indicar partes com d√≠vidas t√©cnicas ou complexidade desnecess√°ria
    - Enviar c√≥digo modularizado em pequenos arquivos separados por pastas.

Informa√ß√µes adicionais:
- Estrutura do projeto: segue o padr√£o de pastas iniciando por src/


## Se houver imagem no contexto, identifique se a pergunta √© sobre o c√≥digo do contexto, sobre a imagem ou sobre os dois para elaborar melhorer respostas.
## Se o usu√°rio fizer uma pergunta que n√£o tem rela√ß√£o com imagem ou contexto, use a sua base de conhecimento fora do contexto para responder de forma inteligente.
** Responda em Portugu√™s-Brasileiro a n√£o ser que o usu√°rio solicite outra l√≠ngua.**

Contexto:



# chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# main.py

# main.py
from core.handlers.signal_handler import setup_signal_handler
from services.image_processor import ImageProcessor
from core.rate_limiter import RateLimiter
import json

def main():
    setup_signal_handler()

    # Inicializa o RateLimiter com o n√∫mero m√°ximo de requisi√ß√µes e o per√≠odo
    rate_limiter = RateLimiter(max_requests=9, period_seconds=60)  # 9 requisi√ß√µes por minuto

    # Passa o RateLimiter para o ImageProcessor
    processor = ImageProcessor(rate_limiter)
    processor.process_images()

    # Obter e imprimir o hist√≥rico ap√≥s o processamento
    history = processor.get_history()
    for item in history:
        print(f"Imagem: {item['image_name']}, Resumo: {item['summary']}")

    # Salvar o hist√≥rico em um arquivo JSON
    with open(processor.historico_json_file, "w") as f:
        json.dump(history, f, indent=4)

if __name__ == "__main__":
    main()

# services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# test_image_generation.py

import os
from dotenv import load_dotenv
from google import genai
from google.generativeai import types
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

client = genai.Client(api_key=api_key)

prompt = "gerar a imagem do simbolo do corinthians."

response = client.models.generate_content(
    model='gemini-2.0-flash-exp-image-generation',
    contents=prompt,
    config=types.GenerateContentConfig(
        response_modalities=['Text', 'Image']
    )
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = Image.open(BytesIO(part.inline_data.data))
        image.save("ed-image.png")
        image.show()

# utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

User: fa√ßa code review da minha aplica√ß√£o.
2025-04-10 08:53:53,641 [INFO] Resposta da IA (texto): Com certeza! Analisei o c√≥digo da sua aplica√ß√£o e preparei algumas sugest√µes para melhorias em legibilidade, performance, seguran√ßa e design.

**1. Estrutura e Modulariza√ß√£o:**

*   **Diret√≥rios:** Organize melhor os arquivos dentro de `src`. Crie subdiret√≥rios para `models`, `services`, `handlers`, `utils`, `config`, etc. Isso facilita a localiza√ß√£o dos arquivos e a compreens√£o da estrutura do projeto.
*   **Arquivo de configura√ß√£o:** Mova a classe `Config` para um arquivo separado (ex: `config.py`) dentro de um diret√≥rio `config`.
*   **Fun√ß√µes:** Quebre fun√ß√µes grandes em fun√ß√µes menores e mais focadas. Isso melhora a legibilidade e facilita o teste.

**2. Boas Pr√°ticas e Melhorias no C√≥digo:**

*   **Rate Limiting:** Implemente o `RateLimiter` nos servi√ßos que consomem a API do Gemini (ex: `ImageProcessor`, `GeminiHandler`). Isso evita sobrecarga na API e garante um uso mais eficiente.
*   **Configura√ß√µes:** Use a classe `Config` para centralizar todas as configura√ß√µes da aplica√ß√£o (ex: chaves de API, modelos, diret√≥rios). Isso facilita a manuten√ß√£o e a configura√ß√£o do projeto.
*   **Logging:** Padronize o uso do logger em toda a aplica√ß√£o. Use os n√≠veis de log apropriados (ex: `info`, `warning`, `error`) para cada tipo de mensagem.
*   **Tratamento de Erros:** Adicione tratamento de erros mais espec√≠fico em cada fun√ß√£o. Isso ajuda a identificar e corrigir problemas mais rapidamente.
*   **Cache:** Utilize o `st.cache_resource` para fun√ß√µes que realizam opera√ß√µes custosas, como a inicializa√ß√£o do `GeminiHandler`. Isso evita a execu√ß√£o repetida dessas opera√ß√µes.
*   **Tipagem:** Utilize tipagem est√°tica (type hints) para melhorar a legibilidade e a seguran√ßa do c√≥digo.
*   **Imagens:** Valide se `uploaded_file` √© realmente um arquivo de imagem antes de tentar exibi-lo, evitando erros caso o usu√°rio envie um arquivo de outro tipo.
*   **Prompts:** Crie arquivos de prompt separados para diferentes tarefas (ex: chat, an√°lise de imagem). Isso facilita a manuten√ß√£o e a personaliza√ß√£o dos prompts.

**3. Seguran√ßa:**

*   **Chaves de API:** Nunca coloque suas chaves de API diretamente no c√≥digo. Use vari√°veis de ambiente ou um arquivo de configura√ß√£o seguro para armazen√°-las.
*   **Valida√ß√£o de Input:** Valide todos os inputs do usu√°rio para evitar ataques de inje√ß√£o de c√≥digo.

**4. Arquitetura:**

*   **Camadas:** Defina claramente as responsabilidades de cada camada da sua aplica√ß√£o (ex: apresenta√ß√£o, l√≥gica de neg√≥cios, acesso a dados). Isso facilita a manuten√ß√£o e a evolu√ß√£o do projeto.
*   **Invers√£o de Depend√™ncia:** Use invers√£o de depend√™ncia para desacoplar as diferentes partes da sua aplica√ß√£o. Isso facilita o teste e a substitui√ß√£o de componentes.
*   **Testes:** Escreva testes unit√°rios e de integra√ß√£o para garantir a qualidade do seu c√≥digo.

**5. D√≠vidas T√©cnicas e Complexidade:**

*   **Fun√ß√µes Longas:** Identifique fun√ß√µes com muitas linhas de c√≥digo e divida-as em fun√ß√µes menores e mais focadas.
*   **L√≥gica Duplicada:** Elimine a l√≥gica duplicada criando fun√ß√µes ou classes reutiliz√°veis.
*   **Coment√°rios:** Adicione coment√°rios para explicar o que o c√≥digo faz, especialmente em partes complexas.

**Exemplo de Refatora√ß√£o:**

Aqui est√° um exemplo de como voc√™ pode refatorar a fun√ß√£o `process_images` na classe `ImageProcessor`:

```python
# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self._post_process_image(image_name, summary)
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _post_process_image(self, image_name, summary):
        self.document_service.add_image_summary(image_name, summary)
        self.markdown_service.add_image_summary(image_name, summary)
        self.document_service.save_document()
        self.markdown_service.save_markdown()

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history
```

**6. C√≥digo Modularizado:**

Para facilitar a visualiza√ß√£o e a organiza√ß√£o, preparei o c√≥digo modularizado em arquivos separados:

```
src/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gemini_handler.py
‚îÇ   ‚îú‚îÄ‚îÄ logger_config.py
‚îÇ   ‚îî‚îÄ‚îÄ rate_limiter.py
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ document_service.py
‚îÇ   ‚îú‚îÄ‚îÄ gpt_services.py
‚îÇ   ‚îú‚îÄ‚îÄ image_processor.py
‚îÇ   ‚îú‚îÄ‚îÄ markdown_service.py
‚îÇ   ‚îî‚îÄ‚îÄ search_files.py
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ file_utils.py
```

**Observa√ß√µes Finais:**

*   A implementa√ß√£o de todas essas sugest√µes pode levar tempo, mas o resultado final ser√° um c√≥digo mais organizado, leg√≠vel, seguro e f√°cil de manter.
*   Priorize as melhorias que trazem o maior impacto no seu projeto.
*   Use um sistema de controle de vers√£o (ex: Git) para acompanhar suas mudan√ßas e facilitar a colabora√ß√£o com outros desenvolvedores.

Se tiver alguma d√∫vida sobre alguma dessas sugest√µes, √© s√≥ perguntar!
2025-04-10 08:53:53,743 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 08:53:53,745 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 08:53:53,747 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 08:53:53,748 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 08:53:53,750 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 08:53:53,751 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 08:53:53,753 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 08:53:53,754 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 08:53:53,757 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 08:53:53,759 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 08:53:53,762 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 08:53:53,765 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 08:53:53,766 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 08:53:53,768 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 08:53:53,770 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 08:55:40,083 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 08:55:40,085 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 08:55:40,086 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 08:55:40,087 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 08:55:40,089 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 08:55:40,091 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 08:55:40,092 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 08:55:40,093 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 08:55:40,095 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 08:55:40,096 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 08:55:40,098 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 08:55:40,099 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 08:55:40,100 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 08:55:40,103 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 08:55:40,105 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 08:55:40,374 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 08:55:40,376 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 08:55:40,377 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 08:55:40,379 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 08:55:40,380 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 08:55:40,381 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 08:55:40,383 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 08:55:40,385 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 08:55:40,386 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 08:55:40,388 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 08:55:40,389 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 08:55:40,391 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 08:55:40,394 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 08:55:40,396 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 08:55:40,397 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 08:55:52,506 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 08:55:52,510 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 08:55:52,513 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 08:55:52,516 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 08:55:52,520 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 08:55:52,523 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 08:55:52,525 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 08:55:52,528 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 08:55:52,531 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 08:55:52,534 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 08:55:52,536 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 08:55:52,539 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 08:55:52,543 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 08:55:52,545 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 08:55:52,549 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 08:55:52,732 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 08:55:52,734 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 08:55:52,736 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 08:55:52,738 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 08:55:52,740 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 08:55:52,742 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 08:55:52,744 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 08:55:52,747 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 08:55:52,749 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 08:55:52,751 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 08:55:52,753 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 08:55:52,754 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 08:55:52,756 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 08:55:52,759 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 08:55:52,761 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 08:55:52,781 [INFO] Enviando para IA - Imagem: C:\Users\jfreis\Documents\azure-ai-sentiment-analysis\assets\20250410085552_clipboard_20250410085540.png, Prompt: Voc√™ √© um assistente inteligente utilizado em um chat com IA, que recebe c√≥digos de uma aplica√ß√£o completa de chat, como voc√™ funciona e tudo que 
√© programado para fazer no seu contexto.

Seu objetivo √©:
- Analisar todo o contexto e aprender com ele.
- Analisar a Pergunta do Usu√°rio.
- Identificar se possui rela√ß√£o com o contexto.
- Se houver rela√ß√£o com o c√≥digo do contexto responder a pergunta sobre o c√≥digo sempre seguindo boas pr√°ticas:
    - Analisar o c√≥digo-fonte contido no projeto enviado
    - Identificar melhorias em legibilidade, performance e seguran√ßa
    - Sugerir pr√°ticas recomendadas de design e arquitetura
    - Indicar partes com d√≠vidas t√©cnicas ou complexidade desnecess√°ria
    - Enviar c√≥digo modularizado em pequenos arquivos separados por pastas.

Informa√ß√µes adicionais:
- Estrutura do projeto: segue o padr√£o de pastas iniciando por src/


## Se houver imagem no contexto, identifique se a pergunta √© sobre o c√≥digo do contexto, sobre a imagem ou sobre os dois para elaborar melhorer respostas.
## Se o usu√°rio fizer uma pergunta que n√£o tem rela√ß√£o com imagem ou contexto, use a sua base de conhecimento fora do contexto para responder de forma inteligente.
** Responda em Portugu√™s-Brasileiro a n√£o ser que o usu√°rio solicite outra l√≠ngua.**

Contexto:



# chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# main.py

# main.py
from core.handlers.signal_handler import setup_signal_handler
from services.image_processor import ImageProcessor
from core.rate_limiter import RateLimiter
import json

def main():
    setup_signal_handler()

    # Inicializa o RateLimiter com o n√∫mero m√°ximo de requisi√ß√µes e o per√≠odo
    rate_limiter = RateLimiter(max_requests=9, period_seconds=60)  # 9 requisi√ß√µes por minuto

    # Passa o RateLimiter para o ImageProcessor
    processor = ImageProcessor(rate_limiter)
    processor.process_images()

    # Obter e imprimir o hist√≥rico ap√≥s o processamento
    history = processor.get_history()
    for item in history:
        print(f"Imagem: {item['image_name']}, Resumo: {item['summary']}")

    # Salvar o hist√≥rico em um arquivo JSON
    with open(processor.historico_json_file, "w") as f:
        json.dump(history, f, indent=4)

if __name__ == "__main__":
    main()

# services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# test_image_generation.py

import os
from dotenv import load_dotenv
from google import genai
from google.generativeai import types
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

client = genai.Client(api_key=api_key)

prompt = "gerar a imagem do simbolo do corinthians."

response = client.models.generate_content(
    model='gemini-2.0-flash-exp-image-generation',
    contents=prompt,
    config=types.GenerateContentConfig(
        response_modalities=['Text', 'Image']
    )
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = Image.open(BytesIO(part.inline_data.data))
        image.save("ed-image.png")
        image.show()

# utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

User: fa√ßa code review da minha aplica√ß√£o.
Assistant: Com certeza! Analisei o c√≥digo da sua aplica√ß√£o e preparei algumas sugest√µes para melhorias em legibilidade, performance, seguran√ßa e design.

**1. Estrutura e Modulariza√ß√£o:**

*   **Diret√≥rios:** Organize melhor os arquivos dentro de `src`. Crie subdiret√≥rios para `models`, `services`, `handlers`, `utils`, `config`, etc. Isso facilita a localiza√ß√£o dos arquivos e a compreens√£o da estrutura do projeto.
*   **Arquivo de configura√ß√£o:** Mova a classe `Config` para um arquivo separado (ex: `config.py`) dentro de um diret√≥rio `config`.
*   **Fun√ß√µes:** Quebre fun√ß√µes grandes em fun√ß√µes menores e mais focadas. Isso melhora a legibilidade e facilita o teste.

**2. Boas Pr√°ticas e Melhorias no C√≥digo:**

*   **Rate Limiting:** Implemente o `RateLimiter` nos servi√ßos que consomem a API do Gemini (ex: `ImageProcessor`, `GeminiHandler`). Isso evita sobrecarga na API e garante um uso mais eficiente.
*   **Configura√ß√µes:** Use a classe `Config` para centralizar todas as configura√ß√µes da aplica√ß√£o (ex: chaves de API, modelos, diret√≥rios). Isso facilita a manuten√ß√£o e a configura√ß√£o do projeto.
*   **Logging:** Padronize o uso do logger em toda a aplica√ß√£o. Use os n√≠veis de log apropriados (ex: `info`, `warning`, `error`) para cada tipo de mensagem.
*   **Tratamento de Erros:** Adicione tratamento de erros mais espec√≠fico em cada fun√ß√£o. Isso ajuda a identificar e corrigir problemas mais rapidamente.
*   **Cache:** Utilize o `st.cache_resource` para fun√ß√µes que realizam opera√ß√µes custosas, como a inicializa√ß√£o do `GeminiHandler`. Isso evita a execu√ß√£o repetida dessas opera√ß√µes.
*   **Tipagem:** Utilize tipagem est√°tica (type hints) para melhorar a legibilidade e a seguran√ßa do c√≥digo.
*   **Imagens:** Valide se `uploaded_file` √© realmente um arquivo de imagem antes de tentar exibi-lo, evitando erros caso o usu√°rio envie um arquivo de outro tipo.
*   **Prompts:** Crie arquivos de prompt separados para diferentes tarefas (ex: chat, an√°lise de imagem). Isso facilita a manuten√ß√£o e a personaliza√ß√£o dos prompts.

**3. Seguran√ßa:**

*   **Chaves de API:** Nunca coloque suas chaves de API diretamente no c√≥digo. Use vari√°veis de ambiente ou um arquivo de configura√ß√£o seguro para armazen√°-las.
*   **Valida√ß√£o de Input:** Valide todos os inputs do usu√°rio para evitar ataques de inje√ß√£o de c√≥digo.

**4. Arquitetura:**

*   **Camadas:** Defina claramente as responsabilidades de cada camada da sua aplica√ß√£o (ex: apresenta√ß√£o, l√≥gica de neg√≥cios, acesso a dados). Isso facilita a manuten√ß√£o e a evolu√ß√£o do projeto.
*   **Invers√£o de Depend√™ncia:** Use invers√£o de depend√™ncia para desacoplar as diferentes partes da sua aplica√ß√£o. Isso facilita o teste e a substitui√ß√£o de componentes.
*   **Testes:** Escreva testes unit√°rios e de integra√ß√£o para garantir a qualidade do seu c√≥digo.

**5. D√≠vidas T√©cnicas e Complexidade:**

*   **Fun√ß√µes Longas:** Identifique fun√ß√µes com muitas linhas de c√≥digo e divida-as em fun√ß√µes menores e mais focadas.
*   **L√≥gica Duplicada:** Elimine a l√≥gica duplicada criando fun√ß√µes ou classes reutiliz√°veis.
*   **Coment√°rios:** Adicione coment√°rios para explicar o que o c√≥digo faz, especialmente em partes complexas.

**Exemplo de Refatora√ß√£o:**

Aqui est√° um exemplo de como voc√™ pode refatorar a fun√ß√£o `process_images` na classe `ImageProcessor`:

```python
# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self._post_process_image(image_name, summary)
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _post_process_image(self, image_name, summary):
        self.document_service.add_image_summary(image_name, summary)
        self.markdown_service.add_image_summary(image_name, summary)
        self.document_service.save_document()
        self.markdown_service.save_markdown()

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history
```

**6. C√≥digo Modularizado:**

Para facilitar a visualiza√ß√£o e a organiza√ß√£o, preparei o c√≥digo modularizado em arquivos separados:

```
src/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gemini_handler.py
‚îÇ   ‚îú‚îÄ‚îÄ logger_config.py
‚îÇ   ‚îî‚îÄ‚îÄ rate_limiter.py
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ document_service.py
‚îÇ   ‚îú‚îÄ‚îÄ gpt_services.py
‚îÇ   ‚îú‚îÄ‚îÄ image_processor.py
‚îÇ   ‚îú‚îÄ‚îÄ markdown_service.py
‚îÇ   ‚îî‚îÄ‚îÄ search_files.py
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ file_utils.py
```

**Observa√ß√µes Finais:**

*   A implementa√ß√£o de todas essas sugest√µes pode levar tempo, mas o resultado final ser√° um c√≥digo mais organizado, leg√≠vel, seguro e f√°cil de manter.
*   Priorize as melhorias que trazem o maior impacto no seu projeto.
*   Use um sistema de controle de vers√£o (ex: Git) para acompanhar suas mudan√ßas e facilitar a colabora√ß√£o com outros desenvolvedores.

Se tiver alguma d√∫vida sobre alguma dessas sugest√µes, √© s√≥ perguntar!
User: Extraia o CNPJ dessa imagem.
2025-04-10 08:55:54,918 [INFO] Resposta da IA (imagem): A imagem cont√©m um comprovante de inscri√ß√£o e de situa√ß√£o cadastral. O CNPJ presente na imagem √©:

`33.024.232/0001-39`
2025-04-10 08:55:55,049 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 08:55:55,051 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 08:55:55,054 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 08:55:55,058 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 08:55:55,065 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 08:55:55,067 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 08:55:55,069 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 08:55:55,071 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 08:55:55,073 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 08:55:55,076 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 08:55:55,081 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 08:55:55,083 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 08:55:55,085 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 08:55:55,087 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 08:55:55,088 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 10:05:54,587 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 10:05:54,589 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 10:05:54,593 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 10:05:54,595 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 10:05:54,597 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 10:05:54,598 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 10:05:54,600 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 10:05:54,602 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 10:05:54,603 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 10:05:54,605 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 10:05:54,608 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 10:05:54,610 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 10:05:54,612 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 10:05:54,613 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 10:05:54,615 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 10:05:54,882 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 10:05:54,884 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 10:05:54,886 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 10:05:54,888 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 10:05:54,889 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 10:05:54,892 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 10:05:54,894 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 10:05:54,895 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 10:05:54,898 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 10:05:54,901 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 10:05:54,903 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 10:05:54,905 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 10:05:54,908 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 10:05:54,910 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 10:05:54,912 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 10:06:06,686 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 10:06:06,688 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 10:06:06,690 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 10:06:06,693 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 10:06:06,695 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 10:06:06,697 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 10:06:06,699 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 10:06:06,700 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 10:06:06,702 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 10:06:06,704 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 10:06:06,706 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 10:06:06,708 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 10:06:06,709 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 10:06:06,711 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 10:06:06,713 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 10:06:06,835 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 10:06:06,837 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 10:06:06,839 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 10:06:06,841 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 10:06:06,843 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 10:06:06,845 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 10:06:06,846 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 10:06:06,849 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 10:06:06,852 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 10:06:06,854 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 10:06:06,855 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 10:06:06,856 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 10:06:06,858 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 10:06:06,860 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 10:06:06,861 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 10:06:06,874 [INFO] Enviando para IA - Imagem: C:\Users\jfreis\Documents\azure-ai-sentiment-analysis\assets\20250410100606_clipboard_20250410100554.png, Prompt: Voc√™ √© um assistente inteligente utilizado em um chat com IA, que recebe c√≥digos de uma aplica√ß√£o completa de chat, como voc√™ funciona e tudo que 
√© programado para fazer no seu contexto.

Seu objetivo √©:
- Analisar todo o contexto e aprender com ele.
- Analisar a Pergunta do Usu√°rio.
- Identificar se possui rela√ß√£o com o contexto.
- Se houver rela√ß√£o com o c√≥digo do contexto responder a pergunta sobre o c√≥digo sempre seguindo boas pr√°ticas:
    - Analisar o c√≥digo-fonte contido no projeto enviado
    - Identificar melhorias em legibilidade, performance e seguran√ßa
    - Sugerir pr√°ticas recomendadas de design e arquitetura
    - Indicar partes com d√≠vidas t√©cnicas ou complexidade desnecess√°ria
    - Enviar c√≥digo modularizado em pequenos arquivos separados por pastas.

Informa√ß√µes adicionais:
- Estrutura do projeto: segue o padr√£o de pastas iniciando por src/


## Se houver imagem no contexto, identifique se a pergunta √© sobre o c√≥digo do contexto, sobre a imagem ou sobre os dois para elaborar melhorer respostas.
## Se o usu√°rio fizer uma pergunta que n√£o tem rela√ß√£o com imagem ou contexto, use a sua base de conhecimento fora do contexto para responder de forma inteligente.
** Responda em Portugu√™s-Brasileiro a n√£o ser que o usu√°rio solicite outra l√≠ngua.**

Contexto:



# chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# main.py

# main.py
from core.handlers.signal_handler import setup_signal_handler
from services.image_processor import ImageProcessor
from core.rate_limiter import RateLimiter
import json

def main():
    setup_signal_handler()

    # Inicializa o RateLimiter com o n√∫mero m√°ximo de requisi√ß√µes e o per√≠odo
    rate_limiter = RateLimiter(max_requests=9, period_seconds=60)  # 9 requisi√ß√µes por minuto

    # Passa o RateLimiter para o ImageProcessor
    processor = ImageProcessor(rate_limiter)
    processor.process_images()

    # Obter e imprimir o hist√≥rico ap√≥s o processamento
    history = processor.get_history()
    for item in history:
        print(f"Imagem: {item['image_name']}, Resumo: {item['summary']}")

    # Salvar o hist√≥rico em um arquivo JSON
    with open(processor.historico_json_file, "w") as f:
        json.dump(history, f, indent=4)

if __name__ == "__main__":
    main()

# services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# test_image_generation.py

import os
from dotenv import load_dotenv
from google import genai
from google.generativeai import types
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

client = genai.Client(api_key=api_key)

prompt = "gerar a imagem do simbolo do corinthians."

response = client.models.generate_content(
    model='gemini-2.0-flash-exp-image-generation',
    contents=prompt,
    config=types.GenerateContentConfig(
        response_modalities=['Text', 'Image']
    )
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = Image.open(BytesIO(part.inline_data.data))
        image.save("ed-image.png")
        image.show()

# utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

User: fa√ßa code review da minha aplica√ß√£o.
Assistant: Com certeza! Analisei o c√≥digo da sua aplica√ß√£o e preparei algumas sugest√µes para melhorias em legibilidade, performance, seguran√ßa e design.

**1. Estrutura e Modulariza√ß√£o:**

*   **Diret√≥rios:** Organize melhor os arquivos dentro de `src`. Crie subdiret√≥rios para `models`, `services`, `handlers`, `utils`, `config`, etc. Isso facilita a localiza√ß√£o dos arquivos e a compreens√£o da estrutura do projeto.
*   **Arquivo de configura√ß√£o:** Mova a classe `Config` para um arquivo separado (ex: `config.py`) dentro de um diret√≥rio `config`.
*   **Fun√ß√µes:** Quebre fun√ß√µes grandes em fun√ß√µes menores e mais focadas. Isso melhora a legibilidade e facilita o teste.

**2. Boas Pr√°ticas e Melhorias no C√≥digo:**

*   **Rate Limiting:** Implemente o `RateLimiter` nos servi√ßos que consomem a API do Gemini (ex: `ImageProcessor`, `GeminiHandler`). Isso evita sobrecarga na API e garante um uso mais eficiente.
*   **Configura√ß√µes:** Use a classe `Config` para centralizar todas as configura√ß√µes da aplica√ß√£o (ex: chaves de API, modelos, diret√≥rios). Isso facilita a manuten√ß√£o e a configura√ß√£o do projeto.
*   **Logging:** Padronize o uso do logger em toda a aplica√ß√£o. Use os n√≠veis de log apropriados (ex: `info`, `warning`, `error`) para cada tipo de mensagem.
*   **Tratamento de Erros:** Adicione tratamento de erros mais espec√≠fico em cada fun√ß√£o. Isso ajuda a identificar e corrigir problemas mais rapidamente.
*   **Cache:** Utilize o `st.cache_resource` para fun√ß√µes que realizam opera√ß√µes custosas, como a inicializa√ß√£o do `GeminiHandler`. Isso evita a execu√ß√£o repetida dessas opera√ß√µes.
*   **Tipagem:** Utilize tipagem est√°tica (type hints) para melhorar a legibilidade e a seguran√ßa do c√≥digo.
*   **Imagens:** Valide se `uploaded_file` √© realmente um arquivo de imagem antes de tentar exibi-lo, evitando erros caso o usu√°rio envie um arquivo de outro tipo.
*   **Prompts:** Crie arquivos de prompt separados para diferentes tarefas (ex: chat, an√°lise de imagem). Isso facilita a manuten√ß√£o e a personaliza√ß√£o dos prompts.

**3. Seguran√ßa:**

*   **Chaves de API:** Nunca coloque suas chaves de API diretamente no c√≥digo. Use vari√°veis de ambiente ou um arquivo de configura√ß√£o seguro para armazen√°-las.
*   **Valida√ß√£o de Input:** Valide todos os inputs do usu√°rio para evitar ataques de inje√ß√£o de c√≥digo.

**4. Arquitetura:**

*   **Camadas:** Defina claramente as responsabilidades de cada camada da sua aplica√ß√£o (ex: apresenta√ß√£o, l√≥gica de neg√≥cios, acesso a dados). Isso facilita a manuten√ß√£o e a evolu√ß√£o do projeto.
*   **Invers√£o de Depend√™ncia:** Use invers√£o de depend√™ncia para desacoplar as diferentes partes da sua aplica√ß√£o. Isso facilita o teste e a substitui√ß√£o de componentes.
*   **Testes:** Escreva testes unit√°rios e de integra√ß√£o para garantir a qualidade do seu c√≥digo.

**5. D√≠vidas T√©cnicas e Complexidade:**

*   **Fun√ß√µes Longas:** Identifique fun√ß√µes com muitas linhas de c√≥digo e divida-as em fun√ß√µes menores e mais focadas.
*   **L√≥gica Duplicada:** Elimine a l√≥gica duplicada criando fun√ß√µes ou classes reutiliz√°veis.
*   **Coment√°rios:** Adicione coment√°rios para explicar o que o c√≥digo faz, especialmente em partes complexas.

**Exemplo de Refatora√ß√£o:**

Aqui est√° um exemplo de como voc√™ pode refatorar a fun√ß√£o `process_images` na classe `ImageProcessor`:

```python
# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self._post_process_image(image_name, summary)
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _post_process_image(self, image_name, summary):
        self.document_service.add_image_summary(image_name, summary)
        self.markdown_service.add_image_summary(image_name, summary)
        self.document_service.save_document()
        self.markdown_service.save_markdown()

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history
```

**6. C√≥digo Modularizado:**

Para facilitar a visualiza√ß√£o e a organiza√ß√£o, preparei o c√≥digo modularizado em arquivos separados:

```
src/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gemini_handler.py
‚îÇ   ‚îú‚îÄ‚îÄ logger_config.py
‚îÇ   ‚îî‚îÄ‚îÄ rate_limiter.py
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ document_service.py
‚îÇ   ‚îú‚îÄ‚îÄ gpt_services.py
‚îÇ   ‚îú‚îÄ‚îÄ image_processor.py
‚îÇ   ‚îú‚îÄ‚îÄ markdown_service.py
‚îÇ   ‚îî‚îÄ‚îÄ search_files.py
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ file_utils.py
```

**Observa√ß√µes Finais:**

*   A implementa√ß√£o de todas essas sugest√µes pode levar tempo, mas o resultado final ser√° um c√≥digo mais organizado, leg√≠vel, seguro e f√°cil de manter.
*   Priorize as melhorias que trazem o maior impacto no seu projeto.
*   Use um sistema de controle de vers√£o (ex: Git) para acompanhar suas mudan√ßas e facilitar a colabora√ß√£o com outros desenvolvedores.

Se tiver alguma d√∫vida sobre alguma dessas sugest√µes, √© s√≥ perguntar!
User: Extraia o CNPJ dessa imagem.
Assistant: A imagem cont√©m um comprovante de inscri√ß√£o e de situa√ß√£o cadastral. O CNPJ presente na imagem √©:

`33.024.232/0001-39`
User: extraia o n√∫mero do chamado que come√ßa com  2025
2025-04-10 10:06:09,693 [INFO] Resposta da IA (imagem): O n√∫mero do chamado que come√ßa com 2025 na imagem √©:

`2025040185005611`

2025-04-10 10:06:09,784 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 10:06:09,786 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 10:06:09,787 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 10:06:09,789 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 10:06:09,790 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 10:06:09,791 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 10:06:09,793 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 10:06:09,795 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 10:06:09,797 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 10:06:09,798 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 10:06:09,800 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 10:06:09,801 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 10:06:09,803 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 10:06:09,804 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 10:06:09,806 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 14:06:00,178 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 14:06:00,189 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 14:06:00,195 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 14:06:00,203 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 14:06:00,208 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 14:06:00,215 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 14:06:00,221 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 14:06:00,229 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 14:06:00,234 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 14:06:00,240 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 14:06:00,246 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 14:06:00,252 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 14:06:00,258 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 14:06:00,263 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 14:06:00,268 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 14:06:11,360 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 14:06:11,362 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 14:06:11,363 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 14:06:11,365 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 14:06:11,366 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 14:06:11,368 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 14:06:11,370 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 14:06:11,372 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 14:06:11,373 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 14:06:11,375 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 14:06:11,376 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 14:06:11,378 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 14:06:11,379 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 14:06:11,381 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 14:06:11,382 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 14:06:11,493 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 14:06:11,495 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 14:06:11,496 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 14:06:11,497 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 14:06:11,499 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 14:06:11,500 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 14:06:11,501 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 14:06:11,503 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 14:06:11,504 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 14:06:11,506 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 14:06:11,508 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 14:06:11,511 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 14:06:11,514 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 14:06:11,516 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 14:06:11,518 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 14:06:11,538 [INFO] Enviando para IA - Imagem: C:\Users\jfreis\Documents\azure-ai-sentiment-analysis\assets\20250410140611_clipboard_20250410100554.png, Prompt: Voc√™ √© um assistente inteligente utilizado em um chat com IA, que recebe c√≥digos de uma aplica√ß√£o completa de chat, como voc√™ funciona e tudo que 
√© programado para fazer no seu contexto.

Seu objetivo √©:
- Analisar todo o contexto e aprender com ele.
- Analisar a Pergunta do Usu√°rio.
- Identificar se possui rela√ß√£o com o contexto.
- Se houver rela√ß√£o com o c√≥digo do contexto responder a pergunta sobre o c√≥digo sempre seguindo boas pr√°ticas:
    - Analisar o c√≥digo-fonte contido no projeto enviado
    - Identificar melhorias em legibilidade, performance e seguran√ßa
    - Sugerir pr√°ticas recomendadas de design e arquitetura
    - Indicar partes com d√≠vidas t√©cnicas ou complexidade desnecess√°ria
    - Enviar c√≥digo modularizado em pequenos arquivos separados por pastas.

Informa√ß√µes adicionais:
- Estrutura do projeto: segue o padr√£o de pastas iniciando por src/


## Se houver imagem no contexto, identifique se a pergunta √© sobre o c√≥digo do contexto, sobre a imagem ou sobre os dois para elaborar melhorer respostas.
## Se o usu√°rio fizer uma pergunta que n√£o tem rela√ß√£o com imagem ou contexto, use a sua base de conhecimento fora do contexto para responder de forma inteligente.
** Responda em Portugu√™s-Brasileiro a n√£o ser que o usu√°rio solicite outra l√≠ngua.**

Contexto:



# chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# main.py

# main.py
from core.handlers.signal_handler import setup_signal_handler
from services.image_processor import ImageProcessor
from core.rate_limiter import RateLimiter
import json

def main():
    setup_signal_handler()

    # Inicializa o RateLimiter com o n√∫mero m√°ximo de requisi√ß√µes e o per√≠odo
    rate_limiter = RateLimiter(max_requests=9, period_seconds=60)  # 9 requisi√ß√µes por minuto

    # Passa o RateLimiter para o ImageProcessor
    processor = ImageProcessor(rate_limiter)
    processor.process_images()

    # Obter e imprimir o hist√≥rico ap√≥s o processamento
    history = processor.get_history()
    for item in history:
        print(f"Imagem: {item['image_name']}, Resumo: {item['summary']}")

    # Salvar o hist√≥rico em um arquivo JSON
    with open(processor.historico_json_file, "w") as f:
        json.dump(history, f, indent=4)

if __name__ == "__main__":
    main()

# services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# test_image_generation.py

import os
from dotenv import load_dotenv
from google import genai
from google.generativeai import types
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

client = genai.Client(api_key=api_key)

prompt = "gerar a imagem do simbolo do corinthians."

response = client.models.generate_content(
    model='gemini-2.0-flash-exp-image-generation',
    contents=prompt,
    config=types.GenerateContentConfig(
        response_modalities=['Text', 'Image']
    )
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = Image.open(BytesIO(part.inline_data.data))
        image.save("ed-image.png")
        image.show()

# utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

User: fa√ßa code review da minha aplica√ß√£o.
Assistant: Com certeza! Analisei o c√≥digo da sua aplica√ß√£o e preparei algumas sugest√µes para melhorias em legibilidade, performance, seguran√ßa e design.

**1. Estrutura e Modulariza√ß√£o:**

*   **Diret√≥rios:** Organize melhor os arquivos dentro de `src`. Crie subdiret√≥rios para `models`, `services`, `handlers`, `utils`, `config`, etc. Isso facilita a localiza√ß√£o dos arquivos e a compreens√£o da estrutura do projeto.
*   **Arquivo de configura√ß√£o:** Mova a classe `Config` para um arquivo separado (ex: `config.py`) dentro de um diret√≥rio `config`.
*   **Fun√ß√µes:** Quebre fun√ß√µes grandes em fun√ß√µes menores e mais focadas. Isso melhora a legibilidade e facilita o teste.

**2. Boas Pr√°ticas e Melhorias no C√≥digo:**

*   **Rate Limiting:** Implemente o `RateLimiter` nos servi√ßos que consomem a API do Gemini (ex: `ImageProcessor`, `GeminiHandler`). Isso evita sobrecarga na API e garante um uso mais eficiente.
*   **Configura√ß√µes:** Use a classe `Config` para centralizar todas as configura√ß√µes da aplica√ß√£o (ex: chaves de API, modelos, diret√≥rios). Isso facilita a manuten√ß√£o e a configura√ß√£o do projeto.
*   **Logging:** Padronize o uso do logger em toda a aplica√ß√£o. Use os n√≠veis de log apropriados (ex: `info`, `warning`, `error`) para cada tipo de mensagem.
*   **Tratamento de Erros:** Adicione tratamento de erros mais espec√≠fico em cada fun√ß√£o. Isso ajuda a identificar e corrigir problemas mais rapidamente.
*   **Cache:** Utilize o `st.cache_resource` para fun√ß√µes que realizam opera√ß√µes custosas, como a inicializa√ß√£o do `GeminiHandler`. Isso evita a execu√ß√£o repetida dessas opera√ß√µes.
*   **Tipagem:** Utilize tipagem est√°tica (type hints) para melhorar a legibilidade e a seguran√ßa do c√≥digo.
*   **Imagens:** Valide se `uploaded_file` √© realmente um arquivo de imagem antes de tentar exibi-lo, evitando erros caso o usu√°rio envie um arquivo de outro tipo.
*   **Prompts:** Crie arquivos de prompt separados para diferentes tarefas (ex: chat, an√°lise de imagem). Isso facilita a manuten√ß√£o e a personaliza√ß√£o dos prompts.

**3. Seguran√ßa:**

*   **Chaves de API:** Nunca coloque suas chaves de API diretamente no c√≥digo. Use vari√°veis de ambiente ou um arquivo de configura√ß√£o seguro para armazen√°-las.
*   **Valida√ß√£o de Input:** Valide todos os inputs do usu√°rio para evitar ataques de inje√ß√£o de c√≥digo.

**4. Arquitetura:**

*   **Camadas:** Defina claramente as responsabilidades de cada camada da sua aplica√ß√£o (ex: apresenta√ß√£o, l√≥gica de neg√≥cios, acesso a dados). Isso facilita a manuten√ß√£o e a evolu√ß√£o do projeto.
*   **Invers√£o de Depend√™ncia:** Use invers√£o de depend√™ncia para desacoplar as diferentes partes da sua aplica√ß√£o. Isso facilita o teste e a substitui√ß√£o de componentes.
*   **Testes:** Escreva testes unit√°rios e de integra√ß√£o para garantir a qualidade do seu c√≥digo.

**5. D√≠vidas T√©cnicas e Complexidade:**

*   **Fun√ß√µes Longas:** Identifique fun√ß√µes com muitas linhas de c√≥digo e divida-as em fun√ß√µes menores e mais focadas.
*   **L√≥gica Duplicada:** Elimine a l√≥gica duplicada criando fun√ß√µes ou classes reutiliz√°veis.
*   **Coment√°rios:** Adicione coment√°rios para explicar o que o c√≥digo faz, especialmente em partes complexas.

**Exemplo de Refatora√ß√£o:**

Aqui est√° um exemplo de como voc√™ pode refatorar a fun√ß√£o `process_images` na classe `ImageProcessor`:

```python
# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self._post_process_image(image_name, summary)
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _post_process_image(self, image_name, summary):
        self.document_service.add_image_summary(image_name, summary)
        self.markdown_service.add_image_summary(image_name, summary)
        self.document_service.save_document()
        self.markdown_service.save_markdown()

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history
```

**6. C√≥digo Modularizado:**

Para facilitar a visualiza√ß√£o e a organiza√ß√£o, preparei o c√≥digo modularizado em arquivos separados:

```
src/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gemini_handler.py
‚îÇ   ‚îú‚îÄ‚îÄ logger_config.py
‚îÇ   ‚îî‚îÄ‚îÄ rate_limiter.py
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ document_service.py
‚îÇ   ‚îú‚îÄ‚îÄ gpt_services.py
‚îÇ   ‚îú‚îÄ‚îÄ image_processor.py
‚îÇ   ‚îú‚îÄ‚îÄ markdown_service.py
‚îÇ   ‚îî‚îÄ‚îÄ search_files.py
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ file_utils.py
```

**Observa√ß√µes Finais:**

*   A implementa√ß√£o de todas essas sugest√µes pode levar tempo, mas o resultado final ser√° um c√≥digo mais organizado, leg√≠vel, seguro e f√°cil de manter.
*   Priorize as melhorias que trazem o maior impacto no seu projeto.
*   Use um sistema de controle de vers√£o (ex: Git) para acompanhar suas mudan√ßas e facilitar a colabora√ß√£o com outros desenvolvedores.

Se tiver alguma d√∫vida sobre alguma dessas sugest√µes, √© s√≥ perguntar!
User: Extraia o CNPJ dessa imagem.
Assistant: A imagem cont√©m um comprovante de inscri√ß√£o e de situa√ß√£o cadastral. O CNPJ presente na imagem √©:

`33.024.232/0001-39`
User: extraia o n√∫mero do chamado que come√ßa com  2025
Assistant: O n√∫mero do chamado que come√ßa com 2025 na imagem √©:

`2025040185005611`

User:  Okay, sorry, this is. Okay, so welcome everyone. So our week we call for Brazil at a ca Dow. So for today, we will discuss the following the ARIBA, the production API, the P2P and S2C ticket status updates. And if we have business processes and change management. So for the ARIBA, here are depending the number of pending decisions and open actions. So we have. So for all we have one action and one information and then. For ERP team, we have two actions and two information. So we have a total of six. So let me go to the ARIBA file. Okay, so here are the items that we have in the ARIBA file. So for the first one, we have the domain name change. So for this one, so this is actually extended until January 31, 2026. But yeah, Flavio, I just want to know if we have progress on this one. I need to check and then I get back to you on this. On this sheet, please. Okay, thank you so much. Okay, so. You have included another one. Yes, that's correct. Yeah, so for the next one, we actually have also the TLS 1 point to connection. To. To be transferred to a TLS 1 point. So this is also for your team to check. So the deadline for this one will be on April 30. So do we have also progress on this one or not yet? I believe that I already described my current situation on a column. On the right on the right. You can find my call up. Sorry, here or on the tracker file, be the change. Sorry, let me check. This one. This one. I'm not sure where are the comments that you have. No, I just have my clue comments about the first one in the second and the TLS. So we are already done. The line five. Let me see if I can. Is it. Ah, this one. Okay. Okay, so this is already close. Yes, this. Yeah. So for that one, could you please provide screen shots here if possible? To stretch. Yes, just to show that it is already deployed on your system. As an evidence. Okay. Thank you so much. Okay. Okay, so let me remove this one also. I don't know why this one educated. Okay, so for the next two items is read your cards to the certificate renewal. So this is still for information only once the assertifcates have been released by. So I will be able to provide it to you also. Either in the juror ticket or via. So actually this should not be in progress. Okay. And then for the next one, we have also the. This environment frees for the. Parent real. Or the for the S to see items actually so. This is still ongoing right now. So we are checking internally with the project team when. This project will end. So for now. All the test things for the. Related to a supplier's contracts. Our entries for now. And lastly for the daily monitor and so since Ricardo is not here. Yes, so. Oh, sorry, I did hear. So just so this is a reminder for. That for them to check the. Monitoring file for Brazil. So actually. We are encountering some or we are a cap we have some documents captured in the daily monitoring. So if you could also help with the card to check this capture documents that would be appreciated. I'm not sure if this is the correct. Okay, so this is still on March. Let me just change this one. Okay. Okay. Let me share my screen. Okay, so this is actually the. Monitoring file for Brazil. So right now we only for now we have one so we are still updating the monitoring file. So yeah, if you could help check this one. And see why this PR is having an error in the. Are you beside or in the air beside render. So this is the. What they call this the error message that was encountered. So yeah, if you could check this on the ER beside it would be appreciate. For the other. I don't think we have some captured documents yet. Yeah, so for now we'll be have one. Just this one. So yeah, that's all for the items. So they have questions before move on to our next items. No, please go ahead. Okay, thank you so much. Okay, so for the production KPIs, it's the same as the last week as discussed. So they are the numbers or the figures for the documents for the transactions in harriba and for the care tickets that have been taken by a to an L3. So as for the P2P tickets status update so for the past week we. So we have a result or we handled six tickets for P2P and as for the open items. So for the first one we have the issue with regards to the PR that is in order processing status. So for this one, yeah, the current issue is that this PR is currently in version three and it is showing an error that the version two has been has been stopping ordering. However, we cannot. Reprocess this one on the CIG side, so that's why we raise an SR for this one. Or an Arriba case. So right now we are trying to set up a call with the Arriba vendor as they are also asking for our availability. So once we have established a schedule for the meeting and discuss this with the Arriba vendor. So we will update the care ticket about the discussion. And for the next one, we have the integration issue for this supply. Can I attend to the point one please. So we are pending Arriba vendor get back to us with a viable time slots to have a conversation. So for this one, we so the Accenture team will discuss this first with the SAP Arriba vendor as we have all the details already. So if so we will discuss all the investigations that we had so far in order to help them further investigate this issue. But according to the plan for the city reader, we also talk about the updating of our environment of testing. If I'm not wrong. That the queue us or the. We have plenty to update our environment of testing. And the QA test test environment. The point is I need to go ahead with our S a p requirements that I have shared with you by. Sorry. So I don't know if this point is blocking our evaluation regarding to S a p. This is the point. The one that you have in email or. Yeah, 200 for eight or far nine. S a p requirements. I mean, we'll have on this. Let me see if I can. The line eight. Are you have very an update in this one? Yes, so for this one, this is only in a riba side of love you and not on the other side. Yeah, but. I'm aware about S a p. The point for me is S a p evaluation. So I need to implement new requirements. My S a p environment in production. So I don't know if the test environment. We need to be update in order to go ahead with this S a p new requirements. Yeah, so for this one of lab, you I think we need to. Wait for the synchronization of the data from the production system to the test environment to be finished. So we do implementations of data changes or. To do some. Testing scenarios in the S to see part. Yeah, but when we are when we will be ready. I have mentioned earlier, we will coordinate this with the project team who's doing the project for this project specifically and ask them when this will be finished as the. Other conscious and Bruno is also asking for this one. So we will update you accordingly regarding this one. Okay. Thank you. Okay. Yeah, so let me discuss first the B to B items. Okay, so for the next one, we have the issue with regards to this supplier. Which was raised by a Tadita. So for this one, they are. And the Tadita mentioned in the ticket that they are coordinating with the bank team for the confirmation of the ACM ID for the supplier. And the last update was made to me about this ticket. And the next one is explained to the explain needs to be created, which already exists. And the value one B are one data needs to be partitioned into to these other suppliers. And that after this is done, they will probably you will proceed with the supplier patchy partitioning for a base trace attack. Yes. Yeah. And you also ask to ask to us to check with the bank if the ACM ID of the supplier is a 35 for. Yes. Something. I don't remember everything. This one. Yeah. Yeah. But the informant says that they don't know what they. ACM, ACM ID of the supplier is. And the next case, can we deactivate this ACM ID and position are from. We will see. Yeah, we will see if we can. If we can try to partition it again, because yes, I have showed in the ticket on our discussion tab. There are two suppliers with that are currently existing, which is one having this ACM ID and the other has no ACM ID has no ACM ACM ID mapping yet. So that's why I suggested to ask the bank team if this is their. They don't know. That's. They don't know this. So. This don't they don't know this information. But. We thought that we can deactivate the ACM and partition it hours. Because they don't pass. They don't know this information, which is ACM ID from this supplier. But they are still using this supplier, right? Yeah. I don't know. Don't sure. We we we talked to the bank. So they were they are already know that we ask to you. We are asking to you to activate this ACM. Yeah, I'm not sure if PCM ID can be deactivated since actually this data is coming from the ERP system. So if they don't know. So if you're asking the local team of the bank team, maybe you can also suggest if if they're ERP team knows this data. But yeah, for now, we will see if if the data for the. The data can be mapped to each to one of the suppliers that I have showed I have shown you in the. In the screenshot. That I have provided. Okay. So right now we can deactivate this ACM. We need to with the bank again. Right. Yes. Yes. Yes. Specifically, maybe as their ERP team instead. Because I don't think the local team knows where this data is coming from. But yeah, as far as I'm concerned, this is integrated in that is or this is this data is coming from the ERP system rather. Okay. We're going to check again. And let you. Sure. For now, we will I will do my best to keep the ticket open for now. Okay. Yeah, so I think that's also do you have questions for these two items for the ptp before we move on to SCC items. Okay. Okay. Thank you. Okay. So for the S2C items. So yeah, we have two items here, which is with regards to the SLP template. Adjustment in SLP template and the. So for the S2 items, both of these are currently still in progress due to the synchronization that is happening between the production and test systems. So for the second item. Yeah, so for this one, this for this one, known, known modifications are allowed for now since yeah. We need to wait for this synchronization synchronization to be finished. And I think we have one more item I haven't I wasn't able to add it here. Yeah, so for this request from you, I love you. I believe with regards to this one. So. We will we are still checking this internally. So once we receive a conclusion for this one, we will update you accordingly. Okay. Thank you. Yeah, I will add this to the read the. Sorry, I forgot to add this yet. But yeah, we will check this internet. So let me know when you test environment, it's a very uploaded. Yeah. Yeah, we will get back to you also for that. Okay. Yeah, so that's all from my side. Do you have other questions or concerns that we can address in the call before we end this? No, for my side. No. Are you guys? Me neither. Okay. Thank you. First one, thank you. Thank you, Ray. Thank you, everyone. And yeah, I will send the minutes of the meeting after the call. So yeah, thank you, everyone. And I wish you a great day ahead. Bye.

Traduza para pt-br
2025-04-10 14:06:31,333 [INFO] Resposta da IA (imagem): Okay, aqui est√° a tradu√ß√£o para portugu√™s brasileiro do di√°logo fornecido:

"Okay, desculpem, √© isso. Okay, ent√£o bem-vindos a todos. Ent√£o, nossa semana chamamos para Brasil na CA Dow. Ent√£o, para hoje, vamos discutir o seguinte: o ARIBA, a API de produ√ß√£o, o P2P e atualiza√ß√µes de status de tickets S2C. E se tivermos processos de neg√≥cios e gest√£o de mudan√ßas. Ent√£o, para o ARIBA, aqui est√£o dependendo o n√∫mero de decis√µes pendentes e a√ß√µes em aberto. Ent√£o n√≥s temos. Ent√£o, para todos n√≥s temos uma a√ß√£o e uma informa√ß√£o e ent√£o. Para a equipe ERP, temos duas a√ß√µes e duas informa√ß√µes. Ent√£o, temos um total de seis. Ent√£o, deixe-me ir para o arquivo ARIBA. Okay, ent√£o aqui est√£o os itens que temos no arquivo ARIBA. Ent√£o, para o primeiro, temos a mudan√ßa de nome de dom√≠nio. Ent√£o, para este, isso √© realmente estendido at√© 31 de janeiro de 2026. Mas sim, Fl√°vio, eu s√≥ quero saber se temos progresso neste. Eu preciso verificar e ent√£o eu volto para voc√™ neste. Nesta folha, por favor. Okay, muito obrigado. Okay, ent√£o. Voc√™ incluiu outro. Sim, est√° correto. Sim, ent√£o para o pr√≥ximo, n√≥s realmente temos tamb√©m a conex√£o TLS 1 ponto para. Para. Para ser transferida para um TLS 1 ponto. Ent√£o isso tamb√©m √© para sua equipe verificar. Ent√£o o prazo para este ser√° em 30 de abril. Ent√£o, n√≥s temos tamb√©m progresso neste ou ainda n√£o? Eu acredito que eu j√° descrevi minha situa√ß√£o atual em uma coluna. Na direita, na direita. Voc√™ pode encontrar minha chamada. Desculpe, aqui ou no arquivo de rastreamento, seja a mudan√ßa. Desculpe, deixe-me verificar. Este. Este. Eu n√£o tenho certeza onde est√£o os coment√°rios que voc√™ tem. N√£o, eu s√≥ tenho meus coment√°rios de pistas sobre o primeiro e o segundo e o TLS. Ent√£o, j√° terminamos. A linha cinco. Deixe-me ver se eu posso. √â isso. Ah, este. Okay. Okay, ent√£o isso j√° est√° fechado. Sim, isto. Sim. Ent√£o para isso, voc√™ poderia por favor fornecer capturas de tela aqui se poss√≠vel? Para alongar. Sim, apenas para mostrar que j√° est√° implantado em seu sistema. Como uma evid√™ncia. Okay. Muito obrigado. Okay. Okay, ent√£o deixe-me remover este tamb√©m. Eu n√£o sei por que este educado. Okay, ent√£o para os pr√≥ximos dois itens √© ler seus cart√µes para a renova√ß√£o do certificado. Ent√£o, isto ainda √© apenas para informa√ß√£o, uma vez que os assertifcates tenham sido liberados por. Ent√£o eu poderei fornec√™-lo a voc√™ tamb√©m. Seja no ingresso do j√∫ri ou via. Ent√£o, na verdade isso n√£o deveria estar em andamento. Okay. E ent√£o para o pr√≥ximo, temos tamb√©m o. Este ambiente libera para o. Real pai. Ou o para os itens S para ver realmente t√£o. Isto ainda est√° em andamento agora. Ent√£o estamos verificando internamente com a equipe do projeto quando. Este projeto terminar√°. Ent√£o por agora. Todas as coisas de teste para o. Relacionado aos contratos de um fornecedor. Nossas entradas por enquanto. E, finalmente, para o monitor di√°rio e ent√£o, j√° que Ricardo n√£o est√° aqui. Sim, ent√£o. Oh, desculpe, eu ouvi aqui. Ent√£o, apenas ent√£o isso √© um lembrete para. Que para eles verifiquem o. Arquivo de monitoramento para o Brasil. Ent√£o, realmente. Estamos encontrando alguns ou estamos um cap n√≥s temos alguns documentos capturados no monitoramento di√°rio. Ent√£o, se voc√™ tamb√©m pudesse ajudar com o cart√£o para verificar esses documentos capturados, seria apreciado. N√£o tenho certeza se isto est√° correto. Okay, ent√£o isto ainda est√° em mar√ßo. Deixe-me apenas mudar isto. Okay. Okay. Deixe-me compartilhar minha tela. Okay, ent√£o este √© realmente o. Arquivo de monitoramento para o Brasil. Ent√£o agora n√≥s apenas por enquanto temos um, ent√£o ainda estamos atualizando o arquivo de monitoramento. Ent√£o sim, se voc√™ pudesse ajudar a verificar este. E veja por que este RP est√° tendo um erro no. Voc√™ est√° ao lado ou no ar ao lado render. Ent√£o este √© o. O que eles chamam isto a mensagem de erro que foi encontrada. Ent√£o sim, se voc√™ pudesse verificar isso no ER ao lado, seria apreciado. Para os outros. Eu n√£o acho que temos alguns documentos capturados ainda. Sim, ent√£o por agora n√≥s teremos um. Apenas este. Ent√£o sim, √© tudo para os itens. Ent√£o eles t√™m perguntas antes de passarmos para nossos pr√≥ximos itens. N√£o, por favor prossiga. Okay, muito obrigado. Okay, ent√£o para os KPIs de produ√ß√£o, √© o mesmo que na semana passada, conforme discutido. Ent√£o eles s√£o os n√∫meros ou as figuras para os documentos para as transa√ß√µes em harriba e para os bilhetes de atendimento que foram tomados por um para um L3. Ent√£o, quanto √† atualiza√ß√£o do status dos bilhetes de atendimento P2P, ent√£o na semana passada n√≥s. Ent√£o temos um resultado ou lidamos com seis bilhetes de atendimento para P2P e quanto aos itens em aberto. Ent√£o, para o primeiro, temos o problema em rela√ß√£o ao PR que est√° em estado de processamento de pedidos. Ent√£o, para este, sim, o problema atual √© que este PR est√° atualmente na vers√£o tr√™s e est√° mostrando um erro de que a vers√£o dois tem interrompido a encomenda. No entanto, n√£o podemos. Reprocessar este no lado CIG, ent√£o √© por isso que levantamos um SR para este. Ou um caso Arriba. Ent√£o agora estamos tentando agendar uma chamada com o fornecedor Arriba, pois eles tamb√©m est√£o perguntando pela nossa disponibilidade. Ent√£o, uma vez que tenhamos estabelecido uma programa√ß√£o para a reuni√£o e discutirmos isso com o fornecedor Arriba. Ent√£o atualizaremos o bilhete de atendimento sobre a discuss√£o. E para o pr√≥ximo, temos o problema de integra√ß√£o para este fornecimento. Posso atender ao ponto um por favor. Ent√£o, estamos pendentes para que o fornecedor Arriba volte para n√≥s com hor√°rios vi√°veis para ter uma conversa. Ent√£o, para este, n√≥s, a equipe Accenture, discutiremos isso primeiro com o fornecedor SAP Arriba, pois j√° temos todos os detalhes. Ent√£o, se assim for, discutiremos todas as investiga√ß√µes que tivemos at√© agora, a fim de ajud√°-los a investigar ainda mais este problema. Mas de acordo com o plano para o leitor da cidade, tamb√©m falamos sobre a atualiza√ß√£o do nosso ambiente de teste. Se eu n√£o estiver enganado. Que o Q us ou o. Temos muito para atualizar nosso ambiente de teste. E o ambiente de teste QA. O ponto √© que eu preciso prosseguir com os nossos requisitos S a p que compartilhei com voc√™ por. Desculpe. Ent√£o, eu n√£o sei se este ponto est√° bloqueando a nossa avalia√ß√£o em rela√ß√£o ao S a p. Este √© o ponto. Aquele que voc√™ tem no e-mail ou. Sim, 200 para oito ou longe nove. Requisitos S a p. Quero dizer, n√≥s teremos neste. Deixe-me ver se eu posso. A linha oito. Voc√™ tem alguma atualiza√ß√£o nisto? Sim, ent√£o, para este, isto √© apenas no lado do Ariba do amor voc√™ e n√£o no outro lado. Sim, mas. Estou ciente sobre S a p. O ponto para mim √© a avalia√ß√£o S a p. Ent√£o eu preciso implementar novos requisitos. Meu ambiente S a p em produ√ß√£o. Ent√£o eu n√£o sei se o ambiente de teste. Precisamos ser atualizados para prosseguir com estes novos requisitos S a p. Sim, ent√£o, para este amor, voc√™, eu acho que precisamos. Espere pela sincroniza√ß√£o dos dados do sistema de produ√ß√£o para o ambiente de teste para terminar. Ent√£o n√≥s fazemos implementa√ß√µes de mudan√ßas de dados ou. Para fazer alguns. Cen√°rios de teste na parte S para ver. Sim, mas quando estaremos prontos. Eu mencionei anteriormente, coordenaremos isto com a equipe do projeto que est√° fazendo o projeto para este projeto especificamente e perguntaremos quando isto terminar√° como o. Outro consciente e Bruno tamb√©m est√° pedindo por isso. Ent√£o n√≥s o atualizaremos em conformidade em rela√ß√£o a este. Okay. Obrigado. Okay. Sim, ent√£o deixe-me discutir primeiro os itens B para B. Okay, ent√£o para o pr√≥ximo, temos o problema em rela√ß√£o a este fornecedor. Que foi levantado por um Tadita. Ent√£o, para este, eles est√£o. E o Tadita mencionou no bilhete de atendimento que eles est√£o coordenando com a equipe do banco para a confirma√ß√£o do ACM ID para o fornecedor. E a √∫ltima atualiza√ß√£o foi feita para mim sobre este bilhete de atendimento. E o pr√≥ximo precisa ser criado, o que j√° existe. E o valor um B s√£o um dados precisa ser particionado em para estes outros fornecedores. E que depois que isso for feito, eles provavelmente prosseguir√£o com a parti√ß√£o do fornecedor para um ataque de rastreamento base. Sim. Sim. E voc√™ tamb√©m pede para nos pedir para verificar com o banco se o ACM ID do fornecedor √© um 35 para. Sim. Algo. Eu n√£o lembro de tudo. Este. Sim. Sim. Mas o informante diz que eles n√£o sabem o que eles. ACM, ACM ID do fornecedor √©. E no pr√≥ximo caso, podemos desativar este ACM ID e posicionar s√£o de. N√≥s veremos. Sim, n√≥s veremos se podemos. Se podemos tentar particion√°-lo novamente, porque sim, eu mostrei no bilhete de atendimento na nossa aba de discuss√£o. Existem dois fornecedores com que est√£o atualmente existentes, que √© um tendo este ACM ID e o outro n√£o tem ACM ID n√£o tem ACM mapeamento de ACM ainda. Ent√£o √© por isso que eu sugeri pedir √† equipe do banco se este √© deles. Eles n√£o sabem. Isso. Eles n√£o sabem esta informa√ß√£o. Mas. N√≥s pensamos que podemos desativar o ACM e particion√°-lo horas. Porque eles n√£o passam. Eles n√£o conhecem esta informa√ß√£o, que √© o ACM ID deste fornecedor. Mas eles ainda est√£o usando este fornecedor, certo? Sim. Eu n√£o sei. N√£o tenho certeza. N√≥s conversamos com o banco. Ent√£o eles j√° sabem que n√≥s pedimos para voc√™. Estamos pedindo para voc√™ ativar este ACM. Sim, n√£o tenho certeza se o PCM ID pode ser desativado, j√° que na verdade estes dados est√£o vindo do sistema ERP. Ent√£o, se eles n√£o sabem. Ent√£o, se voc√™ est√° perguntando para a equipe local da equipe do banco, talvez voc√™ tamb√©m possa sugerir se se a equipe ERP deles sabe estes dados. Mas sim, por enquanto, veremos se se os dados para o. Os dados podem ser mapeados para cada um dos fornecedores que eu mostrei que eu mostrei a voc√™ no. Na captura de tela. Que eu forneci. Okay. Ent√£o, agora n√£o podemos desativar este ACM. Precisamos com o banco novamente. Certo. Sim. Sim. Especificamente, talvez como sua equipe ERP em vez disso. Porque eu n√£o acho que a equipe local sabe de onde estes dados est√£o vindo. Mas sim, tanto quanto eu sei, isto est√° integrado em que √© ou estes dados est√£o vindo do sistema ERP em vez disso. Okay. N√≥s vamos verificar novamente. E deixe voc√™. Claro. Por enquanto, eu farei o meu melhor para manter o bilhete de atendimento aberto por enquanto. Okay. Sim, ent√£o eu acho que isso tamb√©m, voc√™ tem perguntas para estes dois itens para o ptp antes de passarmos para os itens SCC. Okay. Okay. Obrigado. Okay. Ent√£o, para os itens S2C. Ent√£o sim, temos dois itens aqui, que √© em rela√ß√£o ao modelo SLP. Ajuste no modelo SLP e o. Ent√£o para os itens S2, ambos estes est√£o atualmente ainda em andamento devido √† sincroniza√ß√£o que est√° acontecendo entre os sistemas de produ√ß√£o e teste. Ent√£o para o segundo item. Sim, ent√£o para este, para este conhecido, nenhuma modifica√ß√£o conhecida √© permitida por enquanto, j√° que sim. Precisamos esperar por esta sincroniza√ß√£o sincroniza√ß√£o para terminar. E eu acho que temos mais um item eu n√£o fui capaz de adicion√°-lo aqui. Sim, ent√£o para este pedido seu, eu te amo. Eu acredito com rela√ß√£o a este. T√£o. N√≥s verificaremos isto internamente. Ent√£o, uma vez que recebermos uma conclus√£o para este, n√≥s o atualizaremos em conformidade. Okay. Obrigado. Sim, eu adicionarei isto ao leia o. Desculpe, eu esqueci de adicionar isto ainda. Mas sim, n√≥s verificaremos isto na internet. Ent√£o me avise quando seu ambiente de teste, √© uma atualiza√ß√£o muito grande. Sim. Sim, n√≥s entraremos em contato com voc√™ tamb√©m para isso. Okay. Sim, ent√£o √© tudo da minha parte. Voc√™ tem outras perguntas ou preocupa√ß√µes que podemos abordar na chamada antes de terminarmos isto? N√£o, da minha parte. N√£o. Voc√™s? Eu tamb√©m n√£o. Okay. Obrigado. Primeiro, obrigado. Obrigado a todos. E sim, eu enviarei as atas da reuni√£o ap√≥s a chamada. Ent√£o sim, obrigado a todos. E eu desejo a voc√™s um √≥timo dia pela frente. Tchau."

Espero que isso ajude! Avise-me se precisar de mais alguma coisa.

2025-04-10 14:06:31,482 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 14:06:31,484 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 14:06:31,486 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 14:06:31,488 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 14:06:31,489 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 14:06:31,491 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 14:06:31,493 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 14:06:31,495 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 14:06:31,496 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 14:06:31,497 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 14:06:31,499 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 14:06:31,501 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 14:06:31,502 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 14:06:31,503 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 14:06:31,504 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 14:10:51,408 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 14:10:51,410 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 14:10:51,412 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 14:10:51,414 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 14:10:51,416 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 14:10:51,417 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 14:10:51,419 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 14:10:51,421 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 14:10:51,423 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 14:10:51,425 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 14:10:51,427 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 14:10:51,429 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 14:10:51,431 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 14:10:51,433 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 14:10:51,435 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 14:10:51,638 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 14:10:51,640 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 14:10:51,641 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 14:10:51,643 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 14:10:51,645 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 14:10:51,647 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 14:10:51,649 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 14:10:51,650 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 14:10:51,653 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 14:10:51,657 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 14:10:51,659 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 14:10:51,661 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 14:10:51,662 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 14:10:51,664 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 14:10:51,666 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 14:10:51,679 [INFO] Enviando para IA - Imagem: C:\Users\jfreis\Documents\azure-ai-sentiment-analysis\assets\20250410141051_clipboard_20250410100554.png, Prompt: Voc√™ √© um assistente inteligente utilizado em um chat com IA, que recebe c√≥digos de uma aplica√ß√£o completa de chat, como voc√™ funciona e tudo que 
√© programado para fazer no seu contexto.

Seu objetivo √©:
- Analisar todo o contexto e aprender com ele.
- Analisar a Pergunta do Usu√°rio.
- Identificar se possui rela√ß√£o com o contexto.
- Se houver rela√ß√£o com o c√≥digo do contexto responder a pergunta sobre o c√≥digo sempre seguindo boas pr√°ticas:
    - Analisar o c√≥digo-fonte contido no projeto enviado
    - Identificar melhorias em legibilidade, performance e seguran√ßa
    - Sugerir pr√°ticas recomendadas de design e arquitetura
    - Indicar partes com d√≠vidas t√©cnicas ou complexidade desnecess√°ria
    - Enviar c√≥digo modularizado em pequenos arquivos separados por pastas.

Informa√ß√µes adicionais:
- Estrutura do projeto: segue o padr√£o de pastas iniciando por src/


## Se houver imagem no contexto, identifique se a pergunta √© sobre o c√≥digo do contexto, sobre a imagem ou sobre os dois para elaborar melhorer respostas.
## Se o usu√°rio fizer uma pergunta que n√£o tem rela√ß√£o com imagem ou contexto, use a sua base de conhecimento fora do contexto para responder de forma inteligente.
** Responda em Portugu√™s-Brasileiro a n√£o ser que o usu√°rio solicite outra l√≠ngua.**

Contexto:



# chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# main.py

# main.py
from core.handlers.signal_handler import setup_signal_handler
from services.image_processor import ImageProcessor
from core.rate_limiter import RateLimiter
import json

def main():
    setup_signal_handler()

    # Inicializa o RateLimiter com o n√∫mero m√°ximo de requisi√ß√µes e o per√≠odo
    rate_limiter = RateLimiter(max_requests=9, period_seconds=60)  # 9 requisi√ß√µes por minuto

    # Passa o RateLimiter para o ImageProcessor
    processor = ImageProcessor(rate_limiter)
    processor.process_images()

    # Obter e imprimir o hist√≥rico ap√≥s o processamento
    history = processor.get_history()
    for item in history:
        print(f"Imagem: {item['image_name']}, Resumo: {item['summary']}")

    # Salvar o hist√≥rico em um arquivo JSON
    with open(processor.historico_json_file, "w") as f:
        json.dump(history, f, indent=4)

if __name__ == "__main__":
    main()

# services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# test_image_generation.py

import os
from dotenv import load_dotenv
from google import genai
from google.generativeai import types
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

client = genai.Client(api_key=api_key)

prompt = "gerar a imagem do simbolo do corinthians."

response = client.models.generate_content(
    model='gemini-2.0-flash-exp-image-generation',
    contents=prompt,
    config=types.GenerateContentConfig(
        response_modalities=['Text', 'Image']
    )
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = Image.open(BytesIO(part.inline_data.data))
        image.save("ed-image.png")
        image.show()

# utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

User: fa√ßa code review da minha aplica√ß√£o.
Assistant: Com certeza! Analisei o c√≥digo da sua aplica√ß√£o e preparei algumas sugest√µes para melhorias em legibilidade, performance, seguran√ßa e design.

**1. Estrutura e Modulariza√ß√£o:**

*   **Diret√≥rios:** Organize melhor os arquivos dentro de `src`. Crie subdiret√≥rios para `models`, `services`, `handlers`, `utils`, `config`, etc. Isso facilita a localiza√ß√£o dos arquivos e a compreens√£o da estrutura do projeto.
*   **Arquivo de configura√ß√£o:** Mova a classe `Config` para um arquivo separado (ex: `config.py`) dentro de um diret√≥rio `config`.
*   **Fun√ß√µes:** Quebre fun√ß√µes grandes em fun√ß√µes menores e mais focadas. Isso melhora a legibilidade e facilita o teste.

**2. Boas Pr√°ticas e Melhorias no C√≥digo:**

*   **Rate Limiting:** Implemente o `RateLimiter` nos servi√ßos que consomem a API do Gemini (ex: `ImageProcessor`, `GeminiHandler`). Isso evita sobrecarga na API e garante um uso mais eficiente.
*   **Configura√ß√µes:** Use a classe `Config` para centralizar todas as configura√ß√µes da aplica√ß√£o (ex: chaves de API, modelos, diret√≥rios). Isso facilita a manuten√ß√£o e a configura√ß√£o do projeto.
*   **Logging:** Padronize o uso do logger em toda a aplica√ß√£o. Use os n√≠veis de log apropriados (ex: `info`, `warning`, `error`) para cada tipo de mensagem.
*   **Tratamento de Erros:** Adicione tratamento de erros mais espec√≠fico em cada fun√ß√£o. Isso ajuda a identificar e corrigir problemas mais rapidamente.
*   **Cache:** Utilize o `st.cache_resource` para fun√ß√µes que realizam opera√ß√µes custosas, como a inicializa√ß√£o do `GeminiHandler`. Isso evita a execu√ß√£o repetida dessas opera√ß√µes.
*   **Tipagem:** Utilize tipagem est√°tica (type hints) para melhorar a legibilidade e a seguran√ßa do c√≥digo.
*   **Imagens:** Valide se `uploaded_file` √© realmente um arquivo de imagem antes de tentar exibi-lo, evitando erros caso o usu√°rio envie um arquivo de outro tipo.
*   **Prompts:** Crie arquivos de prompt separados para diferentes tarefas (ex: chat, an√°lise de imagem). Isso facilita a manuten√ß√£o e a personaliza√ß√£o dos prompts.

**3. Seguran√ßa:**

*   **Chaves de API:** Nunca coloque suas chaves de API diretamente no c√≥digo. Use vari√°veis de ambiente ou um arquivo de configura√ß√£o seguro para armazen√°-las.
*   **Valida√ß√£o de Input:** Valide todos os inputs do usu√°rio para evitar ataques de inje√ß√£o de c√≥digo.

**4. Arquitetura:**

*   **Camadas:** Defina claramente as responsabilidades de cada camada da sua aplica√ß√£o (ex: apresenta√ß√£o, l√≥gica de neg√≥cios, acesso a dados). Isso facilita a manuten√ß√£o e a evolu√ß√£o do projeto.
*   **Invers√£o de Depend√™ncia:** Use invers√£o de depend√™ncia para desacoplar as diferentes partes da sua aplica√ß√£o. Isso facilita o teste e a substitui√ß√£o de componentes.
*   **Testes:** Escreva testes unit√°rios e de integra√ß√£o para garantir a qualidade do seu c√≥digo.

**5. D√≠vidas T√©cnicas e Complexidade:**

*   **Fun√ß√µes Longas:** Identifique fun√ß√µes com muitas linhas de c√≥digo e divida-as em fun√ß√µes menores e mais focadas.
*   **L√≥gica Duplicada:** Elimine a l√≥gica duplicada criando fun√ß√µes ou classes reutiliz√°veis.
*   **Coment√°rios:** Adicione coment√°rios para explicar o que o c√≥digo faz, especialmente em partes complexas.

**Exemplo de Refatora√ß√£o:**

Aqui est√° um exemplo de como voc√™ pode refatorar a fun√ß√£o `process_images` na classe `ImageProcessor`:

```python
# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self._post_process_image(image_name, summary)
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _post_process_image(self, image_name, summary):
        self.document_service.add_image_summary(image_name, summary)
        self.markdown_service.add_image_summary(image_name, summary)
        self.document_service.save_document()
        self.markdown_service.save_markdown()

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history
```

**6. C√≥digo Modularizado:**

Para facilitar a visualiza√ß√£o e a organiza√ß√£o, preparei o c√≥digo modularizado em arquivos separados:

```
src/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gemini_handler.py
‚îÇ   ‚îú‚îÄ‚îÄ logger_config.py
‚îÇ   ‚îî‚îÄ‚îÄ rate_limiter.py
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ document_service.py
‚îÇ   ‚îú‚îÄ‚îÄ gpt_services.py
‚îÇ   ‚îú‚îÄ‚îÄ image_processor.py
‚îÇ   ‚îú‚îÄ‚îÄ markdown_service.py
‚îÇ   ‚îî‚îÄ‚îÄ search_files.py
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ file_utils.py
```

**Observa√ß√µes Finais:**

*   A implementa√ß√£o de todas essas sugest√µes pode levar tempo, mas o resultado final ser√° um c√≥digo mais organizado, leg√≠vel, seguro e f√°cil de manter.
*   Priorize as melhorias que trazem o maior impacto no seu projeto.
*   Use um sistema de controle de vers√£o (ex: Git) para acompanhar suas mudan√ßas e facilitar a colabora√ß√£o com outros desenvolvedores.

Se tiver alguma d√∫vida sobre alguma dessas sugest√µes, √© s√≥ perguntar!
User: Extraia o CNPJ dessa imagem.
Assistant: A imagem cont√©m um comprovante de inscri√ß√£o e de situa√ß√£o cadastral. O CNPJ presente na imagem √©:

`33.024.232/0001-39`
User: extraia o n√∫mero do chamado que come√ßa com  2025
Assistant: O n√∫mero do chamado que come√ßa com 2025 na imagem √©:

`2025040185005611`

User:  Okay, sorry, this is. Okay, so welcome everyone. So our week we call for Brazil at a ca Dow. So for today, we will discuss the following the ARIBA, the production API, the P2P and S2C ticket status updates. And if we have business processes and change management. So for the ARIBA, here are depending the number of pending decisions and open actions. So we have. So for all we have one action and one information and then. For ERP team, we have two actions and two information. So we have a total of six. So let me go to the ARIBA file. Okay, so here are the items that we have in the ARIBA file. So for the first one, we have the domain name change. So for this one, so this is actually extended until January 31, 2026. But yeah, Flavio, I just want to know if we have progress on this one. I need to check and then I get back to you on this. On this sheet, please. Okay, thank you so much. Okay, so. You have included another one. Yes, that's correct. Yeah, so for the next one, we actually have also the TLS 1 point to connection. To. To be transferred to a TLS 1 point. So this is also for your team to check. So the deadline for this one will be on April 30. So do we have also progress on this one or not yet? I believe that I already described my current situation on a column. On the right on the right. You can find my call up. Sorry, here or on the tracker file, be the change. Sorry, let me check. This one. This one. I'm not sure where are the comments that you have. No, I just have my clue comments about the first one in the second and the TLS. So we are already done. The line five. Let me see if I can. Is it. Ah, this one. Okay. Okay, so this is already close. Yes, this. Yeah. So for that one, could you please provide screen shots here if possible? To stretch. Yes, just to show that it is already deployed on your system. As an evidence. Okay. Thank you so much. Okay. Okay, so let me remove this one also. I don't know why this one educated. Okay, so for the next two items is read your cards to the certificate renewal. So this is still for information only once the assertifcates have been released by. So I will be able to provide it to you also. Either in the juror ticket or via. So actually this should not be in progress. Okay. And then for the next one, we have also the. This environment frees for the. Parent real. Or the for the S to see items actually so. This is still ongoing right now. So we are checking internally with the project team when. This project will end. So for now. All the test things for the. Related to a supplier's contracts. Our entries for now. And lastly for the daily monitor and so since Ricardo is not here. Yes, so. Oh, sorry, I did hear. So just so this is a reminder for. That for them to check the. Monitoring file for Brazil. So actually. We are encountering some or we are a cap we have some documents captured in the daily monitoring. So if you could also help with the card to check this capture documents that would be appreciated. I'm not sure if this is the correct. Okay, so this is still on March. Let me just change this one. Okay. Okay. Let me share my screen. Okay, so this is actually the. Monitoring file for Brazil. So right now we only for now we have one so we are still updating the monitoring file. So yeah, if you could help check this one. And see why this PR is having an error in the. Are you beside or in the air beside render. So this is the. What they call this the error message that was encountered. So yeah, if you could check this on the ER beside it would be appreciate. For the other. I don't think we have some captured documents yet. Yeah, so for now we'll be have one. Just this one. So yeah, that's all for the items. So they have questions before move on to our next items. No, please go ahead. Okay, thank you so much. Okay, so for the production KPIs, it's the same as the last week as discussed. So they are the numbers or the figures for the documents for the transactions in harriba and for the care tickets that have been taken by a to an L3. So as for the P2P tickets status update so for the past week we. So we have a result or we handled six tickets for P2P and as for the open items. So for the first one we have the issue with regards to the PR that is in order processing status. So for this one, yeah, the current issue is that this PR is currently in version three and it is showing an error that the version two has been has been stopping ordering. However, we cannot. Reprocess this one on the CIG side, so that's why we raise an SR for this one. Or an Arriba case. So right now we are trying to set up a call with the Arriba vendor as they are also asking for our availability. So once we have established a schedule for the meeting and discuss this with the Arriba vendor. So we will update the care ticket about the discussion. And for the next one, we have the integration issue for this supply. Can I attend to the point one please. So we are pending Arriba vendor get back to us with a viable time slots to have a conversation. So for this one, we so the Accenture team will discuss this first with the SAP Arriba vendor as we have all the details already. So if so we will discuss all the investigations that we had so far in order to help them further investigate this issue. But according to the plan for the city reader, we also talk about the updating of our environment of testing. If I'm not wrong. That the queue us or the. We have plenty to update our environment of testing. And the QA test test environment. The point is I need to go ahead with our S a p requirements that I have shared with you by. Sorry. So I don't know if this point is blocking our evaluation regarding to S a p. This is the point. The one that you have in email or. Yeah, 200 for eight or far nine. S a p requirements. I mean, we'll have on this. Let me see if I can. The line eight. Are you have very an update in this one? Yes, so for this one, this is only in a riba side of love you and not on the other side. Yeah, but. I'm aware about S a p. The point for me is S a p evaluation. So I need to implement new requirements. My S a p environment in production. So I don't know if the test environment. We need to be update in order to go ahead with this S a p new requirements. Yeah, so for this one of lab, you I think we need to. Wait for the synchronization of the data from the production system to the test environment to be finished. So we do implementations of data changes or. To do some. Testing scenarios in the S to see part. Yeah, but when we are when we will be ready. I have mentioned earlier, we will coordinate this with the project team who's doing the project for this project specifically and ask them when this will be finished as the. Other conscious and Bruno is also asking for this one. So we will update you accordingly regarding this one. Okay. Thank you. Okay. Yeah, so let me discuss first the B to B items. Okay, so for the next one, we have the issue with regards to this supplier. Which was raised by a Tadita. So for this one, they are. And the Tadita mentioned in the ticket that they are coordinating with the bank team for the confirmation of the ACM ID for the supplier. And the last update was made to me about this ticket. And the next one is explained to the explain needs to be created, which already exists. And the value one B are one data needs to be partitioned into to these other suppliers. And that after this is done, they will probably you will proceed with the supplier patchy partitioning for a base trace attack. Yes. Yeah. And you also ask to ask to us to check with the bank if the ACM ID of the supplier is a 35 for. Yes. Something. I don't remember everything. This one. Yeah. Yeah. But the informant says that they don't know what they. ACM, ACM ID of the supplier is. And the next case, can we deactivate this ACM ID and position are from. We will see. Yeah, we will see if we can. If we can try to partition it again, because yes, I have showed in the ticket on our discussion tab. There are two suppliers with that are currently existing, which is one having this ACM ID and the other has no ACM ID has no ACM ACM ID mapping yet. So that's why I suggested to ask the bank team if this is their. They don't know. That's. They don't know this. So. This don't they don't know this information. But. We thought that we can deactivate the ACM and partition it hours. Because they don't pass. They don't know this information, which is ACM ID from this supplier. But they are still using this supplier, right? Yeah. I don't know. Don't sure. We we we talked to the bank. So they were they are already know that we ask to you. We are asking to you to activate this ACM. Yeah, I'm not sure if PCM ID can be deactivated since actually this data is coming from the ERP system. So if they don't know. So if you're asking the local team of the bank team, maybe you can also suggest if if they're ERP team knows this data. But yeah, for now, we will see if if the data for the. The data can be mapped to each to one of the suppliers that I have showed I have shown you in the. In the screenshot. That I have provided. Okay. So right now we can deactivate this ACM. We need to with the bank again. Right. Yes. Yes. Yes. Specifically, maybe as their ERP team instead. Because I don't think the local team knows where this data is coming from. But yeah, as far as I'm concerned, this is integrated in that is or this is this data is coming from the ERP system rather. Okay. We're going to check again. And let you. Sure. For now, we will I will do my best to keep the ticket open for now. Okay. Yeah, so I think that's also do you have questions for these two items for the ptp before we move on to SCC items. Okay. Okay. Thank you. Okay. So for the S2C items. So yeah, we have two items here, which is with regards to the SLP template. Adjustment in SLP template and the. So for the S2 items, both of these are currently still in progress due to the synchronization that is happening between the production and test systems. So for the second item. Yeah, so for this one, this for this one, known, known modifications are allowed for now since yeah. We need to wait for this synchronization synchronization to be finished. And I think we have one more item I haven't I wasn't able to add it here. Yeah, so for this request from you, I love you. I believe with regards to this one. So. We will we are still checking this internally. So once we receive a conclusion for this one, we will update you accordingly. Okay. Thank you. Yeah, I will add this to the read the. Sorry, I forgot to add this yet. But yeah, we will check this internet. So let me know when you test environment, it's a very uploaded. Yeah. Yeah, we will get back to you also for that. Okay. Yeah, so that's all from my side. Do you have other questions or concerns that we can address in the call before we end this? No, for my side. No. Are you guys? Me neither. Okay. Thank you. First one, thank you. Thank you, Ray. Thank you, everyone. And yeah, I will send the minutes of the meeting after the call. So yeah, thank you, everyone. And I wish you a great day ahead. Bye.

Traduza para pt-br
Assistant: Okay, aqui est√° a tradu√ß√£o para portugu√™s brasileiro do di√°logo fornecido:

"Okay, desculpem, √© isso. Okay, ent√£o bem-vindos a todos. Ent√£o, nossa semana chamamos para Brasil na CA Dow. Ent√£o, para hoje, vamos discutir o seguinte: o ARIBA, a API de produ√ß√£o, o P2P e atualiza√ß√µes de status de tickets S2C. E se tivermos processos de neg√≥cios e gest√£o de mudan√ßas. Ent√£o, para o ARIBA, aqui est√£o dependendo o n√∫mero de decis√µes pendentes e a√ß√µes em aberto. Ent√£o n√≥s temos. Ent√£o, para todos n√≥s temos uma a√ß√£o e uma informa√ß√£o e ent√£o. Para a equipe ERP, temos duas a√ß√µes e duas informa√ß√µes. Ent√£o, temos um total de seis. Ent√£o, deixe-me ir para o arquivo ARIBA. Okay, ent√£o aqui est√£o os itens que temos no arquivo ARIBA. Ent√£o, para o primeiro, temos a mudan√ßa de nome de dom√≠nio. Ent√£o, para este, isso √© realmente estendido at√© 31 de janeiro de 2026. Mas sim, Fl√°vio, eu s√≥ quero saber se temos progresso neste. Eu preciso verificar e ent√£o eu volto para voc√™ neste. Nesta folha, por favor. Okay, muito obrigado. Okay, ent√£o. Voc√™ incluiu outro. Sim, est√° correto. Sim, ent√£o para o pr√≥ximo, n√≥s realmente temos tamb√©m a conex√£o TLS 1 ponto para. Para. Para ser transferida para um TLS 1 ponto. Ent√£o isso tamb√©m √© para sua equipe verificar. Ent√£o o prazo para este ser√° em 30 de abril. Ent√£o, n√≥s temos tamb√©m progresso neste ou ainda n√£o? Eu acredito que eu j√° descrevi minha situa√ß√£o atual em uma coluna. Na direita, na direita. Voc√™ pode encontrar minha chamada. Desculpe, aqui ou no arquivo de rastreamento, seja a mudan√ßa. Desculpe, deixe-me verificar. Este. Este. Eu n√£o tenho certeza onde est√£o os coment√°rios que voc√™ tem. N√£o, eu s√≥ tenho meus coment√°rios de pistas sobre o primeiro e o segundo e o TLS. Ent√£o, j√° terminamos. A linha cinco. Deixe-me ver se eu posso. √â isso. Ah, este. Okay. Okay, ent√£o isso j√° est√° fechado. Sim, isto. Sim. Ent√£o para isso, voc√™ poderia por favor fornecer capturas de tela aqui se poss√≠vel? Para alongar. Sim, apenas para mostrar que j√° est√° implantado em seu sistema. Como uma evid√™ncia. Okay. Muito obrigado. Okay. Okay, ent√£o deixe-me remover este tamb√©m. Eu n√£o sei por que este educado. Okay, ent√£o para os pr√≥ximos dois itens √© ler seus cart√µes para a renova√ß√£o do certificado. Ent√£o, isto ainda √© apenas para informa√ß√£o, uma vez que os assertifcates tenham sido liberados por. Ent√£o eu poderei fornec√™-lo a voc√™ tamb√©m. Seja no ingresso do j√∫ri ou via. Ent√£o, na verdade isso n√£o deveria estar em andamento. Okay. E ent√£o para o pr√≥ximo, temos tamb√©m o. Este ambiente libera para o. Real pai. Ou o para os itens S para ver realmente t√£o. Isto ainda est√° em andamento agora. Ent√£o estamos verificando internamente com a equipe do projeto quando. Este projeto terminar√°. Ent√£o por agora. Todas as coisas de teste para o. Relacionado aos contratos de um fornecedor. Nossas entradas por enquanto. E, finalmente, para o monitor di√°rio e ent√£o, j√° que Ricardo n√£o est√° aqui. Sim, ent√£o. Oh, desculpe, eu ouvi aqui. Ent√£o, apenas ent√£o isso √© um lembrete para. Que para eles verifiquem o. Arquivo de monitoramento para o Brasil. Ent√£o, realmente. Estamos encontrando alguns ou estamos um cap n√≥s temos alguns documentos capturados no monitoramento di√°rio. Ent√£o, se voc√™ tamb√©m pudesse ajudar com o cart√£o para verificar esses documentos capturados, seria apreciado. N√£o tenho certeza se isto est√° correto. Okay, ent√£o isto ainda est√° em mar√ßo. Deixe-me apenas mudar isto. Okay. Okay. Deixe-me compartilhar minha tela. Okay, ent√£o este √© realmente o. Arquivo de monitoramento para o Brasil. Ent√£o agora n√≥s apenas por enquanto temos um, ent√£o ainda estamos atualizando o arquivo de monitoramento. Ent√£o sim, se voc√™ pudesse ajudar a verificar este. E veja por que este RP est√° tendo um erro no. Voc√™ est√° ao lado ou no ar ao lado render. Ent√£o este √© o. O que eles chamam isto a mensagem de erro que foi encontrada. Ent√£o sim, se voc√™ pudesse verificar isso no ER ao lado, seria apreciado. Para os outros. Eu n√£o acho que temos alguns documentos capturados ainda. Sim, ent√£o por agora n√≥s teremos um. Apenas este. Ent√£o sim, √© tudo para os itens. Ent√£o eles t√™m perguntas antes de passarmos para nossos pr√≥ximos itens. N√£o, por favor prossiga. Okay, muito obrigado. Okay, ent√£o para os KPIs de produ√ß√£o, √© o mesmo que na semana passada, conforme discutido. Ent√£o eles s√£o os n√∫meros ou as figuras para os documentos para as transa√ß√µes em harriba e para os bilhetes de atendimento que foram tomados por um para um L3. Ent√£o, quanto √† atualiza√ß√£o do status dos bilhetes de atendimento P2P, ent√£o na semana passada n√≥s. Ent√£o temos um resultado ou lidamos com seis bilhetes de atendimento para P2P e quanto aos itens em aberto. Ent√£o, para o primeiro, temos o problema em rela√ß√£o ao PR que est√° em estado de processamento de pedidos. Ent√£o, para este, sim, o problema atual √© que este PR est√° atualmente na vers√£o tr√™s e est√° mostrando um erro de que a vers√£o dois tem interrompido a encomenda. No entanto, n√£o podemos. Reprocessar este no lado CIG, ent√£o √© por isso que levantamos um SR para este. Ou um caso Arriba. Ent√£o agora estamos tentando agendar uma chamada com o fornecedor Arriba, pois eles tamb√©m est√£o perguntando pela nossa disponibilidade. Ent√£o, uma vez que tenhamos estabelecido uma programa√ß√£o para a reuni√£o e discutirmos isso com o fornecedor Arriba. Ent√£o atualizaremos o bilhete de atendimento sobre a discuss√£o. E para o pr√≥ximo, temos o problema de integra√ß√£o para este fornecimento. Posso atender ao ponto um por favor. Ent√£o, estamos pendentes para que o fornecedor Arriba volte para n√≥s com hor√°rios vi√°veis para ter uma conversa. Ent√£o, para este, n√≥s, a equipe Accenture, discutiremos isso primeiro com o fornecedor SAP Arriba, pois j√° temos todos os detalhes. Ent√£o, se assim for, discutiremos todas as investiga√ß√µes que tivemos at√© agora, a fim de ajud√°-los a investigar ainda mais este problema. Mas de acordo com o plano para o leitor da cidade, tamb√©m falamos sobre a atualiza√ß√£o do nosso ambiente de teste. Se eu n√£o estiver enganado. Que o Q us ou o. Temos muito para atualizar nosso ambiente de teste. E o ambiente de teste QA. O ponto √© que eu preciso prosseguir com os nossos requisitos S a p que compartilhei com voc√™ por. Desculpe. Ent√£o, eu n√£o sei se este ponto est√° bloqueando a nossa avalia√ß√£o em rela√ß√£o ao S a p. Este √© o ponto. Aquele que voc√™ tem no e-mail ou. Sim, 200 para oito ou longe nove. Requisitos S a p. Quero dizer, n√≥s teremos neste. Deixe-me ver se eu posso. A linha oito. Voc√™ tem alguma atualiza√ß√£o nisto? Sim, ent√£o, para este, isto √© apenas no lado do Ariba do amor voc√™ e n√£o no outro lado. Sim, mas. Estou ciente sobre S a p. O ponto para mim √© a avalia√ß√£o S a p. Ent√£o eu preciso implementar novos requisitos. Meu ambiente S a p em produ√ß√£o. Ent√£o eu n√£o sei se o ambiente de teste. Precisamos ser atualizados para prosseguir com estes novos requisitos S a p. Sim, ent√£o, para este amor, voc√™, eu acho que precisamos. Espere pela sincroniza√ß√£o dos dados do sistema de produ√ß√£o para o ambiente de teste para terminar. Ent√£o n√≥s fazemos implementa√ß√µes de mudan√ßas de dados ou. Para fazer alguns. Cen√°rios de teste na parte S para ver. Sim, mas quando estaremos prontos. Eu mencionei anteriormente, coordenaremos isto com a equipe do projeto que est√° fazendo o projeto para este projeto especificamente e perguntaremos quando isto terminar√° como o. Outro consciente e Bruno tamb√©m est√° pedindo por isso. Ent√£o n√≥s o atualizaremos em conformidade em rela√ß√£o a este. Okay. Obrigado. Okay. Sim, ent√£o deixe-me discutir primeiro os itens B para B. Okay, ent√£o para o pr√≥ximo, temos o problema em rela√ß√£o a este fornecedor. Que foi levantado por um Tadita. Ent√£o, para este, eles est√£o. E o Tadita mencionou no bilhete de atendimento que eles est√£o coordenando com a equipe do banco para a confirma√ß√£o do ACM ID para o fornecedor. E a √∫ltima atualiza√ß√£o foi feita para mim sobre este bilhete de atendimento. E o pr√≥ximo precisa ser criado, o que j√° existe. E o valor um B s√£o um dados precisa ser particionado em para estes outros fornecedores. E que depois que isso for feito, eles provavelmente prosseguir√£o com a parti√ß√£o do fornecedor para um ataque de rastreamento base. Sim. Sim. E voc√™ tamb√©m pede para nos pedir para verificar com o banco se o ACM ID do fornecedor √© um 35 para. Sim. Algo. Eu n√£o lembro de tudo. Este. Sim. Sim. Mas o informante diz que eles n√£o sabem o que eles. ACM, ACM ID do fornecedor √©. E no pr√≥ximo caso, podemos desativar este ACM ID e posicionar s√£o de. N√≥s veremos. Sim, n√≥s veremos se podemos. Se podemos tentar particion√°-lo novamente, porque sim, eu mostrei no bilhete de atendimento na nossa aba de discuss√£o. Existem dois fornecedores com que est√£o atualmente existentes, que √© um tendo este ACM ID e o outro n√£o tem ACM ID n√£o tem ACM mapeamento de ACM ainda. Ent√£o √© por isso que eu sugeri pedir √† equipe do banco se este √© deles. Eles n√£o sabem. Isso. Eles n√£o sabem esta informa√ß√£o. Mas. N√≥s pensamos que podemos desativar o ACM e particion√°-lo horas. Porque eles n√£o passam. Eles n√£o conhecem esta informa√ß√£o, que √© o ACM ID deste fornecedor. Mas eles ainda est√£o usando este fornecedor, certo? Sim. Eu n√£o sei. N√£o tenho certeza. N√≥s conversamos com o banco. Ent√£o eles j√° sabem que n√≥s pedimos para voc√™. Estamos pedindo para voc√™ ativar este ACM. Sim, n√£o tenho certeza se o PCM ID pode ser desativado, j√° que na verdade estes dados est√£o vindo do sistema ERP. Ent√£o, se eles n√£o sabem. Ent√£o, se voc√™ est√° perguntando para a equipe local da equipe do banco, talvez voc√™ tamb√©m possa sugerir se se a equipe ERP deles sabe estes dados. Mas sim, por enquanto, veremos se se os dados para o. Os dados podem ser mapeados para cada um dos fornecedores que eu mostrei que eu mostrei a voc√™ no. Na captura de tela. Que eu forneci. Okay. Ent√£o, agora n√£o podemos desativar este ACM. Precisamos com o banco novamente. Certo. Sim. Sim. Especificamente, talvez como sua equipe ERP em vez disso. Porque eu n√£o acho que a equipe local sabe de onde estes dados est√£o vindo. Mas sim, tanto quanto eu sei, isto est√° integrado em que √© ou estes dados est√£o vindo do sistema ERP em vez disso. Okay. N√≥s vamos verificar novamente. E deixe voc√™. Claro. Por enquanto, eu farei o meu melhor para manter o bilhete de atendimento aberto por enquanto. Okay. Sim, ent√£o eu acho que isso tamb√©m, voc√™ tem perguntas para estes dois itens para o ptp antes de passarmos para os itens SCC. Okay. Okay. Obrigado. Okay. Ent√£o, para os itens S2C. Ent√£o sim, temos dois itens aqui, que √© em rela√ß√£o ao modelo SLP. Ajuste no modelo SLP e o. Ent√£o para os itens S2, ambos estes est√£o atualmente ainda em andamento devido √† sincroniza√ß√£o que est√° acontecendo entre os sistemas de produ√ß√£o e teste. Ent√£o para o segundo item. Sim, ent√£o para este, para este conhecido, nenhuma modifica√ß√£o conhecida √© permitida por enquanto, j√° que sim. Precisamos esperar por esta sincroniza√ß√£o sincroniza√ß√£o para terminar. E eu acho que temos mais um item eu n√£o fui capaz de adicion√°-lo aqui. Sim, ent√£o para este pedido seu, eu te amo. Eu acredito com rela√ß√£o a este. T√£o. N√≥s verificaremos isto internamente. Ent√£o, uma vez que recebermos uma conclus√£o para este, n√≥s o atualizaremos em conformidade. Okay. Obrigado. Sim, eu adicionarei isto ao leia o. Desculpe, eu esqueci de adicionar isto ainda. Mas sim, n√≥s verificaremos isto na internet. Ent√£o me avise quando seu ambiente de teste, √© uma atualiza√ß√£o muito grande. Sim. Sim, n√≥s entraremos em contato com voc√™ tamb√©m para isso. Okay. Sim, ent√£o √© tudo da minha parte. Voc√™ tem outras perguntas ou preocupa√ß√µes que podemos abordar na chamada antes de terminarmos isto? N√£o, da minha parte. N√£o. Voc√™s? Eu tamb√©m n√£o. Okay. Obrigado. Primeiro, obrigado. Obrigado a todos. E sim, eu enviarei as atas da reuni√£o ap√≥s a chamada. Ent√£o sim, obrigado a todos. E eu desejo a voc√™s um √≥timo dia pela frente. Tchau."

Espero que isso ajude! Avise-me se precisar de mais alguma coisa.

User: Resuma essa reuni√£o com os pontos importantes.
2025-04-10 14:10:56,391 [INFO] Resposta da IA (imagem): Assistant: Claro, aqui est√° um resumo dos pontos importantes da reuni√£o:

**ARIBA:**

*   **Mudan√ßa de Nome de Dom√≠nio:** Estendida at√© 31 de janeiro de 2026. Fl√°vio deve verificar o progresso.
*   **Conex√£o TLS 1.2:** Prazo para transfer√™ncia √© 30 de abril. J√° foi finalizada (linha 5). Solicitaram screenshots como evid√™ncia.
*   **Renova√ß√£o de Certificado:** Aguardando informa√ß√µes para fornecer via ticket ou e-mail.
*   **Ambiente Livre para S2C:** Testes relacionados aos contratos de fornecedores em andamento. Aguardando t√©rmino do projeto.
*   **Monitoramento Di√°rio:** Verificar o arquivo de monitoramento do Brasil e o erro no PR.

**KPIs de Produ√ß√£o:**

*   Sem altera√ß√µes em rela√ß√£o √† semana anterior.

**Status dos Tickets P2P:**

*   Seis tickets resolvidos.
*   **PR em Processamento de Pedido (Vers√£o 3):** Erro na Vers√£o 2. Aguardando agendamento de reuni√£o com o fornecedor Arriba.
*   **Problema de Integra√ß√£o:** Accenture discutir√° com o fornecedor SAP Arriba e atualizar√° o ambiente de teste.
*   **Fornecedor com Problemas no ACM ID:** Verificar com a equipe do banco (possivelmente a equipe ERP) e desativar o ACM ID.

**Itens S2C:**

*   Ajuste no modelo SLP em andamento, aguardando sincroniza√ß√£o entre os sistemas de produ√ß√£o e teste.
*   Solicita√ß√£o de atualiza√ß√£o do ambiente de teste ser√° verificada internamente.

**Geral:**

*   Coordenar a atualiza√ß√£o do ambiente de teste com a equipe do projeto.
*   As atas da reuni√£o ser√£o enviadas ap√≥s a chamada.
2025-04-10 14:10:56,481 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 14:10:56,482 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 14:10:56,485 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 14:10:56,488 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 14:10:56,489 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 14:10:56,491 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 14:10:56,493 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 14:10:56,495 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 14:10:56,497 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 14:10:56,500 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 14:10:56,502 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 14:10:56,504 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 14:10:56,505 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 14:10:56,507 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 14:10:56,509 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 14:13:04,889 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 14:13:04,891 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 14:13:04,892 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 14:13:04,894 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 14:13:04,896 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 14:13:04,898 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 14:13:04,899 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 14:13:04,901 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 14:13:04,902 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 14:13:04,904 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 14:13:04,905 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 14:13:04,907 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 14:13:04,909 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 14:13:04,910 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 14:13:04,911 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 14:13:05,039 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 14:13:05,040 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 14:13:05,042 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 14:13:05,043 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 14:13:05,044 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 14:13:05,046 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 14:13:05,047 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 14:13:05,048 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 14:13:05,050 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 14:13:05,053 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 14:13:05,056 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 14:13:05,058 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 14:13:05,059 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 14:13:05,060 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 14:13:05,062 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 14:13:05,073 [INFO] Enviando para IA - Imagem: C:\Users\jfreis\Documents\azure-ai-sentiment-analysis\assets\20250410141305_clipboard_20250410100554.png, Prompt: Voc√™ √© um assistente inteligente utilizado em um chat com IA, que recebe c√≥digos de uma aplica√ß√£o completa de chat, como voc√™ funciona e tudo que 
√© programado para fazer no seu contexto.

Seu objetivo √©:
- Analisar todo o contexto e aprender com ele.
- Analisar a Pergunta do Usu√°rio.
- Identificar se possui rela√ß√£o com o contexto.
- Se houver rela√ß√£o com o c√≥digo do contexto responder a pergunta sobre o c√≥digo sempre seguindo boas pr√°ticas:
    - Analisar o c√≥digo-fonte contido no projeto enviado
    - Identificar melhorias em legibilidade, performance e seguran√ßa
    - Sugerir pr√°ticas recomendadas de design e arquitetura
    - Indicar partes com d√≠vidas t√©cnicas ou complexidade desnecess√°ria
    - Enviar c√≥digo modularizado em pequenos arquivos separados por pastas.

Informa√ß√µes adicionais:
- Estrutura do projeto: segue o padr√£o de pastas iniciando por src/


## Se houver imagem no contexto, identifique se a pergunta √© sobre o c√≥digo do contexto, sobre a imagem ou sobre os dois para elaborar melhorer respostas.
## Se o usu√°rio fizer uma pergunta que n√£o tem rela√ß√£o com imagem ou contexto, use a sua base de conhecimento fora do contexto para responder de forma inteligente.
** Responda em Portugu√™s-Brasileiro a n√£o ser que o usu√°rio solicite outra l√≠ngua.**

Contexto:



# chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# main.py

# main.py
from core.handlers.signal_handler import setup_signal_handler
from services.image_processor import ImageProcessor
from core.rate_limiter import RateLimiter
import json

def main():
    setup_signal_handler()

    # Inicializa o RateLimiter com o n√∫mero m√°ximo de requisi√ß√µes e o per√≠odo
    rate_limiter = RateLimiter(max_requests=9, period_seconds=60)  # 9 requisi√ß√µes por minuto

    # Passa o RateLimiter para o ImageProcessor
    processor = ImageProcessor(rate_limiter)
    processor.process_images()

    # Obter e imprimir o hist√≥rico ap√≥s o processamento
    history = processor.get_history()
    for item in history:
        print(f"Imagem: {item['image_name']}, Resumo: {item['summary']}")

    # Salvar o hist√≥rico em um arquivo JSON
    with open(processor.historico_json_file, "w") as f:
        json.dump(history, f, indent=4)

if __name__ == "__main__":
    main()

# services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# test_image_generation.py

import os
from dotenv import load_dotenv
from google import genai
from google.generativeai import types
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

client = genai.Client(api_key=api_key)

prompt = "gerar a imagem do simbolo do corinthians."

response = client.models.generate_content(
    model='gemini-2.0-flash-exp-image-generation',
    contents=prompt,
    config=types.GenerateContentConfig(
        response_modalities=['Text', 'Image']
    )
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = Image.open(BytesIO(part.inline_data.data))
        image.save("ed-image.png")
        image.show()

# utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

User: fa√ßa code review da minha aplica√ß√£o.
Assistant: Com certeza! Analisei o c√≥digo da sua aplica√ß√£o e preparei algumas sugest√µes para melhorias em legibilidade, performance, seguran√ßa e design.

**1. Estrutura e Modulariza√ß√£o:**

*   **Diret√≥rios:** Organize melhor os arquivos dentro de `src`. Crie subdiret√≥rios para `models`, `services`, `handlers`, `utils`, `config`, etc. Isso facilita a localiza√ß√£o dos arquivos e a compreens√£o da estrutura do projeto.
*   **Arquivo de configura√ß√£o:** Mova a classe `Config` para um arquivo separado (ex: `config.py`) dentro de um diret√≥rio `config`.
*   **Fun√ß√µes:** Quebre fun√ß√µes grandes em fun√ß√µes menores e mais focadas. Isso melhora a legibilidade e facilita o teste.

**2. Boas Pr√°ticas e Melhorias no C√≥digo:**

*   **Rate Limiting:** Implemente o `RateLimiter` nos servi√ßos que consomem a API do Gemini (ex: `ImageProcessor`, `GeminiHandler`). Isso evita sobrecarga na API e garante um uso mais eficiente.
*   **Configura√ß√µes:** Use a classe `Config` para centralizar todas as configura√ß√µes da aplica√ß√£o (ex: chaves de API, modelos, diret√≥rios). Isso facilita a manuten√ß√£o e a configura√ß√£o do projeto.
*   **Logging:** Padronize o uso do logger em toda a aplica√ß√£o. Use os n√≠veis de log apropriados (ex: `info`, `warning`, `error`) para cada tipo de mensagem.
*   **Tratamento de Erros:** Adicione tratamento de erros mais espec√≠fico em cada fun√ß√£o. Isso ajuda a identificar e corrigir problemas mais rapidamente.
*   **Cache:** Utilize o `st.cache_resource` para fun√ß√µes que realizam opera√ß√µes custosas, como a inicializa√ß√£o do `GeminiHandler`. Isso evita a execu√ß√£o repetida dessas opera√ß√µes.
*   **Tipagem:** Utilize tipagem est√°tica (type hints) para melhorar a legibilidade e a seguran√ßa do c√≥digo.
*   **Imagens:** Valide se `uploaded_file` √© realmente um arquivo de imagem antes de tentar exibi-lo, evitando erros caso o usu√°rio envie um arquivo de outro tipo.
*   **Prompts:** Crie arquivos de prompt separados para diferentes tarefas (ex: chat, an√°lise de imagem). Isso facilita a manuten√ß√£o e a personaliza√ß√£o dos prompts.

**3. Seguran√ßa:**

*   **Chaves de API:** Nunca coloque suas chaves de API diretamente no c√≥digo. Use vari√°veis de ambiente ou um arquivo de configura√ß√£o seguro para armazen√°-las.
*   **Valida√ß√£o de Input:** Valide todos os inputs do usu√°rio para evitar ataques de inje√ß√£o de c√≥digo.

**4. Arquitetura:**

*   **Camadas:** Defina claramente as responsabilidades de cada camada da sua aplica√ß√£o (ex: apresenta√ß√£o, l√≥gica de neg√≥cios, acesso a dados). Isso facilita a manuten√ß√£o e a evolu√ß√£o do projeto.
*   **Invers√£o de Depend√™ncia:** Use invers√£o de depend√™ncia para desacoplar as diferentes partes da sua aplica√ß√£o. Isso facilita o teste e a substitui√ß√£o de componentes.
*   **Testes:** Escreva testes unit√°rios e de integra√ß√£o para garantir a qualidade do seu c√≥digo.

**5. D√≠vidas T√©cnicas e Complexidade:**

*   **Fun√ß√µes Longas:** Identifique fun√ß√µes com muitas linhas de c√≥digo e divida-as em fun√ß√µes menores e mais focadas.
*   **L√≥gica Duplicada:** Elimine a l√≥gica duplicada criando fun√ß√µes ou classes reutiliz√°veis.
*   **Coment√°rios:** Adicione coment√°rios para explicar o que o c√≥digo faz, especialmente em partes complexas.

**Exemplo de Refatora√ß√£o:**

Aqui est√° um exemplo de como voc√™ pode refatorar a fun√ß√£o `process_images` na classe `ImageProcessor`:

```python
# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self._post_process_image(image_name, summary)
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _post_process_image(self, image_name, summary):
        self.document_service.add_image_summary(image_name, summary)
        self.markdown_service.add_image_summary(image_name, summary)
        self.document_service.save_document()
        self.markdown_service.save_markdown()

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history
```

**6. C√≥digo Modularizado:**

Para facilitar a visualiza√ß√£o e a organiza√ß√£o, preparei o c√≥digo modularizado em arquivos separados:

```
src/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gemini_handler.py
‚îÇ   ‚îú‚îÄ‚îÄ logger_config.py
‚îÇ   ‚îî‚îÄ‚îÄ rate_limiter.py
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ document_service.py
‚îÇ   ‚îú‚îÄ‚îÄ gpt_services.py
‚îÇ   ‚îú‚îÄ‚îÄ image_processor.py
‚îÇ   ‚îú‚îÄ‚îÄ markdown_service.py
‚îÇ   ‚îî‚îÄ‚îÄ search_files.py
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ file_utils.py
```

**Observa√ß√µes Finais:**

*   A implementa√ß√£o de todas essas sugest√µes pode levar tempo, mas o resultado final ser√° um c√≥digo mais organizado, leg√≠vel, seguro e f√°cil de manter.
*   Priorize as melhorias que trazem o maior impacto no seu projeto.
*   Use um sistema de controle de vers√£o (ex: Git) para acompanhar suas mudan√ßas e facilitar a colabora√ß√£o com outros desenvolvedores.

Se tiver alguma d√∫vida sobre alguma dessas sugest√µes, √© s√≥ perguntar!
User: Extraia o CNPJ dessa imagem.
Assistant: A imagem cont√©m um comprovante de inscri√ß√£o e de situa√ß√£o cadastral. O CNPJ presente na imagem √©:

`33.024.232/0001-39`
User: extraia o n√∫mero do chamado que come√ßa com  2025
Assistant: O n√∫mero do chamado que come√ßa com 2025 na imagem √©:

`2025040185005611`

User:  Okay, sorry, this is. Okay, so welcome everyone. So our week we call for Brazil at a ca Dow. So for today, we will discuss the following the ARIBA, the production API, the P2P and S2C ticket status updates. And if we have business processes and change management. So for the ARIBA, here are depending the number of pending decisions and open actions. So we have. So for all we have one action and one information and then. For ERP team, we have two actions and two information. So we have a total of six. So let me go to the ARIBA file. Okay, so here are the items that we have in the ARIBA file. So for the first one, we have the domain name change. So for this one, so this is actually extended until January 31, 2026. But yeah, Flavio, I just want to know if we have progress on this one. I need to check and then I get back to you on this. On this sheet, please. Okay, thank you so much. Okay, so. You have included another one. Yes, that's correct. Yeah, so for the next one, we actually have also the TLS 1 point to connection. To. To be transferred to a TLS 1 point. So this is also for your team to check. So the deadline for this one will be on April 30. So do we have also progress on this one or not yet? I believe that I already described my current situation on a column. On the right on the right. You can find my call up. Sorry, here or on the tracker file, be the change. Sorry, let me check. This one. This one. I'm not sure where are the comments that you have. No, I just have my clue comments about the first one in the second and the TLS. So we are already done. The line five. Let me see if I can. Is it. Ah, this one. Okay. Okay, so this is already close. Yes, this. Yeah. So for that one, could you please provide screen shots here if possible? To stretch. Yes, just to show that it is already deployed on your system. As an evidence. Okay. Thank you so much. Okay. Okay, so let me remove this one also. I don't know why this one educated. Okay, so for the next two items is read your cards to the certificate renewal. So this is still for information only once the assertifcates have been released by. So I will be able to provide it to you also. Either in the juror ticket or via. So actually this should not be in progress. Okay. And then for the next one, we have also the. This environment frees for the. Parent real. Or the for the S to see items actually so. This is still ongoing right now. So we are checking internally with the project team when. This project will end. So for now. All the test things for the. Related to a supplier's contracts. Our entries for now. And lastly for the daily monitor and so since Ricardo is not here. Yes, so. Oh, sorry, I did hear. So just so this is a reminder for. That for them to check the. Monitoring file for Brazil. So actually. We are encountering some or we are a cap we have some documents captured in the daily monitoring. So if you could also help with the card to check this capture documents that would be appreciated. I'm not sure if this is the correct. Okay, so this is still on March. Let me just change this one. Okay. Okay. Let me share my screen. Okay, so this is actually the. Monitoring file for Brazil. So right now we only for now we have one so we are still updating the monitoring file. So yeah, if you could help check this one. And see why this PR is having an error in the. Are you beside or in the air beside render. So this is the. What they call this the error message that was encountered. So yeah, if you could check this on the ER beside it would be appreciate. For the other. I don't think we have some captured documents yet. Yeah, so for now we'll be have one. Just this one. So yeah, that's all for the items. So they have questions before move on to our next items. No, please go ahead. Okay, thank you so much. Okay, so for the production KPIs, it's the same as the last week as discussed. So they are the numbers or the figures for the documents for the transactions in harriba and for the care tickets that have been taken by a to an L3. So as for the P2P tickets status update so for the past week we. So we have a result or we handled six tickets for P2P and as for the open items. So for the first one we have the issue with regards to the PR that is in order processing status. So for this one, yeah, the current issue is that this PR is currently in version three and it is showing an error that the version two has been has been stopping ordering. However, we cannot. Reprocess this one on the CIG side, so that's why we raise an SR for this one. Or an Arriba case. So right now we are trying to set up a call with the Arriba vendor as they are also asking for our availability. So once we have established a schedule for the meeting and discuss this with the Arriba vendor. So we will update the care ticket about the discussion. And for the next one, we have the integration issue for this supply. Can I attend to the point one please. So we are pending Arriba vendor get back to us with a viable time slots to have a conversation. So for this one, we so the Accenture team will discuss this first with the SAP Arriba vendor as we have all the details already. So if so we will discuss all the investigations that we had so far in order to help them further investigate this issue. But according to the plan for the city reader, we also talk about the updating of our environment of testing. If I'm not wrong. That the queue us or the. We have plenty to update our environment of testing. And the QA test test environment. The point is I need to go ahead with our S a p requirements that I have shared with you by. Sorry. So I don't know if this point is blocking our evaluation regarding to S a p. This is the point. The one that you have in email or. Yeah, 200 for eight or far nine. S a p requirements. I mean, we'll have on this. Let me see if I can. The line eight. Are you have very an update in this one? Yes, so for this one, this is only in a riba side of love you and not on the other side. Yeah, but. I'm aware about S a p. The point for me is S a p evaluation. So I need to implement new requirements. My S a p environment in production. So I don't know if the test environment. We need to be update in order to go ahead with this S a p new requirements. Yeah, so for this one of lab, you I think we need to. Wait for the synchronization of the data from the production system to the test environment to be finished. So we do implementations of data changes or. To do some. Testing scenarios in the S to see part. Yeah, but when we are when we will be ready. I have mentioned earlier, we will coordinate this with the project team who's doing the project for this project specifically and ask them when this will be finished as the. Other conscious and Bruno is also asking for this one. So we will update you accordingly regarding this one. Okay. Thank you. Okay. Yeah, so let me discuss first the B to B items. Okay, so for the next one, we have the issue with regards to this supplier. Which was raised by a Tadita. So for this one, they are. And the Tadita mentioned in the ticket that they are coordinating with the bank team for the confirmation of the ACM ID for the supplier. And the last update was made to me about this ticket. And the next one is explained to the explain needs to be created, which already exists. And the value one B are one data needs to be partitioned into to these other suppliers. And that after this is done, they will probably you will proceed with the supplier patchy partitioning for a base trace attack. Yes. Yeah. And you also ask to ask to us to check with the bank if the ACM ID of the supplier is a 35 for. Yes. Something. I don't remember everything. This one. Yeah. Yeah. But the informant says that they don't know what they. ACM, ACM ID of the supplier is. And the next case, can we deactivate this ACM ID and position are from. We will see. Yeah, we will see if we can. If we can try to partition it again, because yes, I have showed in the ticket on our discussion tab. There are two suppliers with that are currently existing, which is one having this ACM ID and the other has no ACM ID has no ACM ACM ID mapping yet. So that's why I suggested to ask the bank team if this is their. They don't know. That's. They don't know this. So. This don't they don't know this information. But. We thought that we can deactivate the ACM and partition it hours. Because they don't pass. They don't know this information, which is ACM ID from this supplier. But they are still using this supplier, right? Yeah. I don't know. Don't sure. We we we talked to the bank. So they were they are already know that we ask to you. We are asking to you to activate this ACM. Yeah, I'm not sure if PCM ID can be deactivated since actually this data is coming from the ERP system. So if they don't know. So if you're asking the local team of the bank team, maybe you can also suggest if if they're ERP team knows this data. But yeah, for now, we will see if if the data for the. The data can be mapped to each to one of the suppliers that I have showed I have shown you in the. In the screenshot. That I have provided. Okay. So right now we can deactivate this ACM. We need to with the bank again. Right. Yes. Yes. Yes. Specifically, maybe as their ERP team instead. Because I don't think the local team knows where this data is coming from. But yeah, as far as I'm concerned, this is integrated in that is or this is this data is coming from the ERP system rather. Okay. We're going to check again. And let you. Sure. For now, we will I will do my best to keep the ticket open for now. Okay. Yeah, so I think that's also do you have questions for these two items for the ptp before we move on to SCC items. Okay. Okay. Thank you. Okay. So for the S2C items. So yeah, we have two items here, which is with regards to the SLP template. Adjustment in SLP template and the. So for the S2 items, both of these are currently still in progress due to the synchronization that is happening between the production and test systems. So for the second item. Yeah, so for this one, this for this one, known, known modifications are allowed for now since yeah. We need to wait for this synchronization synchronization to be finished. And I think we have one more item I haven't I wasn't able to add it here. Yeah, so for this request from you, I love you. I believe with regards to this one. So. We will we are still checking this internally. So once we receive a conclusion for this one, we will update you accordingly. Okay. Thank you. Yeah, I will add this to the read the. Sorry, I forgot to add this yet. But yeah, we will check this internet. So let me know when you test environment, it's a very uploaded. Yeah. Yeah, we will get back to you also for that. Okay. Yeah, so that's all from my side. Do you have other questions or concerns that we can address in the call before we end this? No, for my side. No. Are you guys? Me neither. Okay. Thank you. First one, thank you. Thank you, Ray. Thank you, everyone. And yeah, I will send the minutes of the meeting after the call. So yeah, thank you, everyone. And I wish you a great day ahead. Bye.

Traduza para pt-br
Assistant: Okay, aqui est√° a tradu√ß√£o para portugu√™s brasileiro do di√°logo fornecido:

"Okay, desculpem, √© isso. Okay, ent√£o bem-vindos a todos. Ent√£o, nossa semana chamamos para Brasil na CA Dow. Ent√£o, para hoje, vamos discutir o seguinte: o ARIBA, a API de produ√ß√£o, o P2P e atualiza√ß√µes de status de tickets S2C. E se tivermos processos de neg√≥cios e gest√£o de mudan√ßas. Ent√£o, para o ARIBA, aqui est√£o dependendo o n√∫mero de decis√µes pendentes e a√ß√µes em aberto. Ent√£o n√≥s temos. Ent√£o, para todos n√≥s temos uma a√ß√£o e uma informa√ß√£o e ent√£o. Para a equipe ERP, temos duas a√ß√µes e duas informa√ß√µes. Ent√£o, temos um total de seis. Ent√£o, deixe-me ir para o arquivo ARIBA. Okay, ent√£o aqui est√£o os itens que temos no arquivo ARIBA. Ent√£o, para o primeiro, temos a mudan√ßa de nome de dom√≠nio. Ent√£o, para este, isso √© realmente estendido at√© 31 de janeiro de 2026. Mas sim, Fl√°vio, eu s√≥ quero saber se temos progresso neste. Eu preciso verificar e ent√£o eu volto para voc√™ neste. Nesta folha, por favor. Okay, muito obrigado. Okay, ent√£o. Voc√™ incluiu outro. Sim, est√° correto. Sim, ent√£o para o pr√≥ximo, n√≥s realmente temos tamb√©m a conex√£o TLS 1 ponto para. Para. Para ser transferida para um TLS 1 ponto. Ent√£o isso tamb√©m √© para sua equipe verificar. Ent√£o o prazo para este ser√° em 30 de abril. Ent√£o, n√≥s temos tamb√©m progresso neste ou ainda n√£o? Eu acredito que eu j√° descrevi minha situa√ß√£o atual em uma coluna. Na direita, na direita. Voc√™ pode encontrar minha chamada. Desculpe, aqui ou no arquivo de rastreamento, seja a mudan√ßa. Desculpe, deixe-me verificar. Este. Este. Eu n√£o tenho certeza onde est√£o os coment√°rios que voc√™ tem. N√£o, eu s√≥ tenho meus coment√°rios de pistas sobre o primeiro e o segundo e o TLS. Ent√£o, j√° terminamos. A linha cinco. Deixe-me ver se eu posso. √â isso. Ah, este. Okay. Okay, ent√£o isso j√° est√° fechado. Sim, isto. Sim. Ent√£o para isso, voc√™ poderia por favor fornecer capturas de tela aqui se poss√≠vel? Para alongar. Sim, apenas para mostrar que j√° est√° implantado em seu sistema. Como uma evid√™ncia. Okay. Muito obrigado. Okay. Okay, ent√£o deixe-me remover este tamb√©m. Eu n√£o sei por que este educado. Okay, ent√£o para os pr√≥ximos dois itens √© ler seus cart√µes para a renova√ß√£o do certificado. Ent√£o, isto ainda √© apenas para informa√ß√£o, uma vez que os assertifcates tenham sido liberados por. Ent√£o eu poderei fornec√™-lo a voc√™ tamb√©m. Seja no ingresso do j√∫ri ou via. Ent√£o, na verdade isso n√£o deveria estar em andamento. Okay. E ent√£o para o pr√≥ximo, temos tamb√©m o. Este ambiente libera para o. Real pai. Ou o para os itens S para ver realmente t√£o. Isto ainda est√° em andamento agora. Ent√£o estamos verificando internamente com a equipe do projeto quando. Este projeto terminar√°. Ent√£o por agora. Todas as coisas de teste para o. Relacionado aos contratos de um fornecedor. Nossas entradas por enquanto. E, finalmente, para o monitor di√°rio e ent√£o, j√° que Ricardo n√£o est√° aqui. Sim, ent√£o. Oh, desculpe, eu ouvi aqui. Ent√£o, apenas ent√£o isso √© um lembrete para. Que para eles verifiquem o. Arquivo de monitoramento para o Brasil. Ent√£o, realmente. Estamos encontrando alguns ou estamos um cap n√≥s temos alguns documentos capturados no monitoramento di√°rio. Ent√£o, se voc√™ tamb√©m pudesse ajudar com o cart√£o para verificar esses documentos capturados, seria apreciado. N√£o tenho certeza se isto est√° correto. Okay, ent√£o isto ainda est√° em mar√ßo. Deixe-me apenas mudar isto. Okay. Okay. Deixe-me compartilhar minha tela. Okay, ent√£o este √© realmente o. Arquivo de monitoramento para o Brasil. Ent√£o agora n√≥s apenas por enquanto temos um, ent√£o ainda estamos atualizando o arquivo de monitoramento. Ent√£o sim, se voc√™ pudesse ajudar a verificar este. E veja por que este RP est√° tendo um erro no. Voc√™ est√° ao lado ou no ar ao lado render. Ent√£o este √© o. O que eles chamam isto a mensagem de erro que foi encontrada. Ent√£o sim, se voc√™ pudesse verificar isso no ER ao lado, seria apreciado. Para os outros. Eu n√£o acho que temos alguns documentos capturados ainda. Sim, ent√£o por agora n√≥s teremos um. Apenas este. Ent√£o sim, √© tudo para os itens. Ent√£o eles t√™m perguntas antes de passarmos para nossos pr√≥ximos itens. N√£o, por favor prossiga. Okay, muito obrigado. Okay, ent√£o para os KPIs de produ√ß√£o, √© o mesmo que na semana passada, conforme discutido. Ent√£o eles s√£o os n√∫meros ou as figuras para os documentos para as transa√ß√µes em harriba e para os bilhetes de atendimento que foram tomados por um para um L3. Ent√£o, quanto √† atualiza√ß√£o do status dos bilhetes de atendimento P2P, ent√£o na semana passada n√≥s. Ent√£o temos um resultado ou lidamos com seis bilhetes de atendimento para P2P e quanto aos itens em aberto. Ent√£o, para o primeiro, temos o problema em rela√ß√£o ao PR que est√° em estado de processamento de pedidos. Ent√£o, para este, sim, o problema atual √© que este PR est√° atualmente na vers√£o tr√™s e est√° mostrando um erro de que a vers√£o dois tem interrompido a encomenda. No entanto, n√£o podemos. Reprocessar este no lado CIG, ent√£o √© por isso que levantamos um SR para este. Ou um caso Arriba. Ent√£o agora estamos tentando agendar uma chamada com o fornecedor Arriba, pois eles tamb√©m est√£o perguntando pela nossa disponibilidade. Ent√£o, uma vez que tenhamos estabelecido uma programa√ß√£o para a reuni√£o e discutirmos isso com o fornecedor Arriba. Ent√£o atualizaremos o bilhete de atendimento sobre a discuss√£o. E para o pr√≥ximo, temos o problema de integra√ß√£o para este fornecimento. Posso atender ao ponto um por favor. Ent√£o, estamos pendentes para que o fornecedor Arriba volte para n√≥s com hor√°rios vi√°veis para ter uma conversa. Ent√£o, para este, n√≥s, a equipe Accenture, discutiremos isso primeiro com o fornecedor SAP Arriba, pois j√° temos todos os detalhes. Ent√£o, se assim for, discutiremos todas as investiga√ß√µes que tivemos at√© agora, a fim de ajud√°-los a investigar ainda mais este problema. Mas de acordo com o plano para o leitor da cidade, tamb√©m falamos sobre a atualiza√ß√£o do nosso ambiente de teste. Se eu n√£o estiver enganado. Que o Q us ou o. Temos muito para atualizar nosso ambiente de teste. E o ambiente de teste QA. O ponto √© que eu preciso prosseguir com os nossos requisitos S a p que compartilhei com voc√™ por. Desculpe. Ent√£o, eu n√£o sei se este ponto est√° bloqueando a nossa avalia√ß√£o em rela√ß√£o ao S a p. Este √© o ponto. Aquele que voc√™ tem no e-mail ou. Sim, 200 para oito ou longe nove. Requisitos S a p. Quero dizer, n√≥s teremos neste. Deixe-me ver se eu posso. A linha oito. Voc√™ tem alguma atualiza√ß√£o nisto? Sim, ent√£o, para este, isto √© apenas no lado do Ariba do amor voc√™ e n√£o no outro lado. Sim, mas. Estou ciente sobre S a p. O ponto para mim √© a avalia√ß√£o S a p. Ent√£o eu preciso implementar novos requisitos. Meu ambiente S a p em produ√ß√£o. Ent√£o eu n√£o sei se o ambiente de teste. Precisamos ser atualizados para prosseguir com estes novos requisitos S a p. Sim, ent√£o, para este amor, voc√™, eu acho que precisamos. Espere pela sincroniza√ß√£o dos dados do sistema de produ√ß√£o para o ambiente de teste para terminar. Ent√£o n√≥s fazemos implementa√ß√µes de mudan√ßas de dados ou. Para fazer alguns. Cen√°rios de teste na parte S para ver. Sim, mas quando estaremos prontos. Eu mencionei anteriormente, coordenaremos isto com a equipe do projeto que est√° fazendo o projeto para este projeto especificamente e perguntaremos quando isto terminar√° como o. Outro consciente e Bruno tamb√©m est√° pedindo por isso. Ent√£o n√≥s o atualizaremos em conformidade em rela√ß√£o a este. Okay. Obrigado. Okay. Sim, ent√£o deixe-me discutir primeiro os itens B para B. Okay, ent√£o para o pr√≥ximo, temos o problema em rela√ß√£o a este fornecedor. Que foi levantado por um Tadita. Ent√£o, para este, eles est√£o. E o Tadita mencionou no bilhete de atendimento que eles est√£o coordenando com a equipe do banco para a confirma√ß√£o do ACM ID para o fornecedor. E a √∫ltima atualiza√ß√£o foi feita para mim sobre este bilhete de atendimento. E o pr√≥ximo precisa ser criado, o que j√° existe. E o valor um B s√£o um dados precisa ser particionado em para estes outros fornecedores. E que depois que isso for feito, eles provavelmente prosseguir√£o com a parti√ß√£o do fornecedor para um ataque de rastreamento base. Sim. Sim. E voc√™ tamb√©m pede para nos pedir para verificar com o banco se o ACM ID do fornecedor √© um 35 para. Sim. Algo. Eu n√£o lembro de tudo. Este. Sim. Sim. Mas o informante diz que eles n√£o sabem o que eles. ACM, ACM ID do fornecedor √©. E no pr√≥ximo caso, podemos desativar este ACM ID e posicionar s√£o de. N√≥s veremos. Sim, n√≥s veremos se podemos. Se podemos tentar particion√°-lo novamente, porque sim, eu mostrei no bilhete de atendimento na nossa aba de discuss√£o. Existem dois fornecedores com que est√£o atualmente existentes, que √© um tendo este ACM ID e o outro n√£o tem ACM ID n√£o tem ACM mapeamento de ACM ainda. Ent√£o √© por isso que eu sugeri pedir √† equipe do banco se este √© deles. Eles n√£o sabem. Isso. Eles n√£o sabem esta informa√ß√£o. Mas. N√≥s pensamos que podemos desativar o ACM e particion√°-lo horas. Porque eles n√£o passam. Eles n√£o conhecem esta informa√ß√£o, que √© o ACM ID deste fornecedor. Mas eles ainda est√£o usando este fornecedor, certo? Sim. Eu n√£o sei. N√£o tenho certeza. N√≥s conversamos com o banco. Ent√£o eles j√° sabem que n√≥s pedimos para voc√™. Estamos pedindo para voc√™ ativar este ACM. Sim, n√£o tenho certeza se o PCM ID pode ser desativado, j√° que na verdade estes dados est√£o vindo do sistema ERP. Ent√£o, se eles n√£o sabem. Ent√£o, se voc√™ est√° perguntando para a equipe local da equipe do banco, talvez voc√™ tamb√©m possa sugerir se se a equipe ERP deles sabe estes dados. Mas sim, por enquanto, veremos se se os dados para o. Os dados podem ser mapeados para cada um dos fornecedores que eu mostrei que eu mostrei a voc√™ no. Na captura de tela. Que eu forneci. Okay. Ent√£o, agora n√£o podemos desativar este ACM. Precisamos com o banco novamente. Certo. Sim. Sim. Especificamente, talvez como sua equipe ERP em vez disso. Porque eu n√£o acho que a equipe local sabe de onde estes dados est√£o vindo. Mas sim, tanto quanto eu sei, isto est√° integrado em que √© ou estes dados est√£o vindo do sistema ERP em vez disso. Okay. N√≥s vamos verificar novamente. E deixe voc√™. Claro. Por enquanto, eu farei o meu melhor para manter o bilhete de atendimento aberto por enquanto. Okay. Sim, ent√£o eu acho que isso tamb√©m, voc√™ tem perguntas para estes dois itens para o ptp antes de passarmos para os itens SCC. Okay. Okay. Obrigado. Okay. Ent√£o, para os itens S2C. Ent√£o sim, temos dois itens aqui, que √© em rela√ß√£o ao modelo SLP. Ajuste no modelo SLP e o. Ent√£o para os itens S2, ambos estes est√£o atualmente ainda em andamento devido √† sincroniza√ß√£o que est√° acontecendo entre os sistemas de produ√ß√£o e teste. Ent√£o para o segundo item. Sim, ent√£o para este, para este conhecido, nenhuma modifica√ß√£o conhecida √© permitida por enquanto, j√° que sim. Precisamos esperar por esta sincroniza√ß√£o sincroniza√ß√£o para terminar. E eu acho que temos mais um item eu n√£o fui capaz de adicion√°-lo aqui. Sim, ent√£o para este pedido seu, eu te amo. Eu acredito com rela√ß√£o a este. T√£o. N√≥s verificaremos isto internamente. Ent√£o, uma vez que recebermos uma conclus√£o para este, n√≥s o atualizaremos em conformidade. Okay. Obrigado. Sim, eu adicionarei isto ao leia o. Desculpe, eu esqueci de adicionar isto ainda. Mas sim, n√≥s verificaremos isto na internet. Ent√£o me avise quando seu ambiente de teste, √© uma atualiza√ß√£o muito grande. Sim. Sim, n√≥s entraremos em contato com voc√™ tamb√©m para isso. Okay. Sim, ent√£o √© tudo da minha parte. Voc√™ tem outras perguntas ou preocupa√ß√µes que podemos abordar na chamada antes de terminarmos isto? N√£o, da minha parte. N√£o. Voc√™s? Eu tamb√©m n√£o. Okay. Obrigado. Primeiro, obrigado. Obrigado a todos. E sim, eu enviarei as atas da reuni√£o ap√≥s a chamada. Ent√£o sim, obrigado a todos. E eu desejo a voc√™s um √≥timo dia pela frente. Tchau."

Espero que isso ajude! Avise-me se precisar de mais alguma coisa.

User: Resuma essa reuni√£o com os pontos importantes.
Assistant: Assistant: Claro, aqui est√° um resumo dos pontos importantes da reuni√£o:

**ARIBA:**

*   **Mudan√ßa de Nome de Dom√≠nio:** Estendida at√© 31 de janeiro de 2026. Fl√°vio deve verificar o progresso.
*   **Conex√£o TLS 1.2:** Prazo para transfer√™ncia √© 30 de abril. J√° foi finalizada (linha 5). Solicitaram screenshots como evid√™ncia.
*   **Renova√ß√£o de Certificado:** Aguardando informa√ß√µes para fornecer via ticket ou e-mail.
*   **Ambiente Livre para S2C:** Testes relacionados aos contratos de fornecedores em andamento. Aguardando t√©rmino do projeto.
*   **Monitoramento Di√°rio:** Verificar o arquivo de monitoramento do Brasil e o erro no PR.

**KPIs de Produ√ß√£o:**

*   Sem altera√ß√µes em rela√ß√£o √† semana anterior.

**Status dos Tickets P2P:**

*   Seis tickets resolvidos.
*   **PR em Processamento de Pedido (Vers√£o 3):** Erro na Vers√£o 2. Aguardando agendamento de reuni√£o com o fornecedor Arriba.
*   **Problema de Integra√ß√£o:** Accenture discutir√° com o fornecedor SAP Arriba e atualizar√° o ambiente de teste.
*   **Fornecedor com Problemas no ACM ID:** Verificar com a equipe do banco (possivelmente a equipe ERP) e desativar o ACM ID.

**Itens S2C:**

*   Ajuste no modelo SLP em andamento, aguardando sincroniza√ß√£o entre os sistemas de produ√ß√£o e teste.
*   Solicita√ß√£o de atualiza√ß√£o do ambiente de teste ser√° verificada internamente.

**Geral:**

*   Coordenar a atualiza√ß√£o do ambiente de teste com a equipe do projeto.
*   As atas da reuni√£o ser√£o enviadas ap√≥s a chamada.
User: Preciso de mais detalhes sobre o fornecedor que n√£o est√° particionando.
2025-04-10 14:13:08,859 [INFO] Resposta da IA (imagem): Assistant: Ok, com base no di√°logo, aqui est√£o os detalhes sobre o fornecedor com problemas de parti√ß√£o:

*   **Problema:** O fornecedor n√£o est√° sendo particionado corretamente.
*   **Causa:** Existe um problema com o ACM ID (Ariba Cloud Module ID) do fornecedor.
*   **Situa√ß√£o Atual:**
    *   A Tadita est√° coordenando com a equipe do banco para confirmar o ACM ID.
    *   J√° existem dois fornecedores: um com o ACM ID problem√°tico e outro sem nenhum ACM ID.
    *   A equipe do banco (local) n√£o reconhece o ACM ID existente.
*   **A√ß√µes:**
    *   Sugeriu-se questionar a equipe ERP do banco sobre o ACM ID, pois esses dados geralmente v√™m do sistema ERP.
    *   A equipe est√° considerando desativar o ACM ID problem√°tico e tentar particionar novamente o fornecedor.
    *   A equipe precisa verificar com o banco novamente (especificamente a equipe ERP) antes de desativar o ACM ID.

Em resumo, o problema parece estar relacionado √† identifica√ß√£o e ao gerenciamento do ACM ID do fornecedor no sistema banc√°rio, o que est√° impedindo a parti√ß√£o correta no Ariba.

2025-04-10 14:13:09,021 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 14:13:09,022 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 14:13:09,024 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 14:13:09,026 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 14:13:09,027 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 14:13:09,028 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 14:13:09,031 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 14:13:09,033 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 14:13:09,034 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 14:13:09,035 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 14:13:09,036 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 14:13:09,037 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 14:13:09,038 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 14:13:09,040 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 14:13:09,041 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 16:48:32,618 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 16:48:32,628 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 16:48:32,637 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 16:48:32,642 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 16:48:32,649 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 16:48:32,657 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 16:48:32,664 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 16:48:32,673 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 16:48:32,680 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 16:48:32,687 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 16:48:32,694 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 16:48:32,702 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 16:48:32,709 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 16:48:32,716 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 16:48:32,723 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 16:48:33,178 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 16:48:33,180 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 16:48:33,182 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 16:48:33,183 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 16:48:33,185 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 16:48:33,186 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 16:48:33,187 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 16:48:33,189 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 16:48:33,191 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 16:48:33,193 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 16:48:33,195 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 16:48:33,198 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 16:48:33,201 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 16:48:33,203 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 16:48:33,205 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 16:48:33,226 [INFO] Enviando para IA - Imagem: C:\Users\jfreis\Documents\azure-ai-sentiment-analysis\assets\20250410164833_clipboard_20250410100554.png, Prompt: Voc√™ √© um assistente inteligente utilizado em um chat com IA, que recebe c√≥digos de uma aplica√ß√£o completa de chat, como voc√™ funciona e tudo que 
√© programado para fazer no seu contexto.

Seu objetivo √©:
- Analisar todo o contexto e aprender com ele.
- Analisar a Pergunta do Usu√°rio.
- Identificar se possui rela√ß√£o com o contexto.
- Se houver rela√ß√£o com o c√≥digo do contexto responder a pergunta sobre o c√≥digo sempre seguindo boas pr√°ticas:
    - Analisar o c√≥digo-fonte contido no projeto enviado
    - Identificar melhorias em legibilidade, performance e seguran√ßa
    - Sugerir pr√°ticas recomendadas de design e arquitetura
    - Indicar partes com d√≠vidas t√©cnicas ou complexidade desnecess√°ria
    - Enviar c√≥digo modularizado em pequenos arquivos separados por pastas.

Informa√ß√µes adicionais:
- Estrutura do projeto: segue o padr√£o de pastas iniciando por src/


## Se houver imagem no contexto, identifique se a pergunta √© sobre o c√≥digo do contexto, sobre a imagem ou sobre os dois para elaborar melhorer respostas.
## Se o usu√°rio fizer uma pergunta que n√£o tem rela√ß√£o com imagem ou contexto, use a sua base de conhecimento fora do contexto para responder de forma inteligente.
** Responda em Portugu√™s-Brasileiro a n√£o ser que o usu√°rio solicite outra l√≠ngua.**

Contexto:



# chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# main.py

# main.py
from core.handlers.signal_handler import setup_signal_handler
from services.image_processor import ImageProcessor
from core.rate_limiter import RateLimiter
import json

def main():
    setup_signal_handler()

    # Inicializa o RateLimiter com o n√∫mero m√°ximo de requisi√ß√µes e o per√≠odo
    rate_limiter = RateLimiter(max_requests=9, period_seconds=60)  # 9 requisi√ß√µes por minuto

    # Passa o RateLimiter para o ImageProcessor
    processor = ImageProcessor(rate_limiter)
    processor.process_images()

    # Obter e imprimir o hist√≥rico ap√≥s o processamento
    history = processor.get_history()
    for item in history:
        print(f"Imagem: {item['image_name']}, Resumo: {item['summary']}")

    # Salvar o hist√≥rico em um arquivo JSON
    with open(processor.historico_json_file, "w") as f:
        json.dump(history, f, indent=4)

if __name__ == "__main__":
    main()

# services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# test_image_generation.py

import os
from dotenv import load_dotenv
from google import genai
from google.generativeai import types
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

client = genai.Client(api_key=api_key)

prompt = "gerar a imagem do simbolo do corinthians."

response = client.models.generate_content(
    model='gemini-2.0-flash-exp-image-generation',
    contents=prompt,
    config=types.GenerateContentConfig(
        response_modalities=['Text', 'Image']
    )
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = Image.open(BytesIO(part.inline_data.data))
        image.save("ed-image.png")
        image.show()

# utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

User: fa√ßa code review da minha aplica√ß√£o.
Assistant: Com certeza! Analisei o c√≥digo da sua aplica√ß√£o e preparei algumas sugest√µes para melhorias em legibilidade, performance, seguran√ßa e design.

**1. Estrutura e Modulariza√ß√£o:**

*   **Diret√≥rios:** Organize melhor os arquivos dentro de `src`. Crie subdiret√≥rios para `models`, `services`, `handlers`, `utils`, `config`, etc. Isso facilita a localiza√ß√£o dos arquivos e a compreens√£o da estrutura do projeto.
*   **Arquivo de configura√ß√£o:** Mova a classe `Config` para um arquivo separado (ex: `config.py`) dentro de um diret√≥rio `config`.
*   **Fun√ß√µes:** Quebre fun√ß√µes grandes em fun√ß√µes menores e mais focadas. Isso melhora a legibilidade e facilita o teste.

**2. Boas Pr√°ticas e Melhorias no C√≥digo:**

*   **Rate Limiting:** Implemente o `RateLimiter` nos servi√ßos que consomem a API do Gemini (ex: `ImageProcessor`, `GeminiHandler`). Isso evita sobrecarga na API e garante um uso mais eficiente.
*   **Configura√ß√µes:** Use a classe `Config` para centralizar todas as configura√ß√µes da aplica√ß√£o (ex: chaves de API, modelos, diret√≥rios). Isso facilita a manuten√ß√£o e a configura√ß√£o do projeto.
*   **Logging:** Padronize o uso do logger em toda a aplica√ß√£o. Use os n√≠veis de log apropriados (ex: `info`, `warning`, `error`) para cada tipo de mensagem.
*   **Tratamento de Erros:** Adicione tratamento de erros mais espec√≠fico em cada fun√ß√£o. Isso ajuda a identificar e corrigir problemas mais rapidamente.
*   **Cache:** Utilize o `st.cache_resource` para fun√ß√µes que realizam opera√ß√µes custosas, como a inicializa√ß√£o do `GeminiHandler`. Isso evita a execu√ß√£o repetida dessas opera√ß√µes.
*   **Tipagem:** Utilize tipagem est√°tica (type hints) para melhorar a legibilidade e a seguran√ßa do c√≥digo.
*   **Imagens:** Valide se `uploaded_file` √© realmente um arquivo de imagem antes de tentar exibi-lo, evitando erros caso o usu√°rio envie um arquivo de outro tipo.
*   **Prompts:** Crie arquivos de prompt separados para diferentes tarefas (ex: chat, an√°lise de imagem). Isso facilita a manuten√ß√£o e a personaliza√ß√£o dos prompts.

**3. Seguran√ßa:**

*   **Chaves de API:** Nunca coloque suas chaves de API diretamente no c√≥digo. Use vari√°veis de ambiente ou um arquivo de configura√ß√£o seguro para armazen√°-las.
*   **Valida√ß√£o de Input:** Valide todos os inputs do usu√°rio para evitar ataques de inje√ß√£o de c√≥digo.

**4. Arquitetura:**

*   **Camadas:** Defina claramente as responsabilidades de cada camada da sua aplica√ß√£o (ex: apresenta√ß√£o, l√≥gica de neg√≥cios, acesso a dados). Isso facilita a manuten√ß√£o e a evolu√ß√£o do projeto.
*   **Invers√£o de Depend√™ncia:** Use invers√£o de depend√™ncia para desacoplar as diferentes partes da sua aplica√ß√£o. Isso facilita o teste e a substitui√ß√£o de componentes.
*   **Testes:** Escreva testes unit√°rios e de integra√ß√£o para garantir a qualidade do seu c√≥digo.

**5. D√≠vidas T√©cnicas e Complexidade:**

*   **Fun√ß√µes Longas:** Identifique fun√ß√µes com muitas linhas de c√≥digo e divida-as em fun√ß√µes menores e mais focadas.
*   **L√≥gica Duplicada:** Elimine a l√≥gica duplicada criando fun√ß√µes ou classes reutiliz√°veis.
*   **Coment√°rios:** Adicione coment√°rios para explicar o que o c√≥digo faz, especialmente em partes complexas.

**Exemplo de Refatora√ß√£o:**

Aqui est√° um exemplo de como voc√™ pode refatorar a fun√ß√£o `process_images` na classe `ImageProcessor`:

```python
# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self._post_process_image(image_name, summary)
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _post_process_image(self, image_name, summary):
        self.document_service.add_image_summary(image_name, summary)
        self.markdown_service.add_image_summary(image_name, summary)
        self.document_service.save_document()
        self.markdown_service.save_markdown()

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history
```

**6. C√≥digo Modularizado:**

Para facilitar a visualiza√ß√£o e a organiza√ß√£o, preparei o c√≥digo modularizado em arquivos separados:

```
src/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gemini_handler.py
‚îÇ   ‚îú‚îÄ‚îÄ logger_config.py
‚îÇ   ‚îî‚îÄ‚îÄ rate_limiter.py
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ document_service.py
‚îÇ   ‚îú‚îÄ‚îÄ gpt_services.py
‚îÇ   ‚îú‚îÄ‚îÄ image_processor.py
‚îÇ   ‚îú‚îÄ‚îÄ markdown_service.py
‚îÇ   ‚îî‚îÄ‚îÄ search_files.py
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ file_utils.py
```

**Observa√ß√µes Finais:**

*   A implementa√ß√£o de todas essas sugest√µes pode levar tempo, mas o resultado final ser√° um c√≥digo mais organizado, leg√≠vel, seguro e f√°cil de manter.
*   Priorize as melhorias que trazem o maior impacto no seu projeto.
*   Use um sistema de controle de vers√£o (ex: Git) para acompanhar suas mudan√ßas e facilitar a colabora√ß√£o com outros desenvolvedores.

Se tiver alguma d√∫vida sobre alguma dessas sugest√µes, √© s√≥ perguntar!
User: Extraia o CNPJ dessa imagem.
Assistant: A imagem cont√©m um comprovante de inscri√ß√£o e de situa√ß√£o cadastral. O CNPJ presente na imagem √©:

`33.024.232/0001-39`
User: extraia o n√∫mero do chamado que come√ßa com  2025
Assistant: O n√∫mero do chamado que come√ßa com 2025 na imagem √©:

`2025040185005611`

User:  Okay, sorry, this is. Okay, so welcome everyone. So our week we call for Brazil at a ca Dow. So for today, we will discuss the following the ARIBA, the production API, the P2P and S2C ticket status updates. And if we have business processes and change management. So for the ARIBA, here are depending the number of pending decisions and open actions. So we have. So for all we have one action and one information and then. For ERP team, we have two actions and two information. So we have a total of six. So let me go to the ARIBA file. Okay, so here are the items that we have in the ARIBA file. So for the first one, we have the domain name change. So for this one, so this is actually extended until January 31, 2026. But yeah, Flavio, I just want to know if we have progress on this one. I need to check and then I get back to you on this. On this sheet, please. Okay, thank you so much. Okay, so. You have included another one. Yes, that's correct. Yeah, so for the next one, we actually have also the TLS 1 point to connection. To. To be transferred to a TLS 1 point. So this is also for your team to check. So the deadline for this one will be on April 30. So do we have also progress on this one or not yet? I believe that I already described my current situation on a column. On the right on the right. You can find my call up. Sorry, here or on the tracker file, be the change. Sorry, let me check. This one. This one. I'm not sure where are the comments that you have. No, I just have my clue comments about the first one in the second and the TLS. So we are already done. The line five. Let me see if I can. Is it. Ah, this one. Okay. Okay, so this is already close. Yes, this. Yeah. So for that one, could you please provide screen shots here if possible? To stretch. Yes, just to show that it is already deployed on your system. As an evidence. Okay. Thank you so much. Okay. Okay, so let me remove this one also. I don't know why this one educated. Okay, so for the next two items is read your cards to the certificate renewal. So this is still for information only once the assertifcates have been released by. So I will be able to provide it to you also. Either in the juror ticket or via. So actually this should not be in progress. Okay. And then for the next one, we have also the. This environment frees for the. Parent real. Or the for the S to see items actually so. This is still ongoing right now. So we are checking internally with the project team when. This project will end. So for now. All the test things for the. Related to a supplier's contracts. Our entries for now. And lastly for the daily monitor and so since Ricardo is not here. Yes, so. Oh, sorry, I did hear. So just so this is a reminder for. That for them to check the. Monitoring file for Brazil. So actually. We are encountering some or we are a cap we have some documents captured in the daily monitoring. So if you could also help with the card to check this capture documents that would be appreciated. I'm not sure if this is the correct. Okay, so this is still on March. Let me just change this one. Okay. Okay. Let me share my screen. Okay, so this is actually the. Monitoring file for Brazil. So right now we only for now we have one so we are still updating the monitoring file. So yeah, if you could help check this one. And see why this PR is having an error in the. Are you beside or in the air beside render. So this is the. What they call this the error message that was encountered. So yeah, if you could check this on the ER beside it would be appreciate. For the other. I don't think we have some captured documents yet. Yeah, so for now we'll be have one. Just this one. So yeah, that's all for the items. So they have questions before move on to our next items. No, please go ahead. Okay, thank you so much. Okay, so for the production KPIs, it's the same as the last week as discussed. So they are the numbers or the figures for the documents for the transactions in harriba and for the care tickets that have been taken by a to an L3. So as for the P2P tickets status update so for the past week we. So we have a result or we handled six tickets for P2P and as for the open items. So for the first one we have the issue with regards to the PR that is in order processing status. So for this one, yeah, the current issue is that this PR is currently in version three and it is showing an error that the version two has been has been stopping ordering. However, we cannot. Reprocess this one on the CIG side, so that's why we raise an SR for this one. Or an Arriba case. So right now we are trying to set up a call with the Arriba vendor as they are also asking for our availability. So once we have established a schedule for the meeting and discuss this with the Arriba vendor. So we will update the care ticket about the discussion. And for the next one, we have the integration issue for this supply. Can I attend to the point one please. So we are pending Arriba vendor get back to us with a viable time slots to have a conversation. So for this one, we so the Accenture team will discuss this first with the SAP Arriba vendor as we have all the details already. So if so we will discuss all the investigations that we had so far in order to help them further investigate this issue. But according to the plan for the city reader, we also talk about the updating of our environment of testing. If I'm not wrong. That the queue us or the. We have plenty to update our environment of testing. And the QA test test environment. The point is I need to go ahead with our S a p requirements that I have shared with you by. Sorry. So I don't know if this point is blocking our evaluation regarding to S a p. This is the point. The one that you have in email or. Yeah, 200 for eight or far nine. S a p requirements. I mean, we'll have on this. Let me see if I can. The line eight. Are you have very an update in this one? Yes, so for this one, this is only in a riba side of love you and not on the other side. Yeah, but. I'm aware about S a p. The point for me is S a p evaluation. So I need to implement new requirements. My S a p environment in production. So I don't know if the test environment. We need to be update in order to go ahead with this S a p new requirements. Yeah, so for this one of lab, you I think we need to. Wait for the synchronization of the data from the production system to the test environment to be finished. So we do implementations of data changes or. To do some. Testing scenarios in the S to see part. Yeah, but when we are when we will be ready. I have mentioned earlier, we will coordinate this with the project team who's doing the project for this project specifically and ask them when this will be finished as the. Other conscious and Bruno is also asking for this one. So we will update you accordingly regarding this one. Okay. Thank you. Okay. Yeah, so let me discuss first the B to B items. Okay, so for the next one, we have the issue with regards to this supplier. Which was raised by a Tadita. So for this one, they are. And the Tadita mentioned in the ticket that they are coordinating with the bank team for the confirmation of the ACM ID for the supplier. And the last update was made to me about this ticket. And the next one is explained to the explain needs to be created, which already exists. And the value one B are one data needs to be partitioned into to these other suppliers. And that after this is done, they will probably you will proceed with the supplier patchy partitioning for a base trace attack. Yes. Yeah. And you also ask to ask to us to check with the bank if the ACM ID of the supplier is a 35 for. Yes. Something. I don't remember everything. This one. Yeah. Yeah. But the informant says that they don't know what they. ACM, ACM ID of the supplier is. And the next case, can we deactivate this ACM ID and position are from. We will see. Yeah, we will see if we can. If we can try to partition it again, because yes, I have showed in the ticket on our discussion tab. There are two suppliers with that are currently existing, which is one having this ACM ID and the other has no ACM ID has no ACM ACM ID mapping yet. So that's why I suggested to ask the bank team if this is their. They don't know. That's. They don't know this. So. This don't they don't know this information. But. We thought that we can deactivate the ACM and partition it hours. Because they don't pass. They don't know this information, which is ACM ID from this supplier. But they are still using this supplier, right? Yeah. I don't know. Don't sure. We we we talked to the bank. So they were they are already know that we ask to you. We are asking to you to activate this ACM. Yeah, I'm not sure if PCM ID can be deactivated since actually this data is coming from the ERP system. So if they don't know. So if you're asking the local team of the bank team, maybe you can also suggest if if they're ERP team knows this data. But yeah, for now, we will see if if the data for the. The data can be mapped to each to one of the suppliers that I have showed I have shown you in the. In the screenshot. That I have provided. Okay. So right now we can deactivate this ACM. We need to with the bank again. Right. Yes. Yes. Yes. Specifically, maybe as their ERP team instead. Because I don't think the local team knows where this data is coming from. But yeah, as far as I'm concerned, this is integrated in that is or this is this data is coming from the ERP system rather. Okay. We're going to check again. And let you. Sure. For now, we will I will do my best to keep the ticket open for now. Okay. Yeah, so I think that's also do you have questions for these two items for the ptp before we move on to SCC items. Okay. Okay. Thank you. Okay. So for the S2C items. So yeah, we have two items here, which is with regards to the SLP template. Adjustment in SLP template and the. So for the S2 items, both of these are currently still in progress due to the synchronization that is happening between the production and test systems. So for the second item. Yeah, so for this one, this for this one, known, known modifications are allowed for now since yeah. We need to wait for this synchronization synchronization to be finished. And I think we have one more item I haven't I wasn't able to add it here. Yeah, so for this request from you, I love you. I believe with regards to this one. So. We will we are still checking this internally. So once we receive a conclusion for this one, we will update you accordingly. Okay. Thank you. Yeah, I will add this to the read the. Sorry, I forgot to add this yet. But yeah, we will check this internet. So let me know when you test environment, it's a very uploaded. Yeah. Yeah, we will get back to you also for that. Okay. Yeah, so that's all from my side. Do you have other questions or concerns that we can address in the call before we end this? No, for my side. No. Are you guys? Me neither. Okay. Thank you. First one, thank you. Thank you, Ray. Thank you, everyone. And yeah, I will send the minutes of the meeting after the call. So yeah, thank you, everyone. And I wish you a great day ahead. Bye.

Traduza para pt-br
Assistant: Okay, aqui est√° a tradu√ß√£o para portugu√™s brasileiro do di√°logo fornecido:

"Okay, desculpem, √© isso. Okay, ent√£o bem-vindos a todos. Ent√£o, nossa semana chamamos para Brasil na CA Dow. Ent√£o, para hoje, vamos discutir o seguinte: o ARIBA, a API de produ√ß√£o, o P2P e atualiza√ß√µes de status de tickets S2C. E se tivermos processos de neg√≥cios e gest√£o de mudan√ßas. Ent√£o, para o ARIBA, aqui est√£o dependendo o n√∫mero de decis√µes pendentes e a√ß√µes em aberto. Ent√£o n√≥s temos. Ent√£o, para todos n√≥s temos uma a√ß√£o e uma informa√ß√£o e ent√£o. Para a equipe ERP, temos duas a√ß√µes e duas informa√ß√µes. Ent√£o, temos um total de seis. Ent√£o, deixe-me ir para o arquivo ARIBA. Okay, ent√£o aqui est√£o os itens que temos no arquivo ARIBA. Ent√£o, para o primeiro, temos a mudan√ßa de nome de dom√≠nio. Ent√£o, para este, isso √© realmente estendido at√© 31 de janeiro de 2026. Mas sim, Fl√°vio, eu s√≥ quero saber se temos progresso neste. Eu preciso verificar e ent√£o eu volto para voc√™ neste. Nesta folha, por favor. Okay, muito obrigado. Okay, ent√£o. Voc√™ incluiu outro. Sim, est√° correto. Sim, ent√£o para o pr√≥ximo, n√≥s realmente temos tamb√©m a conex√£o TLS 1 ponto para. Para. Para ser transferida para um TLS 1 ponto. Ent√£o isso tamb√©m √© para sua equipe verificar. Ent√£o o prazo para este ser√° em 30 de abril. Ent√£o, n√≥s temos tamb√©m progresso neste ou ainda n√£o? Eu acredito que eu j√° descrevi minha situa√ß√£o atual em uma coluna. Na direita, na direita. Voc√™ pode encontrar minha chamada. Desculpe, aqui ou no arquivo de rastreamento, seja a mudan√ßa. Desculpe, deixe-me verificar. Este. Este. Eu n√£o tenho certeza onde est√£o os coment√°rios que voc√™ tem. N√£o, eu s√≥ tenho meus coment√°rios de pistas sobre o primeiro e o segundo e o TLS. Ent√£o, j√° terminamos. A linha cinco. Deixe-me ver se eu posso. √â isso. Ah, este. Okay. Okay, ent√£o isso j√° est√° fechado. Sim, isto. Sim. Ent√£o para isso, voc√™ poderia por favor fornecer capturas de tela aqui se poss√≠vel? Para alongar. Sim, apenas para mostrar que j√° est√° implantado em seu sistema. Como uma evid√™ncia. Okay. Muito obrigado. Okay. Okay, ent√£o deixe-me remover este tamb√©m. Eu n√£o sei por que este educado. Okay, ent√£o para os pr√≥ximos dois itens √© ler seus cart√µes para a renova√ß√£o do certificado. Ent√£o, isto ainda √© apenas para informa√ß√£o, uma vez que os assertifcates tenham sido liberados por. Ent√£o eu poderei fornec√™-lo a voc√™ tamb√©m. Seja no ingresso do j√∫ri ou via. Ent√£o, na verdade isso n√£o deveria estar em andamento. Okay. E ent√£o para o pr√≥ximo, temos tamb√©m o. Este ambiente libera para o. Real pai. Ou o para os itens S para ver realmente t√£o. Isto ainda est√° em andamento agora. Ent√£o estamos verificando internamente com a equipe do projeto quando. Este projeto terminar√°. Ent√£o por agora. Todas as coisas de teste para o. Relacionado aos contratos de um fornecedor. Nossas entradas por enquanto. E, finalmente, para o monitor di√°rio e ent√£o, j√° que Ricardo n√£o est√° aqui. Sim, ent√£o. Oh, desculpe, eu ouvi aqui. Ent√£o, apenas ent√£o isso √© um lembrete para. Que para eles verifiquem o. Arquivo de monitoramento para o Brasil. Ent√£o, realmente. Estamos encontrando alguns ou estamos um cap n√≥s temos alguns documentos capturados no monitoramento di√°rio. Ent√£o, se voc√™ tamb√©m pudesse ajudar com o cart√£o para verificar esses documentos capturados, seria apreciado. N√£o tenho certeza se isto est√° correto. Okay, ent√£o isto ainda est√° em mar√ßo. Deixe-me apenas mudar isto. Okay. Okay. Deixe-me compartilhar minha tela. Okay, ent√£o este √© realmente o. Arquivo de monitoramento para o Brasil. Ent√£o agora n√≥s apenas por enquanto temos um, ent√£o ainda estamos atualizando o arquivo de monitoramento. Ent√£o sim, se voc√™ pudesse ajudar a verificar este. E veja por que este RP est√° tendo um erro no. Voc√™ est√° ao lado ou no ar ao lado render. Ent√£o este √© o. O que eles chamam isto a mensagem de erro que foi encontrada. Ent√£o sim, se voc√™ pudesse verificar isso no ER ao lado, seria apreciado. Para os outros. Eu n√£o acho que temos alguns documentos capturados ainda. Sim, ent√£o por agora n√≥s teremos um. Apenas este. Ent√£o sim, √© tudo para os itens. Ent√£o eles t√™m perguntas antes de passarmos para nossos pr√≥ximos itens. N√£o, por favor prossiga. Okay, muito obrigado. Okay, ent√£o para os KPIs de produ√ß√£o, √© o mesmo que na semana passada, conforme discutido. Ent√£o eles s√£o os n√∫meros ou as figuras para os documentos para as transa√ß√µes em harriba e para os bilhetes de atendimento que foram tomados por um para um L3. Ent√£o, quanto √† atualiza√ß√£o do status dos bilhetes de atendimento P2P, ent√£o na semana passada n√≥s. Ent√£o temos um resultado ou lidamos com seis bilhetes de atendimento para P2P e quanto aos itens em aberto. Ent√£o, para o primeiro, temos o problema em rela√ß√£o ao PR que est√° em estado de processamento de pedidos. Ent√£o, para este, sim, o problema atual √© que este PR est√° atualmente na vers√£o tr√™s e est√° mostrando um erro de que a vers√£o dois tem interrompido a encomenda. No entanto, n√£o podemos. Reprocessar este no lado CIG, ent√£o √© por isso que levantamos um SR para este. Ou um caso Arriba. Ent√£o agora estamos tentando agendar uma chamada com o fornecedor Arriba, pois eles tamb√©m est√£o perguntando pela nossa disponibilidade. Ent√£o, uma vez que tenhamos estabelecido uma programa√ß√£o para a reuni√£o e discutirmos isso com o fornecedor Arriba. Ent√£o atualizaremos o bilhete de atendimento sobre a discuss√£o. E para o pr√≥ximo, temos o problema de integra√ß√£o para este fornecimento. Posso atender ao ponto um por favor. Ent√£o, estamos pendentes para que o fornecedor Arriba volte para n√≥s com hor√°rios vi√°veis para ter uma conversa. Ent√£o, para este, n√≥s, a equipe Accenture, discutiremos isso primeiro com o fornecedor SAP Arriba, pois j√° temos todos os detalhes. Ent√£o, se assim for, discutiremos todas as investiga√ß√µes que tivemos at√© agora, a fim de ajud√°-los a investigar ainda mais este problema. Mas de acordo com o plano para o leitor da cidade, tamb√©m falamos sobre a atualiza√ß√£o do nosso ambiente de teste. Se eu n√£o estiver enganado. Que o Q us ou o. Temos muito para atualizar nosso ambiente de teste. E o ambiente de teste QA. O ponto √© que eu preciso prosseguir com os nossos requisitos S a p que compartilhei com voc√™ por. Desculpe. Ent√£o, eu n√£o sei se este ponto est√° bloqueando a nossa avalia√ß√£o em rela√ß√£o ao S a p. Este √© o ponto. Aquele que voc√™ tem no e-mail ou. Sim, 200 para oito ou longe nove. Requisitos S a p. Quero dizer, n√≥s teremos neste. Deixe-me ver se eu posso. A linha oito. Voc√™ tem alguma atualiza√ß√£o nisto? Sim, ent√£o, para este, isto √© apenas no lado do Ariba do amor voc√™ e n√£o no outro lado. Sim, mas. Estou ciente sobre S a p. O ponto para mim √© a avalia√ß√£o S a p. Ent√£o eu preciso implementar novos requisitos. Meu ambiente S a p em produ√ß√£o. Ent√£o eu n√£o sei se o ambiente de teste. Precisamos ser atualizados para prosseguir com estes novos requisitos S a p. Sim, ent√£o, para este amor, voc√™, eu acho que precisamos. Espere pela sincroniza√ß√£o dos dados do sistema de produ√ß√£o para o ambiente de teste para terminar. Ent√£o n√≥s fazemos implementa√ß√µes de mudan√ßas de dados ou. Para fazer alguns. Cen√°rios de teste na parte S para ver. Sim, mas quando estaremos prontos. Eu mencionei anteriormente, coordenaremos isto com a equipe do projeto que est√° fazendo o projeto para este projeto especificamente e perguntaremos quando isto terminar√° como o. Outro consciente e Bruno tamb√©m est√° pedindo por isso. Ent√£o n√≥s o atualizaremos em conformidade em rela√ß√£o a este. Okay. Obrigado. Okay. Sim, ent√£o deixe-me discutir primeiro os itens B para B. Okay, ent√£o para o pr√≥ximo, temos o problema em rela√ß√£o a este fornecedor. Que foi levantado por um Tadita. Ent√£o, para este, eles est√£o. E o Tadita mencionou no bilhete de atendimento que eles est√£o coordenando com a equipe do banco para a confirma√ß√£o do ACM ID para o fornecedor. E a √∫ltima atualiza√ß√£o foi feita para mim sobre este bilhete de atendimento. E o pr√≥ximo precisa ser criado, o que j√° existe. E o valor um B s√£o um dados precisa ser particionado em para estes outros fornecedores. E que depois que isso for feito, eles provavelmente prosseguir√£o com a parti√ß√£o do fornecedor para um ataque de rastreamento base. Sim. Sim. E voc√™ tamb√©m pede para nos pedir para verificar com o banco se o ACM ID do fornecedor √© um 35 para. Sim. Algo. Eu n√£o lembro de tudo. Este. Sim. Sim. Mas o informante diz que eles n√£o sabem o que eles. ACM, ACM ID do fornecedor √©. E no pr√≥ximo caso, podemos desativar este ACM ID e posicionar s√£o de. N√≥s veremos. Sim, n√≥s veremos se podemos. Se podemos tentar particion√°-lo novamente, porque sim, eu mostrei no bilhete de atendimento na nossa aba de discuss√£o. Existem dois fornecedores com que est√£o atualmente existentes, que √© um tendo este ACM ID e o outro n√£o tem ACM ID n√£o tem ACM mapeamento de ACM ainda. Ent√£o √© por isso que eu sugeri pedir √† equipe do banco se este √© deles. Eles n√£o sabem. Isso. Eles n√£o sabem esta informa√ß√£o. Mas. N√≥s pensamos que podemos desativar o ACM e particion√°-lo horas. Porque eles n√£o passam. Eles n√£o conhecem esta informa√ß√£o, que √© o ACM ID deste fornecedor. Mas eles ainda est√£o usando este fornecedor, certo? Sim. Eu n√£o sei. N√£o tenho certeza. N√≥s conversamos com o banco. Ent√£o eles j√° sabem que n√≥s pedimos para voc√™. Estamos pedindo para voc√™ ativar este ACM. Sim, n√£o tenho certeza se o PCM ID pode ser desativado, j√° que na verdade estes dados est√£o vindo do sistema ERP. Ent√£o, se eles n√£o sabem. Ent√£o, se voc√™ est√° perguntando para a equipe local da equipe do banco, talvez voc√™ tamb√©m possa sugerir se se a equipe ERP deles sabe estes dados. Mas sim, por enquanto, veremos se se os dados para o. Os dados podem ser mapeados para cada um dos fornecedores que eu mostrei que eu mostrei a voc√™ no. Na captura de tela. Que eu forneci. Okay. Ent√£o, agora n√£o podemos desativar este ACM. Precisamos com o banco novamente. Certo. Sim. Sim. Especificamente, talvez como sua equipe ERP em vez disso. Porque eu n√£o acho que a equipe local sabe de onde estes dados est√£o vindo. Mas sim, tanto quanto eu sei, isto est√° integrado em que √© ou estes dados est√£o vindo do sistema ERP em vez disso. Okay. N√≥s vamos verificar novamente. E deixe voc√™. Claro. Por enquanto, eu farei o meu melhor para manter o bilhete de atendimento aberto por enquanto. Okay. Sim, ent√£o eu acho que isso tamb√©m, voc√™ tem perguntas para estes dois itens para o ptp antes de passarmos para os itens SCC. Okay. Okay. Obrigado. Okay. Ent√£o, para os itens S2C. Ent√£o sim, temos dois itens aqui, que √© em rela√ß√£o ao modelo SLP. Ajuste no modelo SLP e o. Ent√£o para os itens S2, ambos estes est√£o atualmente ainda em andamento devido √† sincroniza√ß√£o que est√° acontecendo entre os sistemas de produ√ß√£o e teste. Ent√£o para o segundo item. Sim, ent√£o para este, para este conhecido, nenhuma modifica√ß√£o conhecida √© permitida por enquanto, j√° que sim. Precisamos esperar por esta sincroniza√ß√£o sincroniza√ß√£o para terminar. E eu acho que temos mais um item eu n√£o fui capaz de adicion√°-lo aqui. Sim, ent√£o para este pedido seu, eu te amo. Eu acredito com rela√ß√£o a este. T√£o. N√≥s verificaremos isto internamente. Ent√£o, uma vez que recebermos uma conclus√£o para este, n√≥s o atualizaremos em conformidade. Okay. Obrigado. Sim, eu adicionarei isto ao leia o. Desculpe, eu esqueci de adicionar isto ainda. Mas sim, n√≥s verificaremos isto na internet. Ent√£o me avise quando seu ambiente de teste, √© uma atualiza√ß√£o muito grande. Sim. Sim, n√≥s entraremos em contato com voc√™ tamb√©m para isso. Okay. Sim, ent√£o √© tudo da minha parte. Voc√™ tem outras perguntas ou preocupa√ß√µes que podemos abordar na chamada antes de terminarmos isto? N√£o, da minha parte. N√£o. Voc√™s? Eu tamb√©m n√£o. Okay. Obrigado. Primeiro, obrigado. Obrigado a todos. E sim, eu enviarei as atas da reuni√£o ap√≥s a chamada. Ent√£o sim, obrigado a todos. E eu desejo a voc√™s um √≥timo dia pela frente. Tchau."

Espero que isso ajude! Avise-me se precisar de mais alguma coisa.

User: Resuma essa reuni√£o com os pontos importantes.
Assistant: Assistant: Claro, aqui est√° um resumo dos pontos importantes da reuni√£o:

**ARIBA:**

*   **Mudan√ßa de Nome de Dom√≠nio:** Estendida at√© 31 de janeiro de 2026. Fl√°vio deve verificar o progresso.
*   **Conex√£o TLS 1.2:** Prazo para transfer√™ncia √© 30 de abril. J√° foi finalizada (linha 5). Solicitaram screenshots como evid√™ncia.
*   **Renova√ß√£o de Certificado:** Aguardando informa√ß√µes para fornecer via ticket ou e-mail.
*   **Ambiente Livre para S2C:** Testes relacionados aos contratos de fornecedores em andamento. Aguardando t√©rmino do projeto.
*   **Monitoramento Di√°rio:** Verificar o arquivo de monitoramento do Brasil e o erro no PR.

**KPIs de Produ√ß√£o:**

*   Sem altera√ß√µes em rela√ß√£o √† semana anterior.

**Status dos Tickets P2P:**

*   Seis tickets resolvidos.
*   **PR em Processamento de Pedido (Vers√£o 3):** Erro na Vers√£o 2. Aguardando agendamento de reuni√£o com o fornecedor Arriba.
*   **Problema de Integra√ß√£o:** Accenture discutir√° com o fornecedor SAP Arriba e atualizar√° o ambiente de teste.
*   **Fornecedor com Problemas no ACM ID:** Verificar com a equipe do banco (possivelmente a equipe ERP) e desativar o ACM ID.

**Itens S2C:**

*   Ajuste no modelo SLP em andamento, aguardando sincroniza√ß√£o entre os sistemas de produ√ß√£o e teste.
*   Solicita√ß√£o de atualiza√ß√£o do ambiente de teste ser√° verificada internamente.

**Geral:**

*   Coordenar a atualiza√ß√£o do ambiente de teste com a equipe do projeto.
*   As atas da reuni√£o ser√£o enviadas ap√≥s a chamada.
User: Preciso de mais detalhes sobre o fornecedor que n√£o est√° particionando.
Assistant: Assistant: Ok, com base no di√°logo, aqui est√£o os detalhes sobre o fornecedor com problemas de parti√ß√£o:

*   **Problema:** O fornecedor n√£o est√° sendo particionado corretamente.
*   **Causa:** Existe um problema com o ACM ID (Ariba Cloud Module ID) do fornecedor.
*   **Situa√ß√£o Atual:**
    *   A Tadita est√° coordenando com a equipe do banco para confirmar o ACM ID.
    *   J√° existem dois fornecedores: um com o ACM ID problem√°tico e outro sem nenhum ACM ID.
    *   A equipe do banco (local) n√£o reconhece o ACM ID existente.
*   **A√ß√µes:**
    *   Sugeriu-se questionar a equipe ERP do banco sobre o ACM ID, pois esses dados geralmente v√™m do sistema ERP.
    *   A equipe est√° considerando desativar o ACM ID problem√°tico e tentar particionar novamente o fornecedor.
    *   A equipe precisa verificar com o banco novamente (especificamente a equipe ERP) antes de desativar o ACM ID.

Em resumo, o problema parece estar relacionado √† identifica√ß√£o e ao gerenciamento do ACM ID do fornecedor no sistema banc√°rio, o que est√° impedindo a parti√ß√£o correta no Ariba.

User: ou cannot associate a common supplier with multiple partitioned suppliers. The partitioned supplier BR3-1_19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA cannot be associated with the common supplier 19381564000140, because this common supplier is already associated with BR1-19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA.
Error executing trigger IntegrationPostLoad on [ariba.common.core.Supplier [BaseId 13436469218331 B+RQAGmDDhr+Ywb 4rgmmupsr.1qa9cqee]] with data {
AmountRoundingForInvExceptionCalculation = "File \"SupplierConsolidated.csv\" (line 15, column AmountRoundingForInvExceptionCalculation): '0'";
CommonSupplier = {
CorpAddrCountry = "File \"SupplierConsolidated.csv\" (line 15, column Country): 'BR'";
CorpAddrLines = "File \"SupplierConsolidated.csv\" (line 15, column Street): 'R GUARARAPES 2064 - 7 ANDAR - BROOKLIN PAULISTA'";
CorpAddrState = "File \"SupplierConsolidated.csv\" (line 15, column State): 'SP'";
CorporateAddress = {
UniqueName = "File \"SupplierConsolidated.csv\" (line 15, column AddressID): 'BR3-1_19381564000140'";
};
CorporateEmailAddress = "File \"SupplierConsolidated.csv\" (line 15, column CorporateEmailAddress): 'rtrevizan@mantris.com.br'";
CorporatePhone = "File \"SupplierConsolidated.csv\" (line 15, column CorporatePhone): '11 944775350'";
HasSyncRelationship = "File \"SupplierConsolidated.csv\" (line 15, column HasSyncRelationship): 'false'";
HasTradingRelationship = "File \"SupplierConsolidated.csv\" (line 15, column HasTradingRelationship): 'false'";
Name = "File \"SupplierConsolidated.csv\" (line 15, column Name): 'MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA'";
PreferredCurrency = {
UniqueName = "File \"SupplierConsolidated.csv\" (line 15, column PreferredCurrency): 'BRL'";
};
PreferredLanguage = {
UniqueName = "File \"SupplierConsolidated.csv\" (line 15, column PreferredLanguage): 'BrazilianPortuguese'";
};
SystemID = "File \"SupplierConsolidated.csv\" (line 15, column SystemID): 'ACM_72530498'";
};
Name = "File \"SupplierConsolidated.csv\" (line 15, column Name): 'MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA'";
PaymentModel = "File \"SupplierConsolidated.csv\" (line 15, column PaymentModel): '-1'";
SubContractor = "File \"SupplierConsolidated.csv\" (line 15, column SubContractor): '0'";
UniqueName = "File \"SupplierConsolidated.csv\" (line 15, column VendorID): 'BR3-1_19381564000140'";
}

o que est√° dizendo nesse erro ?
2025-04-10 16:48:40,524 [INFO] Resposta da IA (imagem): Assistant: O erro indica que voc√™ est√° tentando associar um fornecedor comum a m√∫ltiplos fornecedores particionados, o que n√£o √© permitido no sistema Ariba.

**Detalhes do Erro:**

*   **Mensagem principal:** "Voc√™ n√£o pode associar um fornecedor comum com m√∫ltiplos fornecedores particionados."
*   **Fornecedor particionado com problema:** `BR3-1_19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`
*   **Fornecedor comum:** `19381564000140`
*   **Fornecedor particionado j√° associado ao fornecedor comum:** `BR1-19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`

**Interpreta√ß√£o:**

O sistema j√° tem o fornecedor comum `19381564000140` associado ao fornecedor particionado `BR1-19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`. Voc√™ est√° tentando associar o mesmo fornecedor comum ao fornecedor particionado `BR3-1_19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`, o que causa o erro.

**Poss√≠veis Causas:**

*   **Configura√ß√£o Incorreta:** Pode haver um erro na forma como os fornecedores est√£o configurados no sistema Ariba.
*   **Dados Duplicados:** Possivelmente h√° dados duplicados ou conflitantes na importa√ß√£o do arquivo `SupplierConsolidated.csv`.
*   **L√≥gica de Particionamento Inadequada:** A l√≥gica de particionamento pode n√£o estar funcionando corretamente, resultando em tentativas de associa√ß√µes inv√°lidas.

**Informa√ß√µes Adicionais do Log:**

O log tamb√©m fornece informa√ß√µes sobre os dados do fornecedor que est√£o sendo processados a partir do arquivo `SupplierConsolidated.csv`, incluindo:

*   Nome do fornecedor: `MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`
*   Endere√ßo: `R GUARARAPES 2064 - 7 ANDAR - BROOKLIN PAULISTA`
*   Pa√≠s: `BR`
*   Estado: `SP`
*   E-mail: `rtrevizan@mantris.com.br`
*   Telefone: `11 944775350`
*   ID do sistema: `ACM_72530498`

**Pr√≥ximos Passos:**

1.  **Verifique a configura√ß√£o dos fornecedores:** No sistema Ariba, examine a configura√ß√£o dos fornecedores `BR3-1_19381564000140`, `BR1-19381564000140` e `19381564000140` para identificar quaisquer erros.
2.  **Analise o arquivo `SupplierConsolidated.csv`:** Verifique a linha 15 (onde o erro foi detectado) para garantir que os dados do fornecedor estejam corretos e consistentes.
3.  **Revise a l√≥gica de particionamento:** Certifique-se de que a l√≥gica de particionamento est√° configurada corretamente para evitar associa√ß√µes inv√°lidas.
4.  **Remova ou corrija a associa√ß√£o existente:** Se a associa√ß√£o entre o fornecedor comum e o fornecedor particionado `BR1-19381564000140` estiver incorreta, remova-a ou corrija-a antes de tentar associar o fornecedor comum a `BR3-1_19381564000140`.

Lembre-se de que a solu√ß√£o exata depender√° da sua configura√ß√£o espec√≠fica do Ariba e da sua l√≥gica de particionamento.
2025-04-10 16:48:40,608 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 16:48:40,609 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 16:48:40,611 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 16:48:40,613 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 16:48:40,614 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 16:48:40,616 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 16:48:40,617 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 16:48:40,619 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 16:48:40,621 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 16:48:40,622 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 16:48:40,624 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 16:48:40,625 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 16:48:40,627 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 16:48:40,628 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 16:48:40,629 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:09:16,465 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:09:16,467 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:09:16,469 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:09:16,470 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:09:16,472 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:09:16,473 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:09:16,475 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 17:09:16,476 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:09:16,477 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:09:16,479 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:09:16,480 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:09:16,481 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:09:16,483 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:09:16,484 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 17:09:16,486 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:09:16,629 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:09:16,631 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:09:16,633 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:09:16,635 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:09:16,637 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:09:16,639 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:09:16,641 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 17:09:16,643 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:09:16,645 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:09:16,647 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:09:16,648 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:09:16,650 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:09:16,652 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:09:16,653 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 17:09:16,655 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:09:23,896 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:09:23,897 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:09:23,898 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:09:23,900 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:09:23,902 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:09:23,904 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:09:23,905 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 17:09:23,907 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:09:23,908 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:09:23,910 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:09:23,911 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:09:23,912 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:09:23,914 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:09:23,915 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 17:09:23,917 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:09:24,074 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:09:24,075 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:09:24,077 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:09:24,078 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:09:24,080 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:09:24,081 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:09:24,082 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 17:09:24,084 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:09:24,086 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:09:24,089 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:09:24,092 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:09:24,094 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:09:24,096 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:09:24,097 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 17:09:24,099 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:09:24,118 [INFO] Enviando para IA - Imagem: C:\Users\jfreis\Documents\azure-ai-sentiment-analysis\assets\20250410170924_clipboard_20250410170916.png, Prompt: Voc√™ √© um assistente inteligente utilizado em um chat com IA, que recebe c√≥digos de uma aplica√ß√£o completa de chat, como voc√™ funciona e tudo que 
√© programado para fazer no seu contexto.

Seu objetivo √©:
- Analisar todo o contexto e aprender com ele.
- Analisar a Pergunta do Usu√°rio.
- Identificar se possui rela√ß√£o com o contexto.
- Se houver rela√ß√£o com o c√≥digo do contexto responder a pergunta sobre o c√≥digo sempre seguindo boas pr√°ticas:
    - Analisar o c√≥digo-fonte contido no projeto enviado
    - Identificar melhorias em legibilidade, performance e seguran√ßa
    - Sugerir pr√°ticas recomendadas de design e arquitetura
    - Indicar partes com d√≠vidas t√©cnicas ou complexidade desnecess√°ria
    - Enviar c√≥digo modularizado em pequenos arquivos separados por pastas.

Informa√ß√µes adicionais:
- Estrutura do projeto: segue o padr√£o de pastas iniciando por src/


## Se houver imagem no contexto, identifique se a pergunta √© sobre o c√≥digo do contexto, sobre a imagem ou sobre os dois para elaborar melhorer respostas.
## Se o usu√°rio fizer uma pergunta que n√£o tem rela√ß√£o com imagem ou contexto, use a sua base de conhecimento fora do contexto para responder de forma inteligente.
** Responda em Portugu√™s-Brasileiro a n√£o ser que o usu√°rio solicite outra l√≠ngua.**

Contexto:



# chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# main.py

# main.py
from core.handlers.signal_handler import setup_signal_handler
from services.image_processor import ImageProcessor
from core.rate_limiter import RateLimiter
import json

def main():
    setup_signal_handler()

    # Inicializa o RateLimiter com o n√∫mero m√°ximo de requisi√ß√µes e o per√≠odo
    rate_limiter = RateLimiter(max_requests=9, period_seconds=60)  # 9 requisi√ß√µes por minuto

    # Passa o RateLimiter para o ImageProcessor
    processor = ImageProcessor(rate_limiter)
    processor.process_images()

    # Obter e imprimir o hist√≥rico ap√≥s o processamento
    history = processor.get_history()
    for item in history:
        print(f"Imagem: {item['image_name']}, Resumo: {item['summary']}")

    # Salvar o hist√≥rico em um arquivo JSON
    with open(processor.historico_json_file, "w") as f:
        json.dump(history, f, indent=4)

if __name__ == "__main__":
    main()

# services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# test_image_generation.py

import os
from dotenv import load_dotenv
from google import genai
from google.generativeai import types
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

client = genai.Client(api_key=api_key)

prompt = "gerar a imagem do simbolo do corinthians."

response = client.models.generate_content(
    model='gemini-2.0-flash-exp-image-generation',
    contents=prompt,
    config=types.GenerateContentConfig(
        response_modalities=['Text', 'Image']
    )
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = Image.open(BytesIO(part.inline_data.data))
        image.save("ed-image.png")
        image.show()

# utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

User: fa√ßa code review da minha aplica√ß√£o.
Assistant: Com certeza! Analisei o c√≥digo da sua aplica√ß√£o e preparei algumas sugest√µes para melhorias em legibilidade, performance, seguran√ßa e design.

**1. Estrutura e Modulariza√ß√£o:**

*   **Diret√≥rios:** Organize melhor os arquivos dentro de `src`. Crie subdiret√≥rios para `models`, `services`, `handlers`, `utils`, `config`, etc. Isso facilita a localiza√ß√£o dos arquivos e a compreens√£o da estrutura do projeto.
*   **Arquivo de configura√ß√£o:** Mova a classe `Config` para um arquivo separado (ex: `config.py`) dentro de um diret√≥rio `config`.
*   **Fun√ß√µes:** Quebre fun√ß√µes grandes em fun√ß√µes menores e mais focadas. Isso melhora a legibilidade e facilita o teste.

**2. Boas Pr√°ticas e Melhorias no C√≥digo:**

*   **Rate Limiting:** Implemente o `RateLimiter` nos servi√ßos que consomem a API do Gemini (ex: `ImageProcessor`, `GeminiHandler`). Isso evita sobrecarga na API e garante um uso mais eficiente.
*   **Configura√ß√µes:** Use a classe `Config` para centralizar todas as configura√ß√µes da aplica√ß√£o (ex: chaves de API, modelos, diret√≥rios). Isso facilita a manuten√ß√£o e a configura√ß√£o do projeto.
*   **Logging:** Padronize o uso do logger em toda a aplica√ß√£o. Use os n√≠veis de log apropriados (ex: `info`, `warning`, `error`) para cada tipo de mensagem.
*   **Tratamento de Erros:** Adicione tratamento de erros mais espec√≠fico em cada fun√ß√£o. Isso ajuda a identificar e corrigir problemas mais rapidamente.
*   **Cache:** Utilize o `st.cache_resource` para fun√ß√µes que realizam opera√ß√µes custosas, como a inicializa√ß√£o do `GeminiHandler`. Isso evita a execu√ß√£o repetida dessas opera√ß√µes.
*   **Tipagem:** Utilize tipagem est√°tica (type hints) para melhorar a legibilidade e a seguran√ßa do c√≥digo.
*   **Imagens:** Valide se `uploaded_file` √© realmente um arquivo de imagem antes de tentar exibi-lo, evitando erros caso o usu√°rio envie um arquivo de outro tipo.
*   **Prompts:** Crie arquivos de prompt separados para diferentes tarefas (ex: chat, an√°lise de imagem). Isso facilita a manuten√ß√£o e a personaliza√ß√£o dos prompts.

**3. Seguran√ßa:**

*   **Chaves de API:** Nunca coloque suas chaves de API diretamente no c√≥digo. Use vari√°veis de ambiente ou um arquivo de configura√ß√£o seguro para armazen√°-las.
*   **Valida√ß√£o de Input:** Valide todos os inputs do usu√°rio para evitar ataques de inje√ß√£o de c√≥digo.

**4. Arquitetura:**

*   **Camadas:** Defina claramente as responsabilidades de cada camada da sua aplica√ß√£o (ex: apresenta√ß√£o, l√≥gica de neg√≥cios, acesso a dados). Isso facilita a manuten√ß√£o e a evolu√ß√£o do projeto.
*   **Invers√£o de Depend√™ncia:** Use invers√£o de depend√™ncia para desacoplar as diferentes partes da sua aplica√ß√£o. Isso facilita o teste e a substitui√ß√£o de componentes.
*   **Testes:** Escreva testes unit√°rios e de integra√ß√£o para garantir a qualidade do seu c√≥digo.

**5. D√≠vidas T√©cnicas e Complexidade:**

*   **Fun√ß√µes Longas:** Identifique fun√ß√µes com muitas linhas de c√≥digo e divida-as em fun√ß√µes menores e mais focadas.
*   **L√≥gica Duplicada:** Elimine a l√≥gica duplicada criando fun√ß√µes ou classes reutiliz√°veis.
*   **Coment√°rios:** Adicione coment√°rios para explicar o que o c√≥digo faz, especialmente em partes complexas.

**Exemplo de Refatora√ß√£o:**

Aqui est√° um exemplo de como voc√™ pode refatorar a fun√ß√£o `process_images` na classe `ImageProcessor`:

```python
# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self._post_process_image(image_name, summary)
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _post_process_image(self, image_name, summary):
        self.document_service.add_image_summary(image_name, summary)
        self.markdown_service.add_image_summary(image_name, summary)
        self.document_service.save_document()
        self.markdown_service.save_markdown()

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history
```

**6. C√≥digo Modularizado:**

Para facilitar a visualiza√ß√£o e a organiza√ß√£o, preparei o c√≥digo modularizado em arquivos separados:

```
src/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gemini_handler.py
‚îÇ   ‚îú‚îÄ‚îÄ logger_config.py
‚îÇ   ‚îî‚îÄ‚îÄ rate_limiter.py
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ document_service.py
‚îÇ   ‚îú‚îÄ‚îÄ gpt_services.py
‚îÇ   ‚îú‚îÄ‚îÄ image_processor.py
‚îÇ   ‚îú‚îÄ‚îÄ markdown_service.py
‚îÇ   ‚îî‚îÄ‚îÄ search_files.py
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ file_utils.py
```

**Observa√ß√µes Finais:**

*   A implementa√ß√£o de todas essas sugest√µes pode levar tempo, mas o resultado final ser√° um c√≥digo mais organizado, leg√≠vel, seguro e f√°cil de manter.
*   Priorize as melhorias que trazem o maior impacto no seu projeto.
*   Use um sistema de controle de vers√£o (ex: Git) para acompanhar suas mudan√ßas e facilitar a colabora√ß√£o com outros desenvolvedores.

Se tiver alguma d√∫vida sobre alguma dessas sugest√µes, √© s√≥ perguntar!
User: Extraia o CNPJ dessa imagem.
Assistant: A imagem cont√©m um comprovante de inscri√ß√£o e de situa√ß√£o cadastral. O CNPJ presente na imagem √©:

`33.024.232/0001-39`
User: extraia o n√∫mero do chamado que come√ßa com  2025
Assistant: O n√∫mero do chamado que come√ßa com 2025 na imagem √©:

`2025040185005611`

User:  Okay, sorry, this is. Okay, so welcome everyone. So our week we call for Brazil at a ca Dow. So for today, we will discuss the following the ARIBA, the production API, the P2P and S2C ticket status updates. And if we have business processes and change management. So for the ARIBA, here are depending the number of pending decisions and open actions. So we have. So for all we have one action and one information and then. For ERP team, we have two actions and two information. So we have a total of six. So let me go to the ARIBA file. Okay, so here are the items that we have in the ARIBA file. So for the first one, we have the domain name change. So for this one, so this is actually extended until January 31, 2026. But yeah, Flavio, I just want to know if we have progress on this one. I need to check and then I get back to you on this. On this sheet, please. Okay, thank you so much. Okay, so. You have included another one. Yes, that's correct. Yeah, so for the next one, we actually have also the TLS 1 point to connection. To. To be transferred to a TLS 1 point. So this is also for your team to check. So the deadline for this one will be on April 30. So do we have also progress on this one or not yet? I believe that I already described my current situation on a column. On the right on the right. You can find my call up. Sorry, here or on the tracker file, be the change. Sorry, let me check. This one. This one. I'm not sure where are the comments that you have. No, I just have my clue comments about the first one in the second and the TLS. So we are already done. The line five. Let me see if I can. Is it. Ah, this one. Okay. Okay, so this is already close. Yes, this. Yeah. So for that one, could you please provide screen shots here if possible? To stretch. Yes, just to show that it is already deployed on your system. As an evidence. Okay. Thank you so much. Okay. Okay, so let me remove this one also. I don't know why this one educated. Okay, so for the next two items is read your cards to the certificate renewal. So this is still for information only once the assertifcates have been released by. So I will be able to provide it to you also. Either in the juror ticket or via. So actually this should not be in progress. Okay. And then for the next one, we have also the. This environment frees for the. Parent real. Or the for the S to see items actually so. This is still ongoing right now. So we are checking internally with the project team when. This project will end. So for now. All the test things for the. Related to a supplier's contracts. Our entries for now. And lastly for the daily monitor and so since Ricardo is not here. Yes, so. Oh, sorry, I did hear. So just so this is a reminder for. That for them to check the. Monitoring file for Brazil. So actually. We are encountering some or we are a cap we have some documents captured in the daily monitoring. So if you could also help with the card to check this capture documents that would be appreciated. I'm not sure if this is the correct. Okay, so this is still on March. Let me just change this one. Okay. Okay. Let me share my screen. Okay, so this is actually the. Monitoring file for Brazil. So right now we only for now we have one so we are still updating the monitoring file. So yeah, if you could help check this one. And see why this PR is having an error in the. Are you beside or in the air beside render. So this is the. What they call this the error message that was encountered. So yeah, if you could check this on the ER beside it would be appreciate. For the other. I don't think we have some captured documents yet. Yeah, so for now we'll be have one. Just this one. So yeah, that's all for the items. So they have questions before move on to our next items. No, please go ahead. Okay, thank you so much. Okay, so for the production KPIs, it's the same as the last week as discussed. So they are the numbers or the figures for the documents for the transactions in harriba and for the care tickets that have been taken by a to an L3. So as for the P2P tickets status update so for the past week we. So we have a result or we handled six tickets for P2P and as for the open items. So for the first one we have the issue with regards to the PR that is in order processing status. So for this one, yeah, the current issue is that this PR is currently in version three and it is showing an error that the version two has been has been stopping ordering. However, we cannot. Reprocess this one on the CIG side, so that's why we raise an SR for this one. Or an Arriba case. So right now we are trying to set up a call with the Arriba vendor as they are also asking for our availability. So once we have established a schedule for the meeting and discuss this with the Arriba vendor. So we will update the care ticket about the discussion. And for the next one, we have the integration issue for this supply. Can I attend to the point one please. So we are pending Arriba vendor get back to us with a viable time slots to have a conversation. So for this one, we so the Accenture team will discuss this first with the SAP Arriba vendor as we have all the details already. So if so we will discuss all the investigations that we had so far in order to help them further investigate this issue. But according to the plan for the city reader, we also talk about the updating of our environment of testing. If I'm not wrong. That the queue us or the. We have plenty to update our environment of testing. And the QA test test environment. The point is I need to go ahead with our S a p requirements that I have shared with you by. Sorry. So I don't know if this point is blocking our evaluation regarding to S a p. This is the point. The one that you have in email or. Yeah, 200 for eight or far nine. S a p requirements. I mean, we'll have on this. Let me see if I can. The line eight. Are you have very an update in this one? Yes, so for this one, this is only in a riba side of love you and not on the other side. Yeah, but. I'm aware about S a p. The point for me is S a p evaluation. So I need to implement new requirements. My S a p environment in production. So I don't know if the test environment. We need to be update in order to go ahead with this S a p new requirements. Yeah, so for this one of lab, you I think we need to. Wait for the synchronization of the data from the production system to the test environment to be finished. So we do implementations of data changes or. To do some. Testing scenarios in the S to see part. Yeah, but when we are when we will be ready. I have mentioned earlier, we will coordinate this with the project team who's doing the project for this project specifically and ask them when this will be finished as the. Other conscious and Bruno is also asking for this one. So we will update you accordingly regarding this one. Okay. Thank you. Okay. Yeah, so let me discuss first the B to B items. Okay, so for the next one, we have the issue with regards to this supplier. Which was raised by a Tadita. So for this one, they are. And the Tadita mentioned in the ticket that they are coordinating with the bank team for the confirmation of the ACM ID for the supplier. And the last update was made to me about this ticket. And the next one is explained to the explain needs to be created, which already exists. And the value one B are one data needs to be partitioned into to these other suppliers. And that after this is done, they will probably you will proceed with the supplier patchy partitioning for a base trace attack. Yes. Yeah. And you also ask to ask to us to check with the bank if the ACM ID of the supplier is a 35 for. Yes. Something. I don't remember everything. This one. Yeah. Yeah. But the informant says that they don't know what they. ACM, ACM ID of the supplier is. And the next case, can we deactivate this ACM ID and position are from. We will see. Yeah, we will see if we can. If we can try to partition it again, because yes, I have showed in the ticket on our discussion tab. There are two suppliers with that are currently existing, which is one having this ACM ID and the other has no ACM ID has no ACM ACM ID mapping yet. So that's why I suggested to ask the bank team if this is their. They don't know. That's. They don't know this. So. This don't they don't know this information. But. We thought that we can deactivate the ACM and partition it hours. Because they don't pass. They don't know this information, which is ACM ID from this supplier. But they are still using this supplier, right? Yeah. I don't know. Don't sure. We we we talked to the bank. So they were they are already know that we ask to you. We are asking to you to activate this ACM. Yeah, I'm not sure if PCM ID can be deactivated since actually this data is coming from the ERP system. So if they don't know. So if you're asking the local team of the bank team, maybe you can also suggest if if they're ERP team knows this data. But yeah, for now, we will see if if the data for the. The data can be mapped to each to one of the suppliers that I have showed I have shown you in the. In the screenshot. That I have provided. Okay. So right now we can deactivate this ACM. We need to with the bank again. Right. Yes. Yes. Yes. Specifically, maybe as their ERP team instead. Because I don't think the local team knows where this data is coming from. But yeah, as far as I'm concerned, this is integrated in that is or this is this data is coming from the ERP system rather. Okay. We're going to check again. And let you. Sure. For now, we will I will do my best to keep the ticket open for now. Okay. Yeah, so I think that's also do you have questions for these two items for the ptp before we move on to SCC items. Okay. Okay. Thank you. Okay. So for the S2C items. So yeah, we have two items here, which is with regards to the SLP template. Adjustment in SLP template and the. So for the S2 items, both of these are currently still in progress due to the synchronization that is happening between the production and test systems. So for the second item. Yeah, so for this one, this for this one, known, known modifications are allowed for now since yeah. We need to wait for this synchronization synchronization to be finished. And I think we have one more item I haven't I wasn't able to add it here. Yeah, so for this request from you, I love you. I believe with regards to this one. So. We will we are still checking this internally. So once we receive a conclusion for this one, we will update you accordingly. Okay. Thank you. Yeah, I will add this to the read the. Sorry, I forgot to add this yet. But yeah, we will check this internet. So let me know when you test environment, it's a very uploaded. Yeah. Yeah, we will get back to you also for that. Okay. Yeah, so that's all from my side. Do you have other questions or concerns that we can address in the call before we end this? No, for my side. No. Are you guys? Me neither. Okay. Thank you. First one, thank you. Thank you, Ray. Thank you, everyone. And yeah, I will send the minutes of the meeting after the call. So yeah, thank you, everyone. And I wish you a great day ahead. Bye.

Traduza para pt-br
Assistant: Okay, aqui est√° a tradu√ß√£o para portugu√™s brasileiro do di√°logo fornecido:

"Okay, desculpem, √© isso. Okay, ent√£o bem-vindos a todos. Ent√£o, nossa semana chamamos para Brasil na CA Dow. Ent√£o, para hoje, vamos discutir o seguinte: o ARIBA, a API de produ√ß√£o, o P2P e atualiza√ß√µes de status de tickets S2C. E se tivermos processos de neg√≥cios e gest√£o de mudan√ßas. Ent√£o, para o ARIBA, aqui est√£o dependendo o n√∫mero de decis√µes pendentes e a√ß√µes em aberto. Ent√£o n√≥s temos. Ent√£o, para todos n√≥s temos uma a√ß√£o e uma informa√ß√£o e ent√£o. Para a equipe ERP, temos duas a√ß√µes e duas informa√ß√µes. Ent√£o, temos um total de seis. Ent√£o, deixe-me ir para o arquivo ARIBA. Okay, ent√£o aqui est√£o os itens que temos no arquivo ARIBA. Ent√£o, para o primeiro, temos a mudan√ßa de nome de dom√≠nio. Ent√£o, para este, isso √© realmente estendido at√© 31 de janeiro de 2026. Mas sim, Fl√°vio, eu s√≥ quero saber se temos progresso neste. Eu preciso verificar e ent√£o eu volto para voc√™ neste. Nesta folha, por favor. Okay, muito obrigado. Okay, ent√£o. Voc√™ incluiu outro. Sim, est√° correto. Sim, ent√£o para o pr√≥ximo, n√≥s realmente temos tamb√©m a conex√£o TLS 1 ponto para. Para. Para ser transferida para um TLS 1 ponto. Ent√£o isso tamb√©m √© para sua equipe verificar. Ent√£o o prazo para este ser√° em 30 de abril. Ent√£o, n√≥s temos tamb√©m progresso neste ou ainda n√£o? Eu acredito que eu j√° descrevi minha situa√ß√£o atual em uma coluna. Na direita, na direita. Voc√™ pode encontrar minha chamada. Desculpe, aqui ou no arquivo de rastreamento, seja a mudan√ßa. Desculpe, deixe-me verificar. Este. Este. Eu n√£o tenho certeza onde est√£o os coment√°rios que voc√™ tem. N√£o, eu s√≥ tenho meus coment√°rios de pistas sobre o primeiro e o segundo e o TLS. Ent√£o, j√° terminamos. A linha cinco. Deixe-me ver se eu posso. √â isso. Ah, este. Okay. Okay, ent√£o isso j√° est√° fechado. Sim, isto. Sim. Ent√£o para isso, voc√™ poderia por favor fornecer capturas de tela aqui se poss√≠vel? Para alongar. Sim, apenas para mostrar que j√° est√° implantado em seu sistema. Como uma evid√™ncia. Okay. Muito obrigado. Okay. Okay, ent√£o deixe-me remover este tamb√©m. Eu n√£o sei por que este educado. Okay, ent√£o para os pr√≥ximos dois itens √© ler seus cart√µes para a renova√ß√£o do certificado. Ent√£o, isto ainda √© apenas para informa√ß√£o, uma vez que os assertifcates tenham sido liberados por. Ent√£o eu poderei fornec√™-lo a voc√™ tamb√©m. Seja no ingresso do j√∫ri ou via. Ent√£o, na verdade isso n√£o deveria estar em andamento. Okay. E ent√£o para o pr√≥ximo, temos tamb√©m o. Este ambiente libera para o. Real pai. Ou o para os itens S para ver realmente t√£o. Isto ainda est√° em andamento agora. Ent√£o estamos verificando internamente com a equipe do projeto quando. Este projeto terminar√°. Ent√£o por agora. Todas as coisas de teste para o. Relacionado aos contratos de um fornecedor. Nossas entradas por enquanto. E, finalmente, para o monitor di√°rio e ent√£o, j√° que Ricardo n√£o est√° aqui. Sim, ent√£o. Oh, desculpe, eu ouvi aqui. Ent√£o, apenas ent√£o isso √© um lembrete para. Que para eles verifiquem o. Arquivo de monitoramento para o Brasil. Ent√£o, realmente. Estamos encontrando alguns ou estamos um cap n√≥s temos alguns documentos capturados no monitoramento di√°rio. Ent√£o, se voc√™ tamb√©m pudesse ajudar com o cart√£o para verificar esses documentos capturados, seria apreciado. N√£o tenho certeza se isto est√° correto. Okay, ent√£o isto ainda est√° em mar√ßo. Deixe-me apenas mudar isto. Okay. Okay. Deixe-me compartilhar minha tela. Okay, ent√£o este √© realmente o. Arquivo de monitoramento para o Brasil. Ent√£o agora n√≥s apenas por enquanto temos um, ent√£o ainda estamos atualizando o arquivo de monitoramento. Ent√£o sim, se voc√™ pudesse ajudar a verificar este. E veja por que este RP est√° tendo um erro no. Voc√™ est√° ao lado ou no ar ao lado render. Ent√£o este √© o. O que eles chamam isto a mensagem de erro que foi encontrada. Ent√£o sim, se voc√™ pudesse verificar isso no ER ao lado, seria apreciado. Para os outros. Eu n√£o acho que temos alguns documentos capturados ainda. Sim, ent√£o por agora n√≥s teremos um. Apenas este. Ent√£o sim, √© tudo para os itens. Ent√£o eles t√™m perguntas antes de passarmos para nossos pr√≥ximos itens. N√£o, por favor prossiga. Okay, muito obrigado. Okay, ent√£o para os KPIs de produ√ß√£o, √© o mesmo que na semana passada, conforme discutido. Ent√£o eles s√£o os n√∫meros ou as figuras para os documentos para as transa√ß√µes em harriba e para os bilhetes de atendimento que foram tomados por um para um L3. Ent√£o, quanto √† atualiza√ß√£o do status dos bilhetes de atendimento P2P, ent√£o na semana passada n√≥s. Ent√£o temos um resultado ou lidamos com seis bilhetes de atendimento para P2P e quanto aos itens em aberto. Ent√£o, para o primeiro, temos o problema em rela√ß√£o ao PR que est√° em estado de processamento de pedidos. Ent√£o, para este, sim, o problema atual √© que este PR est√° atualmente na vers√£o tr√™s e est√° mostrando um erro de que a vers√£o dois tem interrompido a encomenda. No entanto, n√£o podemos. Reprocessar este no lado CIG, ent√£o √© por isso que levantamos um SR para este. Ou um caso Arriba. Ent√£o agora estamos tentando agendar uma chamada com o fornecedor Arriba, pois eles tamb√©m est√£o perguntando pela nossa disponibilidade. Ent√£o, uma vez que tenhamos estabelecido uma programa√ß√£o para a reuni√£o e discutirmos isso com o fornecedor Arriba. Ent√£o atualizaremos o bilhete de atendimento sobre a discuss√£o. E para o pr√≥ximo, temos o problema de integra√ß√£o para este fornecimento. Posso atender ao ponto um por favor. Ent√£o, estamos pendentes para que o fornecedor Arriba volte para n√≥s com hor√°rios vi√°veis para ter uma conversa. Ent√£o, para este, n√≥s, a equipe Accenture, discutiremos isso primeiro com o fornecedor SAP Arriba, pois j√° temos todos os detalhes. Ent√£o, se assim for, discutiremos todas as investiga√ß√µes que tivemos at√© agora, a fim de ajud√°-los a investigar ainda mais este problema. Mas de acordo com o plano para o leitor da cidade, tamb√©m falamos sobre a atualiza√ß√£o do nosso ambiente de teste. Se eu n√£o estiver enganado. Que o Q us ou o. Temos muito para atualizar nosso ambiente de teste. E o ambiente de teste QA. O ponto √© que eu preciso prosseguir com os nossos requisitos S a p que compartilhei com voc√™ por. Desculpe. Ent√£o, eu n√£o sei se este ponto est√° bloqueando a nossa avalia√ß√£o em rela√ß√£o ao S a p. Este √© o ponto. Aquele que voc√™ tem no e-mail ou. Sim, 200 para oito ou longe nove. Requisitos S a p. Quero dizer, n√≥s teremos neste. Deixe-me ver se eu posso. A linha oito. Voc√™ tem alguma atualiza√ß√£o nisto? Sim, ent√£o, para este, isto √© apenas no lado do Ariba do amor voc√™ e n√£o no outro lado. Sim, mas. Estou ciente sobre S a p. O ponto para mim √© a avalia√ß√£o S a p. Ent√£o eu preciso implementar novos requisitos. Meu ambiente S a p em produ√ß√£o. Ent√£o eu n√£o sei se o ambiente de teste. Precisamos ser atualizados para prosseguir com estes novos requisitos S a p. Sim, ent√£o, para este amor, voc√™, eu acho que precisamos. Espere pela sincroniza√ß√£o dos dados do sistema de produ√ß√£o para o ambiente de teste para terminar. Ent√£o n√≥s fazemos implementa√ß√µes de mudan√ßas de dados ou. Para fazer alguns. Cen√°rios de teste na parte S para ver. Sim, mas quando estaremos prontos. Eu mencionei anteriormente, coordenaremos isto com a equipe do projeto que est√° fazendo o projeto para este projeto especificamente e perguntaremos quando isto terminar√° como o. Outro consciente e Bruno tamb√©m est√° pedindo por isso. Ent√£o n√≥s o atualizaremos em conformidade em rela√ß√£o a este. Okay. Obrigado. Okay. Sim, ent√£o deixe-me discutir primeiro os itens B para B. Okay, ent√£o para o pr√≥ximo, temos o problema em rela√ß√£o a este fornecedor. Que foi levantado por um Tadita. Ent√£o, para este, eles est√£o. E o Tadita mencionou no bilhete de atendimento que eles est√£o coordenando com a equipe do banco para a confirma√ß√£o do ACM ID para o fornecedor. E a √∫ltima atualiza√ß√£o foi feita para mim sobre este bilhete de atendimento. E o pr√≥ximo precisa ser criado, o que j√° existe. E o valor um B s√£o um dados precisa ser particionado em para estes outros fornecedores. E que depois que isso for feito, eles provavelmente prosseguir√£o com a parti√ß√£o do fornecedor para um ataque de rastreamento base. Sim. Sim. E voc√™ tamb√©m pede para nos pedir para verificar com o banco se o ACM ID do fornecedor √© um 35 para. Sim. Algo. Eu n√£o lembro de tudo. Este. Sim. Sim. Mas o informante diz que eles n√£o sabem o que eles. ACM, ACM ID do fornecedor √©. E no pr√≥ximo caso, podemos desativar este ACM ID e posicionar s√£o de. N√≥s veremos. Sim, n√≥s veremos se podemos. Se podemos tentar particion√°-lo novamente, porque sim, eu mostrei no bilhete de atendimento na nossa aba de discuss√£o. Existem dois fornecedores com que est√£o atualmente existentes, que √© um tendo este ACM ID e o outro n√£o tem ACM ID n√£o tem ACM mapeamento de ACM ainda. Ent√£o √© por isso que eu sugeri pedir √† equipe do banco se este √© deles. Eles n√£o sabem. Isso. Eles n√£o sabem esta informa√ß√£o. Mas. N√≥s pensamos que podemos desativar o ACM e particion√°-lo horas. Porque eles n√£o passam. Eles n√£o conhecem esta informa√ß√£o, que √© o ACM ID deste fornecedor. Mas eles ainda est√£o usando este fornecedor, certo? Sim. Eu n√£o sei. N√£o tenho certeza. N√≥s conversamos com o banco. Ent√£o eles j√° sabem que n√≥s pedimos para voc√™. Estamos pedindo para voc√™ ativar este ACM. Sim, n√£o tenho certeza se o PCM ID pode ser desativado, j√° que na verdade estes dados est√£o vindo do sistema ERP. Ent√£o, se eles n√£o sabem. Ent√£o, se voc√™ est√° perguntando para a equipe local da equipe do banco, talvez voc√™ tamb√©m possa sugerir se se a equipe ERP deles sabe estes dados. Mas sim, por enquanto, veremos se se os dados para o. Os dados podem ser mapeados para cada um dos fornecedores que eu mostrei que eu mostrei a voc√™ no. Na captura de tela. Que eu forneci. Okay. Ent√£o, agora n√£o podemos desativar este ACM. Precisamos com o banco novamente. Certo. Sim. Sim. Especificamente, talvez como sua equipe ERP em vez disso. Porque eu n√£o acho que a equipe local sabe de onde estes dados est√£o vindo. Mas sim, tanto quanto eu sei, isto est√° integrado em que √© ou estes dados est√£o vindo do sistema ERP em vez disso. Okay. N√≥s vamos verificar novamente. E deixe voc√™. Claro. Por enquanto, eu farei o meu melhor para manter o bilhete de atendimento aberto por enquanto. Okay. Sim, ent√£o eu acho que isso tamb√©m, voc√™ tem perguntas para estes dois itens para o ptp antes de passarmos para os itens SCC. Okay. Okay. Obrigado. Okay. Ent√£o, para os itens S2C. Ent√£o sim, temos dois itens aqui, que √© em rela√ß√£o ao modelo SLP. Ajuste no modelo SLP e o. Ent√£o para os itens S2, ambos estes est√£o atualmente ainda em andamento devido √† sincroniza√ß√£o que est√° acontecendo entre os sistemas de produ√ß√£o e teste. Ent√£o para o segundo item. Sim, ent√£o para este, para este conhecido, nenhuma modifica√ß√£o conhecida √© permitida por enquanto, j√° que sim. Precisamos esperar por esta sincroniza√ß√£o sincroniza√ß√£o para terminar. E eu acho que temos mais um item eu n√£o fui capaz de adicion√°-lo aqui. Sim, ent√£o para este pedido seu, eu te amo. Eu acredito com rela√ß√£o a este. T√£o. N√≥s verificaremos isto internamente. Ent√£o, uma vez que recebermos uma conclus√£o para este, n√≥s o atualizaremos em conformidade. Okay. Obrigado. Sim, eu adicionarei isto ao leia o. Desculpe, eu esqueci de adicionar isto ainda. Mas sim, n√≥s verificaremos isto na internet. Ent√£o me avise quando seu ambiente de teste, √© uma atualiza√ß√£o muito grande. Sim. Sim, n√≥s entraremos em contato com voc√™ tamb√©m para isso. Okay. Sim, ent√£o √© tudo da minha parte. Voc√™ tem outras perguntas ou preocupa√ß√µes que podemos abordar na chamada antes de terminarmos isto? N√£o, da minha parte. N√£o. Voc√™s? Eu tamb√©m n√£o. Okay. Obrigado. Primeiro, obrigado. Obrigado a todos. E sim, eu enviarei as atas da reuni√£o ap√≥s a chamada. Ent√£o sim, obrigado a todos. E eu desejo a voc√™s um √≥timo dia pela frente. Tchau."

Espero que isso ajude! Avise-me se precisar de mais alguma coisa.

User: Resuma essa reuni√£o com os pontos importantes.
Assistant: Assistant: Claro, aqui est√° um resumo dos pontos importantes da reuni√£o:

**ARIBA:**

*   **Mudan√ßa de Nome de Dom√≠nio:** Estendida at√© 31 de janeiro de 2026. Fl√°vio deve verificar o progresso.
*   **Conex√£o TLS 1.2:** Prazo para transfer√™ncia √© 30 de abril. J√° foi finalizada (linha 5). Solicitaram screenshots como evid√™ncia.
*   **Renova√ß√£o de Certificado:** Aguardando informa√ß√µes para fornecer via ticket ou e-mail.
*   **Ambiente Livre para S2C:** Testes relacionados aos contratos de fornecedores em andamento. Aguardando t√©rmino do projeto.
*   **Monitoramento Di√°rio:** Verificar o arquivo de monitoramento do Brasil e o erro no PR.

**KPIs de Produ√ß√£o:**

*   Sem altera√ß√µes em rela√ß√£o √† semana anterior.

**Status dos Tickets P2P:**

*   Seis tickets resolvidos.
*   **PR em Processamento de Pedido (Vers√£o 3):** Erro na Vers√£o 2. Aguardando agendamento de reuni√£o com o fornecedor Arriba.
*   **Problema de Integra√ß√£o:** Accenture discutir√° com o fornecedor SAP Arriba e atualizar√° o ambiente de teste.
*   **Fornecedor com Problemas no ACM ID:** Verificar com a equipe do banco (possivelmente a equipe ERP) e desativar o ACM ID.

**Itens S2C:**

*   Ajuste no modelo SLP em andamento, aguardando sincroniza√ß√£o entre os sistemas de produ√ß√£o e teste.
*   Solicita√ß√£o de atualiza√ß√£o do ambiente de teste ser√° verificada internamente.

**Geral:**

*   Coordenar a atualiza√ß√£o do ambiente de teste com a equipe do projeto.
*   As atas da reuni√£o ser√£o enviadas ap√≥s a chamada.
User: Preciso de mais detalhes sobre o fornecedor que n√£o est√° particionando.
Assistant: Assistant: Ok, com base no di√°logo, aqui est√£o os detalhes sobre o fornecedor com problemas de parti√ß√£o:

*   **Problema:** O fornecedor n√£o est√° sendo particionado corretamente.
*   **Causa:** Existe um problema com o ACM ID (Ariba Cloud Module ID) do fornecedor.
*   **Situa√ß√£o Atual:**
    *   A Tadita est√° coordenando com a equipe do banco para confirmar o ACM ID.
    *   J√° existem dois fornecedores: um com o ACM ID problem√°tico e outro sem nenhum ACM ID.
    *   A equipe do banco (local) n√£o reconhece o ACM ID existente.
*   **A√ß√µes:**
    *   Sugeriu-se questionar a equipe ERP do banco sobre o ACM ID, pois esses dados geralmente v√™m do sistema ERP.
    *   A equipe est√° considerando desativar o ACM ID problem√°tico e tentar particionar novamente o fornecedor.
    *   A equipe precisa verificar com o banco novamente (especificamente a equipe ERP) antes de desativar o ACM ID.

Em resumo, o problema parece estar relacionado √† identifica√ß√£o e ao gerenciamento do ACM ID do fornecedor no sistema banc√°rio, o que est√° impedindo a parti√ß√£o correta no Ariba.

User: ou cannot associate a common supplier with multiple partitioned suppliers. The partitioned supplier BR3-1_19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA cannot be associated with the common supplier 19381564000140, because this common supplier is already associated with BR1-19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA.
Error executing trigger IntegrationPostLoad on [ariba.common.core.Supplier [BaseId 13436469218331 B+RQAGmDDhr+Ywb 4rgmmupsr.1qa9cqee]] with data {
AmountRoundingForInvExceptionCalculation = "File \"SupplierConsolidated.csv\" (line 15, column AmountRoundingForInvExceptionCalculation): '0'";
CommonSupplier = {
CorpAddrCountry = "File \"SupplierConsolidated.csv\" (line 15, column Country): 'BR'";
CorpAddrLines = "File \"SupplierConsolidated.csv\" (line 15, column Street): 'R GUARARAPES 2064 - 7 ANDAR - BROOKLIN PAULISTA'";
CorpAddrState = "File \"SupplierConsolidated.csv\" (line 15, column State): 'SP'";
CorporateAddress = {
UniqueName = "File \"SupplierConsolidated.csv\" (line 15, column AddressID): 'BR3-1_19381564000140'";
};
CorporateEmailAddress = "File \"SupplierConsolidated.csv\" (line 15, column CorporateEmailAddress): 'rtrevizan@mantris.com.br'";
CorporatePhone = "File \"SupplierConsolidated.csv\" (line 15, column CorporatePhone): '11 944775350'";
HasSyncRelationship = "File \"SupplierConsolidated.csv\" (line 15, column HasSyncRelationship): 'false'";
HasTradingRelationship = "File \"SupplierConsolidated.csv\" (line 15, column HasTradingRelationship): 'false'";
Name = "File \"SupplierConsolidated.csv\" (line 15, column Name): 'MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA'";
PreferredCurrency = {
UniqueName = "File \"SupplierConsolidated.csv\" (line 15, column PreferredCurrency): 'BRL'";
};
PreferredLanguage = {
UniqueName = "File \"SupplierConsolidated.csv\" (line 15, column PreferredLanguage): 'BrazilianPortuguese'";
};
SystemID = "File \"SupplierConsolidated.csv\" (line 15, column SystemID): 'ACM_72530498'";
};
Name = "File \"SupplierConsolidated.csv\" (line 15, column Name): 'MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA'";
PaymentModel = "File \"SupplierConsolidated.csv\" (line 15, column PaymentModel): '-1'";
SubContractor = "File \"SupplierConsolidated.csv\" (line 15, column SubContractor): '0'";
UniqueName = "File \"SupplierConsolidated.csv\" (line 15, column VendorID): 'BR3-1_19381564000140'";
}

o que est√° dizendo nesse erro ?
Assistant: Assistant: O erro indica que voc√™ est√° tentando associar um fornecedor comum a m√∫ltiplos fornecedores particionados, o que n√£o √© permitido no sistema Ariba.

**Detalhes do Erro:**

*   **Mensagem principal:** "Voc√™ n√£o pode associar um fornecedor comum com m√∫ltiplos fornecedores particionados."
*   **Fornecedor particionado com problema:** `BR3-1_19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`
*   **Fornecedor comum:** `19381564000140`
*   **Fornecedor particionado j√° associado ao fornecedor comum:** `BR1-19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`

**Interpreta√ß√£o:**

O sistema j√° tem o fornecedor comum `19381564000140` associado ao fornecedor particionado `BR1-19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`. Voc√™ est√° tentando associar o mesmo fornecedor comum ao fornecedor particionado `BR3-1_19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`, o que causa o erro.

**Poss√≠veis Causas:**

*   **Configura√ß√£o Incorreta:** Pode haver um erro na forma como os fornecedores est√£o configurados no sistema Ariba.
*   **Dados Duplicados:** Possivelmente h√° dados duplicados ou conflitantes na importa√ß√£o do arquivo `SupplierConsolidated.csv`.
*   **L√≥gica de Particionamento Inadequada:** A l√≥gica de particionamento pode n√£o estar funcionando corretamente, resultando em tentativas de associa√ß√µes inv√°lidas.

**Informa√ß√µes Adicionais do Log:**

O log tamb√©m fornece informa√ß√µes sobre os dados do fornecedor que est√£o sendo processados a partir do arquivo `SupplierConsolidated.csv`, incluindo:

*   Nome do fornecedor: `MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`
*   Endere√ßo: `R GUARARAPES 2064 - 7 ANDAR - BROOKLIN PAULISTA`
*   Pa√≠s: `BR`
*   Estado: `SP`
*   E-mail: `rtrevizan@mantris.com.br`
*   Telefone: `11 944775350`
*   ID do sistema: `ACM_72530498`

**Pr√≥ximos Passos:**

1.  **Verifique a configura√ß√£o dos fornecedores:** No sistema Ariba, examine a configura√ß√£o dos fornecedores `BR3-1_19381564000140`, `BR1-19381564000140` e `19381564000140` para identificar quaisquer erros.
2.  **Analise o arquivo `SupplierConsolidated.csv`:** Verifique a linha 15 (onde o erro foi detectado) para garantir que os dados do fornecedor estejam corretos e consistentes.
3.  **Revise a l√≥gica de particionamento:** Certifique-se de que a l√≥gica de particionamento est√° configurada corretamente para evitar associa√ß√µes inv√°lidas.
4.  **Remova ou corrija a associa√ß√£o existente:** Se a associa√ß√£o entre o fornecedor comum e o fornecedor particionado `BR1-19381564000140` estiver incorreta, remova-a ou corrija-a antes de tentar associar o fornecedor comum a `BR3-1_19381564000140`.

Lembre-se de que a solu√ß√£o exata depender√° da sua configura√ß√£o espec√≠fica do Ariba e da sua l√≥gica de particionamento.
User: extraia o CNPJ da imagem.
2025-04-10 17:09:27,227 [INFO] Resposta da IA (imagem): O CNPJ presente na imagem √©: `47214053000179`.
2025-04-10 17:09:27,319 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:09:27,322 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:09:27,324 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:09:27,326 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:09:27,328 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:09:27,331 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:09:27,333 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 17:09:27,335 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:09:27,337 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:09:27,338 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:09:27,340 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:09:27,342 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:09:27,344 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:09:27,345 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 17:09:27,347 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:43:54,114 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:43:54,117 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:43:54,119 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:43:54,121 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:43:54,122 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:43:54,124 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:43:54,126 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 17:43:54,127 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:43:54,129 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:43:54,132 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:43:54,134 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:43:54,135 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:43:54,137 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:43:54,139 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 17:43:54,140 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:43:54,325 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:43:54,327 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:43:54,328 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:43:54,330 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:43:54,332 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:43:54,333 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:43:54,334 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 17:43:54,336 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:43:54,338 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:43:54,339 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:43:54,341 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:43:54,344 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:43:54,346 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:43:54,347 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 17:43:54,349 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:43:54,370 [INFO] Enviando para IA - Imagem: C:\Users\jfreis\Documents\azure-ai-sentiment-analysis\assets\20250410174354_clipboard_20250410170916.png, Prompt: Voc√™ √© um assistente inteligente utilizado em um chat com IA, que recebe c√≥digos de uma aplica√ß√£o completa de chat, como voc√™ funciona e tudo que 
√© programado para fazer no seu contexto.

Seu objetivo √©:
- Analisar todo o contexto e aprender com ele.
- Analisar a Pergunta do Usu√°rio.
- Identificar se possui rela√ß√£o com o contexto.
- Se houver rela√ß√£o com o c√≥digo do contexto responder a pergunta sobre o c√≥digo sempre seguindo boas pr√°ticas:
    - Analisar o c√≥digo-fonte contido no projeto enviado
    - Identificar melhorias em legibilidade, performance e seguran√ßa
    - Sugerir pr√°ticas recomendadas de design e arquitetura
    - Indicar partes com d√≠vidas t√©cnicas ou complexidade desnecess√°ria
    - Enviar c√≥digo modularizado em pequenos arquivos separados por pastas.

Informa√ß√µes adicionais:
- Estrutura do projeto: segue o padr√£o de pastas iniciando por src/


## Se houver imagem no contexto, identifique se a pergunta √© sobre o c√≥digo do contexto, sobre a imagem ou sobre os dois para elaborar melhorer respostas.
## Se o usu√°rio fizer uma pergunta que n√£o tem rela√ß√£o com imagem ou contexto, use a sua base de conhecimento fora do contexto para responder de forma inteligente.
** Responda em Portugu√™s-Brasileiro a n√£o ser que o usu√°rio solicite outra l√≠ngua.**

Contexto:



# chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# main.py

# main.py
from core.handlers.signal_handler import setup_signal_handler
from services.image_processor import ImageProcessor
from core.rate_limiter import RateLimiter
import json

def main():
    setup_signal_handler()

    # Inicializa o RateLimiter com o n√∫mero m√°ximo de requisi√ß√µes e o per√≠odo
    rate_limiter = RateLimiter(max_requests=9, period_seconds=60)  # 9 requisi√ß√µes por minuto

    # Passa o RateLimiter para o ImageProcessor
    processor = ImageProcessor(rate_limiter)
    processor.process_images()

    # Obter e imprimir o hist√≥rico ap√≥s o processamento
    history = processor.get_history()
    for item in history:
        print(f"Imagem: {item['image_name']}, Resumo: {item['summary']}")

    # Salvar o hist√≥rico em um arquivo JSON
    with open(processor.historico_json_file, "w") as f:
        json.dump(history, f, indent=4)

if __name__ == "__main__":
    main()

# services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# test_image_generation.py

import os
from dotenv import load_dotenv
from google import genai
from google.generativeai import types
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

client = genai.Client(api_key=api_key)

prompt = "gerar a imagem do simbolo do corinthians."

response = client.models.generate_content(
    model='gemini-2.0-flash-exp-image-generation',
    contents=prompt,
    config=types.GenerateContentConfig(
        response_modalities=['Text', 'Image']
    )
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = Image.open(BytesIO(part.inline_data.data))
        image.save("ed-image.png")
        image.show()

# utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

User: fa√ßa code review da minha aplica√ß√£o.
Assistant: Com certeza! Analisei o c√≥digo da sua aplica√ß√£o e preparei algumas sugest√µes para melhorias em legibilidade, performance, seguran√ßa e design.

**1. Estrutura e Modulariza√ß√£o:**

*   **Diret√≥rios:** Organize melhor os arquivos dentro de `src`. Crie subdiret√≥rios para `models`, `services`, `handlers`, `utils`, `config`, etc. Isso facilita a localiza√ß√£o dos arquivos e a compreens√£o da estrutura do projeto.
*   **Arquivo de configura√ß√£o:** Mova a classe `Config` para um arquivo separado (ex: `config.py`) dentro de um diret√≥rio `config`.
*   **Fun√ß√µes:** Quebre fun√ß√µes grandes em fun√ß√µes menores e mais focadas. Isso melhora a legibilidade e facilita o teste.

**2. Boas Pr√°ticas e Melhorias no C√≥digo:**

*   **Rate Limiting:** Implemente o `RateLimiter` nos servi√ßos que consomem a API do Gemini (ex: `ImageProcessor`, `GeminiHandler`). Isso evita sobrecarga na API e garante um uso mais eficiente.
*   **Configura√ß√µes:** Use a classe `Config` para centralizar todas as configura√ß√µes da aplica√ß√£o (ex: chaves de API, modelos, diret√≥rios). Isso facilita a manuten√ß√£o e a configura√ß√£o do projeto.
*   **Logging:** Padronize o uso do logger em toda a aplica√ß√£o. Use os n√≠veis de log apropriados (ex: `info`, `warning`, `error`) para cada tipo de mensagem.
*   **Tratamento de Erros:** Adicione tratamento de erros mais espec√≠fico em cada fun√ß√£o. Isso ajuda a identificar e corrigir problemas mais rapidamente.
*   **Cache:** Utilize o `st.cache_resource` para fun√ß√µes que realizam opera√ß√µes custosas, como a inicializa√ß√£o do `GeminiHandler`. Isso evita a execu√ß√£o repetida dessas opera√ß√µes.
*   **Tipagem:** Utilize tipagem est√°tica (type hints) para melhorar a legibilidade e a seguran√ßa do c√≥digo.
*   **Imagens:** Valide se `uploaded_file` √© realmente um arquivo de imagem antes de tentar exibi-lo, evitando erros caso o usu√°rio envie um arquivo de outro tipo.
*   **Prompts:** Crie arquivos de prompt separados para diferentes tarefas (ex: chat, an√°lise de imagem). Isso facilita a manuten√ß√£o e a personaliza√ß√£o dos prompts.

**3. Seguran√ßa:**

*   **Chaves de API:** Nunca coloque suas chaves de API diretamente no c√≥digo. Use vari√°veis de ambiente ou um arquivo de configura√ß√£o seguro para armazen√°-las.
*   **Valida√ß√£o de Input:** Valide todos os inputs do usu√°rio para evitar ataques de inje√ß√£o de c√≥digo.

**4. Arquitetura:**

*   **Camadas:** Defina claramente as responsabilidades de cada camada da sua aplica√ß√£o (ex: apresenta√ß√£o, l√≥gica de neg√≥cios, acesso a dados). Isso facilita a manuten√ß√£o e a evolu√ß√£o do projeto.
*   **Invers√£o de Depend√™ncia:** Use invers√£o de depend√™ncia para desacoplar as diferentes partes da sua aplica√ß√£o. Isso facilita o teste e a substitui√ß√£o de componentes.
*   **Testes:** Escreva testes unit√°rios e de integra√ß√£o para garantir a qualidade do seu c√≥digo.

**5. D√≠vidas T√©cnicas e Complexidade:**

*   **Fun√ß√µes Longas:** Identifique fun√ß√µes com muitas linhas de c√≥digo e divida-as em fun√ß√µes menores e mais focadas.
*   **L√≥gica Duplicada:** Elimine a l√≥gica duplicada criando fun√ß√µes ou classes reutiliz√°veis.
*   **Coment√°rios:** Adicione coment√°rios para explicar o que o c√≥digo faz, especialmente em partes complexas.

**Exemplo de Refatora√ß√£o:**

Aqui est√° um exemplo de como voc√™ pode refatorar a fun√ß√£o `process_images` na classe `ImageProcessor`:

```python
# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self._post_process_image(image_name, summary)
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _post_process_image(self, image_name, summary):
        self.document_service.add_image_summary(image_name, summary)
        self.markdown_service.add_image_summary(image_name, summary)
        self.document_service.save_document()
        self.markdown_service.save_markdown()

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history
```

**6. C√≥digo Modularizado:**

Para facilitar a visualiza√ß√£o e a organiza√ß√£o, preparei o c√≥digo modularizado em arquivos separados:

```
src/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gemini_handler.py
‚îÇ   ‚îú‚îÄ‚îÄ logger_config.py
‚îÇ   ‚îî‚îÄ‚îÄ rate_limiter.py
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ document_service.py
‚îÇ   ‚îú‚îÄ‚îÄ gpt_services.py
‚îÇ   ‚îú‚îÄ‚îÄ image_processor.py
‚îÇ   ‚îú‚îÄ‚îÄ markdown_service.py
‚îÇ   ‚îî‚îÄ‚îÄ search_files.py
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ file_utils.py
```

**Observa√ß√µes Finais:**

*   A implementa√ß√£o de todas essas sugest√µes pode levar tempo, mas o resultado final ser√° um c√≥digo mais organizado, leg√≠vel, seguro e f√°cil de manter.
*   Priorize as melhorias que trazem o maior impacto no seu projeto.
*   Use um sistema de controle de vers√£o (ex: Git) para acompanhar suas mudan√ßas e facilitar a colabora√ß√£o com outros desenvolvedores.

Se tiver alguma d√∫vida sobre alguma dessas sugest√µes, √© s√≥ perguntar!
User: Extraia o CNPJ dessa imagem.
Assistant: A imagem cont√©m um comprovante de inscri√ß√£o e de situa√ß√£o cadastral. O CNPJ presente na imagem √©:

`33.024.232/0001-39`
User: extraia o n√∫mero do chamado que come√ßa com  2025
Assistant: O n√∫mero do chamado que come√ßa com 2025 na imagem √©:

`2025040185005611`

User:  Okay, sorry, this is. Okay, so welcome everyone. So our week we call for Brazil at a ca Dow. So for today, we will discuss the following the ARIBA, the production API, the P2P and S2C ticket status updates. And if we have business processes and change management. So for the ARIBA, here are depending the number of pending decisions and open actions. So we have. So for all we have one action and one information and then. For ERP team, we have two actions and two information. So we have a total of six. So let me go to the ARIBA file. Okay, so here are the items that we have in the ARIBA file. So for the first one, we have the domain name change. So for this one, so this is actually extended until January 31, 2026. But yeah, Flavio, I just want to know if we have progress on this one. I need to check and then I get back to you on this. On this sheet, please. Okay, thank you so much. Okay, so. You have included another one. Yes, that's correct. Yeah, so for the next one, we actually have also the TLS 1 point to connection. To. To be transferred to a TLS 1 point. So this is also for your team to check. So the deadline for this one will be on April 30. So do we have also progress on this one or not yet? I believe that I already described my current situation on a column. On the right on the right. You can find my call up. Sorry, here or on the tracker file, be the change. Sorry, let me check. This one. This one. I'm not sure where are the comments that you have. No, I just have my clue comments about the first one in the second and the TLS. So we are already done. The line five. Let me see if I can. Is it. Ah, this one. Okay. Okay, so this is already close. Yes, this. Yeah. So for that one, could you please provide screen shots here if possible? To stretch. Yes, just to show that it is already deployed on your system. As an evidence. Okay. Thank you so much. Okay. Okay, so let me remove this one also. I don't know why this one educated. Okay, so for the next two items is read your cards to the certificate renewal. So this is still for information only once the assertifcates have been released by. So I will be able to provide it to you also. Either in the juror ticket or via. So actually this should not be in progress. Okay. And then for the next one, we have also the. This environment frees for the. Parent real. Or the for the S to see items actually so. This is still ongoing right now. So we are checking internally with the project team when. This project will end. So for now. All the test things for the. Related to a supplier's contracts. Our entries for now. And lastly for the daily monitor and so since Ricardo is not here. Yes, so. Oh, sorry, I did hear. So just so this is a reminder for. That for them to check the. Monitoring file for Brazil. So actually. We are encountering some or we are a cap we have some documents captured in the daily monitoring. So if you could also help with the card to check this capture documents that would be appreciated. I'm not sure if this is the correct. Okay, so this is still on March. Let me just change this one. Okay. Okay. Let me share my screen. Okay, so this is actually the. Monitoring file for Brazil. So right now we only for now we have one so we are still updating the monitoring file. So yeah, if you could help check this one. And see why this PR is having an error in the. Are you beside or in the air beside render. So this is the. What they call this the error message that was encountered. So yeah, if you could check this on the ER beside it would be appreciate. For the other. I don't think we have some captured documents yet. Yeah, so for now we'll be have one. Just this one. So yeah, that's all for the items. So they have questions before move on to our next items. No, please go ahead. Okay, thank you so much. Okay, so for the production KPIs, it's the same as the last week as discussed. So they are the numbers or the figures for the documents for the transactions in harriba and for the care tickets that have been taken by a to an L3. So as for the P2P tickets status update so for the past week we. So we have a result or we handled six tickets for P2P and as for the open items. So for the first one we have the issue with regards to the PR that is in order processing status. So for this one, yeah, the current issue is that this PR is currently in version three and it is showing an error that the version two has been has been stopping ordering. However, we cannot. Reprocess this one on the CIG side, so that's why we raise an SR for this one. Or an Arriba case. So right now we are trying to set up a call with the Arriba vendor as they are also asking for our availability. So once we have established a schedule for the meeting and discuss this with the Arriba vendor. So we will update the care ticket about the discussion. And for the next one, we have the integration issue for this supply. Can I attend to the point one please. So we are pending Arriba vendor get back to us with a viable time slots to have a conversation. So for this one, we so the Accenture team will discuss this first with the SAP Arriba vendor as we have all the details already. So if so we will discuss all the investigations that we had so far in order to help them further investigate this issue. But according to the plan for the city reader, we also talk about the updating of our environment of testing. If I'm not wrong. That the queue us or the. We have plenty to update our environment of testing. And the QA test test environment. The point is I need to go ahead with our S a p requirements that I have shared with you by. Sorry. So I don't know if this point is blocking our evaluation regarding to S a p. This is the point. The one that you have in email or. Yeah, 200 for eight or far nine. S a p requirements. I mean, we'll have on this. Let me see if I can. The line eight. Are you have very an update in this one? Yes, so for this one, this is only in a riba side of love you and not on the other side. Yeah, but. I'm aware about S a p. The point for me is S a p evaluation. So I need to implement new requirements. My S a p environment in production. So I don't know if the test environment. We need to be update in order to go ahead with this S a p new requirements. Yeah, so for this one of lab, you I think we need to. Wait for the synchronization of the data from the production system to the test environment to be finished. So we do implementations of data changes or. To do some. Testing scenarios in the S to see part. Yeah, but when we are when we will be ready. I have mentioned earlier, we will coordinate this with the project team who's doing the project for this project specifically and ask them when this will be finished as the. Other conscious and Bruno is also asking for this one. So we will update you accordingly regarding this one. Okay. Thank you. Okay. Yeah, so let me discuss first the B to B items. Okay, so for the next one, we have the issue with regards to this supplier. Which was raised by a Tadita. So for this one, they are. And the Tadita mentioned in the ticket that they are coordinating with the bank team for the confirmation of the ACM ID for the supplier. And the last update was made to me about this ticket. And the next one is explained to the explain needs to be created, which already exists. And the value one B are one data needs to be partitioned into to these other suppliers. And that after this is done, they will probably you will proceed with the supplier patchy partitioning for a base trace attack. Yes. Yeah. And you also ask to ask to us to check with the bank if the ACM ID of the supplier is a 35 for. Yes. Something. I don't remember everything. This one. Yeah. Yeah. But the informant says that they don't know what they. ACM, ACM ID of the supplier is. And the next case, can we deactivate this ACM ID and position are from. We will see. Yeah, we will see if we can. If we can try to partition it again, because yes, I have showed in the ticket on our discussion tab. There are two suppliers with that are currently existing, which is one having this ACM ID and the other has no ACM ID has no ACM ACM ID mapping yet. So that's why I suggested to ask the bank team if this is their. They don't know. That's. They don't know this. So. This don't they don't know this information. But. We thought that we can deactivate the ACM and partition it hours. Because they don't pass. They don't know this information, which is ACM ID from this supplier. But they are still using this supplier, right? Yeah. I don't know. Don't sure. We we we talked to the bank. So they were they are already know that we ask to you. We are asking to you to activate this ACM. Yeah, I'm not sure if PCM ID can be deactivated since actually this data is coming from the ERP system. So if they don't know. So if you're asking the local team of the bank team, maybe you can also suggest if if they're ERP team knows this data. But yeah, for now, we will see if if the data for the. The data can be mapped to each to one of the suppliers that I have showed I have shown you in the. In the screenshot. That I have provided. Okay. So right now we can deactivate this ACM. We need to with the bank again. Right. Yes. Yes. Yes. Specifically, maybe as their ERP team instead. Because I don't think the local team knows where this data is coming from. But yeah, as far as I'm concerned, this is integrated in that is or this is this data is coming from the ERP system rather. Okay. We're going to check again. And let you. Sure. For now, we will I will do my best to keep the ticket open for now. Okay. Yeah, so I think that's also do you have questions for these two items for the ptp before we move on to SCC items. Okay. Okay. Thank you. Okay. So for the S2C items. So yeah, we have two items here, which is with regards to the SLP template. Adjustment in SLP template and the. So for the S2 items, both of these are currently still in progress due to the synchronization that is happening between the production and test systems. So for the second item. Yeah, so for this one, this for this one, known, known modifications are allowed for now since yeah. We need to wait for this synchronization synchronization to be finished. And I think we have one more item I haven't I wasn't able to add it here. Yeah, so for this request from you, I love you. I believe with regards to this one. So. We will we are still checking this internally. So once we receive a conclusion for this one, we will update you accordingly. Okay. Thank you. Yeah, I will add this to the read the. Sorry, I forgot to add this yet. But yeah, we will check this internet. So let me know when you test environment, it's a very uploaded. Yeah. Yeah, we will get back to you also for that. Okay. Yeah, so that's all from my side. Do you have other questions or concerns that we can address in the call before we end this? No, for my side. No. Are you guys? Me neither. Okay. Thank you. First one, thank you. Thank you, Ray. Thank you, everyone. And yeah, I will send the minutes of the meeting after the call. So yeah, thank you, everyone. And I wish you a great day ahead. Bye.

Traduza para pt-br
Assistant: Okay, aqui est√° a tradu√ß√£o para portugu√™s brasileiro do di√°logo fornecido:

"Okay, desculpem, √© isso. Okay, ent√£o bem-vindos a todos. Ent√£o, nossa semana chamamos para Brasil na CA Dow. Ent√£o, para hoje, vamos discutir o seguinte: o ARIBA, a API de produ√ß√£o, o P2P e atualiza√ß√µes de status de tickets S2C. E se tivermos processos de neg√≥cios e gest√£o de mudan√ßas. Ent√£o, para o ARIBA, aqui est√£o dependendo o n√∫mero de decis√µes pendentes e a√ß√µes em aberto. Ent√£o n√≥s temos. Ent√£o, para todos n√≥s temos uma a√ß√£o e uma informa√ß√£o e ent√£o. Para a equipe ERP, temos duas a√ß√µes e duas informa√ß√µes. Ent√£o, temos um total de seis. Ent√£o, deixe-me ir para o arquivo ARIBA. Okay, ent√£o aqui est√£o os itens que temos no arquivo ARIBA. Ent√£o, para o primeiro, temos a mudan√ßa de nome de dom√≠nio. Ent√£o, para este, isso √© realmente estendido at√© 31 de janeiro de 2026. Mas sim, Fl√°vio, eu s√≥ quero saber se temos progresso neste. Eu preciso verificar e ent√£o eu volto para voc√™ neste. Nesta folha, por favor. Okay, muito obrigado. Okay, ent√£o. Voc√™ incluiu outro. Sim, est√° correto. Sim, ent√£o para o pr√≥ximo, n√≥s realmente temos tamb√©m a conex√£o TLS 1 ponto para. Para. Para ser transferida para um TLS 1 ponto. Ent√£o isso tamb√©m √© para sua equipe verificar. Ent√£o o prazo para este ser√° em 30 de abril. Ent√£o, n√≥s temos tamb√©m progresso neste ou ainda n√£o? Eu acredito que eu j√° descrevi minha situa√ß√£o atual em uma coluna. Na direita, na direita. Voc√™ pode encontrar minha chamada. Desculpe, aqui ou no arquivo de rastreamento, seja a mudan√ßa. Desculpe, deixe-me verificar. Este. Este. Eu n√£o tenho certeza onde est√£o os coment√°rios que voc√™ tem. N√£o, eu s√≥ tenho meus coment√°rios de pistas sobre o primeiro e o segundo e o TLS. Ent√£o, j√° terminamos. A linha cinco. Deixe-me ver se eu posso. √â isso. Ah, este. Okay. Okay, ent√£o isso j√° est√° fechado. Sim, isto. Sim. Ent√£o para isso, voc√™ poderia por favor fornecer capturas de tela aqui se poss√≠vel? Para alongar. Sim, apenas para mostrar que j√° est√° implantado em seu sistema. Como uma evid√™ncia. Okay. Muito obrigado. Okay. Okay, ent√£o deixe-me remover este tamb√©m. Eu n√£o sei por que este educado. Okay, ent√£o para os pr√≥ximos dois itens √© ler seus cart√µes para a renova√ß√£o do certificado. Ent√£o, isto ainda √© apenas para informa√ß√£o, uma vez que os assertifcates tenham sido liberados por. Ent√£o eu poderei fornec√™-lo a voc√™ tamb√©m. Seja no ingresso do j√∫ri ou via. Ent√£o, na verdade isso n√£o deveria estar em andamento. Okay. E ent√£o para o pr√≥ximo, temos tamb√©m o. Este ambiente libera para o. Real pai. Ou o para os itens S para ver realmente t√£o. Isto ainda est√° em andamento agora. Ent√£o estamos verificando internamente com a equipe do projeto quando. Este projeto terminar√°. Ent√£o por agora. Todas as coisas de teste para o. Relacionado aos contratos de um fornecedor. Nossas entradas por enquanto. E, finalmente, para o monitor di√°rio e ent√£o, j√° que Ricardo n√£o est√° aqui. Sim, ent√£o. Oh, desculpe, eu ouvi aqui. Ent√£o, apenas ent√£o isso √© um lembrete para. Que para eles verifiquem o. Arquivo de monitoramento para o Brasil. Ent√£o, realmente. Estamos encontrando alguns ou estamos um cap n√≥s temos alguns documentos capturados no monitoramento di√°rio. Ent√£o, se voc√™ tamb√©m pudesse ajudar com o cart√£o para verificar esses documentos capturados, seria apreciado. N√£o tenho certeza se isto est√° correto. Okay, ent√£o isto ainda est√° em mar√ßo. Deixe-me apenas mudar isto. Okay. Okay. Deixe-me compartilhar minha tela. Okay, ent√£o este √© realmente o. Arquivo de monitoramento para o Brasil. Ent√£o agora n√≥s apenas por enquanto temos um, ent√£o ainda estamos atualizando o arquivo de monitoramento. Ent√£o sim, se voc√™ pudesse ajudar a verificar este. E veja por que este RP est√° tendo um erro no. Voc√™ est√° ao lado ou no ar ao lado render. Ent√£o este √© o. O que eles chamam isto a mensagem de erro que foi encontrada. Ent√£o sim, se voc√™ pudesse verificar isso no ER ao lado, seria apreciado. Para os outros. Eu n√£o acho que temos alguns documentos capturados ainda. Sim, ent√£o por agora n√≥s teremos um. Apenas este. Ent√£o sim, √© tudo para os itens. Ent√£o eles t√™m perguntas antes de passarmos para nossos pr√≥ximos itens. N√£o, por favor prossiga. Okay, muito obrigado. Okay, ent√£o para os KPIs de produ√ß√£o, √© o mesmo que na semana passada, conforme discutido. Ent√£o eles s√£o os n√∫meros ou as figuras para os documentos para as transa√ß√µes em harriba e para os bilhetes de atendimento que foram tomados por um para um L3. Ent√£o, quanto √† atualiza√ß√£o do status dos bilhetes de atendimento P2P, ent√£o na semana passada n√≥s. Ent√£o temos um resultado ou lidamos com seis bilhetes de atendimento para P2P e quanto aos itens em aberto. Ent√£o, para o primeiro, temos o problema em rela√ß√£o ao PR que est√° em estado de processamento de pedidos. Ent√£o, para este, sim, o problema atual √© que este PR est√° atualmente na vers√£o tr√™s e est√° mostrando um erro de que a vers√£o dois tem interrompido a encomenda. No entanto, n√£o podemos. Reprocessar este no lado CIG, ent√£o √© por isso que levantamos um SR para este. Ou um caso Arriba. Ent√£o agora estamos tentando agendar uma chamada com o fornecedor Arriba, pois eles tamb√©m est√£o perguntando pela nossa disponibilidade. Ent√£o, uma vez que tenhamos estabelecido uma programa√ß√£o para a reuni√£o e discutirmos isso com o fornecedor Arriba. Ent√£o atualizaremos o bilhete de atendimento sobre a discuss√£o. E para o pr√≥ximo, temos o problema de integra√ß√£o para este fornecimento. Posso atender ao ponto um por favor. Ent√£o, estamos pendentes para que o fornecedor Arriba volte para n√≥s com hor√°rios vi√°veis para ter uma conversa. Ent√£o, para este, n√≥s, a equipe Accenture, discutiremos isso primeiro com o fornecedor SAP Arriba, pois j√° temos todos os detalhes. Ent√£o, se assim for, discutiremos todas as investiga√ß√µes que tivemos at√© agora, a fim de ajud√°-los a investigar ainda mais este problema. Mas de acordo com o plano para o leitor da cidade, tamb√©m falamos sobre a atualiza√ß√£o do nosso ambiente de teste. Se eu n√£o estiver enganado. Que o Q us ou o. Temos muito para atualizar nosso ambiente de teste. E o ambiente de teste QA. O ponto √© que eu preciso prosseguir com os nossos requisitos S a p que compartilhei com voc√™ por. Desculpe. Ent√£o, eu n√£o sei se este ponto est√° bloqueando a nossa avalia√ß√£o em rela√ß√£o ao S a p. Este √© o ponto. Aquele que voc√™ tem no e-mail ou. Sim, 200 para oito ou longe nove. Requisitos S a p. Quero dizer, n√≥s teremos neste. Deixe-me ver se eu posso. A linha oito. Voc√™ tem alguma atualiza√ß√£o nisto? Sim, ent√£o, para este, isto √© apenas no lado do Ariba do amor voc√™ e n√£o no outro lado. Sim, mas. Estou ciente sobre S a p. O ponto para mim √© a avalia√ß√£o S a p. Ent√£o eu preciso implementar novos requisitos. Meu ambiente S a p em produ√ß√£o. Ent√£o eu n√£o sei se o ambiente de teste. Precisamos ser atualizados para prosseguir com estes novos requisitos S a p. Sim, ent√£o, para este amor, voc√™, eu acho que precisamos. Espere pela sincroniza√ß√£o dos dados do sistema de produ√ß√£o para o ambiente de teste para terminar. Ent√£o n√≥s fazemos implementa√ß√µes de mudan√ßas de dados ou. Para fazer alguns. Cen√°rios de teste na parte S para ver. Sim, mas quando estaremos prontos. Eu mencionei anteriormente, coordenaremos isto com a equipe do projeto que est√° fazendo o projeto para este projeto especificamente e perguntaremos quando isto terminar√° como o. Outro consciente e Bruno tamb√©m est√° pedindo por isso. Ent√£o n√≥s o atualizaremos em conformidade em rela√ß√£o a este. Okay. Obrigado. Okay. Sim, ent√£o deixe-me discutir primeiro os itens B para B. Okay, ent√£o para o pr√≥ximo, temos o problema em rela√ß√£o a este fornecedor. Que foi levantado por um Tadita. Ent√£o, para este, eles est√£o. E o Tadita mencionou no bilhete de atendimento que eles est√£o coordenando com a equipe do banco para a confirma√ß√£o do ACM ID para o fornecedor. E a √∫ltima atualiza√ß√£o foi feita para mim sobre este bilhete de atendimento. E o pr√≥ximo precisa ser criado, o que j√° existe. E o valor um B s√£o um dados precisa ser particionado em para estes outros fornecedores. E que depois que isso for feito, eles provavelmente prosseguir√£o com a parti√ß√£o do fornecedor para um ataque de rastreamento base. Sim. Sim. E voc√™ tamb√©m pede para nos pedir para verificar com o banco se o ACM ID do fornecedor √© um 35 para. Sim. Algo. Eu n√£o lembro de tudo. Este. Sim. Sim. Mas o informante diz que eles n√£o sabem o que eles. ACM, ACM ID do fornecedor √©. E no pr√≥ximo caso, podemos desativar este ACM ID e posicionar s√£o de. N√≥s veremos. Sim, n√≥s veremos se podemos. Se podemos tentar particion√°-lo novamente, porque sim, eu mostrei no bilhete de atendimento na nossa aba de discuss√£o. Existem dois fornecedores com que est√£o atualmente existentes, que √© um tendo este ACM ID e o outro n√£o tem ACM ID n√£o tem ACM mapeamento de ACM ainda. Ent√£o √© por isso que eu sugeri pedir √† equipe do banco se este √© deles. Eles n√£o sabem. Isso. Eles n√£o sabem esta informa√ß√£o. Mas. N√≥s pensamos que podemos desativar o ACM e particion√°-lo horas. Porque eles n√£o passam. Eles n√£o conhecem esta informa√ß√£o, que √© o ACM ID deste fornecedor. Mas eles ainda est√£o usando este fornecedor, certo? Sim. Eu n√£o sei. N√£o tenho certeza. N√≥s conversamos com o banco. Ent√£o eles j√° sabem que n√≥s pedimos para voc√™. Estamos pedindo para voc√™ ativar este ACM. Sim, n√£o tenho certeza se o PCM ID pode ser desativado, j√° que na verdade estes dados est√£o vindo do sistema ERP. Ent√£o, se eles n√£o sabem. Ent√£o, se voc√™ est√° perguntando para a equipe local da equipe do banco, talvez voc√™ tamb√©m possa sugerir se se a equipe ERP deles sabe estes dados. Mas sim, por enquanto, veremos se se os dados para o. Os dados podem ser mapeados para cada um dos fornecedores que eu mostrei que eu mostrei a voc√™ no. Na captura de tela. Que eu forneci. Okay. Ent√£o, agora n√£o podemos desativar este ACM. Precisamos com o banco novamente. Certo. Sim. Sim. Especificamente, talvez como sua equipe ERP em vez disso. Porque eu n√£o acho que a equipe local sabe de onde estes dados est√£o vindo. Mas sim, tanto quanto eu sei, isto est√° integrado em que √© ou estes dados est√£o vindo do sistema ERP em vez disso. Okay. N√≥s vamos verificar novamente. E deixe voc√™. Claro. Por enquanto, eu farei o meu melhor para manter o bilhete de atendimento aberto por enquanto. Okay. Sim, ent√£o eu acho que isso tamb√©m, voc√™ tem perguntas para estes dois itens para o ptp antes de passarmos para os itens SCC. Okay. Okay. Obrigado. Okay. Ent√£o, para os itens S2C. Ent√£o sim, temos dois itens aqui, que √© em rela√ß√£o ao modelo SLP. Ajuste no modelo SLP e o. Ent√£o para os itens S2, ambos estes est√£o atualmente ainda em andamento devido √† sincroniza√ß√£o que est√° acontecendo entre os sistemas de produ√ß√£o e teste. Ent√£o para o segundo item. Sim, ent√£o para este, para este conhecido, nenhuma modifica√ß√£o conhecida √© permitida por enquanto, j√° que sim. Precisamos esperar por esta sincroniza√ß√£o sincroniza√ß√£o para terminar. E eu acho que temos mais um item eu n√£o fui capaz de adicion√°-lo aqui. Sim, ent√£o para este pedido seu, eu te amo. Eu acredito com rela√ß√£o a este. T√£o. N√≥s verificaremos isto internamente. Ent√£o, uma vez que recebermos uma conclus√£o para este, n√≥s o atualizaremos em conformidade. Okay. Obrigado. Sim, eu adicionarei isto ao leia o. Desculpe, eu esqueci de adicionar isto ainda. Mas sim, n√≥s verificaremos isto na internet. Ent√£o me avise quando seu ambiente de teste, √© uma atualiza√ß√£o muito grande. Sim. Sim, n√≥s entraremos em contato com voc√™ tamb√©m para isso. Okay. Sim, ent√£o √© tudo da minha parte. Voc√™ tem outras perguntas ou preocupa√ß√µes que podemos abordar na chamada antes de terminarmos isto? N√£o, da minha parte. N√£o. Voc√™s? Eu tamb√©m n√£o. Okay. Obrigado. Primeiro, obrigado. Obrigado a todos. E sim, eu enviarei as atas da reuni√£o ap√≥s a chamada. Ent√£o sim, obrigado a todos. E eu desejo a voc√™s um √≥timo dia pela frente. Tchau."

Espero que isso ajude! Avise-me se precisar de mais alguma coisa.

User: Resuma essa reuni√£o com os pontos importantes.
Assistant: Assistant: Claro, aqui est√° um resumo dos pontos importantes da reuni√£o:

**ARIBA:**

*   **Mudan√ßa de Nome de Dom√≠nio:** Estendida at√© 31 de janeiro de 2026. Fl√°vio deve verificar o progresso.
*   **Conex√£o TLS 1.2:** Prazo para transfer√™ncia √© 30 de abril. J√° foi finalizada (linha 5). Solicitaram screenshots como evid√™ncia.
*   **Renova√ß√£o de Certificado:** Aguardando informa√ß√µes para fornecer via ticket ou e-mail.
*   **Ambiente Livre para S2C:** Testes relacionados aos contratos de fornecedores em andamento. Aguardando t√©rmino do projeto.
*   **Monitoramento Di√°rio:** Verificar o arquivo de monitoramento do Brasil e o erro no PR.

**KPIs de Produ√ß√£o:**

*   Sem altera√ß√µes em rela√ß√£o √† semana anterior.

**Status dos Tickets P2P:**

*   Seis tickets resolvidos.
*   **PR em Processamento de Pedido (Vers√£o 3):** Erro na Vers√£o 2. Aguardando agendamento de reuni√£o com o fornecedor Arriba.
*   **Problema de Integra√ß√£o:** Accenture discutir√° com o fornecedor SAP Arriba e atualizar√° o ambiente de teste.
*   **Fornecedor com Problemas no ACM ID:** Verificar com a equipe do banco (possivelmente a equipe ERP) e desativar o ACM ID.

**Itens S2C:**

*   Ajuste no modelo SLP em andamento, aguardando sincroniza√ß√£o entre os sistemas de produ√ß√£o e teste.
*   Solicita√ß√£o de atualiza√ß√£o do ambiente de teste ser√° verificada internamente.

**Geral:**

*   Coordenar a atualiza√ß√£o do ambiente de teste com a equipe do projeto.
*   As atas da reuni√£o ser√£o enviadas ap√≥s a chamada.
User: Preciso de mais detalhes sobre o fornecedor que n√£o est√° particionando.
Assistant: Assistant: Ok, com base no di√°logo, aqui est√£o os detalhes sobre o fornecedor com problemas de parti√ß√£o:

*   **Problema:** O fornecedor n√£o est√° sendo particionado corretamente.
*   **Causa:** Existe um problema com o ACM ID (Ariba Cloud Module ID) do fornecedor.
*   **Situa√ß√£o Atual:**
    *   A Tadita est√° coordenando com a equipe do banco para confirmar o ACM ID.
    *   J√° existem dois fornecedores: um com o ACM ID problem√°tico e outro sem nenhum ACM ID.
    *   A equipe do banco (local) n√£o reconhece o ACM ID existente.
*   **A√ß√µes:**
    *   Sugeriu-se questionar a equipe ERP do banco sobre o ACM ID, pois esses dados geralmente v√™m do sistema ERP.
    *   A equipe est√° considerando desativar o ACM ID problem√°tico e tentar particionar novamente o fornecedor.
    *   A equipe precisa verificar com o banco novamente (especificamente a equipe ERP) antes de desativar o ACM ID.

Em resumo, o problema parece estar relacionado √† identifica√ß√£o e ao gerenciamento do ACM ID do fornecedor no sistema banc√°rio, o que est√° impedindo a parti√ß√£o correta no Ariba.

User: ou cannot associate a common supplier with multiple partitioned suppliers. The partitioned supplier BR3-1_19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA cannot be associated with the common supplier 19381564000140, because this common supplier is already associated with BR1-19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA.
Error executing trigger IntegrationPostLoad on [ariba.common.core.Supplier [BaseId 13436469218331 B+RQAGmDDhr+Ywb 4rgmmupsr.1qa9cqee]] with data {
AmountRoundingForInvExceptionCalculation = "File \"SupplierConsolidated.csv\" (line 15, column AmountRoundingForInvExceptionCalculation): '0'";
CommonSupplier = {
CorpAddrCountry = "File \"SupplierConsolidated.csv\" (line 15, column Country): 'BR'";
CorpAddrLines = "File \"SupplierConsolidated.csv\" (line 15, column Street): 'R GUARARAPES 2064 - 7 ANDAR - BROOKLIN PAULISTA'";
CorpAddrState = "File \"SupplierConsolidated.csv\" (line 15, column State): 'SP'";
CorporateAddress = {
UniqueName = "File \"SupplierConsolidated.csv\" (line 15, column AddressID): 'BR3-1_19381564000140'";
};
CorporateEmailAddress = "File \"SupplierConsolidated.csv\" (line 15, column CorporateEmailAddress): 'rtrevizan@mantris.com.br'";
CorporatePhone = "File \"SupplierConsolidated.csv\" (line 15, column CorporatePhone): '11 944775350'";
HasSyncRelationship = "File \"SupplierConsolidated.csv\" (line 15, column HasSyncRelationship): 'false'";
HasTradingRelationship = "File \"SupplierConsolidated.csv\" (line 15, column HasTradingRelationship): 'false'";
Name = "File \"SupplierConsolidated.csv\" (line 15, column Name): 'MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA'";
PreferredCurrency = {
UniqueName = "File \"SupplierConsolidated.csv\" (line 15, column PreferredCurrency): 'BRL'";
};
PreferredLanguage = {
UniqueName = "File \"SupplierConsolidated.csv\" (line 15, column PreferredLanguage): 'BrazilianPortuguese'";
};
SystemID = "File \"SupplierConsolidated.csv\" (line 15, column SystemID): 'ACM_72530498'";
};
Name = "File \"SupplierConsolidated.csv\" (line 15, column Name): 'MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA'";
PaymentModel = "File \"SupplierConsolidated.csv\" (line 15, column PaymentModel): '-1'";
SubContractor = "File \"SupplierConsolidated.csv\" (line 15, column SubContractor): '0'";
UniqueName = "File \"SupplierConsolidated.csv\" (line 15, column VendorID): 'BR3-1_19381564000140'";
}

o que est√° dizendo nesse erro ?
Assistant: Assistant: O erro indica que voc√™ est√° tentando associar um fornecedor comum a m√∫ltiplos fornecedores particionados, o que n√£o √© permitido no sistema Ariba.

**Detalhes do Erro:**

*   **Mensagem principal:** "Voc√™ n√£o pode associar um fornecedor comum com m√∫ltiplos fornecedores particionados."
*   **Fornecedor particionado com problema:** `BR3-1_19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`
*   **Fornecedor comum:** `19381564000140`
*   **Fornecedor particionado j√° associado ao fornecedor comum:** `BR1-19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`

**Interpreta√ß√£o:**

O sistema j√° tem o fornecedor comum `19381564000140` associado ao fornecedor particionado `BR1-19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`. Voc√™ est√° tentando associar o mesmo fornecedor comum ao fornecedor particionado `BR3-1_19381564000140:MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`, o que causa o erro.

**Poss√≠veis Causas:**

*   **Configura√ß√£o Incorreta:** Pode haver um erro na forma como os fornecedores est√£o configurados no sistema Ariba.
*   **Dados Duplicados:** Possivelmente h√° dados duplicados ou conflitantes na importa√ß√£o do arquivo `SupplierConsolidated.csv`.
*   **L√≥gica de Particionamento Inadequada:** A l√≥gica de particionamento pode n√£o estar funcionando corretamente, resultando em tentativas de associa√ß√µes inv√°lidas.

**Informa√ß√µes Adicionais do Log:**

O log tamb√©m fornece informa√ß√µes sobre os dados do fornecedor que est√£o sendo processados a partir do arquivo `SupplierConsolidated.csv`, incluindo:

*   Nome do fornecedor: `MANTRIS GESTAO EM SAUDE CORPORATIVA LTDA`
*   Endere√ßo: `R GUARARAPES 2064 - 7 ANDAR - BROOKLIN PAULISTA`
*   Pa√≠s: `BR`
*   Estado: `SP`
*   E-mail: `rtrevizan@mantris.com.br`
*   Telefone: `11 944775350`
*   ID do sistema: `ACM_72530498`

**Pr√≥ximos Passos:**

1.  **Verifique a configura√ß√£o dos fornecedores:** No sistema Ariba, examine a configura√ß√£o dos fornecedores `BR3-1_19381564000140`, `BR1-19381564000140` e `19381564000140` para identificar quaisquer erros.
2.  **Analise o arquivo `SupplierConsolidated.csv`:** Verifique a linha 15 (onde o erro foi detectado) para garantir que os dados do fornecedor estejam corretos e consistentes.
3.  **Revise a l√≥gica de particionamento:** Certifique-se de que a l√≥gica de particionamento est√° configurada corretamente para evitar associa√ß√µes inv√°lidas.
4.  **Remova ou corrija a associa√ß√£o existente:** Se a associa√ß√£o entre o fornecedor comum e o fornecedor particionado `BR1-19381564000140` estiver incorreta, remova-a ou corrija-a antes de tentar associar o fornecedor comum a `BR3-1_19381564000140`.

Lembre-se de que a solu√ß√£o exata depender√° da sua configura√ß√£o espec√≠fica do Ariba e da sua l√≥gica de particionamento.
User: extraia o CNPJ da imagem.
Assistant: O CNPJ presente na imagem √©: `47214053000179`.
User: Como eu devo gerar um prompt para um assistente assim como voc√™?

Voc√™ atualmente recebe meus c√≥digos, imagens e consegue me retornar tudo que eu pergunto.

Ainda consigo armazenar contextos devido a grande quantidade de tokens que a API de LLM e OCR oferece.

Preciso de um assistente que me fa√ßa evoluir na carreira, mudar de emprego

Atualmente tenho registro em carteira de Analista de suporte aplica√ß√µes Pleno.

Mas desenvolvo pap√©is muito mais avan√ßados do que um simples analista.

Abaixo um pouco sobre meu perfil.

Profissional de tecnologia desde 2011, com s√≥lida forma√ß√£o em Desenvolvimento de Software e mais de 300 certifica√ß√µes. Especialista em SAP Ariba (SLP), automa√ß√£o de processos e integra√ß√£o de sistemas, atuando no Projeto Stefanini x Atacad√£o.

üöÄ Principais Compet√™ncias:
üîÑ SAP Ariba SLP ‚Äì Configura√ß√£o e otimiza√ß√£o do ciclo de vida de fornecedores
ü§ñ Automa√ß√£o & IA Generativa - Cria√ß√£o de Agentes Inteligentes, RPA. LLM, OCR.
üîó Integra√ß√£o ERP ‚Äì Sincroniza√ß√£o de dados entre SAP Ariba e sistemas corporativos
üìä Master Data Automation ‚Äì Algoritmo em Python para cadastro automatizado
üë©‚Äçüè´ Treinamento & Suporte ‚Äì Capacita√ß√£o cont√≠nua para usu√°rios

üèÜ Destaques:
‚úîÔ∏è Projeto premiado no Desafio de IA da Stefanini ‚Äì Automa√ß√£o que reduziu tempo operacional e aumentou a precis√£o dos dados
‚úîÔ∏è Desenvolvimento de Agentes IA de automatizando tarefas repetitivas e Integra√ß√£o de Sistemas
‚úîÔ∏è Engenharia de Prompt & IA Generativa
‚úîÔ∏è Engenharia de Software.

üíª Tecnologias: Java| Python | PostgreSQL | Spring Boot | Selenium | LLM| OCR | Git
2025-04-10 17:44:05,903 [INFO] Resposta da IA (imagem): Ok, vamos criar um prompt para um assistente de IA que te ajude a evoluir na sua carreira e buscar novas oportunidades de emprego. O objetivo √© que ele compreenda seu perfil, te auxilie na identifica√ß√£o de oportunidades e forne√ßa orienta√ß√£o estrat√©gica.

**Prompt:**

"Voc√™ √© um consultor de carreira especializado em profissionais de tecnologia com mais de 10 anos de experi√™ncia. Seu objetivo √© auxiliar [Seu Nome] a identificar oportunidades de progress√£o na carreira, com foco em transi√ß√£o para cargos mais avan√ßados e/ou novas empresas que valorizem suas habilidades e conhecimentos.

**Informa√ß√µes sobre [Seu Nome]:**

*   Profissional de tecnologia desde 2011.
*   Analista de Suporte Aplica√ß√µes Pleno (cargo atual, mas com atua√ß√£o em pap√©is mais avan√ßados).
*   Especialista em SAP Ariba (SLP), automa√ß√£o de processos e integra√ß√£o de sistemas.
*   Experi√™ncia no Projeto Stefanini x Atacad√£o.
*   Mais de 300 certifica√ß√µes.
*   Vasta experi√™ncia com ferramentas de automa√ß√£o, IA generativa, agentes inteligentes, RPA, LLM e OCR.
*   Expertise em integra√ß√£o ERP (sincroniza√ß√£o de dados entre SAP Ariba e sistemas corporativos).
*   Desenvolvimento de algoritmo em Python para automa√ß√£o de cadastro (Master Data Automation).
*   Habilidade em treinamento e suporte a usu√°rios.
*   Premiado no Desafio de IA da Stefanini pelo desenvolvimento de automa√ß√£o que reduziu tempo operacional e aumentou a precis√£o dos dados.
*   Forte conhecimento em Engenharia de Prompt & IA Generativa e Engenharia de Software.
*   **Tecnologias:** Java, Python, PostgreSQL, Spring Boot, Selenium, LLM, OCR, Git.

**Tarefas:**

1.  **An√°lise de Perfil:** Analise as informa√ß√µes fornecidas sobre [Seu Nome] e identifique seus pontos fortes, diferenciais e √°reas de expertise mais relevantes para cargos de lideran√ßa ou especialista.
2.  **Identifica√ß√£o de Oportunidades:**
    *   Pesquise vagas de emprego em plataformas como LinkedIn, Glassdoor e outras fontes relevantes, buscando por cargos como:
        *   Analista de Sistemas S√™nior
        *   Especialista em Automa√ß√£o de Processos
        *   Arquiteto de Solu√ß√µes
        *   Consultor SAP Ariba (focado em SLP)
        *   Engenheiro de IA (com foco em automa√ß√£o e integra√ß√£o)
        *   L√≠der T√©cnico
        *   Gerente de Projetos (com foco em SAP Ariba ou automa√ß√£o)
    *   Priorize vagas que valorizem a experi√™ncia com SAP Ariba (SLP), automa√ß√£o, IA generativa e integra√ß√£o de sistemas.
    *   Considere empresas que buscam inova√ß√£o e transforma√ß√£o digital, valorizando a experi√™ncia de [Seu Nome] em projetos de automa√ß√£o e IA.
3.  **Sugest√µes de Aprimoramento:**
    *   Identifique √°reas em que [Seu Nome] pode se aprimorar para aumentar suas chances de sucesso em cargos mais avan√ßados. Isso pode incluir a aquisi√ß√£o de novas certifica√ß√µes, o desenvolvimento de habilidades de lideran√ßa ou a participa√ß√£o em projetos de destaque.
    *   Forne√ßa sugest√µes de cursos, treinamentos e eventos que podem ajudar [Seu Nome] a se manter atualizado com as √∫ltimas tend√™ncias do mercado.
4.  **Revis√£o de Curr√≠culo e Perfil no LinkedIn:**
    *   Revise o curr√≠culo e o perfil no LinkedIn de [Seu Nome] para garantir que destaquem suas principais habilidades, projetos de destaque e resultados alcan√ßados.
    *   Sugira melhorias na descri√ß√£o das experi√™ncias e habilidades para que sejam mais atraentes para recrutadores e empresas.
5.  **Simula√ß√£o de Entrevistas:**
    *   Prepare perguntas de entrevista com base nos cargos e empresas identificados, com foco em desafios t√©cnicos, habilidades de lideran√ßa e experi√™ncia em projetos de automa√ß√£o e IA.
    *   Forne√ßa feedback sobre as respostas de [Seu Nome], com sugest√µes de como melhorar sua comunica√ß√£o e destacar seus pontos fortes.
6.  **Networking:**
    *   Identifique pessoas-chave em empresas de interesse para [Seu Nome] e sugira estrat√©gias para se conectar com elas e construir um relacionamento profissional.
    *   Forne√ßa exemplos de mensagens de contato e abordagens para iniciar conversas relevantes.
7.  **An√°lise de Mercado:**
    *   Monitore as tend√™ncias do mercado de tecnologia e forne√ßa insights sobre as habilidades e conhecimentos mais valorizados pelas empresas.
    *   Identifique novas √°reas de oportunidade em que [Seu Nome] pode se especializar para aumentar sua empregabilidade e potencial de ganhos.

**Instru√ß√µes Adicionais:**

*   Use um tom profissional, amig√°vel e motivador.
*   Baseie suas recomenda√ß√µes em dados e informa√ß√µes relevantes do mercado de tecnologia.
*   Considere a experi√™ncia e os objetivos de carreira de [Seu Nome] ao fornecer sugest√µes e recomenda√ß√µes.
*   Forne√ßa exemplos concretos e pr√°ticos para facilitar a implementa√ß√£o das suas sugest√µes.
*   Mantenha o contexto das conversas anteriores para fornecer um acompanhamento personalizado e eficiente.
*   Seja proativo na identifica√ß√£o de oportunidades e forne√ßa insights valiosos para ajudar [Seu Nome] a alcan√ßar seus objetivos de carreira.
*   Use t√©cnicas de perguntas e respostas para aprofundar o entendimento do perfil e metas de [Seu Nome], para refinar as dicas e aumentar o valor agregado do seu suporte.

**Exemplo de Intera√ß√£o:**

**Usu√°rio:** "Estou me sentindo estagnado no meu cargo atual. Gostaria de explorar oportunidades de lideran√ßa t√©cnica em projetos de automa√ß√£o. O que voc√™ sugere?"

**Assistente:** "Com base na sua experi√™ncia e habilidades, vejo grande potencial para voc√™ em cargos de lideran√ßa t√©cnica em projetos de automa√ß√£o. Para come√ßar, sugiro que revisemos seu curr√≠culo e perfil no LinkedIn para destacar seus projetos de destaque e resultados alcan√ßados. Al√©m disso, podemos pesquisar vagas de emprego em empresas que valorizam a inova√ß√£o e a transforma√ß√£o digital. Voc√™ tem alguma empresa em mente que te interesse?"

**Dicas Adicionais:**

*   **Itera√ß√£o:** Ajuste o prompt conforme necess√°rio para refinar o comportamento do assistente e obter resultados mais precisos.
*   **Personaliza√ß√£o:** Quanto mais detalhes voc√™ fornecer sobre seu perfil, seus objetivos e suas prefer√™ncias, mais personalizado e eficiente ser√° o suporte do assistente.
*   **Feedback:** Forne√ßa feedback constante ao assistente sobre a qualidade das suas respostas para que ele possa aprender e se adaptar √†s suas necessidades.

Espero que este prompt te ajude a criar um assistente de IA poderoso para impulsionar sua carreira!

2025-04-10 17:44:06,025 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:44:06,028 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:44:06,031 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:44:06,033 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:44:06,036 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:44:06,039 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:44:06,042 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 17:44:06,046 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:44:06,049 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:44:06,051 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:44:06,054 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:44:06,056 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:44:06,058 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:44:06,060 [INFO] Arquivo lido com sucesso: test_image_generation.py
2025-04-10 17:44:06,063 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:51:54,357 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 17:51:54,358 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 17:51:54,360 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 17:51:54,361 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:51:54,363 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 17:51:54,365 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:51:54,367 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:51:54,369 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:51:54,371 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:51:54,373 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:51:54,375 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 17:51:54,377 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 17:51:54,378 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 17:51:54,380 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 17:51:54,381 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 17:51:54,384 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 17:51:54,386 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 17:51:54,388 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:51:54,390 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:51:54,391 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:51:54,393 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:51:54,395 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:51:54,396 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:51:54,397 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 17:51:54,400 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 17:51:54,402 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 17:51:54,404 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 17:51:54,405 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 17:51:54,407 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 17:51:54,409 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 17:51:54,410 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:51:54,411 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 17:51:54,412 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 17:51:54,414 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 17:51:54,416 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 17:51:54,418 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 17:51:54,420 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 17:51:54,422 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 17:51:54,423 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 17:51:54,425 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 17:51:54,426 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 17:51:54,428 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 17:51:54,429 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 17:51:54,431 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 17:51:54,432 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 17:51:54,435 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 17:51:54,437 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 17:51:54,439 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 17:51:54,440 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 17:51:54,441 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 17:51:54,443 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 17:51:54,445 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 17:51:54,446 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 17:51:54,448 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 17:51:55,238 [INFO] Modelo Gemini 'gemini-2.0-flash-exp' inicializado com sucesso.
2025-04-10 17:53:29,161 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 17:53:29,163 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 17:53:29,165 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 17:53:29,166 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:53:29,168 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 17:53:29,169 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:53:29,171 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:53:29,173 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:53:29,174 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:53:29,177 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:53:29,179 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 17:53:29,183 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 17:53:29,187 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 17:53:29,189 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 17:53:29,190 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 17:53:29,194 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 17:53:29,196 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 17:53:29,199 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:53:29,201 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:53:29,202 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:53:29,204 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:53:29,205 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:53:29,207 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:53:29,210 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 17:53:29,212 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 17:53:29,215 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 17:53:29,217 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 17:53:29,218 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 17:53:29,220 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 17:53:29,222 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 17:53:29,224 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:53:29,226 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 17:53:29,228 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 17:53:29,231 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 17:53:29,233 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 17:53:29,234 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 17:53:29,236 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 17:53:29,237 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 17:53:29,239 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 17:53:29,241 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 17:53:29,243 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 17:53:29,245 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 17:53:29,248 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 17:53:29,249 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 17:53:29,251 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 17:53:29,252 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 17:53:29,254 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 17:53:29,255 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 17:53:29,257 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 17:53:29,260 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 17:53:29,261 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 17:53:29,263 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 17:53:29,265 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 17:53:29,267 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 17:53:29,388 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 17:53:29,389 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 17:53:29,391 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 17:53:29,393 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:53:29,396 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 17:53:29,399 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:53:29,402 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:53:29,404 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:53:29,405 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:53:29,407 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:53:29,409 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 17:53:29,412 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 17:53:29,415 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 17:53:29,417 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 17:53:29,419 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 17:53:29,420 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 17:53:29,422 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 17:53:29,424 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:53:29,427 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:53:29,429 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:53:29,432 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:53:29,434 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:53:29,436 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:53:29,439 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 17:53:29,444 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 17:53:29,448 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 17:53:29,451 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 17:53:29,453 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 17:53:29,455 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 17:53:29,457 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 17:53:29,460 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:53:29,462 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 17:53:29,466 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 17:53:29,468 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 17:53:29,469 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 17:53:29,472 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 17:53:29,474 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 17:53:29,476 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 17:53:29,478 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 17:53:29,480 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 17:53:29,482 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 17:53:29,484 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 17:53:29,485 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 17:53:29,486 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 17:53:29,488 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 17:53:29,490 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 17:53:29,492 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 17:53:29,494 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 17:53:29,497 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 17:53:29,498 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 17:53:29,500 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 17:53:29,502 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 17:53:29,503 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 17:53:29,505 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 17:53:29,511 [INFO] Enviando para IA - Prompt (sem imagem): Voc√™ √© um assistente inteligente utilizado em um chat com IA, que recebe c√≥digos de uma aplica√ß√£o completa de chat, como voc√™ funciona e tudo que 
√© programado para fazer no seu contexto.

Seu objetivo √©:
- Analisar todo o contexto e aprender com ele.
- Analisar a Pergunta do Usu√°rio.
- Identificar se possui rela√ß√£o com o contexto.
- Se houver rela√ß√£o com o c√≥digo do contexto responder a pergunta sobre o c√≥digo sempre seguindo boas pr√°ticas:
    - Analisar o c√≥digo-fonte contido no projeto enviado
    - Identificar melhorias em legibilidade, performance e seguran√ßa
    - Sugerir pr√°ticas recomendadas de design e arquitetura
    - Indicar partes com d√≠vidas t√©cnicas ou complexidade desnecess√°ria
    - Enviar c√≥digo modularizado em pequenos arquivos separados por pastas.

Informa√ß√µes adicionais:
- Estrutura do projeto: segue o padr√£o de pastas iniciando por src/


## Se houver imagem no contexto, identifique se a pergunta √© sobre o c√≥digo do contexto, sobre a imagem ou sobre os dois para elaborar melhorer respostas.
## Se o usu√°rio fizer uma pergunta que n√£o tem rela√ß√£o com imagem ou contexto, use a sua base de conhecimento fora do contexto para responder de forma inteligente.
** Responda em Portugu√™s-Brasileiro a n√£o ser que o usu√°rio solicite outra l√≠ngua.**

Contexto:



# app_config\app_config.py

from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()
    
    def get_root_path(self):
        return str(self.ROOT_PATH)
    
    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py

from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        transcription_config = TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])


# audio_to_text\audio_to_text.py

import whisper
from audio_to_text.audio_config.audio_config import AudioConfig

class AudioToConverter:
    def __init__(self, audio_config: AudioConfig):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.AUDIO_INPUT_PATH
        self.TRANSCRIPTION_INPUT_PATH = audio_config.TRANSCRIPTION_INPUT_PATH

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            print(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        model = whisper.load_model("base")

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                print(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            print(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            print(f"Erro ao processar o arquivo {audio_file_path}: {e}")


# chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# common_paths\common_paths.py

from pathlib import Path

class CommonPaths:
    def __init__(self):
        # Diret√≥rio atual do script
        self.ROOT_PATH = Path(__file__).resolve().parent

        # Defini√ß√£o dos caminhos comuns
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'output'
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.AUDIO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.TRANSCRIPTION_OUTPUT_PATH = self.ROOT_PATH / 'data'
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'data'

        # Cria√ß√£o dos diret√≥rios
        self.create_directories()

    def create_directories(self):
        self.VIDEO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.VIDEO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.TRANSCRIPTION_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)



# config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# fundamentus_api\fundamentus\__init__.py



# fundamentus_api\fundamentus\dados_b3.py

import locale
import pandas as pd
import streamlit as st
import requests
import fundamentus
import os
import plotly.express as px
from bs4 import BeautifulSoup
from fundamentus.detalhes import get_papel
import logging

# Configura localidade
locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')

# Configura√ß√£o do layout do Streamlit
st.set_page_config(
    page_title="An√°lise de A√ß√µes",
    layout="wide",
    page_icon="üìà"
)

class Acao:
    def __init__(self, papel):
        self.papel = papel
        self.dados_fundamentais = None
        self.proventos = None
        self.detalhes = None
        self.oscilacoes = None  # Adicionando um atributo para oscila√ß√µes

    def carregar_dados_fundamentais(self):
        self.dados_fundamentais = fundamentus.get_resultado().loc[[self.papel]]  # Use colchetes duplos para garantir que seja um DataFrame
        self.remover_formatacao()

    def obter_detalhes(self):
        self.detalhes = get_papel(self.papel)
        if self.detalhes is None or self.detalhes.empty:
            logging.warning(f"Nenhum detalhe encontrado para o papel: {self.papel}")

    def obter_proventos(self):
        url = f"https://www.fundamentus.com.br/proventos.php?papel={self.papel}&tipo=2"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        tabela = soup.find('table', {'id': 'resultado'})

        if not tabela:
            return pd.DataFrame()

        dados = []
        for linha in tabela.find_all('tr')[1:]:
            colunas = linha.find_all('td')
            try:
                valor = float(colunas[1].text.strip().replace(',', '.'))
            except ValueError:
                valor = None  # Se der erro, coloca None para evitar crash

            dados.append([colunas[0].text.strip(), valor, colunas[2].text.strip()])
        
        self.proventos = pd.DataFrame(dados, columns=['Data', 'Valor', 'Tipo'])
        return self.proventos

    def obter_oscilacoes(self):
        url = f"https://www.fundamentus.com.br/detalhes.php?papel={self.papel}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        conteudo_div = soup.find('div', class_='conteudo clearfix')

        if conteudo_div is None:
            return pd.DataFrame()

        oscilacoes_data = []
        oscilacoes_section = conteudo_div.find('td', class_='nivel1', colspan='2')
        
        if oscilacoes_section:
            labels = oscilacoes_section.find_all_next('td', class_='label w1')
            dados = oscilacoes_section.find_all_next('td', class_='data w1')

            for label, dado in zip(labels, dados):
                label_text = label.get_text(strip=True)
                valor_text = dado.find('span', class_='oscil').get_text(strip=True)
                oscilacoes_data.append([label_text, valor_text])

        self.oscilacoes = pd.DataFrame(oscilacoes_data, columns=['Per√≠odo', 'Oscila√ß√£o'])
        return self.oscilacoes

    def remover_formatacao(self):
        colunas_percentuais = ['dy', 'mrgebit', 'mrgliq', 'roic', 'roe', 'c5y']
        for coluna in colunas_percentuais:
            if coluna in self.dados_fundamentais:
                try:
                    self.dados_fundamentais[coluna] = self.dados_fundamentais[coluna].astype(float)
                except ValueError as e:
                    logging.error(f"Erro ao converter coluna {coluna} para float: {e}")

    def formatar_moeda(self, valor):
        return locale.currency(valor, symbol=True, grouping=True)

class Aplicacao:
    def __init__(self):
        self.acoes = fundamentus.get_resultado()

    def ajustar_tipos_dataframe(self, df):
        for coluna in df.columns:
            if df[coluna].dtype == 'object':
                try:
                    df[coluna] = df[coluna].astype(float)
                except ValueError:
                    df[coluna] = df[coluna].astype(str)
            elif df[coluna].dtype in ['int64', 'float64']:
                df[coluna] = df[coluna].astype(float)
        return df

    def exibir_dashboard(self):
        st.sidebar.title("üìä Dashboard de An√°lise de A√ß√µes")
        st.sidebar.write("Selecione um papel para visualizar detalhes.")

        papel_selecionado = st.sidebar.selectbox("Escolha uma a√ß√£o", self.acoes.index)

        acao = Acao(papel_selecionado)
        acao.carregar_dados_fundamentais()
        acao.obter_proventos()
        acao.obter_detalhes()
        acao.obter_oscilacoes()

        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader(f"üìå Dados Fundamentais - {papel_selecionado}")
            dados_fundamentais_df = self.ajustar_tipos_dataframe(acao.dados_fundamentais.T)
            st.dataframe(dados_fundamentais_df, width=400)

        with col2:
            st.subheader("üîç Detalhes")
            if acao.detalhes is not None and not acao.detalhes.empty:
                detalhes_df = pd.DataFrame(acao.detalhes).T.reset_index()
                detalhes_df.columns = ['Descri√ß√£o', 'Valor']
                detalhes_df = self.ajustar_tipos_dataframe(detalhes_df)

                st.subheader("Tabela de Detalhes")
                st.dataframe(detalhes_df, width=800)
            else:
                st.warning("Nenhum detalhe encontrado para essa a√ß√£o.")

        col_dividendos, col_oscilacoes = st.columns([1, 2])

        with col_dividendos:
            st.subheader("üí∞ Dividendos")
            if not acao.proventos.empty:
                proventos_df = self.ajustar_tipos_dataframe(acao.proventos)
                st.write(proventos_df)

        with col_oscilacoes:
            st.subheader("üìâ Oscila√ß√µes")
            if acao.oscilacoes is not None and not acao.oscilacoes.empty:
                oscilacoes_df = self.ajustar_tipos_dataframe(acao.oscilacoes)
                st.write(oscilacoes_df)

        st.subheader("üìà Tabela Geral de A√ß√µes")
        st.dataframe(self.acoes)

# Execu√ß√£o
if __name__ == "__main__":
    app = Aplicacao()
    app.exibir_dashboard()

# fundamentus_api\setup.py

from setuptools import setup, find_packages

setup(
    name='fundamentalvision ',
    version='0.1.0',
    author='Joel FerreiraHeanna dos Reis',
    author_email='heannareis@gmail.com',
    description='Um pacote para an√°lise fundamentalista de a√ß√µes da Bolsa B3 do Brasil.',
    packages=find_packages(),
    install_requires=[
        'pandas',
        'requests',
        'beautifulsoup4',
        'streamlit',
        'plotly',
        'fundamentus'
    ],
    classifiers=[
        'Programming Language :: Python :: 3',
        'License :: OSI Approved :: MIT License',
        'Operating System :: OS Independent',
    ],
    python_requires='>=3.6',
)

# ia_generator.py

import requests
from pathlib import Path
import webbrowser
from config.common_paths import TRANSCRIPTION_OUTPUT_PATH

apiKey = "6UlOOoY/kkmprunma/qNDg"

str_personas = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'personas.txt'
str_contexto = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'contexto.txt'

url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

txt_files = list(TRANSCRIPTION_OUTPUT_PATH.glob('*.txt'))

css_styles = """
<style>
body {
    font-family: Arial, sans-serif;
    margin: 20px;
}

h1, h2, h3 {
    color: #FF8C00;
}

li, strong, p {
    color: #008000;
}

h1 {
    font-size: 24px;
    margin-bottom: 20px;
}

h2 {
    font-size: 20px;
    margin-top: 20px;
    margin-bottom: 10px;
}

ul {
    list-style-type: disc;
    margin-left: 40px;
}

li {
    margin-bottom: 10px;
}

p {
    line-height: 1.6;
}
</style>
"""

if not txt_files:
    print(f"N√£o foram encontrados arquivos .txt no diret√≥rio {TRANSCRIPTION_OUTPUT_PATH}.")
else:
    for txt_file in txt_files:
        if txt_file.is_file():
            print(f"Lendo o arquivo: {txt_file.name}")
            with open(txt_file, 'r', encoding='utf-8') as file:
                str_reuniao = file.read()

            print(f"Enviando o conte√∫do do arquivo {txt_file.name} para a API...")
            data = {
                "inputs": {
                    "str_reuniao": str_reuniao,
                    "str_personas": str_personas.read_text(encoding='utf-8'),
                    "str_contexto": str_contexto.read_text(encoding='utf-8'),
                }
            }

            response = requests.post(f"{url}/api/templates/668de04202493d3063a9d7fa/execute", json=data, headers=headers)
            if response.status_code == 200:
                print(f"Resultado para o arquivo {txt_file.name} recebido.")
                html_content = response.text
                print(response.text)

                # Incluir o CSS no conte√∫do HTML
                html_with_css = f"<html><head>{css_styles}</head><body>{html_content}</body></html>"

                # Salvar o conte√∫do HTML em um arquivo
                output_file = TRANSCRIPTION_OUTPUT_PATH / f"{txt_file.stem}_output.html"
                with open(output_file, 'w', encoding='utf-8') as html_file:
                    html_file.write(html_with_css)

                # Abrir o arquivo HTML no navegador
                webbrowser.open(f"file://{output_file.resolve()}")
            else:
                print(f"Erro ao processar o arquivo {txt_file.name}: {response.status_code}")


# main.py

from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from transcriptions.transcriptions_config import TranscriptionConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from pathlib import Path

def main():
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    root_path = str(PROJECT_ROOT)
    print(f"Root path: {root_path}")  # Para verificar se est√° correto
    api_url = "http://localhost:8081/api/meetings/transcriptions"
    
    # # Configura√ß√£o de v√≠deos
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()
    
    # # Configura√ß√£o de √°udios
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()
    
    # # Processamento de transcri√ß√µes e envio de embeddings
    # embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    # embedding_processor_wrapper.process_transcriptions()

if __name__ == "__main__":
    main()


# send_embeddings_database\embedding_config\embedding_config.py

from app_config.app_config import AppConfig

class EmbeddingConfig(AppConfig):
    def __init__(self, root_path=None, transcription_input_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = transcription_input_path
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'embeddings' / 'output'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH, self.EMBEDDING_OUTPUT_PATH])


# send_embeddings_database\verify_last_enbedding.py

import os
import numpy as np

def get_latest_file(directory):
    # Listar todos os arquivos no diret√≥rio
    files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]
    
    if not files:
        raise FileNotFoundError("Nenhum arquivo encontrado no diret√≥rio.")

    # Encontrar o arquivo mais recente
    latest_file = max(files, key=os.path.getmtime)
    return latest_file

def load_and_print_embedding(directory):
    # Obter o caminho do √∫ltimo arquivo de embedding
    embedding_file_path = get_latest_file(directory)
    
    # Carregar o embedding
    embedding = np.load(embedding_file_path)
    
    # Exibir o conte√∫do do embedding
    print("Embedding carregado:")
    print(embedding)
    print("Dimens√µes do embedding:", embedding.shape)

# Caminho do diret√≥rio de embeddings
embedding_directory = 'C:/Users/HeannarReis/Documents/bsa_atacadao/assets/embeddings/output'

# Carregar e exibir o √∫ltimo embedding
load_and_print_embedding(embedding_directory)


# services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# test_whisper.py

from transformers import pipeline
from common_paths import CommonPaths

commmom_paths = CommonPaths()

# Fun√ß√£o para ler a transcri√ß√£o de um arquivo
def read_transcription(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
    return lines

# Fun√ß√£o para converter a pontua√ß√£o em estrelas
def score_to_stars(score):
    if score >= 0.75:
        return 5
    elif score >= 0.55:
        return 4
    elif score >= 0.35:
        return 3
    elif score >= 0.15:
        return 2
    else:
        return 1

# Inicializar o pipeline de an√°lise de sentimento
sentiment_pipeline = pipeline("sentiment-analysis", model="neuralmind/bert-base-portuguese-cased")

# Caminho para o arquivo de transcri√ß√£o
file_path = commmom_paths.TRANSCRIPTION_OUTPUT_PATH / 'feedback.txt'

# Ler a transcri√ß√£o
lines = read_transcription(file_path)

# Analisar sentimento para cada feedback
for line in lines:
    sentiment = sentiment_pipeline(line.strip())
    score = sentiment[0]['score']
    stars = score_to_stars(score)
    
    # Ajuste manual para feedbacks com aspectos positivos e negativos
    if any(word in line.lower() for word in ["mas", "por√©m", "no entanto"]):
        stars = max(1, stars - 1)  # Reduz uma estrela se houver contradi√ß√£o
    
    # Ajuste adicional baseado em palavras-chave
    positive_keywords = ["excelente", "√≥timo", "perfeito", "r√°pido", "eficiente", "satisfeito", "clara", "eficaz", "bom trabalho"]
    negative_keywords = ["ruim", "p√©ssimo", "horr√≠vel", "poderia", "n√£o resolveu", "insatisfat√≥ria", "confusa", "inadequado", "lento", "n√£o houve seguimento", "n√£o atendeu", "n√£o funcionou", "demorado"]
    
    positive_count = sum(word in line.lower() for word in positive_keywords)
    negative_count = sum(word in line.lower() for word in negative_keywords)
    
    # Ajuste de estrelas baseado na contagem de palavras-chave
    if positive_count > negative_count:
        stars = min(5, stars + 1)
    elif negative_count > positive_count:
        stars = max(1, stars - 1)
    
    print(f"Texto: {line.strip()}")
    print(f"Sentimento: {stars} estrelas")
    print(f"Pontua√ß√£o: {score:.2f}")
    print('---')


# text_to_embedding\embedding_processing.py

from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from transcriptions.transcriptions_config import TranscriptionConfig
from transcriptions.transciption_sender_database import TranscriptionSenderDatabase

class EmbeddingProcessorWrapper:
    def __init__(self, root_path, api_url):
        # Configura√ß√£o de transcri√ß√µes e embeddings
        transcription_config = TranscriptionConfig(root_path=root_path)
        embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())

        self.embedding_processor = EmbeddingProcessor(embedding_config)
        self.transcription_sender = TranscriptionSenderDatabase(api_url)
    
    def process_transcriptions(self):
        # Mostrar o diret√≥rio onde est√° procurando as transcri√ß√µes
        print(f"Diret√≥rio de entrada das transcri√ß√µes: {self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH}")
        
        # Listar todos os arquivos de transcri√ß√£o no diret√≥rio de entrada
        transcription_files = list(self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH.glob('*.txt'))
        if not transcription_files:
            print("Nenhum arquivo de transcri√ß√£o encontrado.")
        for transcription_file_path in transcription_files:
            if transcription_file_path.is_file():
                print(f"Processando arquivo: {transcription_file_path}")
                self.process_and_send_transcription(transcription_file_path)
            else:
                print(f"Arquivo n√£o encontrado: {transcription_file_path}")

    def process_and_send_transcription(self, transcription_file_path):
        try:
            # Ler a transcri√ß√£o do arquivo de texto
            with open(transcription_file_path, 'r', encoding='utf-8') as f:
                transcription_text = f.read()
                if not transcription_text:
                    print(f"Arquivo {transcription_file_path} est√° vazio.")
                    return

            # Gerar o embedding da transcri√ß√£o
            embedding = self.embedding_processor.generate_embedding(transcription_text)
            if embedding is None:
                print(f"Falha ao gerar embedding para o arquivo {transcription_file_path}.")
                return

            # Salvar o embedding em um arquivo .npy
            self.embedding_processor.save_embedding(transcription_file_path, embedding)

            # Enviar os dados para a API
            self.transcription_sender.send_transcription(transcription_text, embedding)

        except Exception as e:
            print(f"Erro ao processar o arquivo {transcription_file_path}: {e}")


# text_to_embedding\texto_to_embedding.py

from sentence_transformers import SentenceTransformer
import numpy as np

class EmbeddingProcessor:
    def __init__(self, embedding_config):
        self.embedding_config = embedding_config
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

    def generate_embedding(self, transcription_text):
        return self.embedding_model.encode(transcription_text)

    def save_embedding(self, transcription_file_path, embedding):
        embedding_file_path = self.embedding_config.EMBEDDING_OUTPUT_PATH / transcription_file_path.with_suffix('.npy').name
        np.save(embedding_file_path, embedding)
        print(f"Embedding salvo em: {embedding_file_path}")
        return embedding_file_path


# transcriptions\transciption_sender_database.py

import requests

class TranscriptionSenderDatabase:
    def __init__(self, api_url):
        self.api_url = api_url

    def send_transcription(self, transcription_text, embedding):
        data = {
            'transcriptionText': transcription_text,
            'embedding': embedding.tolist()
        }

        response = requests.post(self.api_url, json=data)

        if response.status_code == 201:
            print("Transcri√ß√£o e embedding enviados com sucesso.")
        else:
            print(f"Erro ao enviar dados: {response.status_code}")
            print("Resposta da API:")
            print(response.text)


# transcriptions\transcriptions_config.py

from app_config.app_config import AppConfig

class TranscriptionConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = self.ROOT_PATH / 'assets' / 'transcriptions' / 'input'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH])
    
    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# translate\translator_to_english.py

import speech_recognition as sr
from translate import Translator

def ouvir_e_traduzir():
    # Inicializa o reconhecedor de fala
    recognizer = sr.Recognizer()

    # Configura o tradutor
    translator = Translator(to_lang="en", from_lang="pt")

    # Usa o microfone como fonte de √°udio
    with sr.Microphone() as source:
        print("Diga algo em portugu√™s...")

        while True:
            try:
                # Escuta o √°udio do microfone
                audio = recognizer.listen(source)
                
                # Reconhece a fala usando o Google Web Speech API
                texto_portugues = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {texto_portugues}")

                # Traduz o texto para o ingl√™s
                traducao = translator.translate(texto_portugues)
                print(f"Tradu√ß√£o para o ingl√™s: {traducao}")

            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio")
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")

if __name__ == "__main__":
    try:
        ouvir_e_traduzir()
    except KeyboardInterrupt:
        print("Interrompido pelo usu√°rio")


# translate\whispert_translator.py

import whisper
import pyaudio
import numpy as np

# Inicializa o modelo Whisper
model = whisper.load_model("base")

# Configura√ß√µes de √°udio
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024

# Inicializa o PyAudio
audio = pyaudio.PyAudio()

# Abre o stream de √°udio
stream = audio.open(format=FORMAT, channels=CHANNELS,
                    rate=RATE, input=True,
                    frames_per_buffer=CHUNK)

print("Diga algo em portugu√™s...")

try:
    audio_buffer = []

    while True:
        # L√™ dados do microfone
        data = stream.read(CHUNK)
        audio_buffer.append(np.frombuffer(data, dtype=np.int16).flatten().astype(np.float32) / 32768.0)

        # Processa o √°udio a cada 5 segundos
        if len(audio_buffer) * CHUNK / RATE >= 5:
            audio_data = np.concatenate(audio_buffer)
            audio_buffer = []

            # Transcreve e traduz o √°udio usando Whisper
            result = model.transcribe(audio_data, task="translate", language="pt")

            # Exibe a tradu√ß√£o
            print(f"Tradu√ß√£o para o ingl√™s: {result['text']}")

except KeyboardInterrupt:
    print("Interrompido pelo usu√°rio")

    # Fecha o stream de √°udio
    stream.stop_stream()
    stream.close()
    audio.terminate()


# utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

# video_to_audio\video_config\video_config.py

from app_config.app_config import AppConfig

class VideoConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video' / 'input'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.create_directories([self.VIDEO_INPUT_PATH, self.VIDEO_OUTPUT_PATH])

# video_to_audio\video_to_audio.py

from moviepy import VideoFileClip
import glob
import os
from .video_config.video_config import VideoConfig

class VideoToAudioConverter:
    def __init__(self, video_config: VideoConfig):
        self.video_config = video_config

    def convert_video_to_audio(self, video_path, audio_path):
        try:
            video = VideoFileClip(video_path)
            if video.audio:
                video.audio.write_audiofile(audio_path, fps=44100)
                print(f"Convertido {video_path} para {audio_path}")
            else:
                print(f"Aviso: O v√≠deo {video_path} n√£o cont√©m √°udio!")
        except Exception as e:
            print(f"Erro ao converter {video_path}: {e}")

    def process_videos(self):
        input_directory = self.video_config.VIDEO_INPUT_PATH
        output_directory = self.video_config.VIDEO_OUTPUT_PATH

        os.makedirs(output_directory, exist_ok=True)

        # Busca qualquer arquivo de v√≠deo (formatos comuns)
        video_files = glob.glob(os.path.join(input_directory, "*.*"))  # Pega todos os arquivos

        # Filtra apenas arquivos de v√≠deo
        video_extensions = {".mp4", ".mkv", ".avi", ".mov", ".wmv", ".flv"}  
        video_files = [f for f in video_files if os.path.splitext(f)[1].lower() in video_extensions]

        if not video_files:
            print(f"Nenhum arquivo de v√≠deo encontrado em: {input_directory}")
            return

        for video_file in video_files:
            base_name = os.path.basename(video_file)
            audio_file = os.path.join(output_directory, os.path.splitext(base_name)[0] + ".wav")
            self.convert_video_to_audio(video_file, audio_file)

        print("Convers√£o de v√≠deo para √°udio conclu√≠da!")


# voice_assistent\assistent.py

import speech_recognition as sr
import pyttsx3
import re
from collections import deque
import spacy
import requests
import os
import webbrowser
from class_voice_assistent.prompt import create_prompt
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import google.generativeai as genai

# Configura√ß√µes da API
handler = genai('gemini-1.5-flash')

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

voices = engine.getProperty('voices')
engine.setProperty('rate', 180)
print("\nLista de Vozes...")
for indice, vozes in enumerate(voices):
    print(indice, vozes.name)

voz = 1
engine.setProperty('voice', voices[voz].id)

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

# Fun√ß√£o para extrair texto de HTML
def extract_text_from_html(html):
    if not html.strip().startswith('<'):
        print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
        return html
    soup = BeautifulSoup(html, 'html.parser')
    text = ' '.join([p.get_text() for p in soup.find_all('p')])
    return text

def get_text_response(prompt, context, feedback):
    # Gere o conte√∫do com base no prompt usando a classe GenerativeModelHandler
    response = handler.generate_content(prompt)
    return response

# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/api/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


# voice_assistent\class_voice_assistent\api_client.py

import requests


class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, meeting):
        try:
            response_text = self.model.generate_content(prompt, context, meeting)
            return response_text
        except Exception as e:
            print(f"Erro inesperado: {e}")
            return None

    def find_similar_embeddings(self, embedding):
        try:
            print(f"Buscando embeddings similares para: {embedding}")
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            similar_embeddings = response.json()

            # Ordenar por similaridade (assumindo que a API retorna com similaridade em ordem decrescente)
            # Remover duplicatas baseadas na pergunta
            seen_questions = set()
            unique_embeddings = []
            for embedding in similar_embeddings:
                question = embedding['question'].strip().lower()
                if question not in seen_questions:
                    unique_embeddings.append(embedding)
                    seen_questions.add(question)
            print(f"Embeddings similares √∫nicos encontrados: {unique_embeddings}")
            return unique_embeddings
        except requests.RequestException as e:
            print(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            # Converter embeddings de numpy arrays para listas
            if hasattr(question_embedding, 'tolist'):
                question_embedding = question_embedding.tolist()
            if hasattr(answer_embedding, 'tolist'):
                answer_embedding = answer_embedding.tolist()
            
            data = {
                "question": question,
                "questionEmbedding": question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding
            }
            
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                print("Pergunta e resposta salvas com sucesso.")
            else:
                print(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            print(f"Erro em save_question_answer: {e}")


    def fetch_all_contexts(self):
        try:
            response = requests.get("http://localhost:8081/api/contexts/all")
            if response.status_code == 200:
                data = response.json()
                contexts = data.get('contexts', [])
                if isinstance(contexts, list):
                    print(f"Contexto obtido da API: {contexts}")
                    return contexts
                else:
                    print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                    return []
            else:
                print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
                return []
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
            return []

    def fetch_last_meeting(self):
        try:
            response = requests.get("http://localhost:8081/api/meetings/last")
            if response.status_code == 200:
                data = response.json()
                transcription_text = data.get('transcriptionText', "")
                if isinstance(transcription_text, str):
                    print(f"Texto da transcri√ß√£o obtido da API: {transcription_text}")
                    return transcription_text
                else:
                    print(f"Erro: 'transcriptionText' n√£o √© uma string. Dados retornados: {data}")
                    return ""
            else:
                print(f"Erro ao acessar a API de reuni√µes: {response.status_code}, {response.text}")
                return ""
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de reuni√µes: {e}")
            return ""


# voice_assistent\class_voice_assistent\command_interpreter.py

import spacy
from prompt_generator.online_prompt import OnlineResearchPromptGenerator
from prompt_generator.meeting_prompt import MeetingPromptGenerator
from prompt_generator.default_prompt_generator import DefaultPromptGenerator
import re

# Carregar o modelo de linguagem natural
nlp = spacy.load("pt_core_news_sm")

class CommandInterpreter:
    def __init__(self, api_client, question_answer_service, context_manager, max_similar=3):
        self.api_client = api_client
        self.question_answer_service = question_answer_service
        self.context_manager = context_manager
        self.max_similar = max_similar  # Limite de contextos similares

    def interpret_command(self, command, meeting):
        print(f"Interpretando comando: {command}")
        contexts = self.api_client.fetch_all_contexts()
        context_str = "\n".join([context['context'] for context in contexts])

        # Gerar embedding para a pergunta e buscar embeddings similares
        question_embedding = self.question_answer_service.convert_text_to_embedding(command)
        similar_embeddings = self.api_client.find_similar_embeddings(question_embedding)

        # Filtrar para evitar respostas redundantes
        unique_responses = self._filter_unique_responses(similar_embeddings, command)
        similar_context = "\n".join([f"Pergunta: {embedding['question']}\nResposta: {embedding['answer']}" for embedding in unique_responses[:self.max_similar]])

        # Detectar tipo de comando usando regex
        if re.search(r'\b(pesquise|pesquisar|procure)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como pesquisa online.")
            response = self.get_online_research_response(command, context_str, similar_context)
        elif re.search(r'\b(contexto)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como busca de contexto.")
            response = self.get_project_response(command, meeting, context_str, similar_context)
        elif re.search(r'\b(resumo?|t√≥picos da|pontos (relevantes|principais)|an√°lise)\b.*\b(reuni√£o|√∫ltima (reuni√£o|conversa|sess√£o))\b', command, re.IGNORECASE):
            print(f"\nComando identificado como an√°lise de reuni√£o.")
            meeting = self.api_client.fetch_last_meeting()
            response = self.get_meeting_analysis_response(command, context_str, meeting)
        else:
            print(f"\nComando identificado como comando padr√£o.")
            response = self.handle_default_command(command, context_str, meeting, similar_context)

        if response:
            answer_embedding = self.question_answer_service.convert_text_to_embedding(response)
            self.api_client.save_question_answer(command, question_embedding, response, answer_embedding)
            self.context_manager.add_context(command, response)

        return response

    def _filter_unique_responses(self, similar_embeddings, current_command):
        """
        Filtra respostas semelhantes que s√£o muito similares ao comando atual para evitar redund√¢ncia.
        """
        filtered = []
        for embedding in similar_embeddings:
            if embedding['question'].lower() != current_command.lower():
                filtered.append(embedding)
        return filtered

    def handle_default_command(self, command, context_str, meeting, similar_context):
        print(f"\nTratando comando padr√£o: {command}")
        # Combinar o contexto atual com os contextos similares para enriquecer a resposta
        combined_context = f"{context_str}\n{similar_context}"
        prompt = DefaultPromptGenerator().generate_prompt(command, combined_context, meeting)
        response = self.api_client.get_text_response(prompt, combined_context, meeting)
        return response

    # M√©todos get_project_response, get_meeting_analysis_response, get_online_research_response permanecem inalterados

    def get_project_response(self, command, meeting, context_str, similar_context):
        print(f"\nGerando prompt de projeto.")
        prompt = DefaultPromptGenerator().generate_prompt(command, context_str, meeting, similar_context)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_meeting_analysis_response(self, command, context_str, meeting):
        print(f"\nGerando prompt de an√°lise de reuni√£o.")
        prompt = MeetingPromptGenerator().generate_prompt(command, context_str, meeting)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_online_research_response(self, command, context_str, similar_context):
        print(f"\nGerando prompt de pesquisa online.")
        prompt = OnlineResearchPromptGenerator().generate_prompt(command, context_str, similar_context)
        return self.api_client.get_text_response(prompt, context_str, None)


# voice_assistent\class_voice_assistent\context_manager.py

from collections import deque

class ContextManager:
    def __init__(self, maxlen=10):
        self.recent_context = deque(maxlen=maxlen)

    def add_context(self, command, response):
        self.recent_context.append((command, response))

    def get_context(self):
        return "\n".join([context for context, _ in self.recent_context])


# voice_assistent\class_voice_assistent\conversation_history.py



# voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py

import requests
import logging
import google.generativeai as genai

# Configure o logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, feedback):
        try:
            # Gerando o conte√∫do usando a nova API
            response = self.model.generate_content(prompt)
            if response and hasattr(response, 'text'):
                return prompt, response.text
            else:
                logger.error("Resposta inv√°lida da API")
                return prompt, None
        except Exception as e:
            logger.error(f"Erro em get_text_response: {e}")
            return prompt, None

    def find_similar_embeddings(self, embedding):
        try:
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            logger.info(f"Enviando dados para a API de embeddings similares: {data}")
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            logger.error(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            data = {
                "question": question,
                "questionEmbedding": question_embedding.tolist() if hasattr(question_embedding, 'tolist') else question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding.tolist() if hasattr(answer_embedding, 'tolist') else answer_embedding
            }
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                logger.info("Pergunta e resposta salvas com sucesso.")
            else:
                logger.warning(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            logger.error(f"Erro em save_question_answer: {e}")


# voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py

import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        """Carregar vari√°veis do arquivo .env"""
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        """Configurar a chave da API"""
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        """Inicializar o modelo generativo"""
        try:
            self.model = genai.GenerativeModel(self.model_name)
        except Exception as e:  
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content(self, prompt: str, context: str, meeting: str) -> str:
        """Gerar conte√∫do com base no prompt, contexto e reuni√£o"""
        try:
            # Supondo que a API espera um dicion√°rio com os par√¢metros
            request_data = f'''
                "prompt": {prompt},
                "context": {context},
                "meeting": {meeting}
            '''
            print(f"Enviando requisi√ß√£o para a API GenAI: {request_data}")

            response = self.model.generate_content(request_data)
            return response.text
        except Exception as e:
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py

import os
from dotenv import load_dotenv
from groq import Groq

# Carregar vari√°veis do arquivo .env
load_dotenv()

# Recuperar a chave da API
api_key = os.getenv("GROQ_API_KEY")

# Verificar se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API Key is missing. Please set the GROQ_API_KEY in the .env file.")

# Configurar o cliente com a chave da API
client = Groq(api_key=api_key)

# Cria√ß√£o da conclus√£o do chat
chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "De acordo com nossas conversas anteriores, o que voc√™ acha do meu uso de IA ?",
        }
    ],
    model="llama3-8b-8192",
)

print(chat_completion.choices[0].message.content)


# voice_assistent\class_voice_assistent\main.py

import os
from context_manager import ContextManager
from api_client import APIClient
from command_interpreter import CommandInterpreter
from text_command_hendler import TextCommandHandler
from text_processor import TextProcessor
from text_to_speech import TextToSpeech
from voice_command_hendler import VoiceCommandHandler
from question_answers_service import QuestionAnswerService
from gpt_communication.gemini_gpt import GenerativeModelHandler

class MainApp:
    def __init__(self, model):
        self.voice_handler = VoiceCommandHandler()
        self.text_handler = TextCommandHandler()
        self.tts = TextToSpeech()
        self.text_processor = TextProcessor()
        self.api_client = APIClient(
            similarity_url="http://localhost:8081",
            save_url="http://localhost:8081/api/question_answers/save",
            model=model
        )
        self.context_manager = ContextManager()
        self.question_answer_service = QuestionAnswerService()
        self.command_interpreter = CommandInterpreter(
            self.api_client,
            self.question_answer_service,
            self.context_manager
        )

    def handle_command(self, command, meeting=""):
        if command:
            print(f"Pergunta recebida: {command}")
            text_response = self.command_interpreter.interpret_command(command, meeting)
            if text_response:
                print(f"Resposta: {text_response}")
                self.tts.speak_text(text_response)
                self.context_manager.add_context(command, text_response)
                return text_response
        else:
            print("Nenhum comando detectado.")
            return None

    def run(self):
        meeting = ""
        while True:
            try:
                input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
                if input_type == 'v':
                    command = self.voice_handler.capture_voice_command()
                elif input_type == 't':
                    command = self.text_handler.capture_text_command()
                else:
                    print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
                    continue

                response = self.handle_command(command, meeting)
                if response:
                    print(f"Resposta: {response}")
            except Exception as e:
                print(f"Ocorreu um erro: {e}")

if __name__ == "__main__":
    model = GenerativeModelHandler('gemini-1.5-flash')
    app = MainApp(model)
    app.run()

# voice_assistent\class_voice_assistent\prompt.py

def create_prompt(command, context, meeting):
    keywords = ["fa√ßa um resumo da √∫ltima reuni√£o.", "t√≥picos da √∫ltima reuni√£o", "resuma a √∫ltima reuni√£o", "pesquise", "pesquisar", "procure"]
    if any(keyword in command.lower() for keyword in keywords):
        return f"""
        Regras de Meeting:
        - Voc√™ √© respons√°vel por analisar, debater, sugerir e informar melhorias.
        - Resuma de forma clara e Objetiva.
        - N√£o acrescentar t√≠tulo nas respostas.

        [context]: {context}
        -------
        [meeting]: {meeting}
        -------
        [str_texto]: {command}
        """
    else:
        return f"""
        [context]: {context}
        -------
        [str_texto]: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py

class DefaultPromptGenerator:
    def generate_prompt(self, command, combined_context, meeting):
        prompt = (
            f"Comando: {command}\n"
            f"Contexto Anterior:\n{combined_context}\n"
            f"Baseie sua resposta nas informa√ß√µes acima e forne√ßa uma solu√ß√£o detalhada."
        )
        return prompt

# voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class MeetingPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting):
        return f"""
        Regras de Meeting com respostas inteligentes:
        - Responda a pergunta de [str_texto] com base nas diretrizes abaixo...
            - Voc√™ √© respons√°vel analisar com detalhes a reuni√£o de [str_meeting], e fornecer uma longa est√≥ria sobre o assunto.
            - observe os nomes das personas mencionadas no texto de meeting para aprender e melhorar a precis√£o da resposta.
            - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [str_texto]: Responda a pergunta de: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class OnlineResearchPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting, similar_context):
        return f"""
        Regras de Pesquisa Online Inteligente:
        - Utilize similar_context e fa√ßa uma pesquisa online para uma resposta mais precisa das quest√µes de [str_text]
        - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [context]: Regras B√°sicas {context}
        ------
        [similar_context]:
        Perguntas e respostas anteriores.{similar_context}
        ------
        [str_texto]: Responda seguinte pergunta: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py

from abc import ABC, abstractmethod

class PromptGenerator(ABC):
    @abstractmethod
    def generate_prompt(self, command, context, meeting, similar_context):
        pass

# voice_assistent\class_voice_assistent\question_answers_service.py

import requests
import numpy as np
from sentence_transformers import SentenceTransformer

class QuestionAnswerService:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.embedding_model = SentenceTransformer(model_name)

    def convert_text_to_embedding(self, text):
        embedding = self.embedding_model.encode(text)
        #print(f"Embedding gerado para '{text}': {embedding[0]:.16f}") # Adicionado para verificar o embedding gerado
        return embedding


# voice_assistent\class_voice_assistent\text_command_hendler.py

class TextCommandHandler:
    def capture_text_command(self):
        command = input("Digite o seu comando: ")
        return command


# voice_assistent\class_voice_assistent\text_processor.py

from bs4 import BeautifulSoup

class TextProcessor:
    def extract_values_from_json(self, data):
        if isinstance(data, dict):
            return ' '.join([str(value) for value in data.values()])
        elif isinstance(data, list):
            return ' '.join([self.extract_values_from_json(item) for item in data])
        return str(data)

    def extract_text_from_html(self, html):
        if not html.strip().startswith('<'):
            print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
            return html
        soup = BeautifulSoup(html, 'html.parser')
        text = ' '.join([p.get_text() for p in soup.find_all('p')])
        return text


# voice_assistent\class_voice_assistent\text_to_speech.py

import pyttsx3

class TextToSpeech:
    def __init__(self):
        self.engine = pyttsx3.init()

    def speak_text(self, text):
        cleaned_text = self.clean_text(text)
        self.engine.say(cleaned_text)
        self.engine.runAndWait()

    def clean_text(self, text):
        import re
        return re.sub(r'[\*\_\#]', '', text)


# voice_assistent\class_voice_assistent\voice_command_hendler.py

import speech_recognition as sr

class VoiceCommandHandler:
    def capture_voice_command(self):
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            print("Por favor, fale o seu comando:")
            try:
                audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
                print("√Åudio capturado com sucesso.")
                command = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {command}")
                return command
            except sr.WaitTimeoutError:
                print("Tempo de espera expirado. Nenhum √°udio detectado.")
                return None
            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio.")
                return None
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
                return None


# voice_assistent\config.py

# config.py
import pyttsx3
import spacy
from collections import deque

class APIConfig:
    apiKey = "API_KEY"
    url = "https://gpt-templates.saiapplications.com"
    headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")


# voice_assistent\template.py

import speech_recognition as sr
import requests
import pyttsx3
import re
from collections import deque
import spacy
import os
import webbrowser
from voice_assistent.prompt import create_prompt

# Configura√ß√µes da API
apiKey = "6UlOOoY/kkmprunma/qNDg"
url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    if isinstance(text, dict):
        text = extract_values_from_json(text)  # Extrai os valores do dicion√°rio
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

def get_text_response(prompt, context, feedback):
    data = {
        "inputs": {
            "str_texto": prompt,
            "str_contexto": context,
            "str_feedback": feedback
        }
    }
    print(f"Enviando dados para a API: {data}")
    try:
        response = requests.post(f"{url}/api/templates/6691e223802f95c2b394a8bd/execute", json=data, headers=headers)
        print(f"Status da resposta: {response.status_code}")
        if response.status_code == 200:
            try:
                response_data = response.html()  # Tente converter a resposta para JSON
                print("Resposta HTML recebida.")
                return extract_values_from_json(response_data)  # Extrai os valores do JSON
            except ValueError:
                print("A resposta n√£o est√° no formato JSON esperado. Tratando como texto simples.")
                return response.text  # Retorna o texto bruto da resposta
        else:
            print(f"Erro ao acessar a API: {response.status_code}, {response.text}")
            return None
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API: {e}")
        return None

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)


# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


User: Observe esse c√≥digo e identifique pontos que posso melhorar .
2025-04-10 17:53:53,696 [INFO] Resposta da IA (texto): Com certeza! Analisei o c√≥digo e encontrei algumas √°reas com oportunidades de melhoria em termos de legibilidade, organiza√ß√£o e otimiza√ß√£o. Abaixo, apresento as sugest√µes e um exemplo de como voc√™ pode refatorar seu c√≥digo:

**1. Modulariza√ß√£o e Organiza√ß√£o:**

*   **Problema:** O arquivo `chat_streamlit.py` est√° muito grande e cont√©m v√°rias responsabilidades (gerenciamento da interface Streamlit, intera√ß√£o com o Gemini, manipula√ß√£o de imagens, etc.).
*   **Solu√ß√£o:** Divida o c√≥digo em m√≥dulos menores, cada um com uma responsabilidade bem definida. Isso facilita a manuten√ß√£o, o teste e a reutiliza√ß√£o do c√≥digo.

**2. Gerenciamento de Estado:**

*   **Problema:** O uso excessivo de `st.session_state` pode tornar o c√≥digo dif√≠cil de entender e depurar.
*   **Solu√ß√£o:** Agrupe as vari√°veis de estado relacionadas em classes ou dicion√°rios e use fun√ß√µes para atualizar o estado de forma consistente.

**3. Tratamento de Erros:**

*   **Problema:** Os blocos `try...except` est√£o muito gen√©ricos, o que dificulta a identifica√ß√£o e o tratamento de erros espec√≠ficos.
*   **Solu√ß√£o:** Use exce√ß√µes mais espec√≠ficas e forne√ßa mensagens de erro claras e informativas.

**4. Performance:**

*   **Problema:** A leitura de todos os arquivos Python no in√≠cio do script pode ser lenta, especialmente em projetos grandes.
*   **Solu√ß√£o:** Use um cache para armazenar o conte√∫do dos arquivos Python e atualize o cache apenas quando os arquivos forem modificados.

**5. Seguran√ßa:**

*   **Problema:** A chave da API do Gemini est√° armazenada no arquivo `.env`. Embora isso seja melhor do que incluir a chave diretamente no c√≥digo, ainda n√£o √© ideal.
*   **Solu√ß√£o:** Use um sistema de gerenciamento de segredos mais robusto para armazenar e acessar a chave da API.

**6. Rate Limiting:**

*   **Problema:** A l√≥gica de rate limiting est√° implementada diretamente no `chat_streamlit.py`.
*   **Solu√ß√£o:** Mova a l√≥gica de rate limiting para uma classe separada e use-a em todos os lugares onde voc√™ interage com o Gemini.

**Exemplo de Refatora√ß√£o:**

Aqui est√° um exemplo de como voc√™ pode refatorar o c√≥digo `chat_streamlit.py` para melhorar a modulariza√ß√£o e a organiza√ß√£o:

**`src/chat_app/components/sidebar.py`**

```python
# src/chat_app/components/sidebar.py
import streamlit as st

def sidebar():
    with st.sidebar:
        st.title("Chat IA Inteligente")

        # Se√ß√£o de gera√ß√£o de imagem
        st.markdown("### Gerar Imagem")
        image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
        if st.button("Gerar Imagem"):   
            if image_prompt:
                generated_image = generate_image(image_prompt)

                if generated_image:
                    st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                    st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                    st.rerun()
            else:
                st.warning("Por favor, digite um prompt para gerar a imagem.")

        # Se√ß√£o de imagens (sempre vis√≠vel)
        st.markdown("### Adicionar Imagem (Opcional)")
        st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

        # Layout em duas colunas para os bot√µes de imagem
        col1, col2 = st.columns(2)

        with col1:
            # Bot√£o para verificar a √°rea de transfer√™ncia
            if st.button("üìã Colar", use_container_width=True):
                if on_paste_click():
                    st.success("Imagem colada!")
                    st.rerun()
                else:
                    st.warning("Nada encontrado.")

        with col2:
            # Bot√£o para limpar a imagem atual (se houver)
            if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
                if st.button("üóëÔ∏è Limpar", use_container_width=True):
                    clear_all_images()
                    st.rerun()
            else:
                # Placeholder para manter o layout alinhado
                st.write("")

        # Uploader de imagem com chave din√¢mica
        uploaded_file = st.file_uploader(
            "üì∑ Ou fa√ßa upload de imagem",
            type=["png", "jpg", "jpeg"],
            label_visibility="visible",
            key=st.session_state.file_uploader_key
        )

        # Atualiza o estado da imagem quando um arquivo √© carregado
        if uploaded_file:
            st.session_state.uploaded_image = uploaded_file
            on_file_upload()
            st.success("Imagem carregada!")

        # Exibe a imagem selecionada na barra lateral
        if st.session_state.clipboard_image_preview:
            st.image(st.session_state.clipboard_image_preview, use_container_width=True)
            st.caption("Imagem da √°rea de transfer√™ncia")
        elif st.session_state.uploaded_image:
            st.image(st.session_state.uploaded_image, use_container_width=True)
            st.caption("Imagem carregada")

        st.markdown("---")

        # Bot√£o para limpar o hist√≥rico de conversa
        if st.button("üßπ Limpar conversa", use_container_width=True):
            st.session_state.messages = []
            st.rerun()

        st.caption("Desenvolvido com Streamlit e Gemini AI")
```

**`src/chat_app/components/chat_history.py`**

```python
# src/chat_app/components/chat_history.py
import streamlit as st

def chat_history():
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            # Se houver imagem, exiba-a (se armazenada)
            if message.get("image"):
                st.image(message["image"], use_container_width=True)
            # Exibe o conte√∫do da mensagem (texto)
            st.markdown(message["content"])
```

**`src/chat_app/utils/image_utils.py`**

```python
# src/chat_app/utils/image_utils.py
from PIL import Image
import io
from datetime import datetime
import os
from config.config import Config

def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

def save_image(image_data):
    os.makedirs(Config.ASSETS_DIR, exist_ok=True)
    img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
    img_path = os.path.join(Config.ASSETS_DIR, img_name)
    with open(img_path, "wb") as f:
        f.write(image_data.getbuffer())
    with Image.open(img_path) as img:
        img_display = img.copy()
    return img_path, img_display
```

**`src/chat_app/app.py`**

```python
# src/chat_app/app.py
import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python
from chat_app.components.sidebar import sidebar
from chat_app.components.chat_history import chat_history
from chat_app.utils.image_utils import check_clipboard, save_image

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        img_path, img_display = save_image(image_data)

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
sidebar()

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
chat_history()

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)
```

**Pr√≥ximos Passos:**

1.  **Implemente as Refatora√ß√µes:** Comece movendo o c√≥digo para os arquivos sugeridos.
2.  **Teste:** Ap√≥s cada refatora√ß√£o, execute testes para garantir que nada foi quebrado.
3.  **Continue Refatorando:** Continue movendo o c√≥digo e adaptando as sugest√µes aqui mencionadas.

Ao seguir essas sugest√µes, voc√™ tornar√° seu c√≥digo mais limpo, organizado e f√°cil de manter.
2025-04-10 17:53:53,823 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 17:53:53,824 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 17:53:53,826 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 17:53:53,828 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:53:53,830 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 17:53:53,832 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:53:53,834 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:53:53,836 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:53:53,837 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:53:53,839 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:53:53,840 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 17:53:53,841 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 17:53:53,842 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 17:53:53,844 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 17:53:53,846 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 17:53:53,848 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 17:53:53,851 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 17:53:53,852 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:53:53,854 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:53:53,855 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:53:53,857 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:53:53,858 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:53:53,860 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:53:53,862 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 17:53:53,864 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 17:53:53,867 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 17:53:53,868 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 17:53:53,870 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 17:53:53,871 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 17:53:53,873 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 17:53:53,874 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:53:53,876 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 17:53:53,877 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 17:53:53,880 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 17:53:53,882 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 17:53:53,884 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 17:53:53,885 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 17:53:53,886 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 17:53:53,888 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 17:53:53,890 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 17:53:53,891 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 17:53:53,893 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 17:53:53,894 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 17:53:53,897 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 17:53:53,899 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 17:53:53,900 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 17:53:53,902 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 17:53:53,903 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 17:53:53,904 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 17:53:53,906 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 17:53:53,907 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 17:53:53,908 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 17:53:53,910 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 17:53:53,912 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 17:59:51,184 [INFO] Arquivo lido com sucesso: chat_streamlit.py
2025-04-10 17:59:51,186 [INFO] Arquivo lido com sucesso: config\config.py
2025-04-10 17:59:51,187 [INFO] Arquivo lido com sucesso: core\handlers\gemini_handler.py
2025-04-10 17:59:51,188 [INFO] Arquivo lido com sucesso: core\handlers\signal_handler.py
2025-04-10 17:59:51,189 [INFO] Arquivo lido com sucesso: core\logger_config.py
2025-04-10 17:59:51,190 [INFO] Arquivo lido com sucesso: core\rate_limiter.py
2025-04-10 17:59:51,192 [INFO] Arquivo lido com sucesso: services\document_service.py
2025-04-10 17:59:51,193 [INFO] Arquivo lido com sucesso: services\gpt_services.py
2025-04-10 17:59:51,195 [INFO] Arquivo lido com sucesso: services\image_processor.py
2025-04-10 17:59:51,196 [INFO] Arquivo lido com sucesso: services\image_services.py
2025-04-10 17:59:51,198 [INFO] Arquivo lido com sucesso: services\markdown_service.py
2025-04-10 17:59:51,201 [INFO] Arquivo lido com sucesso: services\search_files.py
2025-04-10 17:59:51,202 [INFO] Arquivo lido com sucesso: utils\file_utils.py
2025-04-10 17:59:51,930 [INFO] Modelo Gemini 'gemini-2.0-flash-exp' inicializado com sucesso.
2025-04-10 18:00:51,391 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 18:00:51,392 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 18:00:51,393 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 18:00:51,394 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 18:00:51,396 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 18:00:51,397 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 18:00:51,399 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 18:00:51,400 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 18:00:51,401 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 18:00:51,403 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 18:00:51,405 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 18:00:51,408 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 18:00:51,409 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 18:00:51,410 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 18:00:51,412 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 18:00:51,414 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 18:00:51,415 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 18:00:51,416 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 18:00:51,418 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 18:00:51,419 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 18:00:51,421 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 18:00:51,423 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 18:00:51,425 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 18:00:51,427 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 18:00:51,428 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 18:00:51,430 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 18:00:51,431 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 18:00:51,433 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 18:00:51,434 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 18:00:51,435 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 18:00:51,437 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 18:00:51,439 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 18:00:51,441 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 18:00:51,443 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 18:00:51,444 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 18:00:51,445 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 18:00:51,447 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 18:00:51,448 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 18:00:51,449 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 18:00:51,450 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 18:00:51,452 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 18:00:51,454 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 18:00:51,455 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 18:00:51,458 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 18:00:51,459 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 18:00:51,461 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 18:00:51,462 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 18:00:51,463 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 18:00:51,465 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 18:00:51,466 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 18:00:51,467 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 18:00:51,469 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 18:00:51,471 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 18:00:51,473 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 19:43:20,540 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 19:43:20,547 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 19:43:20,552 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 19:43:20,558 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 19:43:20,566 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 19:43:20,573 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 19:43:20,579 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 19:43:20,584 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 19:43:20,589 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 19:43:20,596 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 19:43:20,602 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 19:43:20,607 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 19:43:20,614 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 19:43:20,619 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 19:43:20,624 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 19:43:20,630 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 19:43:20,634 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 19:43:20,635 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 19:43:20,640 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 19:43:20,647 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 19:43:20,654 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 19:43:20,661 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 19:43:20,667 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 19:43:20,672 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 19:43:20,679 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 19:43:20,685 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 19:43:20,689 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 19:43:20,695 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 19:43:20,700 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 19:43:20,705 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 19:43:20,711 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 19:43:20,716 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 19:43:20,721 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 19:43:20,727 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 19:43:20,733 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 19:43:20,739 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 19:43:20,744 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 19:43:20,745 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 19:43:20,751 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 19:43:20,756 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 19:43:20,763 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 19:43:20,769 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 19:43:20,773 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 19:43:20,778 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 19:43:20,783 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 19:43:20,788 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 19:43:20,793 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 19:43:20,798 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 19:43:20,803 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 19:43:20,809 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 19:43:20,814 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 19:43:20,821 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 19:43:20,827 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 19:43:20,836 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 19:43:21,126 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 19:43:21,131 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 19:43:21,133 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 19:43:21,135 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 19:43:21,137 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 19:43:21,139 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 19:43:21,141 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 19:43:21,143 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 19:43:21,146 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 19:43:21,148 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 19:43:21,150 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 19:43:21,151 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 19:43:21,153 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 19:43:21,154 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 19:43:21,156 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 19:43:21,157 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 19:43:21,159 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 19:43:21,161 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 19:43:21,164 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 19:43:21,166 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 19:43:21,168 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 19:43:21,170 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 19:43:21,171 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 19:43:21,174 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 19:43:21,176 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 19:43:21,224 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 19:43:21,232 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 19:43:21,234 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 19:43:21,239 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 19:43:21,249 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 19:43:21,255 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 19:43:21,257 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 19:43:21,259 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 19:43:21,262 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 19:43:21,264 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 19:43:21,266 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 19:43:21,268 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 19:43:21,271 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 19:43:21,278 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 19:43:21,282 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 19:43:21,285 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 19:43:21,287 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 19:43:21,288 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 19:43:21,289 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 19:43:21,291 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 19:43:21,293 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 19:43:21,296 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 19:43:21,298 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 19:43:21,299 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 19:43:21,300 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 19:43:21,302 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 19:43:21,303 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 19:43:21,305 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 19:43:21,306 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 19:43:21,309 [INFO] Enviando para IA - Prompt (sem imagem): Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas.

Contexto:



# app_config\app_config.py

from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()
    
    def get_root_path(self):
        return str(self.ROOT_PATH)
    
    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py

from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        transcription_config = TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])


# audio_to_text\audio_to_text.py

import whisper
from audio_to_text.audio_config.audio_config import AudioConfig

class AudioToConverter:
    def __init__(self, audio_config: AudioConfig):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.AUDIO_INPUT_PATH
        self.TRANSCRIPTION_INPUT_PATH = audio_config.TRANSCRIPTION_INPUT_PATH

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            print(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        model = whisper.load_model("base")

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                print(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            print(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            print(f"Erro ao processar o arquivo {audio_file_path}: {e}")


# chat_app\chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# chat_app\config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# chat_app\services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# chat_app\services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# chat_app\services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# chat_app\utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

# common_paths\common_paths.py

from pathlib import Path

class CommonPaths:
    def __init__(self):
        # Diret√≥rio atual do script
        self.ROOT_PATH = Path(__file__).resolve().parent

        # Defini√ß√£o dos caminhos comuns
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'output'
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.AUDIO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.TRANSCRIPTION_OUTPUT_PATH = self.ROOT_PATH / 'data'
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'data'

        # Cria√ß√£o dos diret√≥rios
        self.create_directories()

    def create_directories(self):
        self.VIDEO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.VIDEO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.TRANSCRIPTION_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)



# fundamentus_api\fundamentus\__init__.py



# fundamentus_api\fundamentus\dados_b3.py

import locale
import pandas as pd
import streamlit as st
import requests
import fundamentus
import os
import plotly.express as px
from bs4 import BeautifulSoup
from fundamentus.detalhes import get_papel
import logging

# Configura localidade
locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')

# Configura√ß√£o do layout do Streamlit
st.set_page_config(
    page_title="An√°lise de A√ß√µes",
    layout="wide",
    page_icon="üìà"
)

class Acao:
    def __init__(self, papel):
        self.papel = papel
        self.dados_fundamentais = None
        self.proventos = None
        self.detalhes = None
        self.oscilacoes = None  # Adicionando um atributo para oscila√ß√µes

    def carregar_dados_fundamentais(self):
        self.dados_fundamentais = fundamentus.get_resultado().loc[[self.papel]]  # Use colchetes duplos para garantir que seja um DataFrame
        self.remover_formatacao()

    def obter_detalhes(self):
        self.detalhes = get_papel(self.papel)
        if self.detalhes is None or self.detalhes.empty:
            logging.warning(f"Nenhum detalhe encontrado para o papel: {self.papel}")

    def obter_proventos(self):
        url = f"https://www.fundamentus.com.br/proventos.php?papel={self.papel}&tipo=2"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        tabela = soup.find('table', {'id': 'resultado'})

        if not tabela:
            return pd.DataFrame()

        dados = []
        for linha in tabela.find_all('tr')[1:]:
            colunas = linha.find_all('td')
            try:
                valor = float(colunas[1].text.strip().replace(',', '.'))
            except ValueError:
                valor = None  # Se der erro, coloca None para evitar crash

            dados.append([colunas[0].text.strip(), valor, colunas[2].text.strip()])
        
        self.proventos = pd.DataFrame(dados, columns=['Data', 'Valor', 'Tipo'])
        return self.proventos

    def obter_oscilacoes(self):
        url = f"https://www.fundamentus.com.br/detalhes.php?papel={self.papel}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        conteudo_div = soup.find('div', class_='conteudo clearfix')

        if conteudo_div is None:
            return pd.DataFrame()

        oscilacoes_data = []
        oscilacoes_section = conteudo_div.find('td', class_='nivel1', colspan='2')
        
        if oscilacoes_section:
            labels = oscilacoes_section.find_all_next('td', class_='label w1')
            dados = oscilacoes_section.find_all_next('td', class_='data w1')

            for label, dado in zip(labels, dados):
                label_text = label.get_text(strip=True)
                valor_text = dado.find('span', class_='oscil').get_text(strip=True)
                oscilacoes_data.append([label_text, valor_text])

        self.oscilacoes = pd.DataFrame(oscilacoes_data, columns=['Per√≠odo', 'Oscila√ß√£o'])
        return self.oscilacoes

    def remover_formatacao(self):
        colunas_percentuais = ['dy', 'mrgebit', 'mrgliq', 'roic', 'roe', 'c5y']
        for coluna in colunas_percentuais:
            if coluna in self.dados_fundamentais:
                try:
                    self.dados_fundamentais[coluna] = self.dados_fundamentais[coluna].astype(float)
                except ValueError as e:
                    logging.error(f"Erro ao converter coluna {coluna} para float: {e}")

    def formatar_moeda(self, valor):
        return locale.currency(valor, symbol=True, grouping=True)

class Aplicacao:
    def __init__(self):
        self.acoes = fundamentus.get_resultado()

    def ajustar_tipos_dataframe(self, df):
        for coluna in df.columns:
            if df[coluna].dtype == 'object':
                try:
                    df[coluna] = df[coluna].astype(float)
                except ValueError:
                    df[coluna] = df[coluna].astype(str)
            elif df[coluna].dtype in ['int64', 'float64']:
                df[coluna] = df[coluna].astype(float)
        return df

    def exibir_dashboard(self):
        st.sidebar.title("üìä Dashboard de An√°lise de A√ß√µes")
        st.sidebar.write("Selecione um papel para visualizar detalhes.")

        papel_selecionado = st.sidebar.selectbox("Escolha uma a√ß√£o", self.acoes.index)

        acao = Acao(papel_selecionado)
        acao.carregar_dados_fundamentais()
        acao.obter_proventos()
        acao.obter_detalhes()
        acao.obter_oscilacoes()

        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader(f"üìå Dados Fundamentais - {papel_selecionado}")
            dados_fundamentais_df = self.ajustar_tipos_dataframe(acao.dados_fundamentais.T)
            st.dataframe(dados_fundamentais_df, width=400)

        with col2:
            st.subheader("üîç Detalhes")
            if acao.detalhes is not None and not acao.detalhes.empty:
                detalhes_df = pd.DataFrame(acao.detalhes).T.reset_index()
                detalhes_df.columns = ['Descri√ß√£o', 'Valor']
                detalhes_df = self.ajustar_tipos_dataframe(detalhes_df)

                st.subheader("Tabela de Detalhes")
                st.dataframe(detalhes_df, width=800)
            else:
                st.warning("Nenhum detalhe encontrado para essa a√ß√£o.")

        col_dividendos, col_oscilacoes = st.columns([1, 2])

        with col_dividendos:
            st.subheader("üí∞ Dividendos")
            if not acao.proventos.empty:
                proventos_df = self.ajustar_tipos_dataframe(acao.proventos)
                st.write(proventos_df)

        with col_oscilacoes:
            st.subheader("üìâ Oscila√ß√µes")
            if acao.oscilacoes is not None and not acao.oscilacoes.empty:
                oscilacoes_df = self.ajustar_tipos_dataframe(acao.oscilacoes)
                st.write(oscilacoes_df)

        st.subheader("üìà Tabela Geral de A√ß√µes")
        st.dataframe(self.acoes)

# Execu√ß√£o
if __name__ == "__main__":
    app = Aplicacao()
    app.exibir_dashboard()

# fundamentus_api\setup.py

from setuptools import setup, find_packages

setup(
    name='fundamentalvision ',
    version='0.1.0',
    author='Joel FerreiraHeanna dos Reis',
    author_email='heannareis@gmail.com',
    description='Um pacote para an√°lise fundamentalista de a√ß√µes da Bolsa B3 do Brasil.',
    packages=find_packages(),
    install_requires=[
        'pandas',
        'requests',
        'beautifulsoup4',
        'streamlit',
        'plotly',
        'fundamentus'
    ],
    classifiers=[
        'Programming Language :: Python :: 3',
        'License :: OSI Approved :: MIT License',
        'Operating System :: OS Independent',
    ],
    python_requires='>=3.6',
)

# ia_generator.py

import requests
from pathlib import Path
import webbrowser
from config.common_paths import TRANSCRIPTION_OUTPUT_PATH

apiKey = "6UlOOoY/kkmprunma/qNDg"

str_personas = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'personas.txt'
str_contexto = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'contexto.txt'

url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

txt_files = list(TRANSCRIPTION_OUTPUT_PATH.glob('*.txt'))

css_styles = """
<style>
body {
    font-family: Arial, sans-serif;
    margin: 20px;
}

h1, h2, h3 {
    color: #FF8C00;
}

li, strong, p {
    color: #008000;
}

h1 {
    font-size: 24px;
    margin-bottom: 20px;
}

h2 {
    font-size: 20px;
    margin-top: 20px;
    margin-bottom: 10px;
}

ul {
    list-style-type: disc;
    margin-left: 40px;
}

li {
    margin-bottom: 10px;
}

p {
    line-height: 1.6;
}
</style>
"""

if not txt_files:
    print(f"N√£o foram encontrados arquivos .txt no diret√≥rio {TRANSCRIPTION_OUTPUT_PATH}.")
else:
    for txt_file in txt_files:
        if txt_file.is_file():
            print(f"Lendo o arquivo: {txt_file.name}")
            with open(txt_file, 'r', encoding='utf-8') as file:
                str_reuniao = file.read()

            print(f"Enviando o conte√∫do do arquivo {txt_file.name} para a API...")
            data = {
                "inputs": {
                    "str_reuniao": str_reuniao,
                    "str_personas": str_personas.read_text(encoding='utf-8'),
                    "str_contexto": str_contexto.read_text(encoding='utf-8'),
                }
            }

            response = requests.post(f"{url}/api/templates/668de04202493d3063a9d7fa/execute", json=data, headers=headers)
            if response.status_code == 200:
                print(f"Resultado para o arquivo {txt_file.name} recebido.")
                html_content = response.text
                print(response.text)

                # Incluir o CSS no conte√∫do HTML
                html_with_css = f"<html><head>{css_styles}</head><body>{html_content}</body></html>"

                # Salvar o conte√∫do HTML em um arquivo
                output_file = TRANSCRIPTION_OUTPUT_PATH / f"{txt_file.stem}_output.html"
                with open(output_file, 'w', encoding='utf-8') as html_file:
                    html_file.write(html_with_css)

                # Abrir o arquivo HTML no navegador
                webbrowser.open(f"file://{output_file.resolve()}")
            else:
                print(f"Erro ao processar o arquivo {txt_file.name}: {response.status_code}")


# main.py

from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from transcriptions.transcriptions_config import TranscriptionConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from pathlib import Path

def main():
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    root_path = str(PROJECT_ROOT)
    print(f"Root path: {root_path}")  # Para verificar se est√° correto
    api_url = "http://localhost:8081/api/meetings/transcriptions"
    
    # # Configura√ß√£o de v√≠deos
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()
    
    # # Configura√ß√£o de √°udios
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()
    
    # # Processamento de transcri√ß√µes e envio de embeddings
    # embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    # embedding_processor_wrapper.process_transcriptions()

if __name__ == "__main__":
    main()


# send_embeddings_database\embedding_config\embedding_config.py

from app_config.app_config import AppConfig

class EmbeddingConfig(AppConfig):
    def __init__(self, root_path=None, transcription_input_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = transcription_input_path
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'embeddings' / 'output'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH, self.EMBEDDING_OUTPUT_PATH])


# send_embeddings_database\verify_last_enbedding.py

import os
import numpy as np

def get_latest_file(directory):
    # Listar todos os arquivos no diret√≥rio
    files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]
    
    if not files:
        raise FileNotFoundError("Nenhum arquivo encontrado no diret√≥rio.")

    # Encontrar o arquivo mais recente
    latest_file = max(files, key=os.path.getmtime)
    return latest_file

def load_and_print_embedding(directory):
    # Obter o caminho do √∫ltimo arquivo de embedding
    embedding_file_path = get_latest_file(directory)
    
    # Carregar o embedding
    embedding = np.load(embedding_file_path)
    
    # Exibir o conte√∫do do embedding
    print("Embedding carregado:")
    print(embedding)
    print("Dimens√µes do embedding:", embedding.shape)

# Caminho do diret√≥rio de embeddings
embedding_directory = 'C:/Users/HeannarReis/Documents/bsa_atacadao/assets/embeddings/output'

# Carregar e exibir o √∫ltimo embedding
load_and_print_embedding(embedding_directory)


# test_whisper.py

from transformers import pipeline
from common_paths import CommonPaths

commmom_paths = CommonPaths()

# Fun√ß√£o para ler a transcri√ß√£o de um arquivo
def read_transcription(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
    return lines

# Fun√ß√£o para converter a pontua√ß√£o em estrelas
def score_to_stars(score):
    if score >= 0.75:
        return 5
    elif score >= 0.55:
        return 4
    elif score >= 0.35:
        return 3
    elif score >= 0.15:
        return 2
    else:
        return 1

# Inicializar o pipeline de an√°lise de sentimento
sentiment_pipeline = pipeline("sentiment-analysis", model="neuralmind/bert-base-portuguese-cased")

# Caminho para o arquivo de transcri√ß√£o
file_path = commmom_paths.TRANSCRIPTION_OUTPUT_PATH / 'feedback.txt'

# Ler a transcri√ß√£o
lines = read_transcription(file_path)

# Analisar sentimento para cada feedback
for line in lines:
    sentiment = sentiment_pipeline(line.strip())
    score = sentiment[0]['score']
    stars = score_to_stars(score)
    
    # Ajuste manual para feedbacks com aspectos positivos e negativos
    if any(word in line.lower() for word in ["mas", "por√©m", "no entanto"]):
        stars = max(1, stars - 1)  # Reduz uma estrela se houver contradi√ß√£o
    
    # Ajuste adicional baseado em palavras-chave
    positive_keywords = ["excelente", "√≥timo", "perfeito", "r√°pido", "eficiente", "satisfeito", "clara", "eficaz", "bom trabalho"]
    negative_keywords = ["ruim", "p√©ssimo", "horr√≠vel", "poderia", "n√£o resolveu", "insatisfat√≥ria", "confusa", "inadequado", "lento", "n√£o houve seguimento", "n√£o atendeu", "n√£o funcionou", "demorado"]
    
    positive_count = sum(word in line.lower() for word in positive_keywords)
    negative_count = sum(word in line.lower() for word in negative_keywords)
    
    # Ajuste de estrelas baseado na contagem de palavras-chave
    if positive_count > negative_count:
        stars = min(5, stars + 1)
    elif negative_count > positive_count:
        stars = max(1, stars - 1)
    
    print(f"Texto: {line.strip()}")
    print(f"Sentimento: {stars} estrelas")
    print(f"Pontua√ß√£o: {score:.2f}")
    print('---')


# text_to_embedding\embedding_processing.py

from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from transcriptions.transcriptions_config import TranscriptionConfig
from transcriptions.transciption_sender_database import TranscriptionSenderDatabase

class EmbeddingProcessorWrapper:
    def __init__(self, root_path, api_url):
        # Configura√ß√£o de transcri√ß√µes e embeddings
        transcription_config = TranscriptionConfig(root_path=root_path)
        embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())

        self.embedding_processor = EmbeddingProcessor(embedding_config)
        self.transcription_sender = TranscriptionSenderDatabase(api_url)
    
    def process_transcriptions(self):
        # Mostrar o diret√≥rio onde est√° procurando as transcri√ß√µes
        print(f"Diret√≥rio de entrada das transcri√ß√µes: {self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH}")
        
        # Listar todos os arquivos de transcri√ß√£o no diret√≥rio de entrada
        transcription_files = list(self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH.glob('*.txt'))
        if not transcription_files:
            print("Nenhum arquivo de transcri√ß√£o encontrado.")
        for transcription_file_path in transcription_files:
            if transcription_file_path.is_file():
                print(f"Processando arquivo: {transcription_file_path}")
                self.process_and_send_transcription(transcription_file_path)
            else:
                print(f"Arquivo n√£o encontrado: {transcription_file_path}")

    def process_and_send_transcription(self, transcription_file_path):
        try:
            # Ler a transcri√ß√£o do arquivo de texto
            with open(transcription_file_path, 'r', encoding='utf-8') as f:
                transcription_text = f.read()
                if not transcription_text:
                    print(f"Arquivo {transcription_file_path} est√° vazio.")
                    return

            # Gerar o embedding da transcri√ß√£o
            embedding = self.embedding_processor.generate_embedding(transcription_text)
            if embedding is None:
                print(f"Falha ao gerar embedding para o arquivo {transcription_file_path}.")
                return

            # Salvar o embedding em um arquivo .npy
            self.embedding_processor.save_embedding(transcription_file_path, embedding)

            # Enviar os dados para a API
            self.transcription_sender.send_transcription(transcription_text, embedding)

        except Exception as e:
            print(f"Erro ao processar o arquivo {transcription_file_path}: {e}")


# text_to_embedding\texto_to_embedding.py

from sentence_transformers import SentenceTransformer
import numpy as np

class EmbeddingProcessor:
    def __init__(self, embedding_config):
        self.embedding_config = embedding_config
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

    def generate_embedding(self, transcription_text):
        return self.embedding_model.encode(transcription_text)

    def save_embedding(self, transcription_file_path, embedding):
        embedding_file_path = self.embedding_config.EMBEDDING_OUTPUT_PATH / transcription_file_path.with_suffix('.npy').name
        np.save(embedding_file_path, embedding)
        print(f"Embedding salvo em: {embedding_file_path}")
        return embedding_file_path


# transcriptions\transciption_sender_database.py

import requests

class TranscriptionSenderDatabase:
    def __init__(self, api_url):
        self.api_url = api_url

    def send_transcription(self, transcription_text, embedding):
        data = {
            'transcriptionText': transcription_text,
            'embedding': embedding.tolist()
        }

        response = requests.post(self.api_url, json=data)

        if response.status_code == 201:
            print("Transcri√ß√£o e embedding enviados com sucesso.")
        else:
            print(f"Erro ao enviar dados: {response.status_code}")
            print("Resposta da API:")
            print(response.text)


# transcriptions\transcriptions_config.py

from app_config.app_config import AppConfig

class TranscriptionConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = self.ROOT_PATH / 'assets' / 'transcriptions' / 'input'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH])
    
    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# translate\translator_to_english.py

import speech_recognition as sr
from translate import Translator

def ouvir_e_traduzir():
    # Inicializa o reconhecedor de fala
    recognizer = sr.Recognizer()

    # Configura o tradutor
    translator = Translator(to_lang="en", from_lang="pt")

    # Usa o microfone como fonte de √°udio
    with sr.Microphone() as source:
        print("Diga algo em portugu√™s...")

        while True:
            try:
                # Escuta o √°udio do microfone
                audio = recognizer.listen(source)
                
                # Reconhece a fala usando o Google Web Speech API
                texto_portugues = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {texto_portugues}")

                # Traduz o texto para o ingl√™s
                traducao = translator.translate(texto_portugues)
                print(f"Tradu√ß√£o para o ingl√™s: {traducao}")

            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio")
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")

if __name__ == "__main__":
    try:
        ouvir_e_traduzir()
    except KeyboardInterrupt:
        print("Interrompido pelo usu√°rio")


# translate\whispert_translator.py

import whisper
import pyaudio
import numpy as np

# Inicializa o modelo Whisper
model = whisper.load_model("base")

# Configura√ß√µes de √°udio
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024

# Inicializa o PyAudio
audio = pyaudio.PyAudio()

# Abre o stream de √°udio
stream = audio.open(format=FORMAT, channels=CHANNELS,
                    rate=RATE, input=True,
                    frames_per_buffer=CHUNK)

print("Diga algo em portugu√™s...")

try:
    audio_buffer = []

    while True:
        # L√™ dados do microfone
        data = stream.read(CHUNK)
        audio_buffer.append(np.frombuffer(data, dtype=np.int16).flatten().astype(np.float32) / 32768.0)

        # Processa o √°udio a cada 5 segundos
        if len(audio_buffer) * CHUNK / RATE >= 5:
            audio_data = np.concatenate(audio_buffer)
            audio_buffer = []

            # Transcreve e traduz o √°udio usando Whisper
            result = model.transcribe(audio_data, task="translate", language="pt")

            # Exibe a tradu√ß√£o
            print(f"Tradu√ß√£o para o ingl√™s: {result['text']}")

except KeyboardInterrupt:
    print("Interrompido pelo usu√°rio")

    # Fecha o stream de √°udio
    stream.stop_stream()
    stream.close()
    audio.terminate()


# video_to_audio\video_config\video_config.py

from app_config.app_config import AppConfig

class VideoConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video' / 'input'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.create_directories([self.VIDEO_INPUT_PATH, self.VIDEO_OUTPUT_PATH])

# video_to_audio\video_to_audio.py

from moviepy import VideoFileClip
import glob
import os
from .video_config.video_config import VideoConfig

class VideoToAudioConverter:
    def __init__(self, video_config: VideoConfig):
        self.video_config = video_config

    def convert_video_to_audio(self, video_path, audio_path):
        try:
            video = VideoFileClip(video_path)
            if video.audio:
                video.audio.write_audiofile(audio_path, fps=44100)
                print(f"Convertido {video_path} para {audio_path}")
            else:
                print(f"Aviso: O v√≠deo {video_path} n√£o cont√©m √°udio!")
        except Exception as e:
            print(f"Erro ao converter {video_path}: {e}")

    def process_videos(self):
        input_directory = self.video_config.VIDEO_INPUT_PATH
        output_directory = self.video_config.VIDEO_OUTPUT_PATH

        os.makedirs(output_directory, exist_ok=True)

        # Busca qualquer arquivo de v√≠deo (formatos comuns)
        video_files = glob.glob(os.path.join(input_directory, "*.*"))  # Pega todos os arquivos

        # Filtra apenas arquivos de v√≠deo
        video_extensions = {".mp4", ".mkv", ".avi", ".mov", ".wmv", ".flv"}  
        video_files = [f for f in video_files if os.path.splitext(f)[1].lower() in video_extensions]

        if not video_files:
            print(f"Nenhum arquivo de v√≠deo encontrado em: {input_directory}")
            return

        for video_file in video_files:
            base_name = os.path.basename(video_file)
            audio_file = os.path.join(output_directory, os.path.splitext(base_name)[0] + ".wav")
            self.convert_video_to_audio(video_file, audio_file)

        print("Convers√£o de v√≠deo para √°udio conclu√≠da!")


# voice_assistent\assistent.py

import speech_recognition as sr
import pyttsx3
import re
from collections import deque
import spacy
import requests
import os
import webbrowser
from class_voice_assistent.prompt import create_prompt
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import google.generativeai as genai

# Configura√ß√µes da API
handler = genai('gemini-1.5-flash')

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

voices = engine.getProperty('voices')
engine.setProperty('rate', 180)
print("\nLista de Vozes...")
for indice, vozes in enumerate(voices):
    print(indice, vozes.name)

voz = 1
engine.setProperty('voice', voices[voz].id)

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

# Fun√ß√£o para extrair texto de HTML
def extract_text_from_html(html):
    if not html.strip().startswith('<'):
        print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
        return html
    soup = BeautifulSoup(html, 'html.parser')
    text = ' '.join([p.get_text() for p in soup.find_all('p')])
    return text

def get_text_response(prompt, context, feedback):
    # Gere o conte√∫do com base no prompt usando a classe GenerativeModelHandler
    response = handler.generate_content(prompt)
    return response

# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/api/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


# voice_assistent\class_voice_assistent\api_client.py

import requests


class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, meeting):
        try:
            response_text = self.model.generate_content(prompt, context, meeting)
            return response_text
        except Exception as e:
            print(f"Erro inesperado: {e}")
            return None

    def find_similar_embeddings(self, embedding):
        try:
            print(f"Buscando embeddings similares para: {embedding}")
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            similar_embeddings = response.json()

            # Ordenar por similaridade (assumindo que a API retorna com similaridade em ordem decrescente)
            # Remover duplicatas baseadas na pergunta
            seen_questions = set()
            unique_embeddings = []
            for embedding in similar_embeddings:
                question = embedding['question'].strip().lower()
                if question not in seen_questions:
                    unique_embeddings.append(embedding)
                    seen_questions.add(question)
            print(f"Embeddings similares √∫nicos encontrados: {unique_embeddings}")
            return unique_embeddings
        except requests.RequestException as e:
            print(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            # Converter embeddings de numpy arrays para listas
            if hasattr(question_embedding, 'tolist'):
                question_embedding = question_embedding.tolist()
            if hasattr(answer_embedding, 'tolist'):
                answer_embedding = answer_embedding.tolist()
            
            data = {
                "question": question,
                "questionEmbedding": question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding
            }
            
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                print("Pergunta e resposta salvas com sucesso.")
            else:
                print(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            print(f"Erro em save_question_answer: {e}")


    def fetch_all_contexts(self):
        try:
            response = requests.get("http://localhost:8081/api/contexts/all")
            if response.status_code == 200:
                data = response.json()
                contexts = data.get('contexts', [])
                if isinstance(contexts, list):
                    print(f"Contexto obtido da API: {contexts}")
                    return contexts
                else:
                    print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                    return []
            else:
                print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
                return []
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
            return []

    def fetch_last_meeting(self):
        try:
            response = requests.get("http://localhost:8081/api/meetings/last")
            if response.status_code == 200:
                data = response.json()
                transcription_text = data.get('transcriptionText', "")
                if isinstance(transcription_text, str):
                    print(f"Texto da transcri√ß√£o obtido da API: {transcription_text}")
                    return transcription_text
                else:
                    print(f"Erro: 'transcriptionText' n√£o √© uma string. Dados retornados: {data}")
                    return ""
            else:
                print(f"Erro ao acessar a API de reuni√µes: {response.status_code}, {response.text}")
                return ""
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de reuni√µes: {e}")
            return ""


# voice_assistent\class_voice_assistent\command_interpreter.py

import spacy
from prompt_generator.online_prompt import OnlineResearchPromptGenerator
from prompt_generator.meeting_prompt import MeetingPromptGenerator
from prompt_generator.default_prompt_generator import DefaultPromptGenerator
import re

# Carregar o modelo de linguagem natural
nlp = spacy.load("pt_core_news_sm")

class CommandInterpreter:
    def __init__(self, api_client, question_answer_service, context_manager, max_similar=3):
        self.api_client = api_client
        self.question_answer_service = question_answer_service
        self.context_manager = context_manager
        self.max_similar = max_similar  # Limite de contextos similares

    def interpret_command(self, command, meeting):
        print(f"Interpretando comando: {command}")
        contexts = self.api_client.fetch_all_contexts()
        context_str = "\n".join([context['context'] for context in contexts])

        # Gerar embedding para a pergunta e buscar embeddings similares
        question_embedding = self.question_answer_service.convert_text_to_embedding(command)
        similar_embeddings = self.api_client.find_similar_embeddings(question_embedding)

        # Filtrar para evitar respostas redundantes
        unique_responses = self._filter_unique_responses(similar_embeddings, command)
        similar_context = "\n".join([f"Pergunta: {embedding['question']}\nResposta: {embedding['answer']}" for embedding in unique_responses[:self.max_similar]])

        # Detectar tipo de comando usando regex
        if re.search(r'\b(pesquise|pesquisar|procure)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como pesquisa online.")
            response = self.get_online_research_response(command, context_str, similar_context)
        elif re.search(r'\b(contexto)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como busca de contexto.")
            response = self.get_project_response(command, meeting, context_str, similar_context)
        elif re.search(r'\b(resumo?|t√≥picos da|pontos (relevantes|principais)|an√°lise)\b.*\b(reuni√£o|√∫ltima (reuni√£o|conversa|sess√£o))\b', command, re.IGNORECASE):
            print(f"\nComando identificado como an√°lise de reuni√£o.")
            meeting = self.api_client.fetch_last_meeting()
            response = self.get_meeting_analysis_response(command, context_str, meeting)
        else:
            print(f"\nComando identificado como comando padr√£o.")
            response = self.handle_default_command(command, context_str, meeting, similar_context)

        if response:
            answer_embedding = self.question_answer_service.convert_text_to_embedding(response)
            self.api_client.save_question_answer(command, question_embedding, response, answer_embedding)
            self.context_manager.add_context(command, response)

        return response

    def _filter_unique_responses(self, similar_embeddings, current_command):
        """
        Filtra respostas semelhantes que s√£o muito similares ao comando atual para evitar redund√¢ncia.
        """
        filtered = []
        for embedding in similar_embeddings:
            if embedding['question'].lower() != current_command.lower():
                filtered.append(embedding)
        return filtered

    def handle_default_command(self, command, context_str, meeting, similar_context):
        print(f"\nTratando comando padr√£o: {command}")
        # Combinar o contexto atual com os contextos similares para enriquecer a resposta
        combined_context = f"{context_str}\n{similar_context}"
        prompt = DefaultPromptGenerator().generate_prompt(command, combined_context, meeting)
        response = self.api_client.get_text_response(prompt, combined_context, meeting)
        return response

    # M√©todos get_project_response, get_meeting_analysis_response, get_online_research_response permanecem inalterados

    def get_project_response(self, command, meeting, context_str, similar_context):
        print(f"\nGerando prompt de projeto.")
        prompt = DefaultPromptGenerator().generate_prompt(command, context_str, meeting, similar_context)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_meeting_analysis_response(self, command, context_str, meeting):
        print(f"\nGerando prompt de an√°lise de reuni√£o.")
        prompt = MeetingPromptGenerator().generate_prompt(command, context_str, meeting)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_online_research_response(self, command, context_str, similar_context):
        print(f"\nGerando prompt de pesquisa online.")
        prompt = OnlineResearchPromptGenerator().generate_prompt(command, context_str, similar_context)
        return self.api_client.get_text_response(prompt, context_str, None)


# voice_assistent\class_voice_assistent\context_manager.py

from collections import deque

class ContextManager:
    def __init__(self, maxlen=10):
        self.recent_context = deque(maxlen=maxlen)

    def add_context(self, command, response):
        self.recent_context.append((command, response))

    def get_context(self):
        return "\n".join([context for context, _ in self.recent_context])


# voice_assistent\class_voice_assistent\conversation_history.py



# voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py

import requests
import logging
import google.generativeai as genai

# Configure o logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, feedback):
        try:
            # Gerando o conte√∫do usando a nova API
            response = self.model.generate_content(prompt)
            if response and hasattr(response, 'text'):
                return prompt, response.text
            else:
                logger.error("Resposta inv√°lida da API")
                return prompt, None
        except Exception as e:
            logger.error(f"Erro em get_text_response: {e}")
            return prompt, None

    def find_similar_embeddings(self, embedding):
        try:
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            logger.info(f"Enviando dados para a API de embeddings similares: {data}")
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            logger.error(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            data = {
                "question": question,
                "questionEmbedding": question_embedding.tolist() if hasattr(question_embedding, 'tolist') else question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding.tolist() if hasattr(answer_embedding, 'tolist') else answer_embedding
            }
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                logger.info("Pergunta e resposta salvas com sucesso.")
            else:
                logger.warning(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            logger.error(f"Erro em save_question_answer: {e}")


# voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py

import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        """Carregar vari√°veis do arquivo .env"""
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        """Configurar a chave da API"""
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        """Inicializar o modelo generativo"""
        try:
            self.model = genai.GenerativeModel(self.model_name)
        except Exception as e:  
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content(self, prompt: str, context: str, meeting: str) -> str:
        """Gerar conte√∫do com base no prompt, contexto e reuni√£o"""
        try:
            # Supondo que a API espera um dicion√°rio com os par√¢metros
            request_data = f'''
                "prompt": {prompt},
                "context": {context},
                "meeting": {meeting}
            '''
            print(f"Enviando requisi√ß√£o para a API GenAI: {request_data}")

            response = self.model.generate_content(request_data)
            return response.text
        except Exception as e:
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py

import os
from dotenv import load_dotenv
from groq import Groq

# Carregar vari√°veis do arquivo .env
load_dotenv()

# Recuperar a chave da API
api_key = os.getenv("GROQ_API_KEY")

# Verificar se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API Key is missing. Please set the GROQ_API_KEY in the .env file.")

# Configurar o cliente com a chave da API
client = Groq(api_key=api_key)

# Cria√ß√£o da conclus√£o do chat
chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "De acordo com nossas conversas anteriores, o que voc√™ acha do meu uso de IA ?",
        }
    ],
    model="llama3-8b-8192",
)

print(chat_completion.choices[0].message.content)


# voice_assistent\class_voice_assistent\main.py

import os
from context_manager import ContextManager
from api_client import APIClient
from command_interpreter import CommandInterpreter
from text_command_hendler import TextCommandHandler
from text_processor import TextProcessor
from text_to_speech import TextToSpeech
from voice_command_hendler import VoiceCommandHandler
from question_answers_service import QuestionAnswerService
from gpt_communication.gemini_gpt import GenerativeModelHandler

class MainApp:
    def __init__(self, model):
        self.voice_handler = VoiceCommandHandler()
        self.text_handler = TextCommandHandler()
        self.tts = TextToSpeech()
        self.text_processor = TextProcessor()
        self.api_client = APIClient(
            similarity_url="http://localhost:8081",
            save_url="http://localhost:8081/api/question_answers/save",
            model=model
        )
        self.context_manager = ContextManager()
        self.question_answer_service = QuestionAnswerService()
        self.command_interpreter = CommandInterpreter(
            self.api_client,
            self.question_answer_service,
            self.context_manager
        )

    def handle_command(self, command, meeting=""):
        if command:
            print(f"Pergunta recebida: {command}")
            text_response = self.command_interpreter.interpret_command(command, meeting)
            if text_response:
                print(f"Resposta: {text_response}")
                self.tts.speak_text(text_response)
                self.context_manager.add_context(command, text_response)
                return text_response
        else:
            print("Nenhum comando detectado.")
            return None

    def run(self):
        meeting = ""
        while True:
            try:
                input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
                if input_type == 'v':
                    command = self.voice_handler.capture_voice_command()
                elif input_type == 't':
                    command = self.text_handler.capture_text_command()
                else:
                    print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
                    continue

                response = self.handle_command(command, meeting)
                if response:
                    print(f"Resposta: {response}")
            except Exception as e:
                print(f"Ocorreu um erro: {e}")

if __name__ == "__main__":
    model = GenerativeModelHandler('gemini-1.5-flash')
    app = MainApp(model)
    app.run()

# voice_assistent\class_voice_assistent\prompt.py

def create_prompt(command, context, meeting):
    keywords = ["fa√ßa um resumo da √∫ltima reuni√£o.", "t√≥picos da √∫ltima reuni√£o", "resuma a √∫ltima reuni√£o", "pesquise", "pesquisar", "procure"]
    if any(keyword in command.lower() for keyword in keywords):
        return f"""
        Regras de Meeting:
        - Voc√™ √© respons√°vel por analisar, debater, sugerir e informar melhorias.
        - Resuma de forma clara e Objetiva.
        - N√£o acrescentar t√≠tulo nas respostas.

        [context]: {context}
        -------
        [meeting]: {meeting}
        -------
        [str_texto]: {command}
        """
    else:
        return f"""
        [context]: {context}
        -------
        [str_texto]: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py

class DefaultPromptGenerator:
    def generate_prompt(self, command, combined_context, meeting):
        prompt = (
            f"Comando: {command}\n"
            f"Contexto Anterior:\n{combined_context}\n"
            f"Baseie sua resposta nas informa√ß√µes acima e forne√ßa uma solu√ß√£o detalhada."
        )
        return prompt

# voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class MeetingPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting):
        return f"""
        Regras de Meeting com respostas inteligentes:
        - Responda a pergunta de [str_texto] com base nas diretrizes abaixo...
            - Voc√™ √© respons√°vel analisar com detalhes a reuni√£o de [str_meeting], e fornecer uma longa est√≥ria sobre o assunto.
            - observe os nomes das personas mencionadas no texto de meeting para aprender e melhorar a precis√£o da resposta.
            - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [str_texto]: Responda a pergunta de: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class OnlineResearchPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting, similar_context):
        return f"""
        Regras de Pesquisa Online Inteligente:
        - Utilize similar_context e fa√ßa uma pesquisa online para uma resposta mais precisa das quest√µes de [str_text]
        - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [context]: Regras B√°sicas {context}
        ------
        [similar_context]:
        Perguntas e respostas anteriores.{similar_context}
        ------
        [str_texto]: Responda seguinte pergunta: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py

from abc import ABC, abstractmethod

class PromptGenerator(ABC):
    @abstractmethod
    def generate_prompt(self, command, context, meeting, similar_context):
        pass

# voice_assistent\class_voice_assistent\question_answers_service.py

import requests
import numpy as np
from sentence_transformers import SentenceTransformer

class QuestionAnswerService:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.embedding_model = SentenceTransformer(model_name)

    def convert_text_to_embedding(self, text):
        embedding = self.embedding_model.encode(text)
        #print(f"Embedding gerado para '{text}': {embedding[0]:.16f}") # Adicionado para verificar o embedding gerado
        return embedding


# voice_assistent\class_voice_assistent\text_command_hendler.py

class TextCommandHandler:
    def capture_text_command(self):
        command = input("Digite o seu comando: ")
        return command


# voice_assistent\class_voice_assistent\text_processor.py

from bs4 import BeautifulSoup

class TextProcessor:
    def extract_values_from_json(self, data):
        if isinstance(data, dict):
            return ' '.join([str(value) for value in data.values()])
        elif isinstance(data, list):
            return ' '.join([self.extract_values_from_json(item) for item in data])
        return str(data)

    def extract_text_from_html(self, html):
        if not html.strip().startswith('<'):
            print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
            return html
        soup = BeautifulSoup(html, 'html.parser')
        text = ' '.join([p.get_text() for p in soup.find_all('p')])
        return text


# voice_assistent\class_voice_assistent\text_to_speech.py

import pyttsx3

class TextToSpeech:
    def __init__(self):
        self.engine = pyttsx3.init()

    def speak_text(self, text):
        cleaned_text = self.clean_text(text)
        self.engine.say(cleaned_text)
        self.engine.runAndWait()

    def clean_text(self, text):
        import re
        return re.sub(r'[\*\_\#]', '', text)


# voice_assistent\class_voice_assistent\voice_command_hendler.py

import speech_recognition as sr

class VoiceCommandHandler:
    def capture_voice_command(self):
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            print("Por favor, fale o seu comando:")
            try:
                audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
                print("√Åudio capturado com sucesso.")
                command = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {command}")
                return command
            except sr.WaitTimeoutError:
                print("Tempo de espera expirado. Nenhum √°udio detectado.")
                return None
            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio.")
                return None
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
                return None


# voice_assistent\config.py

# config.py
import pyttsx3
import spacy
from collections import deque

class APIConfig:
    apiKey = "API_KEY"
    url = "https://gpt-templates.saiapplications.com"
    headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")


# voice_assistent\template.py

import speech_recognition as sr
import requests
import pyttsx3
import re
from collections import deque
import spacy
import os
import webbrowser
from voice_assistent.prompt import create_prompt

# Configura√ß√µes da API
apiKey = "6UlOOoY/kkmprunma/qNDg"
url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    if isinstance(text, dict):
        text = extract_values_from_json(text)  # Extrai os valores do dicion√°rio
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

def get_text_response(prompt, context, feedback):
    data = {
        "inputs": {
            "str_texto": prompt,
            "str_contexto": context,
            "str_feedback": feedback
        }
    }
    print(f"Enviando dados para a API: {data}")
    try:
        response = requests.post(f"{url}/api/templates/6691e223802f95c2b394a8bd/execute", json=data, headers=headers)
        print(f"Status da resposta: {response.status_code}")
        if response.status_code == 200:
            try:
                response_data = response.html()  # Tente converter a resposta para JSON
                print("Resposta HTML recebida.")
                return extract_values_from_json(response_data)  # Extrai os valores do JSON
            except ValueError:
                print("A resposta n√£o est√° no formato JSON esperado. Tratando como texto simples.")
                return response.text  # Retorna o texto bruto da resposta
        else:
            print(f"Erro ao acessar a API: {response.status_code}, {response.text}")
            return None
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API: {e}")
        return None

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)


# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


User: Como posso integrar todas as aplica√ß√µes para funcionar em uma √∫nica MAIN.py ?

Streamlit. Chat de voz. converter v√≠deo para audio e audio para texto e depois salvar no banco de dados.
2025-04-10 19:43:31,253 [INFO] Resposta da IA (texto): Para integrar todas as aplica√ß√µes em um √∫nico `main.py`, voc√™ precisa modularizar seu c√≥digo existente e usar uma estrutura central que coordene a execu√ß√£o das diferentes partes (Streamlit chat de voz, convers√£o de v√≠deo para √°udio, √°udio para texto e salvamento no banco de dados).

Aqui est√° um esbo√ßo de como voc√™ pode abordar isso, com √™nfase na organiza√ß√£o e coordena√ß√£o das tarefas:

```python
# main.py

import streamlit as st
import os
from pathlib import Path

# Importar as fun√ß√µes e classes de cada m√≥dulo
from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from voice_assistent.class_voice_assistent.main import MainApp
from voice_assistent.class_voice_assistent.gpt_communication.gemini_gpt import GenerativeModelHandler
from transcriptions.transcriptions_config import TranscriptionConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from config.config import Config
from core.rate_limiter import RateLimiter

# 1. Configura√ß√£o Inicial
PROJECT_ROOT = Path(__file__).resolve().parent
root_path = str(PROJECT_ROOT)
print(f"Root path: {root_path}")

Config.ensure_directories()

# 2. Fun√ß√µes de Processamento
def process_videos():
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()

def process_audio():
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()

def process_transcriptions_and_embeddings(api_url):
    transcription_config = TranscriptionConfig(root_path=root_path)
    embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())
    embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    embedding_processor_wrapper.process_transcriptions()

# 3. Interface Streamlit
def main():
    st.title("Aplica√ß√µes Integradas")

    # 3.1. Sidebar com op√ß√µes
    app_mode = st.sidebar.selectbox(
        "Escolha a aplica√ß√£o:",
        ["Chat de Voz", "Converter V√≠deo para √Åudio", "Converter √Åudio para Texto", "Enviar Embeddings para o Banco de Dados"]
    )

    # 3.2. L√≥gica para cada aplica√ß√£o
    if app_mode == "Chat de Voz":
        st.header("Chat de Voz")
        model = GenerativeModelHandler('gemini-1.5-flash')
        app = MainApp(model)
        app.run()

    elif app_mode == "Converter V√≠deo para √Åudio":
        st.header("Converter V√≠deo para √Åudio")
        if st.button("Converter V√≠deos"):
            process_videos()
            st.success("V√≠deos convertidos para √°udio com sucesso!")

    elif app_mode == "Converter √Åudio para Texto":
        st.header("Converter √Åudio para Texto")
        if st.button("Converter √Åudios"):
            process_audio()
            st.success("√Åudios convertidos para texto com sucesso!")

    elif app_mode == "Enviar Embeddings para o Banco de Dados":
        st.header("Enviar Embeddings para o Banco de Dados")
        api_url = st.text_input("URL da API para enviar as transcri√ß√µes:", "http://localhost:8081/api/meetings/transcriptions")

        if st.button("Enviar Embeddings"):
            process_transcriptions_and_embeddings(api_url)
            st.success("Embeddings enviados para o banco de dados com sucesso!")

# 4. Execu√ß√£o Principal
if __name__ == "__main__":
    main()
```

### Estrutura do Projeto

-   **`main.py`**: Este √© o ponto de entrada. Ele usa Streamlit para criar uma interface que permite selecionar qual parte da aplica√ß√£o executar.

-   **`video_to_audio/`**, **`audio_to_text/`**, **`text_to_embedding/`**, **`voice_assistent/`**: Esses diret√≥rios cont√™m o c√≥digo existente de cada parte da sua aplica√ß√£o.

### Passos para Implementar

1.  **Modulariza√ß√£o:**

    *   Certifique-se de que cada parte da sua aplica√ß√£o (convers√£o de v√≠deo, convers√£o de √°udio, chat de voz) esteja bem encapsulada em fun√ß√µes ou classes reutiliz√°veis.
    *   Mova essas fun√ß√µes e classes para os respectivos m√≥dulos (arquivos `.py` dentro de seus diret√≥rios).

2.  **Integra√ß√£o no `main.py`:**

    *   Importe as fun√ß√µes e classes dos m√≥dulos.
    *   Use Streamlit para criar uma interface que permita ao usu√°rio escolher qual fun√ß√£o executar.
    *   Implemente bot√µes ou seletores para acionar as diferentes partes da aplica√ß√£o.

3.  **Gerenciamento de Depend√™ncias:**

    *   Certifique-se de que todas as depend√™ncias necess√°rias para cada parte da aplica√ß√£o estejam instaladas.  Considere usar um arquivo `requirements.txt` para listar todas as depend√™ncias.

4.  **Testes:**

    *   Teste cada parte da aplica√ß√£o individualmente para garantir que funcionem corretamente.
    *   Teste a integra√ß√£o geral para garantir que as diferentes partes possam ser executadas em sequ√™ncia ou individualmente, conforme necess√°rio.

### Pontos Chave

*   **Modulariza√ß√£o:** Dividir o c√≥digo em m√≥dulos facilita a manuten√ß√£o e reutiliza√ß√£o.
*   **Interface Streamlit:** Streamlit permite criar uma interface web simples para interagir com sua aplica√ß√£o.
*   **Gerenciamento de Estado:** Use `st.session_state` para manter o estado entre as execu√ß√µes da aplica√ß√£o Streamlit (por exemplo, se um v√≠deo foi convertido ou n√£o).
*   **Tratamento de Erros:** Implemente tratamento de erros para lidar com falhas em qualquer parte da aplica√ß√£o e fornecer feedback √∫til ao usu√°rio.
*   **Configura√ß√£o:** Utilize arquivos de configura√ß√£o (como o seu `config.py`) para armazenar caminhos de arquivos, URLs de API e outras configura√ß√µes que podem precisar ser ajustadas.

Seguindo esses passos, voc√™ deve conseguir integrar todas as suas aplica√ß√µes em um √∫nico script `main.py` com uma interface Streamlit para facilitar o uso e a demonstra√ß√£o.

2025-04-10 19:43:31,356 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 19:43:31,358 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 19:43:31,359 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 19:43:31,362 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 19:43:31,364 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 19:43:31,365 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 19:43:31,367 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 19:43:31,369 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 19:43:31,372 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 19:43:31,374 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 19:43:31,376 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 19:43:31,379 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 19:43:31,382 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 19:43:31,384 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 19:43:31,386 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 19:43:31,387 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 19:43:31,389 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 19:43:31,390 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 19:43:31,392 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 19:43:31,393 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 19:43:31,395 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 19:43:31,397 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 19:43:31,400 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 19:43:31,401 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 19:43:31,403 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 19:43:31,405 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 19:43:31,406 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 19:43:31,408 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 19:43:31,409 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 19:43:31,412 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 19:43:31,414 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 19:43:31,416 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 19:43:31,418 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 19:43:31,419 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 19:43:31,421 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 19:43:31,422 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 19:43:31,424 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 19:43:31,425 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 19:43:31,426 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 19:43:31,428 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 19:43:31,430 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 19:43:31,433 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 19:43:31,434 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 19:43:31,436 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 19:43:31,437 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 19:43:31,439 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 19:43:31,440 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 19:43:31,441 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 19:43:31,443 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 19:43:31,445 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 19:43:31,447 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 19:43:31,451 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 19:43:31,452 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 19:43:31,454 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 19:46:09,713 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 19:46:09,715 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 19:46:09,716 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 19:46:09,718 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 19:46:09,720 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 19:46:09,722 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 19:46:09,724 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 19:46:09,726 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 19:46:09,728 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 19:46:09,730 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 19:46:09,732 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 19:46:09,733 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 19:46:09,735 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 19:46:09,737 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 19:46:09,739 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 19:46:09,740 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 19:46:09,742 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 19:46:09,744 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 19:46:09,747 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 19:46:09,749 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 19:46:09,751 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 19:46:09,753 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 19:46:09,755 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 19:46:09,757 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 19:46:09,758 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 19:46:09,761 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 19:46:09,764 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 19:46:09,766 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 19:46:09,768 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 19:46:09,771 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 19:46:09,772 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 19:46:09,774 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 19:46:09,775 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 19:46:09,778 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 19:46:09,780 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 19:46:09,782 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 19:46:09,784 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 19:46:09,785 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 19:46:09,786 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 19:46:09,788 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 19:46:09,790 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 19:46:09,792 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 19:46:09,794 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 19:46:09,797 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 19:46:09,799 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 19:46:09,801 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 19:46:09,803 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 19:46:09,804 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 19:46:09,806 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 19:46:09,808 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 19:46:09,810 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 19:46:09,813 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 19:46:09,815 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 19:46:09,817 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 19:46:09,946 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 19:46:09,948 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 19:46:09,949 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 19:46:09,952 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 19:46:09,954 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 19:46:09,956 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 19:46:09,957 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 19:46:09,959 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 19:46:09,962 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 19:46:09,964 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 19:46:09,967 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 19:46:09,969 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 19:46:09,971 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 19:46:09,972 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 19:46:09,974 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 19:46:09,976 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 19:46:09,978 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 19:46:09,980 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 19:46:09,983 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 19:46:09,986 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 19:46:09,988 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 19:46:09,990 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 19:46:09,991 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 19:46:09,993 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 19:46:09,995 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 19:46:09,996 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 19:46:09,999 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 19:46:10,000 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 19:46:10,002 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 19:46:10,003 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 19:46:10,005 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 19:46:10,010 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 19:46:10,019 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 19:46:10,021 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 19:46:10,024 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 19:46:10,025 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 19:46:10,027 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 19:46:10,028 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 19:46:10,029 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 19:46:10,032 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 19:46:10,033 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 19:46:10,035 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 19:46:10,036 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 19:46:10,038 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 19:46:10,039 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 19:46:10,041 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 19:46:10,042 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 19:46:10,044 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 19:46:10,047 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 19:46:10,049 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 19:46:10,051 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 19:46:10,053 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 19:46:10,054 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 19:46:10,056 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 19:46:10,061 [INFO] Enviando para IA - Prompt (sem imagem): Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas.

Contexto:



# app_config\app_config.py

from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()
    
    def get_root_path(self):
        return str(self.ROOT_PATH)
    
    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py

from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        transcription_config = TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])


# audio_to_text\audio_to_text.py

import whisper
from audio_to_text.audio_config.audio_config import AudioConfig

class AudioToConverter:
    def __init__(self, audio_config: AudioConfig):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.AUDIO_INPUT_PATH
        self.TRANSCRIPTION_INPUT_PATH = audio_config.TRANSCRIPTION_INPUT_PATH

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            print(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        model = whisper.load_model("base")

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                print(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            print(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            print(f"Erro ao processar o arquivo {audio_file_path}: {e}")


# chat_app\chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# chat_app\config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# chat_app\services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# chat_app\services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# chat_app\services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# chat_app\utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

# common_paths\common_paths.py

from pathlib import Path

class CommonPaths:
    def __init__(self):
        # Diret√≥rio atual do script
        self.ROOT_PATH = Path(__file__).resolve().parent

        # Defini√ß√£o dos caminhos comuns
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'output'
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.AUDIO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.TRANSCRIPTION_OUTPUT_PATH = self.ROOT_PATH / 'data'
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'data'

        # Cria√ß√£o dos diret√≥rios
        self.create_directories()

    def create_directories(self):
        self.VIDEO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.VIDEO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.TRANSCRIPTION_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)



# fundamentus_api\fundamentus\__init__.py



# fundamentus_api\fundamentus\dados_b3.py

import locale
import pandas as pd
import streamlit as st
import requests
import fundamentus
import os
import plotly.express as px
from bs4 import BeautifulSoup
from fundamentus.detalhes import get_papel
import logging

# Configura localidade
locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')

# Configura√ß√£o do layout do Streamlit
st.set_page_config(
    page_title="An√°lise de A√ß√µes",
    layout="wide",
    page_icon="üìà"
)

class Acao:
    def __init__(self, papel):
        self.papel = papel
        self.dados_fundamentais = None
        self.proventos = None
        self.detalhes = None
        self.oscilacoes = None  # Adicionando um atributo para oscila√ß√µes

    def carregar_dados_fundamentais(self):
        self.dados_fundamentais = fundamentus.get_resultado().loc[[self.papel]]  # Use colchetes duplos para garantir que seja um DataFrame
        self.remover_formatacao()

    def obter_detalhes(self):
        self.detalhes = get_papel(self.papel)
        if self.detalhes is None or self.detalhes.empty:
            logging.warning(f"Nenhum detalhe encontrado para o papel: {self.papel}")

    def obter_proventos(self):
        url = f"https://www.fundamentus.com.br/proventos.php?papel={self.papel}&tipo=2"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        tabela = soup.find('table', {'id': 'resultado'})

        if not tabela:
            return pd.DataFrame()

        dados = []
        for linha in tabela.find_all('tr')[1:]:
            colunas = linha.find_all('td')
            try:
                valor = float(colunas[1].text.strip().replace(',', '.'))
            except ValueError:
                valor = None  # Se der erro, coloca None para evitar crash

            dados.append([colunas[0].text.strip(), valor, colunas[2].text.strip()])
        
        self.proventos = pd.DataFrame(dados, columns=['Data', 'Valor', 'Tipo'])
        return self.proventos

    def obter_oscilacoes(self):
        url = f"https://www.fundamentus.com.br/detalhes.php?papel={self.papel}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        conteudo_div = soup.find('div', class_='conteudo clearfix')

        if conteudo_div is None:
            return pd.DataFrame()

        oscilacoes_data = []
        oscilacoes_section = conteudo_div.find('td', class_='nivel1', colspan='2')
        
        if oscilacoes_section:
            labels = oscilacoes_section.find_all_next('td', class_='label w1')
            dados = oscilacoes_section.find_all_next('td', class_='data w1')

            for label, dado in zip(labels, dados):
                label_text = label.get_text(strip=True)
                valor_text = dado.find('span', class_='oscil').get_text(strip=True)
                oscilacoes_data.append([label_text, valor_text])

        self.oscilacoes = pd.DataFrame(oscilacoes_data, columns=['Per√≠odo', 'Oscila√ß√£o'])
        return self.oscilacoes

    def remover_formatacao(self):
        colunas_percentuais = ['dy', 'mrgebit', 'mrgliq', 'roic', 'roe', 'c5y']
        for coluna in colunas_percentuais:
            if coluna in self.dados_fundamentais:
                try:
                    self.dados_fundamentais[coluna] = self.dados_fundamentais[coluna].astype(float)
                except ValueError as e:
                    logging.error(f"Erro ao converter coluna {coluna} para float: {e}")

    def formatar_moeda(self, valor):
        return locale.currency(valor, symbol=True, grouping=True)

class Aplicacao:
    def __init__(self):
        self.acoes = fundamentus.get_resultado()

    def ajustar_tipos_dataframe(self, df):
        for coluna in df.columns:
            if df[coluna].dtype == 'object':
                try:
                    df[coluna] = df[coluna].astype(float)
                except ValueError:
                    df[coluna] = df[coluna].astype(str)
            elif df[coluna].dtype in ['int64', 'float64']:
                df[coluna] = df[coluna].astype(float)
        return df

    def exibir_dashboard(self):
        st.sidebar.title("üìä Dashboard de An√°lise de A√ß√µes")
        st.sidebar.write("Selecione um papel para visualizar detalhes.")

        papel_selecionado = st.sidebar.selectbox("Escolha uma a√ß√£o", self.acoes.index)

        acao = Acao(papel_selecionado)
        acao.carregar_dados_fundamentais()
        acao.obter_proventos()
        acao.obter_detalhes()
        acao.obter_oscilacoes()

        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader(f"üìå Dados Fundamentais - {papel_selecionado}")
            dados_fundamentais_df = self.ajustar_tipos_dataframe(acao.dados_fundamentais.T)
            st.dataframe(dados_fundamentais_df, width=400)

        with col2:
            st.subheader("üîç Detalhes")
            if acao.detalhes is not None and not acao.detalhes.empty:
                detalhes_df = pd.DataFrame(acao.detalhes).T.reset_index()
                detalhes_df.columns = ['Descri√ß√£o', 'Valor']
                detalhes_df = self.ajustar_tipos_dataframe(detalhes_df)

                st.subheader("Tabela de Detalhes")
                st.dataframe(detalhes_df, width=800)
            else:
                st.warning("Nenhum detalhe encontrado para essa a√ß√£o.")

        col_dividendos, col_oscilacoes = st.columns([1, 2])

        with col_dividendos:
            st.subheader("üí∞ Dividendos")
            if not acao.proventos.empty:
                proventos_df = self.ajustar_tipos_dataframe(acao.proventos)
                st.write(proventos_df)

        with col_oscilacoes:
            st.subheader("üìâ Oscila√ß√µes")
            if acao.oscilacoes is not None and not acao.oscilacoes.empty:
                oscilacoes_df = self.ajustar_tipos_dataframe(acao.oscilacoes)
                st.write(oscilacoes_df)

        st.subheader("üìà Tabela Geral de A√ß√µes")
        st.dataframe(self.acoes)

# Execu√ß√£o
if __name__ == "__main__":
    app = Aplicacao()
    app.exibir_dashboard()

# fundamentus_api\setup.py

from setuptools import setup, find_packages

setup(
    name='fundamentalvision ',
    version='0.1.0',
    author='Joel FerreiraHeanna dos Reis',
    author_email='heannareis@gmail.com',
    description='Um pacote para an√°lise fundamentalista de a√ß√µes da Bolsa B3 do Brasil.',
    packages=find_packages(),
    install_requires=[
        'pandas',
        'requests',
        'beautifulsoup4',
        'streamlit',
        'plotly',
        'fundamentus'
    ],
    classifiers=[
        'Programming Language :: Python :: 3',
        'License :: OSI Approved :: MIT License',
        'Operating System :: OS Independent',
    ],
    python_requires='>=3.6',
)

# ia_generator.py

import requests
from pathlib import Path
import webbrowser
from config.common_paths import TRANSCRIPTION_OUTPUT_PATH

apiKey = "6UlOOoY/kkmprunma/qNDg"

str_personas = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'personas.txt'
str_contexto = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'contexto.txt'

url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

txt_files = list(TRANSCRIPTION_OUTPUT_PATH.glob('*.txt'))

css_styles = """
<style>
body {
    font-family: Arial, sans-serif;
    margin: 20px;
}

h1, h2, h3 {
    color: #FF8C00;
}

li, strong, p {
    color: #008000;
}

h1 {
    font-size: 24px;
    margin-bottom: 20px;
}

h2 {
    font-size: 20px;
    margin-top: 20px;
    margin-bottom: 10px;
}

ul {
    list-style-type: disc;
    margin-left: 40px;
}

li {
    margin-bottom: 10px;
}

p {
    line-height: 1.6;
}
</style>
"""

if not txt_files:
    print(f"N√£o foram encontrados arquivos .txt no diret√≥rio {TRANSCRIPTION_OUTPUT_PATH}.")
else:
    for txt_file in txt_files:
        if txt_file.is_file():
            print(f"Lendo o arquivo: {txt_file.name}")
            with open(txt_file, 'r', encoding='utf-8') as file:
                str_reuniao = file.read()

            print(f"Enviando o conte√∫do do arquivo {txt_file.name} para a API...")
            data = {
                "inputs": {
                    "str_reuniao": str_reuniao,
                    "str_personas": str_personas.read_text(encoding='utf-8'),
                    "str_contexto": str_contexto.read_text(encoding='utf-8'),
                }
            }

            response = requests.post(f"{url}/api/templates/668de04202493d3063a9d7fa/execute", json=data, headers=headers)
            if response.status_code == 200:
                print(f"Resultado para o arquivo {txt_file.name} recebido.")
                html_content = response.text
                print(response.text)

                # Incluir o CSS no conte√∫do HTML
                html_with_css = f"<html><head>{css_styles}</head><body>{html_content}</body></html>"

                # Salvar o conte√∫do HTML em um arquivo
                output_file = TRANSCRIPTION_OUTPUT_PATH / f"{txt_file.stem}_output.html"
                with open(output_file, 'w', encoding='utf-8') as html_file:
                    html_file.write(html_with_css)

                # Abrir o arquivo HTML no navegador
                webbrowser.open(f"file://{output_file.resolve()}")
            else:
                print(f"Erro ao processar o arquivo {txt_file.name}: {response.status_code}")


# main.py

from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from transcriptions.transcriptions_config import TranscriptionConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from pathlib import Path

def main():
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    root_path = str(PROJECT_ROOT)
    print(f"Root path: {root_path}")  # Para verificar se est√° correto
    api_url = "http://localhost:8081/api/meetings/transcriptions"
    
    # # Configura√ß√£o de v√≠deos
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()
    
    # # Configura√ß√£o de √°udios
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()
    
    # # Processamento de transcri√ß√µes e envio de embeddings
    # embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    # embedding_processor_wrapper.process_transcriptions()

if __name__ == "__main__":
    main()


# send_embeddings_database\embedding_config\embedding_config.py

from app_config.app_config import AppConfig

class EmbeddingConfig(AppConfig):
    def __init__(self, root_path=None, transcription_input_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = transcription_input_path
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'embeddings' / 'output'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH, self.EMBEDDING_OUTPUT_PATH])


# send_embeddings_database\verify_last_enbedding.py

import os
import numpy as np

def get_latest_file(directory):
    # Listar todos os arquivos no diret√≥rio
    files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]
    
    if not files:
        raise FileNotFoundError("Nenhum arquivo encontrado no diret√≥rio.")

    # Encontrar o arquivo mais recente
    latest_file = max(files, key=os.path.getmtime)
    return latest_file

def load_and_print_embedding(directory):
    # Obter o caminho do √∫ltimo arquivo de embedding
    embedding_file_path = get_latest_file(directory)
    
    # Carregar o embedding
    embedding = np.load(embedding_file_path)
    
    # Exibir o conte√∫do do embedding
    print("Embedding carregado:")
    print(embedding)
    print("Dimens√µes do embedding:", embedding.shape)

# Caminho do diret√≥rio de embeddings
embedding_directory = 'C:/Users/HeannarReis/Documents/bsa_atacadao/assets/embeddings/output'

# Carregar e exibir o √∫ltimo embedding
load_and_print_embedding(embedding_directory)


# test_whisper.py

from transformers import pipeline
from common_paths import CommonPaths

commmom_paths = CommonPaths()

# Fun√ß√£o para ler a transcri√ß√£o de um arquivo
def read_transcription(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
    return lines

# Fun√ß√£o para converter a pontua√ß√£o em estrelas
def score_to_stars(score):
    if score >= 0.75:
        return 5
    elif score >= 0.55:
        return 4
    elif score >= 0.35:
        return 3
    elif score >= 0.15:
        return 2
    else:
        return 1

# Inicializar o pipeline de an√°lise de sentimento
sentiment_pipeline = pipeline("sentiment-analysis", model="neuralmind/bert-base-portuguese-cased")

# Caminho para o arquivo de transcri√ß√£o
file_path = commmom_paths.TRANSCRIPTION_OUTPUT_PATH / 'feedback.txt'

# Ler a transcri√ß√£o
lines = read_transcription(file_path)

# Analisar sentimento para cada feedback
for line in lines:
    sentiment = sentiment_pipeline(line.strip())
    score = sentiment[0]['score']
    stars = score_to_stars(score)
    
    # Ajuste manual para feedbacks com aspectos positivos e negativos
    if any(word in line.lower() for word in ["mas", "por√©m", "no entanto"]):
        stars = max(1, stars - 1)  # Reduz uma estrela se houver contradi√ß√£o
    
    # Ajuste adicional baseado em palavras-chave
    positive_keywords = ["excelente", "√≥timo", "perfeito", "r√°pido", "eficiente", "satisfeito", "clara", "eficaz", "bom trabalho"]
    negative_keywords = ["ruim", "p√©ssimo", "horr√≠vel", "poderia", "n√£o resolveu", "insatisfat√≥ria", "confusa", "inadequado", "lento", "n√£o houve seguimento", "n√£o atendeu", "n√£o funcionou", "demorado"]
    
    positive_count = sum(word in line.lower() for word in positive_keywords)
    negative_count = sum(word in line.lower() for word in negative_keywords)
    
    # Ajuste de estrelas baseado na contagem de palavras-chave
    if positive_count > negative_count:
        stars = min(5, stars + 1)
    elif negative_count > positive_count:
        stars = max(1, stars - 1)
    
    print(f"Texto: {line.strip()}")
    print(f"Sentimento: {stars} estrelas")
    print(f"Pontua√ß√£o: {score:.2f}")
    print('---')


# text_to_embedding\embedding_processing.py

from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from transcriptions.transcriptions_config import TranscriptionConfig
from transcriptions.transciption_sender_database import TranscriptionSenderDatabase

class EmbeddingProcessorWrapper:
    def __init__(self, root_path, api_url):
        # Configura√ß√£o de transcri√ß√µes e embeddings
        transcription_config = TranscriptionConfig(root_path=root_path)
        embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())

        self.embedding_processor = EmbeddingProcessor(embedding_config)
        self.transcription_sender = TranscriptionSenderDatabase(api_url)
    
    def process_transcriptions(self):
        # Mostrar o diret√≥rio onde est√° procurando as transcri√ß√µes
        print(f"Diret√≥rio de entrada das transcri√ß√µes: {self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH}")
        
        # Listar todos os arquivos de transcri√ß√£o no diret√≥rio de entrada
        transcription_files = list(self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH.glob('*.txt'))
        if not transcription_files:
            print("Nenhum arquivo de transcri√ß√£o encontrado.")
        for transcription_file_path in transcription_files:
            if transcription_file_path.is_file():
                print(f"Processando arquivo: {transcription_file_path}")
                self.process_and_send_transcription(transcription_file_path)
            else:
                print(f"Arquivo n√£o encontrado: {transcription_file_path}")

    def process_and_send_transcription(self, transcription_file_path):
        try:
            # Ler a transcri√ß√£o do arquivo de texto
            with open(transcription_file_path, 'r', encoding='utf-8') as f:
                transcription_text = f.read()
                if not transcription_text:
                    print(f"Arquivo {transcription_file_path} est√° vazio.")
                    return

            # Gerar o embedding da transcri√ß√£o
            embedding = self.embedding_processor.generate_embedding(transcription_text)
            if embedding is None:
                print(f"Falha ao gerar embedding para o arquivo {transcription_file_path}.")
                return

            # Salvar o embedding em um arquivo .npy
            self.embedding_processor.save_embedding(transcription_file_path, embedding)

            # Enviar os dados para a API
            self.transcription_sender.send_transcription(transcription_text, embedding)

        except Exception as e:
            print(f"Erro ao processar o arquivo {transcription_file_path}: {e}")


# text_to_embedding\texto_to_embedding.py

from sentence_transformers import SentenceTransformer
import numpy as np

class EmbeddingProcessor:
    def __init__(self, embedding_config):
        self.embedding_config = embedding_config
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

    def generate_embedding(self, transcription_text):
        return self.embedding_model.encode(transcription_text)

    def save_embedding(self, transcription_file_path, embedding):
        embedding_file_path = self.embedding_config.EMBEDDING_OUTPUT_PATH / transcription_file_path.with_suffix('.npy').name
        np.save(embedding_file_path, embedding)
        print(f"Embedding salvo em: {embedding_file_path}")
        return embedding_file_path


# transcriptions\transciption_sender_database.py

import requests

class TranscriptionSenderDatabase:
    def __init__(self, api_url):
        self.api_url = api_url

    def send_transcription(self, transcription_text, embedding):
        data = {
            'transcriptionText': transcription_text,
            'embedding': embedding.tolist()
        }

        response = requests.post(self.api_url, json=data)

        if response.status_code == 201:
            print("Transcri√ß√£o e embedding enviados com sucesso.")
        else:
            print(f"Erro ao enviar dados: {response.status_code}")
            print("Resposta da API:")
            print(response.text)


# transcriptions\transcriptions_config.py

from app_config.app_config import AppConfig

class TranscriptionConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = self.ROOT_PATH / 'assets' / 'transcriptions' / 'input'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH])
    
    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# translate\translator_to_english.py

import speech_recognition as sr
from translate import Translator

def ouvir_e_traduzir():
    # Inicializa o reconhecedor de fala
    recognizer = sr.Recognizer()

    # Configura o tradutor
    translator = Translator(to_lang="en", from_lang="pt")

    # Usa o microfone como fonte de √°udio
    with sr.Microphone() as source:
        print("Diga algo em portugu√™s...")

        while True:
            try:
                # Escuta o √°udio do microfone
                audio = recognizer.listen(source)
                
                # Reconhece a fala usando o Google Web Speech API
                texto_portugues = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {texto_portugues}")

                # Traduz o texto para o ingl√™s
                traducao = translator.translate(texto_portugues)
                print(f"Tradu√ß√£o para o ingl√™s: {traducao}")

            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio")
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")

if __name__ == "__main__":
    try:
        ouvir_e_traduzir()
    except KeyboardInterrupt:
        print("Interrompido pelo usu√°rio")


# translate\whispert_translator.py

import whisper
import pyaudio
import numpy as np

# Inicializa o modelo Whisper
model = whisper.load_model("base")

# Configura√ß√µes de √°udio
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024

# Inicializa o PyAudio
audio = pyaudio.PyAudio()

# Abre o stream de √°udio
stream = audio.open(format=FORMAT, channels=CHANNELS,
                    rate=RATE, input=True,
                    frames_per_buffer=CHUNK)

print("Diga algo em portugu√™s...")

try:
    audio_buffer = []

    while True:
        # L√™ dados do microfone
        data = stream.read(CHUNK)
        audio_buffer.append(np.frombuffer(data, dtype=np.int16).flatten().astype(np.float32) / 32768.0)

        # Processa o √°udio a cada 5 segundos
        if len(audio_buffer) * CHUNK / RATE >= 5:
            audio_data = np.concatenate(audio_buffer)
            audio_buffer = []

            # Transcreve e traduz o √°udio usando Whisper
            result = model.transcribe(audio_data, task="translate", language="pt")

            # Exibe a tradu√ß√£o
            print(f"Tradu√ß√£o para o ingl√™s: {result['text']}")

except KeyboardInterrupt:
    print("Interrompido pelo usu√°rio")

    # Fecha o stream de √°udio
    stream.stop_stream()
    stream.close()
    audio.terminate()


# video_to_audio\video_config\video_config.py

from app_config.app_config import AppConfig

class VideoConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video' / 'input'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.create_directories([self.VIDEO_INPUT_PATH, self.VIDEO_OUTPUT_PATH])

# video_to_audio\video_to_audio.py

from moviepy import VideoFileClip
import glob
import os
from .video_config.video_config import VideoConfig

class VideoToAudioConverter:
    def __init__(self, video_config: VideoConfig):
        self.video_config = video_config

    def convert_video_to_audio(self, video_path, audio_path):
        try:
            video = VideoFileClip(video_path)
            if video.audio:
                video.audio.write_audiofile(audio_path, fps=44100)
                print(f"Convertido {video_path} para {audio_path}")
            else:
                print(f"Aviso: O v√≠deo {video_path} n√£o cont√©m √°udio!")
        except Exception as e:
            print(f"Erro ao converter {video_path}: {e}")

    def process_videos(self):
        input_directory = self.video_config.VIDEO_INPUT_PATH
        output_directory = self.video_config.VIDEO_OUTPUT_PATH

        os.makedirs(output_directory, exist_ok=True)

        # Busca qualquer arquivo de v√≠deo (formatos comuns)
        video_files = glob.glob(os.path.join(input_directory, "*.*"))  # Pega todos os arquivos

        # Filtra apenas arquivos de v√≠deo
        video_extensions = {".mp4", ".mkv", ".avi", ".mov", ".wmv", ".flv"}  
        video_files = [f for f in video_files if os.path.splitext(f)[1].lower() in video_extensions]

        if not video_files:
            print(f"Nenhum arquivo de v√≠deo encontrado em: {input_directory}")
            return

        for video_file in video_files:
            base_name = os.path.basename(video_file)
            audio_file = os.path.join(output_directory, os.path.splitext(base_name)[0] + ".wav")
            self.convert_video_to_audio(video_file, audio_file)

        print("Convers√£o de v√≠deo para √°udio conclu√≠da!")


# voice_assistent\assistent.py

import speech_recognition as sr
import pyttsx3
import re
from collections import deque
import spacy
import requests
import os
import webbrowser
from class_voice_assistent.prompt import create_prompt
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import google.generativeai as genai

# Configura√ß√µes da API
handler = genai('gemini-1.5-flash')

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

voices = engine.getProperty('voices')
engine.setProperty('rate', 180)
print("\nLista de Vozes...")
for indice, vozes in enumerate(voices):
    print(indice, vozes.name)

voz = 1
engine.setProperty('voice', voices[voz].id)

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

# Fun√ß√£o para extrair texto de HTML
def extract_text_from_html(html):
    if not html.strip().startswith('<'):
        print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
        return html
    soup = BeautifulSoup(html, 'html.parser')
    text = ' '.join([p.get_text() for p in soup.find_all('p')])
    return text

def get_text_response(prompt, context, feedback):
    # Gere o conte√∫do com base no prompt usando a classe GenerativeModelHandler
    response = handler.generate_content(prompt)
    return response

# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/api/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


# voice_assistent\class_voice_assistent\api_client.py

import requests


class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, meeting):
        try:
            response_text = self.model.generate_content(prompt, context, meeting)
            return response_text
        except Exception as e:
            print(f"Erro inesperado: {e}")
            return None

    def find_similar_embeddings(self, embedding):
        try:
            print(f"Buscando embeddings similares para: {embedding}")
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            similar_embeddings = response.json()

            # Ordenar por similaridade (assumindo que a API retorna com similaridade em ordem decrescente)
            # Remover duplicatas baseadas na pergunta
            seen_questions = set()
            unique_embeddings = []
            for embedding in similar_embeddings:
                question = embedding['question'].strip().lower()
                if question not in seen_questions:
                    unique_embeddings.append(embedding)
                    seen_questions.add(question)
            print(f"Embeddings similares √∫nicos encontrados: {unique_embeddings}")
            return unique_embeddings
        except requests.RequestException as e:
            print(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            # Converter embeddings de numpy arrays para listas
            if hasattr(question_embedding, 'tolist'):
                question_embedding = question_embedding.tolist()
            if hasattr(answer_embedding, 'tolist'):
                answer_embedding = answer_embedding.tolist()
            
            data = {
                "question": question,
                "questionEmbedding": question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding
            }
            
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                print("Pergunta e resposta salvas com sucesso.")
            else:
                print(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            print(f"Erro em save_question_answer: {e}")


    def fetch_all_contexts(self):
        try:
            response = requests.get("http://localhost:8081/api/contexts/all")
            if response.status_code == 200:
                data = response.json()
                contexts = data.get('contexts', [])
                if isinstance(contexts, list):
                    print(f"Contexto obtido da API: {contexts}")
                    return contexts
                else:
                    print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                    return []
            else:
                print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
                return []
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
            return []

    def fetch_last_meeting(self):
        try:
            response = requests.get("http://localhost:8081/api/meetings/last")
            if response.status_code == 200:
                data = response.json()
                transcription_text = data.get('transcriptionText', "")
                if isinstance(transcription_text, str):
                    print(f"Texto da transcri√ß√£o obtido da API: {transcription_text}")
                    return transcription_text
                else:
                    print(f"Erro: 'transcriptionText' n√£o √© uma string. Dados retornados: {data}")
                    return ""
            else:
                print(f"Erro ao acessar a API de reuni√µes: {response.status_code}, {response.text}")
                return ""
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de reuni√µes: {e}")
            return ""


# voice_assistent\class_voice_assistent\command_interpreter.py

import spacy
from prompt_generator.online_prompt import OnlineResearchPromptGenerator
from prompt_generator.meeting_prompt import MeetingPromptGenerator
from prompt_generator.default_prompt_generator import DefaultPromptGenerator
import re

# Carregar o modelo de linguagem natural
nlp = spacy.load("pt_core_news_sm")

class CommandInterpreter:
    def __init__(self, api_client, question_answer_service, context_manager, max_similar=3):
        self.api_client = api_client
        self.question_answer_service = question_answer_service
        self.context_manager = context_manager
        self.max_similar = max_similar  # Limite de contextos similares

    def interpret_command(self, command, meeting):
        print(f"Interpretando comando: {command}")
        contexts = self.api_client.fetch_all_contexts()
        context_str = "\n".join([context['context'] for context in contexts])

        # Gerar embedding para a pergunta e buscar embeddings similares
        question_embedding = self.question_answer_service.convert_text_to_embedding(command)
        similar_embeddings = self.api_client.find_similar_embeddings(question_embedding)

        # Filtrar para evitar respostas redundantes
        unique_responses = self._filter_unique_responses(similar_embeddings, command)
        similar_context = "\n".join([f"Pergunta: {embedding['question']}\nResposta: {embedding['answer']}" for embedding in unique_responses[:self.max_similar]])

        # Detectar tipo de comando usando regex
        if re.search(r'\b(pesquise|pesquisar|procure)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como pesquisa online.")
            response = self.get_online_research_response(command, context_str, similar_context)
        elif re.search(r'\b(contexto)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como busca de contexto.")
            response = self.get_project_response(command, meeting, context_str, similar_context)
        elif re.search(r'\b(resumo?|t√≥picos da|pontos (relevantes|principais)|an√°lise)\b.*\b(reuni√£o|√∫ltima (reuni√£o|conversa|sess√£o))\b', command, re.IGNORECASE):
            print(f"\nComando identificado como an√°lise de reuni√£o.")
            meeting = self.api_client.fetch_last_meeting()
            response = self.get_meeting_analysis_response(command, context_str, meeting)
        else:
            print(f"\nComando identificado como comando padr√£o.")
            response = self.handle_default_command(command, context_str, meeting, similar_context)

        if response:
            answer_embedding = self.question_answer_service.convert_text_to_embedding(response)
            self.api_client.save_question_answer(command, question_embedding, response, answer_embedding)
            self.context_manager.add_context(command, response)

        return response

    def _filter_unique_responses(self, similar_embeddings, current_command):
        """
        Filtra respostas semelhantes que s√£o muito similares ao comando atual para evitar redund√¢ncia.
        """
        filtered = []
        for embedding in similar_embeddings:
            if embedding['question'].lower() != current_command.lower():
                filtered.append(embedding)
        return filtered

    def handle_default_command(self, command, context_str, meeting, similar_context):
        print(f"\nTratando comando padr√£o: {command}")
        # Combinar o contexto atual com os contextos similares para enriquecer a resposta
        combined_context = f"{context_str}\n{similar_context}"
        prompt = DefaultPromptGenerator().generate_prompt(command, combined_context, meeting)
        response = self.api_client.get_text_response(prompt, combined_context, meeting)
        return response

    # M√©todos get_project_response, get_meeting_analysis_response, get_online_research_response permanecem inalterados

    def get_project_response(self, command, meeting, context_str, similar_context):
        print(f"\nGerando prompt de projeto.")
        prompt = DefaultPromptGenerator().generate_prompt(command, context_str, meeting, similar_context)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_meeting_analysis_response(self, command, context_str, meeting):
        print(f"\nGerando prompt de an√°lise de reuni√£o.")
        prompt = MeetingPromptGenerator().generate_prompt(command, context_str, meeting)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_online_research_response(self, command, context_str, similar_context):
        print(f"\nGerando prompt de pesquisa online.")
        prompt = OnlineResearchPromptGenerator().generate_prompt(command, context_str, similar_context)
        return self.api_client.get_text_response(prompt, context_str, None)


# voice_assistent\class_voice_assistent\context_manager.py

from collections import deque

class ContextManager:
    def __init__(self, maxlen=10):
        self.recent_context = deque(maxlen=maxlen)

    def add_context(self, command, response):
        self.recent_context.append((command, response))

    def get_context(self):
        return "\n".join([context for context, _ in self.recent_context])


# voice_assistent\class_voice_assistent\conversation_history.py



# voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py

import requests
import logging
import google.generativeai as genai

# Configure o logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, feedback):
        try:
            # Gerando o conte√∫do usando a nova API
            response = self.model.generate_content(prompt)
            if response and hasattr(response, 'text'):
                return prompt, response.text
            else:
                logger.error("Resposta inv√°lida da API")
                return prompt, None
        except Exception as e:
            logger.error(f"Erro em get_text_response: {e}")
            return prompt, None

    def find_similar_embeddings(self, embedding):
        try:
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            logger.info(f"Enviando dados para a API de embeddings similares: {data}")
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            logger.error(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            data = {
                "question": question,
                "questionEmbedding": question_embedding.tolist() if hasattr(question_embedding, 'tolist') else question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding.tolist() if hasattr(answer_embedding, 'tolist') else answer_embedding
            }
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                logger.info("Pergunta e resposta salvas com sucesso.")
            else:
                logger.warning(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            logger.error(f"Erro em save_question_answer: {e}")


# voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py

import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        """Carregar vari√°veis do arquivo .env"""
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        """Configurar a chave da API"""
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        """Inicializar o modelo generativo"""
        try:
            self.model = genai.GenerativeModel(self.model_name)
        except Exception as e:  
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content(self, prompt: str, context: str, meeting: str) -> str:
        """Gerar conte√∫do com base no prompt, contexto e reuni√£o"""
        try:
            # Supondo que a API espera um dicion√°rio com os par√¢metros
            request_data = f'''
                "prompt": {prompt},
                "context": {context},
                "meeting": {meeting}
            '''
            print(f"Enviando requisi√ß√£o para a API GenAI: {request_data}")

            response = self.model.generate_content(request_data)
            return response.text
        except Exception as e:
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py

import os
from dotenv import load_dotenv
from groq import Groq

# Carregar vari√°veis do arquivo .env
load_dotenv()

# Recuperar a chave da API
api_key = os.getenv("GROQ_API_KEY")

# Verificar se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API Key is missing. Please set the GROQ_API_KEY in the .env file.")

# Configurar o cliente com a chave da API
client = Groq(api_key=api_key)

# Cria√ß√£o da conclus√£o do chat
chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "De acordo com nossas conversas anteriores, o que voc√™ acha do meu uso de IA ?",
        }
    ],
    model="llama3-8b-8192",
)

print(chat_completion.choices[0].message.content)


# voice_assistent\class_voice_assistent\main.py

import os
from context_manager import ContextManager
from api_client import APIClient
from command_interpreter import CommandInterpreter
from text_command_hendler import TextCommandHandler
from text_processor import TextProcessor
from text_to_speech import TextToSpeech
from voice_command_hendler import VoiceCommandHandler
from question_answers_service import QuestionAnswerService
from gpt_communication.gemini_gpt import GenerativeModelHandler

class MainApp:
    def __init__(self, model):
        self.voice_handler = VoiceCommandHandler()
        self.text_handler = TextCommandHandler()
        self.tts = TextToSpeech()
        self.text_processor = TextProcessor()
        self.api_client = APIClient(
            similarity_url="http://localhost:8081",
            save_url="http://localhost:8081/api/question_answers/save",
            model=model
        )
        self.context_manager = ContextManager()
        self.question_answer_service = QuestionAnswerService()
        self.command_interpreter = CommandInterpreter(
            self.api_client,
            self.question_answer_service,
            self.context_manager
        )

    def handle_command(self, command, meeting=""):
        if command:
            print(f"Pergunta recebida: {command}")
            text_response = self.command_interpreter.interpret_command(command, meeting)
            if text_response:
                print(f"Resposta: {text_response}")
                self.tts.speak_text(text_response)
                self.context_manager.add_context(command, text_response)
                return text_response
        else:
            print("Nenhum comando detectado.")
            return None

    def run(self):
        meeting = ""
        while True:
            try:
                input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
                if input_type == 'v':
                    command = self.voice_handler.capture_voice_command()
                elif input_type == 't':
                    command = self.text_handler.capture_text_command()
                else:
                    print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
                    continue

                response = self.handle_command(command, meeting)
                if response:
                    print(f"Resposta: {response}")
            except Exception as e:
                print(f"Ocorreu um erro: {e}")

if __name__ == "__main__":
    model = GenerativeModelHandler('gemini-1.5-flash')
    app = MainApp(model)
    app.run()

# voice_assistent\class_voice_assistent\prompt.py

def create_prompt(command, context, meeting):
    keywords = ["fa√ßa um resumo da √∫ltima reuni√£o.", "t√≥picos da √∫ltima reuni√£o", "resuma a √∫ltima reuni√£o", "pesquise", "pesquisar", "procure"]
    if any(keyword in command.lower() for keyword in keywords):
        return f"""
        Regras de Meeting:
        - Voc√™ √© respons√°vel por analisar, debater, sugerir e informar melhorias.
        - Resuma de forma clara e Objetiva.
        - N√£o acrescentar t√≠tulo nas respostas.

        [context]: {context}
        -------
        [meeting]: {meeting}
        -------
        [str_texto]: {command}
        """
    else:
        return f"""
        [context]: {context}
        -------
        [str_texto]: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py

class DefaultPromptGenerator:
    def generate_prompt(self, command, combined_context, meeting):
        prompt = (
            f"Comando: {command}\n"
            f"Contexto Anterior:\n{combined_context}\n"
            f"Baseie sua resposta nas informa√ß√µes acima e forne√ßa uma solu√ß√£o detalhada."
        )
        return prompt

# voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class MeetingPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting):
        return f"""
        Regras de Meeting com respostas inteligentes:
        - Responda a pergunta de [str_texto] com base nas diretrizes abaixo...
            - Voc√™ √© respons√°vel analisar com detalhes a reuni√£o de [str_meeting], e fornecer uma longa est√≥ria sobre o assunto.
            - observe os nomes das personas mencionadas no texto de meeting para aprender e melhorar a precis√£o da resposta.
            - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [str_texto]: Responda a pergunta de: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class OnlineResearchPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting, similar_context):
        return f"""
        Regras de Pesquisa Online Inteligente:
        - Utilize similar_context e fa√ßa uma pesquisa online para uma resposta mais precisa das quest√µes de [str_text]
        - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [context]: Regras B√°sicas {context}
        ------
        [similar_context]:
        Perguntas e respostas anteriores.{similar_context}
        ------
        [str_texto]: Responda seguinte pergunta: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py

from abc import ABC, abstractmethod

class PromptGenerator(ABC):
    @abstractmethod
    def generate_prompt(self, command, context, meeting, similar_context):
        pass

# voice_assistent\class_voice_assistent\question_answers_service.py

import requests
import numpy as np
from sentence_transformers import SentenceTransformer

class QuestionAnswerService:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.embedding_model = SentenceTransformer(model_name)

    def convert_text_to_embedding(self, text):
        embedding = self.embedding_model.encode(text)
        #print(f"Embedding gerado para '{text}': {embedding[0]:.16f}") # Adicionado para verificar o embedding gerado
        return embedding


# voice_assistent\class_voice_assistent\text_command_hendler.py

class TextCommandHandler:
    def capture_text_command(self):
        command = input("Digite o seu comando: ")
        return command


# voice_assistent\class_voice_assistent\text_processor.py

from bs4 import BeautifulSoup

class TextProcessor:
    def extract_values_from_json(self, data):
        if isinstance(data, dict):
            return ' '.join([str(value) for value in data.values()])
        elif isinstance(data, list):
            return ' '.join([self.extract_values_from_json(item) for item in data])
        return str(data)

    def extract_text_from_html(self, html):
        if not html.strip().startswith('<'):
            print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
            return html
        soup = BeautifulSoup(html, 'html.parser')
        text = ' '.join([p.get_text() for p in soup.find_all('p')])
        return text


# voice_assistent\class_voice_assistent\text_to_speech.py

import pyttsx3

class TextToSpeech:
    def __init__(self):
        self.engine = pyttsx3.init()

    def speak_text(self, text):
        cleaned_text = self.clean_text(text)
        self.engine.say(cleaned_text)
        self.engine.runAndWait()

    def clean_text(self, text):
        import re
        return re.sub(r'[\*\_\#]', '', text)


# voice_assistent\class_voice_assistent\voice_command_hendler.py

import speech_recognition as sr

class VoiceCommandHandler:
    def capture_voice_command(self):
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            print("Por favor, fale o seu comando:")
            try:
                audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
                print("√Åudio capturado com sucesso.")
                command = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {command}")
                return command
            except sr.WaitTimeoutError:
                print("Tempo de espera expirado. Nenhum √°udio detectado.")
                return None
            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio.")
                return None
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
                return None


# voice_assistent\config.py

# config.py
import pyttsx3
import spacy
from collections import deque

class APIConfig:
    apiKey = "API_KEY"
    url = "https://gpt-templates.saiapplications.com"
    headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")


# voice_assistent\template.py

import speech_recognition as sr
import requests
import pyttsx3
import re
from collections import deque
import spacy
import os
import webbrowser
from voice_assistent.prompt import create_prompt

# Configura√ß√µes da API
apiKey = "6UlOOoY/kkmprunma/qNDg"
url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    if isinstance(text, dict):
        text = extract_values_from_json(text)  # Extrai os valores do dicion√°rio
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

def get_text_response(prompt, context, feedback):
    data = {
        "inputs": {
            "str_texto": prompt,
            "str_contexto": context,
            "str_feedback": feedback
        }
    }
    print(f"Enviando dados para a API: {data}")
    try:
        response = requests.post(f"{url}/api/templates/6691e223802f95c2b394a8bd/execute", json=data, headers=headers)
        print(f"Status da resposta: {response.status_code}")
        if response.status_code == 200:
            try:
                response_data = response.html()  # Tente converter a resposta para JSON
                print("Resposta HTML recebida.")
                return extract_values_from_json(response_data)  # Extrai os valores do JSON
            except ValueError:
                print("A resposta n√£o est√° no formato JSON esperado. Tratando como texto simples.")
                return response.text  # Retorna o texto bruto da resposta
        else:
            print(f"Erro ao acessar a API: {response.status_code}, {response.text}")
            return None
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API: {e}")
        return None

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)


# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


User: Como posso integrar todas as aplica√ß√µes para funcionar em uma √∫nica MAIN.py ?

Streamlit. Chat de voz. converter v√≠deo para audio e audio para texto e depois salvar no banco de dados.
Assistant: Para integrar todas as aplica√ß√µes em um √∫nico `main.py`, voc√™ precisa modularizar seu c√≥digo existente e usar uma estrutura central que coordene a execu√ß√£o das diferentes partes (Streamlit chat de voz, convers√£o de v√≠deo para √°udio, √°udio para texto e salvamento no banco de dados).

Aqui est√° um esbo√ßo de como voc√™ pode abordar isso, com √™nfase na organiza√ß√£o e coordena√ß√£o das tarefas:

```python
# main.py

import streamlit as st
import os
from pathlib import Path

# Importar as fun√ß√µes e classes de cada m√≥dulo
from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from voice_assistent.class_voice_assistent.main import MainApp
from voice_assistent.class_voice_assistent.gpt_communication.gemini_gpt import GenerativeModelHandler
from transcriptions.transcriptions_config import TranscriptionConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from config.config import Config
from core.rate_limiter import RateLimiter

# 1. Configura√ß√£o Inicial
PROJECT_ROOT = Path(__file__).resolve().parent
root_path = str(PROJECT_ROOT)
print(f"Root path: {root_path}")

Config.ensure_directories()

# 2. Fun√ß√µes de Processamento
def process_videos():
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()

def process_audio():
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()

def process_transcriptions_and_embeddings(api_url):
    transcription_config = TranscriptionConfig(root_path=root_path)
    embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())
    embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    embedding_processor_wrapper.process_transcriptions()

# 3. Interface Streamlit
def main():
    st.title("Aplica√ß√µes Integradas")

    # 3.1. Sidebar com op√ß√µes
    app_mode = st.sidebar.selectbox(
        "Escolha a aplica√ß√£o:",
        ["Chat de Voz", "Converter V√≠deo para √Åudio", "Converter √Åudio para Texto", "Enviar Embeddings para o Banco de Dados"]
    )

    # 3.2. L√≥gica para cada aplica√ß√£o
    if app_mode == "Chat de Voz":
        st.header("Chat de Voz")
        model = GenerativeModelHandler('gemini-1.5-flash')
        app = MainApp(model)
        app.run()

    elif app_mode == "Converter V√≠deo para √Åudio":
        st.header("Converter V√≠deo para √Åudio")
        if st.button("Converter V√≠deos"):
            process_videos()
            st.success("V√≠deos convertidos para √°udio com sucesso!")

    elif app_mode == "Converter √Åudio para Texto":
        st.header("Converter √Åudio para Texto")
        if st.button("Converter √Åudios"):
            process_audio()
            st.success("√Åudios convertidos para texto com sucesso!")

    elif app_mode == "Enviar Embeddings para o Banco de Dados":
        st.header("Enviar Embeddings para o Banco de Dados")
        api_url = st.text_input("URL da API para enviar as transcri√ß√µes:", "http://localhost:8081/api/meetings/transcriptions")

        if st.button("Enviar Embeddings"):
            process_transcriptions_and_embeddings(api_url)
            st.success("Embeddings enviados para o banco de dados com sucesso!")

# 4. Execu√ß√£o Principal
if __name__ == "__main__":
    main()
```

### Estrutura do Projeto

-   **`main.py`**: Este √© o ponto de entrada. Ele usa Streamlit para criar uma interface que permite selecionar qual parte da aplica√ß√£o executar.

-   **`video_to_audio/`**, **`audio_to_text/`**, **`text_to_embedding/`**, **`voice_assistent/`**: Esses diret√≥rios cont√™m o c√≥digo existente de cada parte da sua aplica√ß√£o.

### Passos para Implementar

1.  **Modulariza√ß√£o:**

    *   Certifique-se de que cada parte da sua aplica√ß√£o (convers√£o de v√≠deo, convers√£o de √°udio, chat de voz) esteja bem encapsulada em fun√ß√µes ou classes reutiliz√°veis.
    *   Mova essas fun√ß√µes e classes para os respectivos m√≥dulos (arquivos `.py` dentro de seus diret√≥rios).

2.  **Integra√ß√£o no `main.py`:**

    *   Importe as fun√ß√µes e classes dos m√≥dulos.
    *   Use Streamlit para criar uma interface que permita ao usu√°rio escolher qual fun√ß√£o executar.
    *   Implemente bot√µes ou seletores para acionar as diferentes partes da aplica√ß√£o.

3.  **Gerenciamento de Depend√™ncias:**

    *   Certifique-se de que todas as depend√™ncias necess√°rias para cada parte da aplica√ß√£o estejam instaladas.  Considere usar um arquivo `requirements.txt` para listar todas as depend√™ncias.

4.  **Testes:**

    *   Teste cada parte da aplica√ß√£o individualmente para garantir que funcionem corretamente.
    *   Teste a integra√ß√£o geral para garantir que as diferentes partes possam ser executadas em sequ√™ncia ou individualmente, conforme necess√°rio.

### Pontos Chave

*   **Modulariza√ß√£o:** Dividir o c√≥digo em m√≥dulos facilita a manuten√ß√£o e reutiliza√ß√£o.
*   **Interface Streamlit:** Streamlit permite criar uma interface web simples para interagir com sua aplica√ß√£o.
*   **Gerenciamento de Estado:** Use `st.session_state` para manter o estado entre as execu√ß√µes da aplica√ß√£o Streamlit (por exemplo, se um v√≠deo foi convertido ou n√£o).
*   **Tratamento de Erros:** Implemente tratamento de erros para lidar com falhas em qualquer parte da aplica√ß√£o e fornecer feedback √∫til ao usu√°rio.
*   **Configura√ß√£o:** Utilize arquivos de configura√ß√£o (como o seu `config.py`) para armazenar caminhos de arquivos, URLs de API e outras configura√ß√µes que podem precisar ser ajustadas.

Seguindo esses passos, voc√™ deve conseguir integrar todas as suas aplica√ß√µes em um √∫nico script `main.py` com uma interface Streamlit para facilitar o uso e a demonstra√ß√£o.

User: observe em src/chat_streamlit que j√° tenho uma aplica√ß√£o que funciona como chat e consegue gerar imagem e ler imagem com OCR... atualmente s√≥ funciona por text .... quero colocar via comando de voz tbm  com a parte da aplica√ß√£o que usa Speech Recoginition
2025-04-10 19:46:17,968 [INFO] Resposta da IA (texto): Ok, para integrar o comando de voz ao seu `chat_streamlit.py`, voc√™ precisar√° adaptar o c√≥digo existente para incluir a funcionalidade de reconhecimento de voz e direcionar a entrada de voz para as mesmas fun√ß√µes que j√° processam o texto. Aqui est√° um guia passo a passo de como fazer isso:

**1. Importar as Bibliotecas Necess√°rias:**

Adicione as seguintes importa√ß√µes ao topo do seu arquivo `chat_streamlit.py`:

```python
import speech_recognition as sr
import threading
```

**2. Fun√ß√£o para Capturar Comando de Voz:**

Crie uma fun√ß√£o para capturar o comando de voz usando `speech_recognition`. Esta fun√ß√£o ser√° executada em uma thread separada para evitar bloquear a interface do Streamlit.

```python
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.write("Diga algo...")  # Mensagem na interface
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            command = recognizer.recognize_google(audio, language='pt-BR')
            st.write(f"Voc√™ disse: {command}")  # Mostra o comando reconhecido
            return command
        except sr.WaitTimeoutError:
            st.write("Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            st.write("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            st.write(f"Erro ao solicitar resultados: {e}")
            return None
```

**3. Adicionar um Bot√£o para Ativar o Reconhecimento de Voz:**

Adicione um bot√£o na barra lateral para iniciar a captura de voz. Esse bot√£o iniciar√° uma thread que executa a fun√ß√£o `capture_voice_command`.

```python
with st.sidebar:
    # ... (seu c√≥digo existente da barra lateral)

    if st.button("üé§ Usar Comando de Voz"):
        st.session_state.voice_command = None  # Limpa o comando anterior
        st.session_state.voice_thread = threading.Thread(target=lambda: setattr(st.session_state, 'voice_command', capture_voice_command()))
        st.session_state.voice_thread.start()
```

**4. Modificar a L√≥gica de Processamento de Mensagens:**

Modifique a l√≥gica de processamento de mensagens para verificar se h√° um comando de voz capturado. Se houver, use esse comando como entrada para a fun√ß√£o `process_message`.

```python
# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # ... (seu c√≥digo existente para determinar o placeholder)

    # Verifica se um comando de voz foi capturado
    if 'voice_command' in st.session_state and st.session_state.voice_command:
        user_input = st.session_state.voice_command
        process_message(user_input, current_image)
        st.session_state.voice_command = None  # Limpa o comando para n√£o repetir

    else:
        user_input = st.chat_input(placeholder)

        if user_input:
            # Processa a mensagem com a imagem (se houver) ou apenas texto
            process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)
```

**Explica√ß√£o das Modifica√ß√µes:**

*   **`capture_voice_command()`:** Esta fun√ß√£o captura o √°udio do microfone, tenta reconhecer a fala e retorna o comando de texto. Ela tamb√©m exibe mensagens de status na interface do Streamlit.
*   **Bot√£o "üé§ Usar Comando de Voz":** Quando este bot√£o √© clicado, ele cria e inicia uma nova thread que executa a fun√ß√£o `capture_voice_command`.  O resultado do comando de voz √© armazenado em `st.session_state.voice_command`.
*   **L√≥gica de Processamento Modificada:** A se√ß√£o de entrada de texto agora verifica se `st.session_state.voice_command` cont√©m um valor. Se sim, ele usa esse valor como a entrada do usu√°rio e chama `process_message`. Depois, ele limpa `st.session_state.voice_command` para evitar que o comando seja processado novamente.
*   **Thread:** Usar uma thread para a captura de voz √© crucial porque `recognizer.listen()` √© um m√©todo bloqueante. Sem uma thread, a interface do Streamlit ficaria congelada enquanto o √°udio √© capturado.

**Pontos Adicionais:**

*   **Permiss√µes do Microfone:** Certifique-se de que seu navegador tenha permiss√£o para acessar o microfone.
*   **Thread Safety:** Tenha cuidado com a seguran√ßa de threads ao modificar `st.session_state`. Streamlit n√£o √© inerentemente thread-safe, ent√£o evite opera√ß√µes simult√¢neas que possam causar problemas. Usar `setattr` como mostrado √© uma maneira segura de atualizar o estado.
*   **Feedback Visual:** Forne√ßa feedback visual ao usu√°rio para que saiba quando o sistema est√° gravando, processando ou aguardando um comando de voz.

Com estas modifica√ß√µes, seu `chat_streamlit.py` deve ser capaz de capturar comandos de voz e process√°-los da mesma forma que os comandos de texto. Isso adicionar√° a funcionalidade de controle por voz que voc√™ deseja.

2025-04-10 19:46:18,074 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 19:46:18,075 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 19:46:18,077 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 19:46:18,079 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 19:46:18,081 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 19:46:18,083 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 19:46:18,085 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 19:46:18,087 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 19:46:18,089 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 19:46:18,091 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 19:46:18,093 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 19:46:18,095 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 19:46:18,098 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 19:46:18,100 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 19:46:18,102 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 19:46:18,104 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 19:46:18,106 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 19:46:18,107 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 19:46:18,109 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 19:46:18,111 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 19:46:18,114 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 19:46:18,117 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 19:46:18,119 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 19:46:18,121 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 19:46:18,123 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 19:46:18,126 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 19:46:18,128 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 19:46:18,131 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 19:46:18,134 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 19:46:18,136 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 19:46:18,138 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 19:46:18,140 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 19:46:18,142 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 19:46:18,144 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 19:46:18,147 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 19:46:18,150 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 19:46:18,152 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 19:46:18,153 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 19:46:18,155 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 19:46:18,157 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 19:46:18,159 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 19:46:18,162 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 19:46:18,165 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 19:46:18,167 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 19:46:18,169 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 19:46:18,171 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 19:46:18,173 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 19:46:18,175 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 19:46:18,178 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 19:46:18,180 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 19:46:18,183 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 19:46:18,185 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 19:46:18,187 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 19:46:18,189 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 19:53:12,131 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 19:53:12,133 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 19:53:12,135 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 19:53:12,136 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 19:53:12,138 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 19:53:12,140 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 19:53:12,142 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 19:53:12,144 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 19:53:12,146 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 19:53:12,147 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 19:53:12,149 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 19:53:12,151 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 19:53:12,153 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 19:53:12,156 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 19:53:12,158 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 19:53:12,161 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 19:53:12,163 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 19:53:12,164 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 19:53:12,165 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 19:53:12,167 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 19:53:12,168 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 19:53:12,169 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 19:53:12,171 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 19:53:12,176 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 19:53:12,178 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 19:53:12,179 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 19:53:12,180 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 19:53:12,182 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 19:53:12,183 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 19:53:12,184 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 19:53:12,186 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 19:53:12,188 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 19:53:12,190 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 19:53:12,192 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 19:53:12,193 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 19:53:12,194 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 19:53:12,196 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 19:53:12,197 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 19:53:12,198 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 19:53:12,200 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 19:53:12,202 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 19:53:12,204 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 19:53:12,207 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 19:53:12,210 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 19:53:12,211 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 19:53:12,213 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 19:53:12,216 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 19:53:12,217 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 19:53:12,219 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 19:53:12,222 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 19:53:12,225 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 19:53:12,226 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 19:53:12,228 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 19:53:12,230 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 19:53:12,353 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 19:53:12,355 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 19:53:12,356 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 19:53:12,358 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 19:53:12,360 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 19:53:12,362 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 19:53:12,364 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 19:53:12,365 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 19:53:12,367 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 19:53:12,369 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 19:53:12,371 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 19:53:12,373 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 19:53:12,375 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 19:53:12,377 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 19:53:12,379 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 19:53:12,381 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 19:53:12,382 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 19:53:12,383 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 19:53:12,384 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 19:53:12,386 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 19:53:12,388 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 19:53:12,391 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 19:53:12,392 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 19:53:12,394 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 19:53:12,395 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 19:53:12,397 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 19:53:12,402 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 19:53:12,409 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 19:53:12,411 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 19:53:12,414 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 19:53:12,416 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 19:53:12,417 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 19:53:12,419 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 19:53:12,421 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 19:53:12,423 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 19:53:12,424 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 19:53:12,426 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 19:53:12,427 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 19:53:12,428 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 19:53:12,429 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 19:53:12,431 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 19:53:12,432 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 19:53:12,433 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 19:53:12,435 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 19:53:12,436 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 19:53:12,438 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 19:53:12,440 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 19:53:12,442 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 19:53:12,443 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 19:53:12,444 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 19:53:12,445 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 19:53:12,447 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 19:53:12,448 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 19:53:12,450 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 19:53:12,452 [INFO] Enviando para IA - Prompt (sem imagem): Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas.

Contexto:



# app_config\app_config.py

from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()
    
    def get_root_path(self):
        return str(self.ROOT_PATH)
    
    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py

from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        transcription_config = TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])


# audio_to_text\audio_to_text.py

import whisper
from audio_to_text.audio_config.audio_config import AudioConfig

class AudioToConverter:
    def __init__(self, audio_config: AudioConfig):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.AUDIO_INPUT_PATH
        self.TRANSCRIPTION_INPUT_PATH = audio_config.TRANSCRIPTION_INPUT_PATH

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            print(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        model = whisper.load_model("base")

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                print(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            print(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            print(f"Erro ao processar o arquivo {audio_file_path}: {e}")


# chat_app\chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# chat_app\config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# chat_app\services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# chat_app\services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# chat_app\services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# chat_app\utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

# common_paths\common_paths.py

from pathlib import Path

class CommonPaths:
    def __init__(self):
        # Diret√≥rio atual do script
        self.ROOT_PATH = Path(__file__).resolve().parent

        # Defini√ß√£o dos caminhos comuns
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'output'
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.AUDIO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.TRANSCRIPTION_OUTPUT_PATH = self.ROOT_PATH / 'data'
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'data'

        # Cria√ß√£o dos diret√≥rios
        self.create_directories()

    def create_directories(self):
        self.VIDEO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.VIDEO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.TRANSCRIPTION_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)



# fundamentus_api\fundamentus\__init__.py



# fundamentus_api\fundamentus\dados_b3.py

import locale
import pandas as pd
import streamlit as st
import requests
import fundamentus
import os
import plotly.express as px
from bs4 import BeautifulSoup
from fundamentus.detalhes import get_papel
import logging

# Configura localidade
locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')

# Configura√ß√£o do layout do Streamlit
st.set_page_config(
    page_title="An√°lise de A√ß√µes",
    layout="wide",
    page_icon="üìà"
)

class Acao:
    def __init__(self, papel):
        self.papel = papel
        self.dados_fundamentais = None
        self.proventos = None
        self.detalhes = None
        self.oscilacoes = None  # Adicionando um atributo para oscila√ß√µes

    def carregar_dados_fundamentais(self):
        self.dados_fundamentais = fundamentus.get_resultado().loc[[self.papel]]  # Use colchetes duplos para garantir que seja um DataFrame
        self.remover_formatacao()

    def obter_detalhes(self):
        self.detalhes = get_papel(self.papel)
        if self.detalhes is None or self.detalhes.empty:
            logging.warning(f"Nenhum detalhe encontrado para o papel: {self.papel}")

    def obter_proventos(self):
        url = f"https://www.fundamentus.com.br/proventos.php?papel={self.papel}&tipo=2"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        tabela = soup.find('table', {'id': 'resultado'})

        if not tabela:
            return pd.DataFrame()

        dados = []
        for linha in tabela.find_all('tr')[1:]:
            colunas = linha.find_all('td')
            try:
                valor = float(colunas[1].text.strip().replace(',', '.'))
            except ValueError:
                valor = None  # Se der erro, coloca None para evitar crash

            dados.append([colunas[0].text.strip(), valor, colunas[2].text.strip()])
        
        self.proventos = pd.DataFrame(dados, columns=['Data', 'Valor', 'Tipo'])
        return self.proventos

    def obter_oscilacoes(self):
        url = f"https://www.fundamentus.com.br/detalhes.php?papel={self.papel}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        conteudo_div = soup.find('div', class_='conteudo clearfix')

        if conteudo_div is None:
            return pd.DataFrame()

        oscilacoes_data = []
        oscilacoes_section = conteudo_div.find('td', class_='nivel1', colspan='2')
        
        if oscilacoes_section:
            labels = oscilacoes_section.find_all_next('td', class_='label w1')
            dados = oscilacoes_section.find_all_next('td', class_='data w1')

            for label, dado in zip(labels, dados):
                label_text = label.get_text(strip=True)
                valor_text = dado.find('span', class_='oscil').get_text(strip=True)
                oscilacoes_data.append([label_text, valor_text])

        self.oscilacoes = pd.DataFrame(oscilacoes_data, columns=['Per√≠odo', 'Oscila√ß√£o'])
        return self.oscilacoes

    def remover_formatacao(self):
        colunas_percentuais = ['dy', 'mrgebit', 'mrgliq', 'roic', 'roe', 'c5y']
        for coluna in colunas_percentuais:
            if coluna in self.dados_fundamentais:
                try:
                    self.dados_fundamentais[coluna] = self.dados_fundamentais[coluna].astype(float)
                except ValueError as e:
                    logging.error(f"Erro ao converter coluna {coluna} para float: {e}")

    def formatar_moeda(self, valor):
        return locale.currency(valor, symbol=True, grouping=True)

class Aplicacao:
    def __init__(self):
        self.acoes = fundamentus.get_resultado()

    def ajustar_tipos_dataframe(self, df):
        for coluna in df.columns:
            if df[coluna].dtype == 'object':
                try:
                    df[coluna] = df[coluna].astype(float)
                except ValueError:
                    df[coluna] = df[coluna].astype(str)
            elif df[coluna].dtype in ['int64', 'float64']:
                df[coluna] = df[coluna].astype(float)
        return df

    def exibir_dashboard(self):
        st.sidebar.title("üìä Dashboard de An√°lise de A√ß√µes")
        st.sidebar.write("Selecione um papel para visualizar detalhes.")

        papel_selecionado = st.sidebar.selectbox("Escolha uma a√ß√£o", self.acoes.index)

        acao = Acao(papel_selecionado)
        acao.carregar_dados_fundamentais()
        acao.obter_proventos()
        acao.obter_detalhes()
        acao.obter_oscilacoes()

        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader(f"üìå Dados Fundamentais - {papel_selecionado}")
            dados_fundamentais_df = self.ajustar_tipos_dataframe(acao.dados_fundamentais.T)
            st.dataframe(dados_fundamentais_df, width=400)

        with col2:
            st.subheader("üîç Detalhes")
            if acao.detalhes is not None and not acao.detalhes.empty:
                detalhes_df = pd.DataFrame(acao.detalhes).T.reset_index()
                detalhes_df.columns = ['Descri√ß√£o', 'Valor']
                detalhes_df = self.ajustar_tipos_dataframe(detalhes_df)

                st.subheader("Tabela de Detalhes")
                st.dataframe(detalhes_df, width=800)
            else:
                st.warning("Nenhum detalhe encontrado para essa a√ß√£o.")

        col_dividendos, col_oscilacoes = st.columns([1, 2])

        with col_dividendos:
            st.subheader("üí∞ Dividendos")
            if not acao.proventos.empty:
                proventos_df = self.ajustar_tipos_dataframe(acao.proventos)
                st.write(proventos_df)

        with col_oscilacoes:
            st.subheader("üìâ Oscila√ß√µes")
            if acao.oscilacoes is not None and not acao.oscilacoes.empty:
                oscilacoes_df = self.ajustar_tipos_dataframe(acao.oscilacoes)
                st.write(oscilacoes_df)

        st.subheader("üìà Tabela Geral de A√ß√µes")
        st.dataframe(self.acoes)

# Execu√ß√£o
if __name__ == "__main__":
    app = Aplicacao()
    app.exibir_dashboard()

# fundamentus_api\setup.py

from setuptools import setup, find_packages

setup(
    name='fundamentalvision ',
    version='0.1.0',
    author='Joel FerreiraHeanna dos Reis',
    author_email='heannareis@gmail.com',
    description='Um pacote para an√°lise fundamentalista de a√ß√µes da Bolsa B3 do Brasil.',
    packages=find_packages(),
    install_requires=[
        'pandas',
        'requests',
        'beautifulsoup4',
        'streamlit',
        'plotly',
        'fundamentus'
    ],
    classifiers=[
        'Programming Language :: Python :: 3',
        'License :: OSI Approved :: MIT License',
        'Operating System :: OS Independent',
    ],
    python_requires='>=3.6',
)

# ia_generator.py

import requests
from pathlib import Path
import webbrowser
from config.common_paths import TRANSCRIPTION_OUTPUT_PATH

apiKey = "6UlOOoY/kkmprunma/qNDg"

str_personas = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'personas.txt'
str_contexto = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'contexto.txt'

url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

txt_files = list(TRANSCRIPTION_OUTPUT_PATH.glob('*.txt'))

css_styles = """
<style>
body {
    font-family: Arial, sans-serif;
    margin: 20px;
}

h1, h2, h3 {
    color: #FF8C00;
}

li, strong, p {
    color: #008000;
}

h1 {
    font-size: 24px;
    margin-bottom: 20px;
}

h2 {
    font-size: 20px;
    margin-top: 20px;
    margin-bottom: 10px;
}

ul {
    list-style-type: disc;
    margin-left: 40px;
}

li {
    margin-bottom: 10px;
}

p {
    line-height: 1.6;
}
</style>
"""

if not txt_files:
    print(f"N√£o foram encontrados arquivos .txt no diret√≥rio {TRANSCRIPTION_OUTPUT_PATH}.")
else:
    for txt_file in txt_files:
        if txt_file.is_file():
            print(f"Lendo o arquivo: {txt_file.name}")
            with open(txt_file, 'r', encoding='utf-8') as file:
                str_reuniao = file.read()

            print(f"Enviando o conte√∫do do arquivo {txt_file.name} para a API...")
            data = {
                "inputs": {
                    "str_reuniao": str_reuniao,
                    "str_personas": str_personas.read_text(encoding='utf-8'),
                    "str_contexto": str_contexto.read_text(encoding='utf-8'),
                }
            }

            response = requests.post(f"{url}/api/templates/668de04202493d3063a9d7fa/execute", json=data, headers=headers)
            if response.status_code == 200:
                print(f"Resultado para o arquivo {txt_file.name} recebido.")
                html_content = response.text
                print(response.text)

                # Incluir o CSS no conte√∫do HTML
                html_with_css = f"<html><head>{css_styles}</head><body>{html_content}</body></html>"

                # Salvar o conte√∫do HTML em um arquivo
                output_file = TRANSCRIPTION_OUTPUT_PATH / f"{txt_file.stem}_output.html"
                with open(output_file, 'w', encoding='utf-8') as html_file:
                    html_file.write(html_with_css)

                # Abrir o arquivo HTML no navegador
                webbrowser.open(f"file://{output_file.resolve()}")
            else:
                print(f"Erro ao processar o arquivo {txt_file.name}: {response.status_code}")


# main.py

from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from transcriptions.transcriptions_config import TranscriptionConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from pathlib import Path

def main():
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    root_path = str(PROJECT_ROOT)
    print(f"Root path: {root_path}")  # Para verificar se est√° correto
    api_url = "http://localhost:8081/api/meetings/transcriptions"
    
    # # Configura√ß√£o de v√≠deos
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()
    
    # # Configura√ß√£o de √°udios
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()
    
    # # Processamento de transcri√ß√µes e envio de embeddings
    # embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    # embedding_processor_wrapper.process_transcriptions()

if __name__ == "__main__":
    main()


# send_embeddings_database\embedding_config\embedding_config.py

from app_config.app_config import AppConfig

class EmbeddingConfig(AppConfig):
    def __init__(self, root_path=None, transcription_input_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = transcription_input_path
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'embeddings' / 'output'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH, self.EMBEDDING_OUTPUT_PATH])


# send_embeddings_database\verify_last_enbedding.py

import os
import numpy as np

def get_latest_file(directory):
    # Listar todos os arquivos no diret√≥rio
    files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]
    
    if not files:
        raise FileNotFoundError("Nenhum arquivo encontrado no diret√≥rio.")

    # Encontrar o arquivo mais recente
    latest_file = max(files, key=os.path.getmtime)
    return latest_file

def load_and_print_embedding(directory):
    # Obter o caminho do √∫ltimo arquivo de embedding
    embedding_file_path = get_latest_file(directory)
    
    # Carregar o embedding
    embedding = np.load(embedding_file_path)
    
    # Exibir o conte√∫do do embedding
    print("Embedding carregado:")
    print(embedding)
    print("Dimens√µes do embedding:", embedding.shape)

# Caminho do diret√≥rio de embeddings
embedding_directory = 'C:/Users/HeannarReis/Documents/bsa_atacadao/assets/embeddings/output'

# Carregar e exibir o √∫ltimo embedding
load_and_print_embedding(embedding_directory)


# test_whisper.py

from transformers import pipeline
from common_paths import CommonPaths

commmom_paths = CommonPaths()

# Fun√ß√£o para ler a transcri√ß√£o de um arquivo
def read_transcription(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
    return lines

# Fun√ß√£o para converter a pontua√ß√£o em estrelas
def score_to_stars(score):
    if score >= 0.75:
        return 5
    elif score >= 0.55:
        return 4
    elif score >= 0.35:
        return 3
    elif score >= 0.15:
        return 2
    else:
        return 1

# Inicializar o pipeline de an√°lise de sentimento
sentiment_pipeline = pipeline("sentiment-analysis", model="neuralmind/bert-base-portuguese-cased")

# Caminho para o arquivo de transcri√ß√£o
file_path = commmom_paths.TRANSCRIPTION_OUTPUT_PATH / 'feedback.txt'

# Ler a transcri√ß√£o
lines = read_transcription(file_path)

# Analisar sentimento para cada feedback
for line in lines:
    sentiment = sentiment_pipeline(line.strip())
    score = sentiment[0]['score']
    stars = score_to_stars(score)
    
    # Ajuste manual para feedbacks com aspectos positivos e negativos
    if any(word in line.lower() for word in ["mas", "por√©m", "no entanto"]):
        stars = max(1, stars - 1)  # Reduz uma estrela se houver contradi√ß√£o
    
    # Ajuste adicional baseado em palavras-chave
    positive_keywords = ["excelente", "√≥timo", "perfeito", "r√°pido", "eficiente", "satisfeito", "clara", "eficaz", "bom trabalho"]
    negative_keywords = ["ruim", "p√©ssimo", "horr√≠vel", "poderia", "n√£o resolveu", "insatisfat√≥ria", "confusa", "inadequado", "lento", "n√£o houve seguimento", "n√£o atendeu", "n√£o funcionou", "demorado"]
    
    positive_count = sum(word in line.lower() for word in positive_keywords)
    negative_count = sum(word in line.lower() for word in negative_keywords)
    
    # Ajuste de estrelas baseado na contagem de palavras-chave
    if positive_count > negative_count:
        stars = min(5, stars + 1)
    elif negative_count > positive_count:
        stars = max(1, stars - 1)
    
    print(f"Texto: {line.strip()}")
    print(f"Sentimento: {stars} estrelas")
    print(f"Pontua√ß√£o: {score:.2f}")
    print('---')


# text_to_embedding\embedding_processing.py

from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from transcriptions.transcriptions_config import TranscriptionConfig
from transcriptions.transciption_sender_database import TranscriptionSenderDatabase

class EmbeddingProcessorWrapper:
    def __init__(self, root_path, api_url):
        # Configura√ß√£o de transcri√ß√µes e embeddings
        transcription_config = TranscriptionConfig(root_path=root_path)
        embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())

        self.embedding_processor = EmbeddingProcessor(embedding_config)
        self.transcription_sender = TranscriptionSenderDatabase(api_url)
    
    def process_transcriptions(self):
        # Mostrar o diret√≥rio onde est√° procurando as transcri√ß√µes
        print(f"Diret√≥rio de entrada das transcri√ß√µes: {self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH}")
        
        # Listar todos os arquivos de transcri√ß√£o no diret√≥rio de entrada
        transcription_files = list(self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH.glob('*.txt'))
        if not transcription_files:
            print("Nenhum arquivo de transcri√ß√£o encontrado.")
        for transcription_file_path in transcription_files:
            if transcription_file_path.is_file():
                print(f"Processando arquivo: {transcription_file_path}")
                self.process_and_send_transcription(transcription_file_path)
            else:
                print(f"Arquivo n√£o encontrado: {transcription_file_path}")

    def process_and_send_transcription(self, transcription_file_path):
        try:
            # Ler a transcri√ß√£o do arquivo de texto
            with open(transcription_file_path, 'r', encoding='utf-8') as f:
                transcription_text = f.read()
                if not transcription_text:
                    print(f"Arquivo {transcription_file_path} est√° vazio.")
                    return

            # Gerar o embedding da transcri√ß√£o
            embedding = self.embedding_processor.generate_embedding(transcription_text)
            if embedding is None:
                print(f"Falha ao gerar embedding para o arquivo {transcription_file_path}.")
                return

            # Salvar o embedding em um arquivo .npy
            self.embedding_processor.save_embedding(transcription_file_path, embedding)

            # Enviar os dados para a API
            self.transcription_sender.send_transcription(transcription_text, embedding)

        except Exception as e:
            print(f"Erro ao processar o arquivo {transcription_file_path}: {e}")


# text_to_embedding\texto_to_embedding.py

from sentence_transformers import SentenceTransformer
import numpy as np

class EmbeddingProcessor:
    def __init__(self, embedding_config):
        self.embedding_config = embedding_config
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

    def generate_embedding(self, transcription_text):
        return self.embedding_model.encode(transcription_text)

    def save_embedding(self, transcription_file_path, embedding):
        embedding_file_path = self.embedding_config.EMBEDDING_OUTPUT_PATH / transcription_file_path.with_suffix('.npy').name
        np.save(embedding_file_path, embedding)
        print(f"Embedding salvo em: {embedding_file_path}")
        return embedding_file_path


# transcriptions\transciption_sender_database.py

import requests

class TranscriptionSenderDatabase:
    def __init__(self, api_url):
        self.api_url = api_url

    def send_transcription(self, transcription_text, embedding):
        data = {
            'transcriptionText': transcription_text,
            'embedding': embedding.tolist()
        }

        response = requests.post(self.api_url, json=data)

        if response.status_code == 201:
            print("Transcri√ß√£o e embedding enviados com sucesso.")
        else:
            print(f"Erro ao enviar dados: {response.status_code}")
            print("Resposta da API:")
            print(response.text)


# transcriptions\transcriptions_config.py

from app_config.app_config import AppConfig

class TranscriptionConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = self.ROOT_PATH / 'assets' / 'transcriptions' / 'input'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH])
    
    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# translate\translator_to_english.py

import speech_recognition as sr
from translate import Translator

def ouvir_e_traduzir():
    # Inicializa o reconhecedor de fala
    recognizer = sr.Recognizer()

    # Configura o tradutor
    translator = Translator(to_lang="en", from_lang="pt")

    # Usa o microfone como fonte de √°udio
    with sr.Microphone() as source:
        print("Diga algo em portugu√™s...")

        while True:
            try:
                # Escuta o √°udio do microfone
                audio = recognizer.listen(source)
                
                # Reconhece a fala usando o Google Web Speech API
                texto_portugues = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {texto_portugues}")

                # Traduz o texto para o ingl√™s
                traducao = translator.translate(texto_portugues)
                print(f"Tradu√ß√£o para o ingl√™s: {traducao}")

            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio")
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")

if __name__ == "__main__":
    try:
        ouvir_e_traduzir()
    except KeyboardInterrupt:
        print("Interrompido pelo usu√°rio")


# translate\whispert_translator.py

import whisper
import pyaudio
import numpy as np

# Inicializa o modelo Whisper
model = whisper.load_model("base")

# Configura√ß√µes de √°udio
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024

# Inicializa o PyAudio
audio = pyaudio.PyAudio()

# Abre o stream de √°udio
stream = audio.open(format=FORMAT, channels=CHANNELS,
                    rate=RATE, input=True,
                    frames_per_buffer=CHUNK)

print("Diga algo em portugu√™s...")

try:
    audio_buffer = []

    while True:
        # L√™ dados do microfone
        data = stream.read(CHUNK)
        audio_buffer.append(np.frombuffer(data, dtype=np.int16).flatten().astype(np.float32) / 32768.0)

        # Processa o √°udio a cada 5 segundos
        if len(audio_buffer) * CHUNK / RATE >= 5:
            audio_data = np.concatenate(audio_buffer)
            audio_buffer = []

            # Transcreve e traduz o √°udio usando Whisper
            result = model.transcribe(audio_data, task="translate", language="pt")

            # Exibe a tradu√ß√£o
            print(f"Tradu√ß√£o para o ingl√™s: {result['text']}")

except KeyboardInterrupt:
    print("Interrompido pelo usu√°rio")

    # Fecha o stream de √°udio
    stream.stop_stream()
    stream.close()
    audio.terminate()


# video_to_audio\video_config\video_config.py

from app_config.app_config import AppConfig

class VideoConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video' / 'input'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.create_directories([self.VIDEO_INPUT_PATH, self.VIDEO_OUTPUT_PATH])

# video_to_audio\video_to_audio.py

from moviepy import VideoFileClip
import glob
import os
from .video_config.video_config import VideoConfig

class VideoToAudioConverter:
    def __init__(self, video_config: VideoConfig):
        self.video_config = video_config

    def convert_video_to_audio(self, video_path, audio_path):
        try:
            video = VideoFileClip(video_path)
            if video.audio:
                video.audio.write_audiofile(audio_path, fps=44100)
                print(f"Convertido {video_path} para {audio_path}")
            else:
                print(f"Aviso: O v√≠deo {video_path} n√£o cont√©m √°udio!")
        except Exception as e:
            print(f"Erro ao converter {video_path}: {e}")

    def process_videos(self):
        input_directory = self.video_config.VIDEO_INPUT_PATH
        output_directory = self.video_config.VIDEO_OUTPUT_PATH

        os.makedirs(output_directory, exist_ok=True)

        # Busca qualquer arquivo de v√≠deo (formatos comuns)
        video_files = glob.glob(os.path.join(input_directory, "*.*"))  # Pega todos os arquivos

        # Filtra apenas arquivos de v√≠deo
        video_extensions = {".mp4", ".mkv", ".avi", ".mov", ".wmv", ".flv"}  
        video_files = [f for f in video_files if os.path.splitext(f)[1].lower() in video_extensions]

        if not video_files:
            print(f"Nenhum arquivo de v√≠deo encontrado em: {input_directory}")
            return

        for video_file in video_files:
            base_name = os.path.basename(video_file)
            audio_file = os.path.join(output_directory, os.path.splitext(base_name)[0] + ".wav")
            self.convert_video_to_audio(video_file, audio_file)

        print("Convers√£o de v√≠deo para √°udio conclu√≠da!")


# voice_assistent\assistent.py

import speech_recognition as sr
import pyttsx3
import re
from collections import deque
import spacy
import requests
import os
import webbrowser
from class_voice_assistent.prompt import create_prompt
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import google.generativeai as genai

# Configura√ß√µes da API
handler = genai('gemini-1.5-flash')

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

voices = engine.getProperty('voices')
engine.setProperty('rate', 180)
print("\nLista de Vozes...")
for indice, vozes in enumerate(voices):
    print(indice, vozes.name)

voz = 1
engine.setProperty('voice', voices[voz].id)

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

# Fun√ß√£o para extrair texto de HTML
def extract_text_from_html(html):
    if not html.strip().startswith('<'):
        print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
        return html
    soup = BeautifulSoup(html, 'html.parser')
    text = ' '.join([p.get_text() for p in soup.find_all('p')])
    return text

def get_text_response(prompt, context, feedback):
    # Gere o conte√∫do com base no prompt usando a classe GenerativeModelHandler
    response = handler.generate_content(prompt)
    return response

# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/api/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


# voice_assistent\class_voice_assistent\api_client.py

import requests


class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, meeting):
        try:
            response_text = self.model.generate_content(prompt, context, meeting)
            return response_text
        except Exception as e:
            print(f"Erro inesperado: {e}")
            return None

    def find_similar_embeddings(self, embedding):
        try:
            print(f"Buscando embeddings similares para: {embedding}")
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            similar_embeddings = response.json()

            # Ordenar por similaridade (assumindo que a API retorna com similaridade em ordem decrescente)
            # Remover duplicatas baseadas na pergunta
            seen_questions = set()
            unique_embeddings = []
            for embedding in similar_embeddings:
                question = embedding['question'].strip().lower()
                if question not in seen_questions:
                    unique_embeddings.append(embedding)
                    seen_questions.add(question)
            print(f"Embeddings similares √∫nicos encontrados: {unique_embeddings}")
            return unique_embeddings
        except requests.RequestException as e:
            print(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            # Converter embeddings de numpy arrays para listas
            if hasattr(question_embedding, 'tolist'):
                question_embedding = question_embedding.tolist()
            if hasattr(answer_embedding, 'tolist'):
                answer_embedding = answer_embedding.tolist()
            
            data = {
                "question": question,
                "questionEmbedding": question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding
            }
            
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                print("Pergunta e resposta salvas com sucesso.")
            else:
                print(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            print(f"Erro em save_question_answer: {e}")


    def fetch_all_contexts(self):
        try:
            response = requests.get("http://localhost:8081/api/contexts/all")
            if response.status_code == 200:
                data = response.json()
                contexts = data.get('contexts', [])
                if isinstance(contexts, list):
                    print(f"Contexto obtido da API: {contexts}")
                    return contexts
                else:
                    print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                    return []
            else:
                print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
                return []
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
            return []

    def fetch_last_meeting(self):
        try:
            response = requests.get("http://localhost:8081/api/meetings/last")
            if response.status_code == 200:
                data = response.json()
                transcription_text = data.get('transcriptionText', "")
                if isinstance(transcription_text, str):
                    print(f"Texto da transcri√ß√£o obtido da API: {transcription_text}")
                    return transcription_text
                else:
                    print(f"Erro: 'transcriptionText' n√£o √© uma string. Dados retornados: {data}")
                    return ""
            else:
                print(f"Erro ao acessar a API de reuni√µes: {response.status_code}, {response.text}")
                return ""
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de reuni√µes: {e}")
            return ""


# voice_assistent\class_voice_assistent\command_interpreter.py

import spacy
from prompt_generator.online_prompt import OnlineResearchPromptGenerator
from prompt_generator.meeting_prompt import MeetingPromptGenerator
from prompt_generator.default_prompt_generator import DefaultPromptGenerator
import re

# Carregar o modelo de linguagem natural
nlp = spacy.load("pt_core_news_sm")

class CommandInterpreter:
    def __init__(self, api_client, question_answer_service, context_manager, max_similar=3):
        self.api_client = api_client
        self.question_answer_service = question_answer_service
        self.context_manager = context_manager
        self.max_similar = max_similar  # Limite de contextos similares

    def interpret_command(self, command, meeting):
        print(f"Interpretando comando: {command}")
        contexts = self.api_client.fetch_all_contexts()
        context_str = "\n".join([context['context'] for context in contexts])

        # Gerar embedding para a pergunta e buscar embeddings similares
        question_embedding = self.question_answer_service.convert_text_to_embedding(command)
        similar_embeddings = self.api_client.find_similar_embeddings(question_embedding)

        # Filtrar para evitar respostas redundantes
        unique_responses = self._filter_unique_responses(similar_embeddings, command)
        similar_context = "\n".join([f"Pergunta: {embedding['question']}\nResposta: {embedding['answer']}" for embedding in unique_responses[:self.max_similar]])

        # Detectar tipo de comando usando regex
        if re.search(r'\b(pesquise|pesquisar|procure)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como pesquisa online.")
            response = self.get_online_research_response(command, context_str, similar_context)
        elif re.search(r'\b(contexto)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como busca de contexto.")
            response = self.get_project_response(command, meeting, context_str, similar_context)
        elif re.search(r'\b(resumo?|t√≥picos da|pontos (relevantes|principais)|an√°lise)\b.*\b(reuni√£o|√∫ltima (reuni√£o|conversa|sess√£o))\b', command, re.IGNORECASE):
            print(f"\nComando identificado como an√°lise de reuni√£o.")
            meeting = self.api_client.fetch_last_meeting()
            response = self.get_meeting_analysis_response(command, context_str, meeting)
        else:
            print(f"\nComando identificado como comando padr√£o.")
            response = self.handle_default_command(command, context_str, meeting, similar_context)

        if response:
            answer_embedding = self.question_answer_service.convert_text_to_embedding(response)
            self.api_client.save_question_answer(command, question_embedding, response, answer_embedding)
            self.context_manager.add_context(command, response)

        return response

    def _filter_unique_responses(self, similar_embeddings, current_command):
        """
        Filtra respostas semelhantes que s√£o muito similares ao comando atual para evitar redund√¢ncia.
        """
        filtered = []
        for embedding in similar_embeddings:
            if embedding['question'].lower() != current_command.lower():
                filtered.append(embedding)
        return filtered

    def handle_default_command(self, command, context_str, meeting, similar_context):
        print(f"\nTratando comando padr√£o: {command}")
        # Combinar o contexto atual com os contextos similares para enriquecer a resposta
        combined_context = f"{context_str}\n{similar_context}"
        prompt = DefaultPromptGenerator().generate_prompt(command, combined_context, meeting)
        response = self.api_client.get_text_response(prompt, combined_context, meeting)
        return response

    # M√©todos get_project_response, get_meeting_analysis_response, get_online_research_response permanecem inalterados

    def get_project_response(self, command, meeting, context_str, similar_context):
        print(f"\nGerando prompt de projeto.")
        prompt = DefaultPromptGenerator().generate_prompt(command, context_str, meeting, similar_context)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_meeting_analysis_response(self, command, context_str, meeting):
        print(f"\nGerando prompt de an√°lise de reuni√£o.")
        prompt = MeetingPromptGenerator().generate_prompt(command, context_str, meeting)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_online_research_response(self, command, context_str, similar_context):
        print(f"\nGerando prompt de pesquisa online.")
        prompt = OnlineResearchPromptGenerator().generate_prompt(command, context_str, similar_context)
        return self.api_client.get_text_response(prompt, context_str, None)


# voice_assistent\class_voice_assistent\context_manager.py

from collections import deque

class ContextManager:
    def __init__(self, maxlen=10):
        self.recent_context = deque(maxlen=maxlen)

    def add_context(self, command, response):
        self.recent_context.append((command, response))

    def get_context(self):
        return "\n".join([context for context, _ in self.recent_context])


# voice_assistent\class_voice_assistent\conversation_history.py



# voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py

import requests
import logging
import google.generativeai as genai

# Configure o logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, feedback):
        try:
            # Gerando o conte√∫do usando a nova API
            response = self.model.generate_content(prompt)
            if response and hasattr(response, 'text'):
                return prompt, response.text
            else:
                logger.error("Resposta inv√°lida da API")
                return prompt, None
        except Exception as e:
            logger.error(f"Erro em get_text_response: {e}")
            return prompt, None

    def find_similar_embeddings(self, embedding):
        try:
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            logger.info(f"Enviando dados para a API de embeddings similares: {data}")
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            logger.error(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            data = {
                "question": question,
                "questionEmbedding": question_embedding.tolist() if hasattr(question_embedding, 'tolist') else question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding.tolist() if hasattr(answer_embedding, 'tolist') else answer_embedding
            }
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                logger.info("Pergunta e resposta salvas com sucesso.")
            else:
                logger.warning(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            logger.error(f"Erro em save_question_answer: {e}")


# voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py

import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        """Carregar vari√°veis do arquivo .env"""
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        """Configurar a chave da API"""
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        """Inicializar o modelo generativo"""
        try:
            self.model = genai.GenerativeModel(self.model_name)
        except Exception as e:  
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content(self, prompt: str, context: str, meeting: str) -> str:
        """Gerar conte√∫do com base no prompt, contexto e reuni√£o"""
        try:
            # Supondo que a API espera um dicion√°rio com os par√¢metros
            request_data = f'''
                "prompt": {prompt},
                "context": {context},
                "meeting": {meeting}
            '''
            print(f"Enviando requisi√ß√£o para a API GenAI: {request_data}")

            response = self.model.generate_content(request_data)
            return response.text
        except Exception as e:
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py

import os
from dotenv import load_dotenv
from groq import Groq

# Carregar vari√°veis do arquivo .env
load_dotenv()

# Recuperar a chave da API
api_key = os.getenv("GROQ_API_KEY")

# Verificar se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API Key is missing. Please set the GROQ_API_KEY in the .env file.")

# Configurar o cliente com a chave da API
client = Groq(api_key=api_key)

# Cria√ß√£o da conclus√£o do chat
chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "De acordo com nossas conversas anteriores, o que voc√™ acha do meu uso de IA ?",
        }
    ],
    model="llama3-8b-8192",
)

print(chat_completion.choices[0].message.content)


# voice_assistent\class_voice_assistent\main.py

import os
from context_manager import ContextManager
from api_client import APIClient
from command_interpreter import CommandInterpreter
from text_command_hendler import TextCommandHandler
from text_processor import TextProcessor
from text_to_speech import TextToSpeech
from voice_command_hendler import VoiceCommandHandler
from question_answers_service import QuestionAnswerService
from gpt_communication.gemini_gpt import GenerativeModelHandler

class MainApp:
    def __init__(self, model):
        self.voice_handler = VoiceCommandHandler()
        self.text_handler = TextCommandHandler()
        self.tts = TextToSpeech()
        self.text_processor = TextProcessor()
        self.api_client = APIClient(
            similarity_url="http://localhost:8081",
            save_url="http://localhost:8081/api/question_answers/save",
            model=model
        )
        self.context_manager = ContextManager()
        self.question_answer_service = QuestionAnswerService()
        self.command_interpreter = CommandInterpreter(
            self.api_client,
            self.question_answer_service,
            self.context_manager
        )

    def handle_command(self, command, meeting=""):
        if command:
            print(f"Pergunta recebida: {command}")
            text_response = self.command_interpreter.interpret_command(command, meeting)
            if text_response:
                print(f"Resposta: {text_response}")
                self.tts.speak_text(text_response)
                self.context_manager.add_context(command, text_response)
                return text_response
        else:
            print("Nenhum comando detectado.")
            return None

    def run(self):
        meeting = ""
        while True:
            try:
                input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
                if input_type == 'v':
                    command = self.voice_handler.capture_voice_command()
                elif input_type == 't':
                    command = self.text_handler.capture_text_command()
                else:
                    print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
                    continue

                response = self.handle_command(command, meeting)
                if response:
                    print(f"Resposta: {response}")
            except Exception as e:
                print(f"Ocorreu um erro: {e}")

if __name__ == "__main__":
    model = GenerativeModelHandler('gemini-1.5-flash')
    app = MainApp(model)
    app.run()

# voice_assistent\class_voice_assistent\prompt.py

def create_prompt(command, context, meeting):
    keywords = ["fa√ßa um resumo da √∫ltima reuni√£o.", "t√≥picos da √∫ltima reuni√£o", "resuma a √∫ltima reuni√£o", "pesquise", "pesquisar", "procure"]
    if any(keyword in command.lower() for keyword in keywords):
        return f"""
        Regras de Meeting:
        - Voc√™ √© respons√°vel por analisar, debater, sugerir e informar melhorias.
        - Resuma de forma clara e Objetiva.
        - N√£o acrescentar t√≠tulo nas respostas.

        [context]: {context}
        -------
        [meeting]: {meeting}
        -------
        [str_texto]: {command}
        """
    else:
        return f"""
        [context]: {context}
        -------
        [str_texto]: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py

class DefaultPromptGenerator:
    def generate_prompt(self, command, combined_context, meeting):
        prompt = (
            f"Comando: {command}\n"
            f"Contexto Anterior:\n{combined_context}\n"
            f"Baseie sua resposta nas informa√ß√µes acima e forne√ßa uma solu√ß√£o detalhada."
        )
        return prompt

# voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class MeetingPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting):
        return f"""
        Regras de Meeting com respostas inteligentes:
        - Responda a pergunta de [str_texto] com base nas diretrizes abaixo...
            - Voc√™ √© respons√°vel analisar com detalhes a reuni√£o de [str_meeting], e fornecer uma longa est√≥ria sobre o assunto.
            - observe os nomes das personas mencionadas no texto de meeting para aprender e melhorar a precis√£o da resposta.
            - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [str_texto]: Responda a pergunta de: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class OnlineResearchPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting, similar_context):
        return f"""
        Regras de Pesquisa Online Inteligente:
        - Utilize similar_context e fa√ßa uma pesquisa online para uma resposta mais precisa das quest√µes de [str_text]
        - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [context]: Regras B√°sicas {context}
        ------
        [similar_context]:
        Perguntas e respostas anteriores.{similar_context}
        ------
        [str_texto]: Responda seguinte pergunta: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py

from abc import ABC, abstractmethod

class PromptGenerator(ABC):
    @abstractmethod
    def generate_prompt(self, command, context, meeting, similar_context):
        pass

# voice_assistent\class_voice_assistent\question_answers_service.py

import requests
import numpy as np
from sentence_transformers import SentenceTransformer

class QuestionAnswerService:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.embedding_model = SentenceTransformer(model_name)

    def convert_text_to_embedding(self, text):
        embedding = self.embedding_model.encode(text)
        #print(f"Embedding gerado para '{text}': {embedding[0]:.16f}") # Adicionado para verificar o embedding gerado
        return embedding


# voice_assistent\class_voice_assistent\text_command_hendler.py

class TextCommandHandler:
    def capture_text_command(self):
        command = input("Digite o seu comando: ")
        return command


# voice_assistent\class_voice_assistent\text_processor.py

from bs4 import BeautifulSoup

class TextProcessor:
    def extract_values_from_json(self, data):
        if isinstance(data, dict):
            return ' '.join([str(value) for value in data.values()])
        elif isinstance(data, list):
            return ' '.join([self.extract_values_from_json(item) for item in data])
        return str(data)

    def extract_text_from_html(self, html):
        if not html.strip().startswith('<'):
            print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
            return html
        soup = BeautifulSoup(html, 'html.parser')
        text = ' '.join([p.get_text() for p in soup.find_all('p')])
        return text


# voice_assistent\class_voice_assistent\text_to_speech.py

import pyttsx3

class TextToSpeech:
    def __init__(self):
        self.engine = pyttsx3.init()

    def speak_text(self, text):
        cleaned_text = self.clean_text(text)
        self.engine.say(cleaned_text)
        self.engine.runAndWait()

    def clean_text(self, text):
        import re
        return re.sub(r'[\*\_\#]', '', text)


# voice_assistent\class_voice_assistent\voice_command_hendler.py

import speech_recognition as sr

class VoiceCommandHandler:
    def capture_voice_command(self):
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            print("Por favor, fale o seu comando:")
            try:
                audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
                print("√Åudio capturado com sucesso.")
                command = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {command}")
                return command
            except sr.WaitTimeoutError:
                print("Tempo de espera expirado. Nenhum √°udio detectado.")
                return None
            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio.")
                return None
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
                return None


# voice_assistent\config.py

# config.py
import pyttsx3
import spacy
from collections import deque

class APIConfig:
    apiKey = "API_KEY"
    url = "https://gpt-templates.saiapplications.com"
    headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")


# voice_assistent\template.py

import speech_recognition as sr
import requests
import pyttsx3
import re
from collections import deque
import spacy
import os
import webbrowser
from voice_assistent.prompt import create_prompt

# Configura√ß√µes da API
apiKey = "6UlOOoY/kkmprunma/qNDg"
url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    if isinstance(text, dict):
        text = extract_values_from_json(text)  # Extrai os valores do dicion√°rio
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

def get_text_response(prompt, context, feedback):
    data = {
        "inputs": {
            "str_texto": prompt,
            "str_contexto": context,
            "str_feedback": feedback
        }
    }
    print(f"Enviando dados para a API: {data}")
    try:
        response = requests.post(f"{url}/api/templates/6691e223802f95c2b394a8bd/execute", json=data, headers=headers)
        print(f"Status da resposta: {response.status_code}")
        if response.status_code == 200:
            try:
                response_data = response.html()  # Tente converter a resposta para JSON
                print("Resposta HTML recebida.")
                return extract_values_from_json(response_data)  # Extrai os valores do JSON
            except ValueError:
                print("A resposta n√£o est√° no formato JSON esperado. Tratando como texto simples.")
                return response.text  # Retorna o texto bruto da resposta
        else:
            print(f"Erro ao acessar a API: {response.status_code}, {response.text}")
            return None
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API: {e}")
        return None

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)


# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


User: Como posso integrar todas as aplica√ß√µes para funcionar em uma √∫nica MAIN.py ?

Streamlit. Chat de voz. converter v√≠deo para audio e audio para texto e depois salvar no banco de dados.
Assistant: Para integrar todas as aplica√ß√µes em um √∫nico `main.py`, voc√™ precisa modularizar seu c√≥digo existente e usar uma estrutura central que coordene a execu√ß√£o das diferentes partes (Streamlit chat de voz, convers√£o de v√≠deo para √°udio, √°udio para texto e salvamento no banco de dados).

Aqui est√° um esbo√ßo de como voc√™ pode abordar isso, com √™nfase na organiza√ß√£o e coordena√ß√£o das tarefas:

```python
# main.py

import streamlit as st
import os
from pathlib import Path

# Importar as fun√ß√µes e classes de cada m√≥dulo
from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from voice_assistent.class_voice_assistent.main import MainApp
from voice_assistent.class_voice_assistent.gpt_communication.gemini_gpt import GenerativeModelHandler
from transcriptions.transcriptions_config import TranscriptionConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from config.config import Config
from core.rate_limiter import RateLimiter

# 1. Configura√ß√£o Inicial
PROJECT_ROOT = Path(__file__).resolve().parent
root_path = str(PROJECT_ROOT)
print(f"Root path: {root_path}")

Config.ensure_directories()

# 2. Fun√ß√µes de Processamento
def process_videos():
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()

def process_audio():
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()

def process_transcriptions_and_embeddings(api_url):
    transcription_config = TranscriptionConfig(root_path=root_path)
    embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())
    embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    embedding_processor_wrapper.process_transcriptions()

# 3. Interface Streamlit
def main():
    st.title("Aplica√ß√µes Integradas")

    # 3.1. Sidebar com op√ß√µes
    app_mode = st.sidebar.selectbox(
        "Escolha a aplica√ß√£o:",
        ["Chat de Voz", "Converter V√≠deo para √Åudio", "Converter √Åudio para Texto", "Enviar Embeddings para o Banco de Dados"]
    )

    # 3.2. L√≥gica para cada aplica√ß√£o
    if app_mode == "Chat de Voz":
        st.header("Chat de Voz")
        model = GenerativeModelHandler('gemini-1.5-flash')
        app = MainApp(model)
        app.run()

    elif app_mode == "Converter V√≠deo para √Åudio":
        st.header("Converter V√≠deo para √Åudio")
        if st.button("Converter V√≠deos"):
            process_videos()
            st.success("V√≠deos convertidos para √°udio com sucesso!")

    elif app_mode == "Converter √Åudio para Texto":
        st.header("Converter √Åudio para Texto")
        if st.button("Converter √Åudios"):
            process_audio()
            st.success("√Åudios convertidos para texto com sucesso!")

    elif app_mode == "Enviar Embeddings para o Banco de Dados":
        st.header("Enviar Embeddings para o Banco de Dados")
        api_url = st.text_input("URL da API para enviar as transcri√ß√µes:", "http://localhost:8081/api/meetings/transcriptions")

        if st.button("Enviar Embeddings"):
            process_transcriptions_and_embeddings(api_url)
            st.success("Embeddings enviados para o banco de dados com sucesso!")

# 4. Execu√ß√£o Principal
if __name__ == "__main__":
    main()
```

### Estrutura do Projeto

-   **`main.py`**: Este √© o ponto de entrada. Ele usa Streamlit para criar uma interface que permite selecionar qual parte da aplica√ß√£o executar.

-   **`video_to_audio/`**, **`audio_to_text/`**, **`text_to_embedding/`**, **`voice_assistent/`**: Esses diret√≥rios cont√™m o c√≥digo existente de cada parte da sua aplica√ß√£o.

### Passos para Implementar

1.  **Modulariza√ß√£o:**

    *   Certifique-se de que cada parte da sua aplica√ß√£o (convers√£o de v√≠deo, convers√£o de √°udio, chat de voz) esteja bem encapsulada em fun√ß√µes ou classes reutiliz√°veis.
    *   Mova essas fun√ß√µes e classes para os respectivos m√≥dulos (arquivos `.py` dentro de seus diret√≥rios).

2.  **Integra√ß√£o no `main.py`:**

    *   Importe as fun√ß√µes e classes dos m√≥dulos.
    *   Use Streamlit para criar uma interface que permita ao usu√°rio escolher qual fun√ß√£o executar.
    *   Implemente bot√µes ou seletores para acionar as diferentes partes da aplica√ß√£o.

3.  **Gerenciamento de Depend√™ncias:**

    *   Certifique-se de que todas as depend√™ncias necess√°rias para cada parte da aplica√ß√£o estejam instaladas.  Considere usar um arquivo `requirements.txt` para listar todas as depend√™ncias.

4.  **Testes:**

    *   Teste cada parte da aplica√ß√£o individualmente para garantir que funcionem corretamente.
    *   Teste a integra√ß√£o geral para garantir que as diferentes partes possam ser executadas em sequ√™ncia ou individualmente, conforme necess√°rio.

### Pontos Chave

*   **Modulariza√ß√£o:** Dividir o c√≥digo em m√≥dulos facilita a manuten√ß√£o e reutiliza√ß√£o.
*   **Interface Streamlit:** Streamlit permite criar uma interface web simples para interagir com sua aplica√ß√£o.
*   **Gerenciamento de Estado:** Use `st.session_state` para manter o estado entre as execu√ß√µes da aplica√ß√£o Streamlit (por exemplo, se um v√≠deo foi convertido ou n√£o).
*   **Tratamento de Erros:** Implemente tratamento de erros para lidar com falhas em qualquer parte da aplica√ß√£o e fornecer feedback √∫til ao usu√°rio.
*   **Configura√ß√£o:** Utilize arquivos de configura√ß√£o (como o seu `config.py`) para armazenar caminhos de arquivos, URLs de API e outras configura√ß√µes que podem precisar ser ajustadas.

Seguindo esses passos, voc√™ deve conseguir integrar todas as suas aplica√ß√µes em um √∫nico script `main.py` com uma interface Streamlit para facilitar o uso e a demonstra√ß√£o.

User: observe em src/chat_streamlit que j√° tenho uma aplica√ß√£o que funciona como chat e consegue gerar imagem e ler imagem com OCR... atualmente s√≥ funciona por text .... quero colocar via comando de voz tbm  com a parte da aplica√ß√£o que usa Speech Recoginition
Assistant: Ok, para integrar o comando de voz ao seu `chat_streamlit.py`, voc√™ precisar√° adaptar o c√≥digo existente para incluir a funcionalidade de reconhecimento de voz e direcionar a entrada de voz para as mesmas fun√ß√µes que j√° processam o texto. Aqui est√° um guia passo a passo de como fazer isso:

**1. Importar as Bibliotecas Necess√°rias:**

Adicione as seguintes importa√ß√µes ao topo do seu arquivo `chat_streamlit.py`:

```python
import speech_recognition as sr
import threading
```

**2. Fun√ß√£o para Capturar Comando de Voz:**

Crie uma fun√ß√£o para capturar o comando de voz usando `speech_recognition`. Esta fun√ß√£o ser√° executada em uma thread separada para evitar bloquear a interface do Streamlit.

```python
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.write("Diga algo...")  # Mensagem na interface
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            command = recognizer.recognize_google(audio, language='pt-BR')
            st.write(f"Voc√™ disse: {command}")  # Mostra o comando reconhecido
            return command
        except sr.WaitTimeoutError:
            st.write("Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            st.write("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            st.write(f"Erro ao solicitar resultados: {e}")
            return None
```

**3. Adicionar um Bot√£o para Ativar o Reconhecimento de Voz:**

Adicione um bot√£o na barra lateral para iniciar a captura de voz. Esse bot√£o iniciar√° uma thread que executa a fun√ß√£o `capture_voice_command`.

```python
with st.sidebar:
    # ... (seu c√≥digo existente da barra lateral)

    if st.button("üé§ Usar Comando de Voz"):
        st.session_state.voice_command = None  # Limpa o comando anterior
        st.session_state.voice_thread = threading.Thread(target=lambda: setattr(st.session_state, 'voice_command', capture_voice_command()))
        st.session_state.voice_thread.start()
```

**4. Modificar a L√≥gica de Processamento de Mensagens:**

Modifique a l√≥gica de processamento de mensagens para verificar se h√° um comando de voz capturado. Se houver, use esse comando como entrada para a fun√ß√£o `process_message`.

```python
# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # ... (seu c√≥digo existente para determinar o placeholder)

    # Verifica se um comando de voz foi capturado
    if 'voice_command' in st.session_state and st.session_state.voice_command:
        user_input = st.session_state.voice_command
        process_message(user_input, current_image)
        st.session_state.voice_command = None  # Limpa o comando para n√£o repetir

    else:
        user_input = st.chat_input(placeholder)

        if user_input:
            # Processa a mensagem com a imagem (se houver) ou apenas texto
            process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)
```

**Explica√ß√£o das Modifica√ß√µes:**

*   **`capture_voice_command()`:** Esta fun√ß√£o captura o √°udio do microfone, tenta reconhecer a fala e retorna o comando de texto. Ela tamb√©m exibe mensagens de status na interface do Streamlit.
*   **Bot√£o "üé§ Usar Comando de Voz":** Quando este bot√£o √© clicado, ele cria e inicia uma nova thread que executa a fun√ß√£o `capture_voice_command`.  O resultado do comando de voz √© armazenado em `st.session_state.voice_command`.
*   **L√≥gica de Processamento Modificada:** A se√ß√£o de entrada de texto agora verifica se `st.session_state.voice_command` cont√©m um valor. Se sim, ele usa esse valor como a entrada do usu√°rio e chama `process_message`. Depois, ele limpa `st.session_state.voice_command` para evitar que o comando seja processado novamente.
*   **Thread:** Usar uma thread para a captura de voz √© crucial porque `recognizer.listen()` √© um m√©todo bloqueante. Sem uma thread, a interface do Streamlit ficaria congelada enquanto o √°udio √© capturado.

**Pontos Adicionais:**

*   **Permiss√µes do Microfone:** Certifique-se de que seu navegador tenha permiss√£o para acessar o microfone.
*   **Thread Safety:** Tenha cuidado com a seguran√ßa de threads ao modificar `st.session_state`. Streamlit n√£o √© inerentemente thread-safe, ent√£o evite opera√ß√µes simult√¢neas que possam causar problemas. Usar `setattr` como mostrado √© uma maneira segura de atualizar o estado.
*   **Feedback Visual:** Forne√ßa feedback visual ao usu√°rio para que saiba quando o sistema est√° gravando, processando ou aguardando um comando de voz.

Com estas modifica√ß√µes, seu `chat_streamlit.py` deve ser capaz de capturar comandos de voz e process√°-los da mesma forma que os comandos de texto. Isso adicionar√° a funcionalidade de controle por voz que voc√™ deseja.

User: eu ja tenho uma aplica√ß√£o de comando de voz dentro da pasta voice_assistent.
2025-04-10 19:53:29,067 [INFO] Resposta da IA (texto): Entendi. Em vez de criar uma nova fun√ß√£o de captura de voz, podemos integrar a sua aplica√ß√£o existente `voice_assistent` ao `chat_streamlit.py`. Isso envolve principalmente reutilizar as fun√ß√µes de captura e interpreta√ß√£o de comandos da sua aplica√ß√£o `voice_assistent` existente e integr√°-las na interface do Streamlit.

Aqui est√£o os passos detalhados:

**1. Importar as Fun√ß√µes Necess√°rias de `voice_assistent`:**

No topo do seu arquivo `chat_streamlit.py`, importe as fun√ß√µes que voc√™ precisa de `voice_assistent.main`:

```python
from voice_assistent.class_voice_assistent.main import MainApp
from voice_assistent.class_voice_assistent.gpt_communication.gemini_gpt import GenerativeModelHandler
import threading
import streamlit as st
```

**2. Inicializar a Aplica√ß√£o `voice_assistent`:**

Voc√™ precisar√° inicializar a aplica√ß√£o `voice_assistent` uma vez, preferencialmente fora do loop principal do Streamlit, para que n√£o seja reinicializada a cada intera√ß√£o.

```python
# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Inicializa a aplica√ß√£o de voz
@st.cache_resource
def get_voice_app():
    model = GenerativeModelHandler('gemini-1.5-flash')
    return MainApp(model)

voice_app = get_voice_app()
```

**3. Modificar o Bot√£o de Comando de Voz:**

Modifique o bot√£o na barra lateral para usar a fun√ß√£o de captura de voz da sua aplica√ß√£o `voice_assistent`. Em vez de criar uma nova thread, voc√™ chamar√° a fun√ß√£o `handle_command` da sua `voice_app` diretamente.

```python
with st.sidebar:
    # ... (seu c√≥digo existente da barra lateral)

    if st.button("üé§ Usar Comando de Voz"):
        st.session_state.voice_command = None  # Limpa o comando anterior
        st.session_state.voice_thread = threading.Thread(target=lambda: setattr(st.session_state, 'voice_command', voice_app.handle_command(voice_app.voice_handler.capture_voice_command())))
        st.session_state.voice_thread.start()
```

**4. Modificar a L√≥gica de Processamento de Mensagens:**

Modifique a l√≥gica de processamento de mensagens para verificar se h√° um comando de voz capturado. Se houver, use esse comando como entrada para a fun√ß√£o `process_message`.

```python
# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # ... (seu c√≥digo existente para determinar o placeholder)

    # Verifica se um comando de voz foi capturado
    if 'voice_command' in st.session_state and st.session_state.voice_command:
        user_input = st.session_state.voice_command
        process_message(user_input, current_image)
        st.session_state.voice_command = None  # Limpa o comando para n√£o repetir

    else:
        user_input = st.chat_input(placeholder)

        if user_input:
            # Processa a mensagem com a imagem (se houver) ou apenas texto
            process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)
```

**Explica√ß√£o das Modifica√ß√µes:**

*   **Importa√ß√£o de `MainApp`:** Importe a classe `MainApp` da sua aplica√ß√£o `voice_assistent`.
*   **Inicializa√ß√£o de `MainApp`:** Inicialize a aplica√ß√£o `MainApp` usando o modelo `GenerativeModelHandler`. Isso deve ser feito apenas uma vez.
*   **Bot√£o "üé§ Usar Comando de Voz":** Quando este bot√£o √© clicado, ele chama `voice_app.run()` para iniciar a captura de voz.
*   **L√≥gica de Processamento Modificada:** A se√ß√£o de entrada de texto agora verifica se `st.session_state.voice_command` cont√©m um valor. Se sim, ele usa esse valor como a entrada do usu√°rio e chama `process_message`. Depois, ele limpa `st.session_state.voice_command` para evitar que o comando seja processado novamente.

**Considera√ß√µes Importantes:**

*   **Cache:** Para garantir que a `MainApp` e o `GenerativeModelHandler` sejam inicializados apenas uma vez, use `@st.cache_resource`. Isso evita a reinicializa√ß√£o a cada intera√ß√£o.
*   **`handle_command`:** A fun√ß√£o `handle_command` deve retornar o texto da resposta. Este texto √© ent√£o usado como entrada para `process_message`.
*   **State Management:** O uso de `st.session_state` permite manter o estado entre as execu√ß√µes da aplica√ß√£o Streamlit.

Com estas modifica√ß√µes, seu `chat_streamlit.py` deve ser capaz de capturar comandos de voz usando a aplica√ß√£o `voice_assistent` e process√°-los da mesma forma que os comandos de texto. Isso adicionar√° a funcionalidade de controle por voz que voc√™ deseja.

2025-04-10 19:53:29,154 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 19:53:29,157 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 19:53:29,159 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 19:53:29,161 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 19:53:29,163 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 19:53:29,164 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 19:53:29,166 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 19:53:29,167 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 19:53:29,169 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 19:53:29,170 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 19:53:29,172 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 19:53:29,174 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 19:53:29,176 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 19:53:29,178 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 19:53:29,179 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 19:53:29,180 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 19:53:29,181 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 19:53:29,183 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 19:53:29,184 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 19:53:29,186 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 19:53:29,187 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 19:53:29,189 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 19:53:29,192 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 19:53:29,195 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 19:53:29,223 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 19:53:29,225 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 19:53:29,226 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 19:53:29,228 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 19:53:29,233 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 19:53:29,238 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 19:53:29,241 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 19:53:29,242 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 19:53:29,244 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 19:53:29,245 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 19:53:29,247 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 19:53:29,248 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 19:53:29,249 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 19:53:29,250 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 19:53:29,251 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 19:53:29,252 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 19:53:29,253 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 19:53:29,255 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 19:53:29,256 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 19:53:29,258 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 19:53:29,259 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 19:53:29,260 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 19:53:29,262 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 19:53:29,263 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 19:53:29,264 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 19:53:29,265 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 19:53:29,266 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 19:53:29,268 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 19:53:29,269 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 19:53:29,270 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:12:56,290 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:12:56,291 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:12:56,293 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:12:56,295 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:12:56,296 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:12:56,299 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:12:56,300 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:12:56,301 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:12:56,303 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:12:56,304 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:12:56,306 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:12:56,307 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:12:56,308 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:12:56,310 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:12:56,313 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:12:56,315 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:12:56,316 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:12:56,317 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:12:56,319 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:12:56,320 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:12:56,323 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:12:56,324 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:12:56,327 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:12:56,330 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:12:56,331 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:12:56,333 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:12:56,334 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:12:56,336 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:12:56,338 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:12:56,341 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:12:56,345 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:12:56,347 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:12:56,349 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:12:56,350 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:12:56,351 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:12:56,353 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:12:56,354 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:12:56,355 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:12:56,357 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:12:56,358 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:12:56,360 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:12:56,362 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:12:56,364 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:12:56,365 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:12:56,366 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:12:56,368 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:12:56,370 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:12:56,371 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:12:56,373 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:12:56,376 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:12:56,379 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:12:56,380 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:12:56,382 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:12:56,384 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:12:56,508 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:12:56,510 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:12:56,511 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:12:56,512 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:12:56,514 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:12:56,516 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:12:56,518 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:12:56,519 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:12:56,521 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:12:56,522 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:12:56,524 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:12:56,526 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:12:56,530 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:12:56,532 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:12:56,534 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:12:56,536 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:12:56,538 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:12:56,539 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:12:56,541 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:12:56,543 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:12:56,545 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:12:56,548 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:12:56,549 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:12:56,551 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:12:56,552 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:12:56,554 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:12:56,556 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:12:56,557 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:12:56,559 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:12:56,561 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:12:56,563 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:12:56,565 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:12:56,566 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:12:56,568 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:12:56,569 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:12:56,570 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:12:56,571 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:12:56,572 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:12:56,574 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:12:56,575 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:12:56,577 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:12:56,580 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:12:56,582 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:12:56,583 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:12:56,584 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:12:56,585 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:12:56,587 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:12:56,588 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:12:56,589 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:12:56,590 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:12:56,591 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:12:56,593 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:12:56,595 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:12:56,596 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:12:56,598 [INFO] Enviando para IA - Prompt (sem imagem): Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas.

Contexto:



# app_config\app_config.py

from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()
    
    def get_root_path(self):
        return str(self.ROOT_PATH)
    
    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py

from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        transcription_config = TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])


# audio_to_text\audio_to_text.py

import whisper
from audio_to_text.audio_config.audio_config import AudioConfig

class AudioToConverter:
    def __init__(self, audio_config: AudioConfig):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.AUDIO_INPUT_PATH
        self.TRANSCRIPTION_INPUT_PATH = audio_config.TRANSCRIPTION_INPUT_PATH

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            print(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        model = whisper.load_model("base")

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                print(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            print(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            print(f"Erro ao processar o arquivo {audio_file_path}: {e}")


# chat_app\chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# chat_app\config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# chat_app\services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# chat_app\services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# chat_app\services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# chat_app\utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

# common_paths\common_paths.py

from pathlib import Path

class CommonPaths:
    def __init__(self):
        # Diret√≥rio atual do script
        self.ROOT_PATH = Path(__file__).resolve().parent

        # Defini√ß√£o dos caminhos comuns
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'output'
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.AUDIO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.TRANSCRIPTION_OUTPUT_PATH = self.ROOT_PATH / 'data'
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'data'

        # Cria√ß√£o dos diret√≥rios
        self.create_directories()

    def create_directories(self):
        self.VIDEO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.VIDEO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.TRANSCRIPTION_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)



# fundamentus_api\fundamentus\__init__.py



# fundamentus_api\fundamentus\dados_b3.py

import locale
import pandas as pd
import streamlit as st
import requests
import fundamentus
import os
import plotly.express as px
from bs4 import BeautifulSoup
from fundamentus.detalhes import get_papel
import logging

# Configura localidade
locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')

# Configura√ß√£o do layout do Streamlit
st.set_page_config(
    page_title="An√°lise de A√ß√µes",
    layout="wide",
    page_icon="üìà"
)

class Acao:
    def __init__(self, papel):
        self.papel = papel
        self.dados_fundamentais = None
        self.proventos = None
        self.detalhes = None
        self.oscilacoes = None  # Adicionando um atributo para oscila√ß√µes

    def carregar_dados_fundamentais(self):
        self.dados_fundamentais = fundamentus.get_resultado().loc[[self.papel]]  # Use colchetes duplos para garantir que seja um DataFrame
        self.remover_formatacao()

    def obter_detalhes(self):
        self.detalhes = get_papel(self.papel)
        if self.detalhes is None or self.detalhes.empty:
            logging.warning(f"Nenhum detalhe encontrado para o papel: {self.papel}")

    def obter_proventos(self):
        url = f"https://www.fundamentus.com.br/proventos.php?papel={self.papel}&tipo=2"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        tabela = soup.find('table', {'id': 'resultado'})

        if not tabela:
            return pd.DataFrame()

        dados = []
        for linha in tabela.find_all('tr')[1:]:
            colunas = linha.find_all('td')
            try:
                valor = float(colunas[1].text.strip().replace(',', '.'))
            except ValueError:
                valor = None  # Se der erro, coloca None para evitar crash

            dados.append([colunas[0].text.strip(), valor, colunas[2].text.strip()])
        
        self.proventos = pd.DataFrame(dados, columns=['Data', 'Valor', 'Tipo'])
        return self.proventos

    def obter_oscilacoes(self):
        url = f"https://www.fundamentus.com.br/detalhes.php?papel={self.papel}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        conteudo_div = soup.find('div', class_='conteudo clearfix')

        if conteudo_div is None:
            return pd.DataFrame()

        oscilacoes_data = []
        oscilacoes_section = conteudo_div.find('td', class_='nivel1', colspan='2')
        
        if oscilacoes_section:
            labels = oscilacoes_section.find_all_next('td', class_='label w1')
            dados = oscilacoes_section.find_all_next('td', class_='data w1')

            for label, dado in zip(labels, dados):
                label_text = label.get_text(strip=True)
                valor_text = dado.find('span', class_='oscil').get_text(strip=True)
                oscilacoes_data.append([label_text, valor_text])

        self.oscilacoes = pd.DataFrame(oscilacoes_data, columns=['Per√≠odo', 'Oscila√ß√£o'])
        return self.oscilacoes

    def remover_formatacao(self):
        colunas_percentuais = ['dy', 'mrgebit', 'mrgliq', 'roic', 'roe', 'c5y']
        for coluna in colunas_percentuais:
            if coluna in self.dados_fundamentais:
                try:
                    self.dados_fundamentais[coluna] = self.dados_fundamentais[coluna].astype(float)
                except ValueError as e:
                    logging.error(f"Erro ao converter coluna {coluna} para float: {e}")

    def formatar_moeda(self, valor):
        return locale.currency(valor, symbol=True, grouping=True)

class Aplicacao:
    def __init__(self):
        self.acoes = fundamentus.get_resultado()

    def ajustar_tipos_dataframe(self, df):
        for coluna in df.columns:
            if df[coluna].dtype == 'object':
                try:
                    df[coluna] = df[coluna].astype(float)
                except ValueError:
                    df[coluna] = df[coluna].astype(str)
            elif df[coluna].dtype in ['int64', 'float64']:
                df[coluna] = df[coluna].astype(float)
        return df

    def exibir_dashboard(self):
        st.sidebar.title("üìä Dashboard de An√°lise de A√ß√µes")
        st.sidebar.write("Selecione um papel para visualizar detalhes.")

        papel_selecionado = st.sidebar.selectbox("Escolha uma a√ß√£o", self.acoes.index)

        acao = Acao(papel_selecionado)
        acao.carregar_dados_fundamentais()
        acao.obter_proventos()
        acao.obter_detalhes()
        acao.obter_oscilacoes()

        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader(f"üìå Dados Fundamentais - {papel_selecionado}")
            dados_fundamentais_df = self.ajustar_tipos_dataframe(acao.dados_fundamentais.T)
            st.dataframe(dados_fundamentais_df, width=400)

        with col2:
            st.subheader("üîç Detalhes")
            if acao.detalhes is not None and not acao.detalhes.empty:
                detalhes_df = pd.DataFrame(acao.detalhes).T.reset_index()
                detalhes_df.columns = ['Descri√ß√£o', 'Valor']
                detalhes_df = self.ajustar_tipos_dataframe(detalhes_df)

                st.subheader("Tabela de Detalhes")
                st.dataframe(detalhes_df, width=800)
            else:
                st.warning("Nenhum detalhe encontrado para essa a√ß√£o.")

        col_dividendos, col_oscilacoes = st.columns([1, 2])

        with col_dividendos:
            st.subheader("üí∞ Dividendos")
            if not acao.proventos.empty:
                proventos_df = self.ajustar_tipos_dataframe(acao.proventos)
                st.write(proventos_df)

        with col_oscilacoes:
            st.subheader("üìâ Oscila√ß√µes")
            if acao.oscilacoes is not None and not acao.oscilacoes.empty:
                oscilacoes_df = self.ajustar_tipos_dataframe(acao.oscilacoes)
                st.write(oscilacoes_df)

        st.subheader("üìà Tabela Geral de A√ß√µes")
        st.dataframe(self.acoes)

# Execu√ß√£o
if __name__ == "__main__":
    app = Aplicacao()
    app.exibir_dashboard()

# fundamentus_api\setup.py

from setuptools import setup, find_packages

setup(
    name='fundamentalvision ',
    version='0.1.0',
    author='Joel FerreiraHeanna dos Reis',
    author_email='heannareis@gmail.com',
    description='Um pacote para an√°lise fundamentalista de a√ß√µes da Bolsa B3 do Brasil.',
    packages=find_packages(),
    install_requires=[
        'pandas',
        'requests',
        'beautifulsoup4',
        'streamlit',
        'plotly',
        'fundamentus'
    ],
    classifiers=[
        'Programming Language :: Python :: 3',
        'License :: OSI Approved :: MIT License',
        'Operating System :: OS Independent',
    ],
    python_requires='>=3.6',
)

# ia_generator.py

import requests
from pathlib import Path
import webbrowser
from config.common_paths import TRANSCRIPTION_OUTPUT_PATH

apiKey = "6UlOOoY/kkmprunma/qNDg"

str_personas = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'personas.txt'
str_contexto = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'contexto.txt'

url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

txt_files = list(TRANSCRIPTION_OUTPUT_PATH.glob('*.txt'))

css_styles = """
<style>
body {
    font-family: Arial, sans-serif;
    margin: 20px;
}

h1, h2, h3 {
    color: #FF8C00;
}

li, strong, p {
    color: #008000;
}

h1 {
    font-size: 24px;
    margin-bottom: 20px;
}

h2 {
    font-size: 20px;
    margin-top: 20px;
    margin-bottom: 10px;
}

ul {
    list-style-type: disc;
    margin-left: 40px;
}

li {
    margin-bottom: 10px;
}

p {
    line-height: 1.6;
}
</style>
"""

if not txt_files:
    print(f"N√£o foram encontrados arquivos .txt no diret√≥rio {TRANSCRIPTION_OUTPUT_PATH}.")
else:
    for txt_file in txt_files:
        if txt_file.is_file():
            print(f"Lendo o arquivo: {txt_file.name}")
            with open(txt_file, 'r', encoding='utf-8') as file:
                str_reuniao = file.read()

            print(f"Enviando o conte√∫do do arquivo {txt_file.name} para a API...")
            data = {
                "inputs": {
                    "str_reuniao": str_reuniao,
                    "str_personas": str_personas.read_text(encoding='utf-8'),
                    "str_contexto": str_contexto.read_text(encoding='utf-8'),
                }
            }

            response = requests.post(f"{url}/api/templates/668de04202493d3063a9d7fa/execute", json=data, headers=headers)
            if response.status_code == 200:
                print(f"Resultado para o arquivo {txt_file.name} recebido.")
                html_content = response.text
                print(response.text)

                # Incluir o CSS no conte√∫do HTML
                html_with_css = f"<html><head>{css_styles}</head><body>{html_content}</body></html>"

                # Salvar o conte√∫do HTML em um arquivo
                output_file = TRANSCRIPTION_OUTPUT_PATH / f"{txt_file.stem}_output.html"
                with open(output_file, 'w', encoding='utf-8') as html_file:
                    html_file.write(html_with_css)

                # Abrir o arquivo HTML no navegador
                webbrowser.open(f"file://{output_file.resolve()}")
            else:
                print(f"Erro ao processar o arquivo {txt_file.name}: {response.status_code}")


# main.py

from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from transcriptions.transcriptions_config import TranscriptionConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from pathlib import Path

def main():
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    root_path = str(PROJECT_ROOT)
    print(f"Root path: {root_path}")  # Para verificar se est√° correto
    api_url = "http://localhost:8081/api/meetings/transcriptions"
    
    # # Configura√ß√£o de v√≠deos
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()
    
    # # Configura√ß√£o de √°udios
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()
    
    # # Processamento de transcri√ß√µes e envio de embeddings
    # embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    # embedding_processor_wrapper.process_transcriptions()

if __name__ == "__main__":
    main()


# send_embeddings_database\embedding_config\embedding_config.py

from app_config.app_config import AppConfig

class EmbeddingConfig(AppConfig):
    def __init__(self, root_path=None, transcription_input_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = transcription_input_path
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'embeddings' / 'output'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH, self.EMBEDDING_OUTPUT_PATH])


# send_embeddings_database\verify_last_enbedding.py

import os
import numpy as np

def get_latest_file(directory):
    # Listar todos os arquivos no diret√≥rio
    files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]
    
    if not files:
        raise FileNotFoundError("Nenhum arquivo encontrado no diret√≥rio.")

    # Encontrar o arquivo mais recente
    latest_file = max(files, key=os.path.getmtime)
    return latest_file

def load_and_print_embedding(directory):
    # Obter o caminho do √∫ltimo arquivo de embedding
    embedding_file_path = get_latest_file(directory)
    
    # Carregar o embedding
    embedding = np.load(embedding_file_path)
    
    # Exibir o conte√∫do do embedding
    print("Embedding carregado:")
    print(embedding)
    print("Dimens√µes do embedding:", embedding.shape)

# Caminho do diret√≥rio de embeddings
embedding_directory = 'C:/Users/HeannarReis/Documents/bsa_atacadao/assets/embeddings/output'

# Carregar e exibir o √∫ltimo embedding
load_and_print_embedding(embedding_directory)


# test_whisper.py

from transformers import pipeline
from common_paths import CommonPaths

commmom_paths = CommonPaths()

# Fun√ß√£o para ler a transcri√ß√£o de um arquivo
def read_transcription(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
    return lines

# Fun√ß√£o para converter a pontua√ß√£o em estrelas
def score_to_stars(score):
    if score >= 0.75:
        return 5
    elif score >= 0.55:
        return 4
    elif score >= 0.35:
        return 3
    elif score >= 0.15:
        return 2
    else:
        return 1

# Inicializar o pipeline de an√°lise de sentimento
sentiment_pipeline = pipeline("sentiment-analysis", model="neuralmind/bert-base-portuguese-cased")

# Caminho para o arquivo de transcri√ß√£o
file_path = commmom_paths.TRANSCRIPTION_OUTPUT_PATH / 'feedback.txt'

# Ler a transcri√ß√£o
lines = read_transcription(file_path)

# Analisar sentimento para cada feedback
for line in lines:
    sentiment = sentiment_pipeline(line.strip())
    score = sentiment[0]['score']
    stars = score_to_stars(score)
    
    # Ajuste manual para feedbacks com aspectos positivos e negativos
    if any(word in line.lower() for word in ["mas", "por√©m", "no entanto"]):
        stars = max(1, stars - 1)  # Reduz uma estrela se houver contradi√ß√£o
    
    # Ajuste adicional baseado em palavras-chave
    positive_keywords = ["excelente", "√≥timo", "perfeito", "r√°pido", "eficiente", "satisfeito", "clara", "eficaz", "bom trabalho"]
    negative_keywords = ["ruim", "p√©ssimo", "horr√≠vel", "poderia", "n√£o resolveu", "insatisfat√≥ria", "confusa", "inadequado", "lento", "n√£o houve seguimento", "n√£o atendeu", "n√£o funcionou", "demorado"]
    
    positive_count = sum(word in line.lower() for word in positive_keywords)
    negative_count = sum(word in line.lower() for word in negative_keywords)
    
    # Ajuste de estrelas baseado na contagem de palavras-chave
    if positive_count > negative_count:
        stars = min(5, stars + 1)
    elif negative_count > positive_count:
        stars = max(1, stars - 1)
    
    print(f"Texto: {line.strip()}")
    print(f"Sentimento: {stars} estrelas")
    print(f"Pontua√ß√£o: {score:.2f}")
    print('---')


# text_to_embedding\embedding_processing.py

from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from transcriptions.transcriptions_config import TranscriptionConfig
from transcriptions.transciption_sender_database import TranscriptionSenderDatabase

class EmbeddingProcessorWrapper:
    def __init__(self, root_path, api_url):
        # Configura√ß√£o de transcri√ß√µes e embeddings
        transcription_config = TranscriptionConfig(root_path=root_path)
        embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())

        self.embedding_processor = EmbeddingProcessor(embedding_config)
        self.transcription_sender = TranscriptionSenderDatabase(api_url)
    
    def process_transcriptions(self):
        # Mostrar o diret√≥rio onde est√° procurando as transcri√ß√µes
        print(f"Diret√≥rio de entrada das transcri√ß√µes: {self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH}")
        
        # Listar todos os arquivos de transcri√ß√£o no diret√≥rio de entrada
        transcription_files = list(self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH.glob('*.txt'))
        if not transcription_files:
            print("Nenhum arquivo de transcri√ß√£o encontrado.")
        for transcription_file_path in transcription_files:
            if transcription_file_path.is_file():
                print(f"Processando arquivo: {transcription_file_path}")
                self.process_and_send_transcription(transcription_file_path)
            else:
                print(f"Arquivo n√£o encontrado: {transcription_file_path}")

    def process_and_send_transcription(self, transcription_file_path):
        try:
            # Ler a transcri√ß√£o do arquivo de texto
            with open(transcription_file_path, 'r', encoding='utf-8') as f:
                transcription_text = f.read()
                if not transcription_text:
                    print(f"Arquivo {transcription_file_path} est√° vazio.")
                    return

            # Gerar o embedding da transcri√ß√£o
            embedding = self.embedding_processor.generate_embedding(transcription_text)
            if embedding is None:
                print(f"Falha ao gerar embedding para o arquivo {transcription_file_path}.")
                return

            # Salvar o embedding em um arquivo .npy
            self.embedding_processor.save_embedding(transcription_file_path, embedding)

            # Enviar os dados para a API
            self.transcription_sender.send_transcription(transcription_text, embedding)

        except Exception as e:
            print(f"Erro ao processar o arquivo {transcription_file_path}: {e}")


# text_to_embedding\texto_to_embedding.py

from sentence_transformers import SentenceTransformer
import numpy as np

class EmbeddingProcessor:
    def __init__(self, embedding_config):
        self.embedding_config = embedding_config
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

    def generate_embedding(self, transcription_text):
        return self.embedding_model.encode(transcription_text)

    def save_embedding(self, transcription_file_path, embedding):
        embedding_file_path = self.embedding_config.EMBEDDING_OUTPUT_PATH / transcription_file_path.with_suffix('.npy').name
        np.save(embedding_file_path, embedding)
        print(f"Embedding salvo em: {embedding_file_path}")
        return embedding_file_path


# transcriptions\transciption_sender_database.py

import requests

class TranscriptionSenderDatabase:
    def __init__(self, api_url):
        self.api_url = api_url

    def send_transcription(self, transcription_text, embedding):
        data = {
            'transcriptionText': transcription_text,
            'embedding': embedding.tolist()
        }

        response = requests.post(self.api_url, json=data)

        if response.status_code == 201:
            print("Transcri√ß√£o e embedding enviados com sucesso.")
        else:
            print(f"Erro ao enviar dados: {response.status_code}")
            print("Resposta da API:")
            print(response.text)


# transcriptions\transcriptions_config.py

from app_config.app_config import AppConfig

class TranscriptionConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = self.ROOT_PATH / 'assets' / 'transcriptions' / 'input'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH])
    
    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# translate\translator_to_english.py

import speech_recognition as sr
from translate import Translator

def ouvir_e_traduzir():
    # Inicializa o reconhecedor de fala
    recognizer = sr.Recognizer()

    # Configura o tradutor
    translator = Translator(to_lang="en", from_lang="pt")

    # Usa o microfone como fonte de √°udio
    with sr.Microphone() as source:
        print("Diga algo em portugu√™s...")

        while True:
            try:
                # Escuta o √°udio do microfone
                audio = recognizer.listen(source)
                
                # Reconhece a fala usando o Google Web Speech API
                texto_portugues = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {texto_portugues}")

                # Traduz o texto para o ingl√™s
                traducao = translator.translate(texto_portugues)
                print(f"Tradu√ß√£o para o ingl√™s: {traducao}")

            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio")
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")

if __name__ == "__main__":
    try:
        ouvir_e_traduzir()
    except KeyboardInterrupt:
        print("Interrompido pelo usu√°rio")


# translate\whispert_translator.py

import whisper
import pyaudio
import numpy as np

# Inicializa o modelo Whisper
model = whisper.load_model("base")

# Configura√ß√µes de √°udio
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024

# Inicializa o PyAudio
audio = pyaudio.PyAudio()

# Abre o stream de √°udio
stream = audio.open(format=FORMAT, channels=CHANNELS,
                    rate=RATE, input=True,
                    frames_per_buffer=CHUNK)

print("Diga algo em portugu√™s...")

try:
    audio_buffer = []

    while True:
        # L√™ dados do microfone
        data = stream.read(CHUNK)
        audio_buffer.append(np.frombuffer(data, dtype=np.int16).flatten().astype(np.float32) / 32768.0)

        # Processa o √°udio a cada 5 segundos
        if len(audio_buffer) * CHUNK / RATE >= 5:
            audio_data = np.concatenate(audio_buffer)
            audio_buffer = []

            # Transcreve e traduz o √°udio usando Whisper
            result = model.transcribe(audio_data, task="translate", language="pt")

            # Exibe a tradu√ß√£o
            print(f"Tradu√ß√£o para o ingl√™s: {result['text']}")

except KeyboardInterrupt:
    print("Interrompido pelo usu√°rio")

    # Fecha o stream de √°udio
    stream.stop_stream()
    stream.close()
    audio.terminate()


# video_to_audio\video_config\video_config.py

from app_config.app_config import AppConfig

class VideoConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video' / 'input'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.create_directories([self.VIDEO_INPUT_PATH, self.VIDEO_OUTPUT_PATH])

# video_to_audio\video_to_audio.py

from moviepy import VideoFileClip
import glob
import os
from .video_config.video_config import VideoConfig

class VideoToAudioConverter:
    def __init__(self, video_config: VideoConfig):
        self.video_config = video_config

    def convert_video_to_audio(self, video_path, audio_path):
        try:
            video = VideoFileClip(video_path)
            if video.audio:
                video.audio.write_audiofile(audio_path, fps=44100)
                print(f"Convertido {video_path} para {audio_path}")
            else:
                print(f"Aviso: O v√≠deo {video_path} n√£o cont√©m √°udio!")
        except Exception as e:
            print(f"Erro ao converter {video_path}: {e}")

    def process_videos(self):
        input_directory = self.video_config.VIDEO_INPUT_PATH
        output_directory = self.video_config.VIDEO_OUTPUT_PATH

        os.makedirs(output_directory, exist_ok=True)

        # Busca qualquer arquivo de v√≠deo (formatos comuns)
        video_files = glob.glob(os.path.join(input_directory, "*.*"))  # Pega todos os arquivos

        # Filtra apenas arquivos de v√≠deo
        video_extensions = {".mp4", ".mkv", ".avi", ".mov", ".wmv", ".flv"}  
        video_files = [f for f in video_files if os.path.splitext(f)[1].lower() in video_extensions]

        if not video_files:
            print(f"Nenhum arquivo de v√≠deo encontrado em: {input_directory}")
            return

        for video_file in video_files:
            base_name = os.path.basename(video_file)
            audio_file = os.path.join(output_directory, os.path.splitext(base_name)[0] + ".wav")
            self.convert_video_to_audio(video_file, audio_file)

        print("Convers√£o de v√≠deo para √°udio conclu√≠da!")


# voice_assistent\assistent.py

import speech_recognition as sr
import pyttsx3
import re
from collections import deque
import spacy
import requests
import os
import webbrowser
from class_voice_assistent.prompt import create_prompt
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import google.generativeai as genai

# Configura√ß√µes da API
handler = genai('gemini-1.5-flash')

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

voices = engine.getProperty('voices')
engine.setProperty('rate', 180)
print("\nLista de Vozes...")
for indice, vozes in enumerate(voices):
    print(indice, vozes.name)

voz = 1
engine.setProperty('voice', voices[voz].id)

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

# Fun√ß√£o para extrair texto de HTML
def extract_text_from_html(html):
    if not html.strip().startswith('<'):
        print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
        return html
    soup = BeautifulSoup(html, 'html.parser')
    text = ' '.join([p.get_text() for p in soup.find_all('p')])
    return text

def get_text_response(prompt, context, feedback):
    # Gere o conte√∫do com base no prompt usando a classe GenerativeModelHandler
    response = handler.generate_content(prompt)
    return response

# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/api/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


# voice_assistent\class_voice_assistent\api_client.py

import requests


class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, meeting):
        try:
            response_text = self.model.generate_content(prompt, context, meeting)
            return response_text
        except Exception as e:
            print(f"Erro inesperado: {e}")
            return None

    def find_similar_embeddings(self, embedding):
        try:
            print(f"Buscando embeddings similares para: {embedding}")
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            similar_embeddings = response.json()

            # Ordenar por similaridade (assumindo que a API retorna com similaridade em ordem decrescente)
            # Remover duplicatas baseadas na pergunta
            seen_questions = set()
            unique_embeddings = []
            for embedding in similar_embeddings:
                question = embedding['question'].strip().lower()
                if question not in seen_questions:
                    unique_embeddings.append(embedding)
                    seen_questions.add(question)
            print(f"Embeddings similares √∫nicos encontrados: {unique_embeddings}")
            return unique_embeddings
        except requests.RequestException as e:
            print(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            # Converter embeddings de numpy arrays para listas
            if hasattr(question_embedding, 'tolist'):
                question_embedding = question_embedding.tolist()
            if hasattr(answer_embedding, 'tolist'):
                answer_embedding = answer_embedding.tolist()
            
            data = {
                "question": question,
                "questionEmbedding": question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding
            }
            
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                print("Pergunta e resposta salvas com sucesso.")
            else:
                print(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            print(f"Erro em save_question_answer: {e}")


    def fetch_all_contexts(self):
        try:
            response = requests.get("http://localhost:8081/api/contexts/all")
            if response.status_code == 200:
                data = response.json()
                contexts = data.get('contexts', [])
                if isinstance(contexts, list):
                    print(f"Contexto obtido da API: {contexts}")
                    return contexts
                else:
                    print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                    return []
            else:
                print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
                return []
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
            return []

    def fetch_last_meeting(self):
        try:
            response = requests.get("http://localhost:8081/api/meetings/last")
            if response.status_code == 200:
                data = response.json()
                transcription_text = data.get('transcriptionText', "")
                if isinstance(transcription_text, str):
                    print(f"Texto da transcri√ß√£o obtido da API: {transcription_text}")
                    return transcription_text
                else:
                    print(f"Erro: 'transcriptionText' n√£o √© uma string. Dados retornados: {data}")
                    return ""
            else:
                print(f"Erro ao acessar a API de reuni√µes: {response.status_code}, {response.text}")
                return ""
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de reuni√µes: {e}")
            return ""


# voice_assistent\class_voice_assistent\command_interpreter.py

import spacy
from prompt_generator.online_prompt import OnlineResearchPromptGenerator
from prompt_generator.meeting_prompt import MeetingPromptGenerator
from prompt_generator.default_prompt_generator import DefaultPromptGenerator
import re

# Carregar o modelo de linguagem natural
nlp = spacy.load("pt_core_news_sm")

class CommandInterpreter:
    def __init__(self, api_client, question_answer_service, context_manager, max_similar=3):
        self.api_client = api_client
        self.question_answer_service = question_answer_service
        self.context_manager = context_manager
        self.max_similar = max_similar  # Limite de contextos similares

    def interpret_command(self, command, meeting):
        print(f"Interpretando comando: {command}")
        contexts = self.api_client.fetch_all_contexts()
        context_str = "\n".join([context['context'] for context in contexts])

        # Gerar embedding para a pergunta e buscar embeddings similares
        question_embedding = self.question_answer_service.convert_text_to_embedding(command)
        similar_embeddings = self.api_client.find_similar_embeddings(question_embedding)

        # Filtrar para evitar respostas redundantes
        unique_responses = self._filter_unique_responses(similar_embeddings, command)
        similar_context = "\n".join([f"Pergunta: {embedding['question']}\nResposta: {embedding['answer']}" for embedding in unique_responses[:self.max_similar]])

        # Detectar tipo de comando usando regex
        if re.search(r'\b(pesquise|pesquisar|procure)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como pesquisa online.")
            response = self.get_online_research_response(command, context_str, similar_context)
        elif re.search(r'\b(contexto)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como busca de contexto.")
            response = self.get_project_response(command, meeting, context_str, similar_context)
        elif re.search(r'\b(resumo?|t√≥picos da|pontos (relevantes|principais)|an√°lise)\b.*\b(reuni√£o|√∫ltima (reuni√£o|conversa|sess√£o))\b', command, re.IGNORECASE):
            print(f"\nComando identificado como an√°lise de reuni√£o.")
            meeting = self.api_client.fetch_last_meeting()
            response = self.get_meeting_analysis_response(command, context_str, meeting)
        else:
            print(f"\nComando identificado como comando padr√£o.")
            response = self.handle_default_command(command, context_str, meeting, similar_context)

        if response:
            answer_embedding = self.question_answer_service.convert_text_to_embedding(response)
            self.api_client.save_question_answer(command, question_embedding, response, answer_embedding)
            self.context_manager.add_context(command, response)

        return response

    def _filter_unique_responses(self, similar_embeddings, current_command):
        """
        Filtra respostas semelhantes que s√£o muito similares ao comando atual para evitar redund√¢ncia.
        """
        filtered = []
        for embedding in similar_embeddings:
            if embedding['question'].lower() != current_command.lower():
                filtered.append(embedding)
        return filtered

    def handle_default_command(self, command, context_str, meeting, similar_context):
        print(f"\nTratando comando padr√£o: {command}")
        # Combinar o contexto atual com os contextos similares para enriquecer a resposta
        combined_context = f"{context_str}\n{similar_context}"
        prompt = DefaultPromptGenerator().generate_prompt(command, combined_context, meeting)
        response = self.api_client.get_text_response(prompt, combined_context, meeting)
        return response

    # M√©todos get_project_response, get_meeting_analysis_response, get_online_research_response permanecem inalterados

    def get_project_response(self, command, meeting, context_str, similar_context):
        print(f"\nGerando prompt de projeto.")
        prompt = DefaultPromptGenerator().generate_prompt(command, context_str, meeting, similar_context)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_meeting_analysis_response(self, command, context_str, meeting):
        print(f"\nGerando prompt de an√°lise de reuni√£o.")
        prompt = MeetingPromptGenerator().generate_prompt(command, context_str, meeting)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_online_research_response(self, command, context_str, similar_context):
        print(f"\nGerando prompt de pesquisa online.")
        prompt = OnlineResearchPromptGenerator().generate_prompt(command, context_str, similar_context)
        return self.api_client.get_text_response(prompt, context_str, None)


# voice_assistent\class_voice_assistent\context_manager.py

from collections import deque

class ContextManager:
    def __init__(self, maxlen=10):
        self.recent_context = deque(maxlen=maxlen)

    def add_context(self, command, response):
        self.recent_context.append((command, response))

    def get_context(self):
        return "\n".join([context for context, _ in self.recent_context])


# voice_assistent\class_voice_assistent\conversation_history.py



# voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py

import requests
import logging
import google.generativeai as genai

# Configure o logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, feedback):
        try:
            # Gerando o conte√∫do usando a nova API
            response = self.model.generate_content(prompt)
            if response and hasattr(response, 'text'):
                return prompt, response.text
            else:
                logger.error("Resposta inv√°lida da API")
                return prompt, None
        except Exception as e:
            logger.error(f"Erro em get_text_response: {e}")
            return prompt, None

    def find_similar_embeddings(self, embedding):
        try:
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            logger.info(f"Enviando dados para a API de embeddings similares: {data}")
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            logger.error(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            data = {
                "question": question,
                "questionEmbedding": question_embedding.tolist() if hasattr(question_embedding, 'tolist') else question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding.tolist() if hasattr(answer_embedding, 'tolist') else answer_embedding
            }
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                logger.info("Pergunta e resposta salvas com sucesso.")
            else:
                logger.warning(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            logger.error(f"Erro em save_question_answer: {e}")


# voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py

import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        """Carregar vari√°veis do arquivo .env"""
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        """Configurar a chave da API"""
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        """Inicializar o modelo generativo"""
        try:
            self.model = genai.GenerativeModel(self.model_name)
        except Exception as e:  
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content(self, prompt: str, context: str, meeting: str) -> str:
        """Gerar conte√∫do com base no prompt, contexto e reuni√£o"""
        try:
            # Supondo que a API espera um dicion√°rio com os par√¢metros
            request_data = f'''
                "prompt": {prompt},
                "context": {context},
                "meeting": {meeting}
            '''
            print(f"Enviando requisi√ß√£o para a API GenAI: {request_data}")

            response = self.model.generate_content(request_data)
            return response.text
        except Exception as e:
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py

import os
from dotenv import load_dotenv
from groq import Groq

# Carregar vari√°veis do arquivo .env
load_dotenv()

# Recuperar a chave da API
api_key = os.getenv("GROQ_API_KEY")

# Verificar se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API Key is missing. Please set the GROQ_API_KEY in the .env file.")

# Configurar o cliente com a chave da API
client = Groq(api_key=api_key)

# Cria√ß√£o da conclus√£o do chat
chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "De acordo com nossas conversas anteriores, o que voc√™ acha do meu uso de IA ?",
        }
    ],
    model="llama3-8b-8192",
)

print(chat_completion.choices[0].message.content)


# voice_assistent\class_voice_assistent\main.py

import os
from context_manager import ContextManager
from api_client import APIClient
from command_interpreter import CommandInterpreter
from text_command_hendler import TextCommandHandler
from text_processor import TextProcessor
from text_to_speech import TextToSpeech
from voice_command_hendler import VoiceCommandHandler
from question_answers_service import QuestionAnswerService
from gpt_communication.gemini_gpt import GenerativeModelHandler

class MainApp:
    def __init__(self, model):
        self.voice_handler = VoiceCommandHandler()
        self.text_handler = TextCommandHandler()
        self.tts = TextToSpeech()
        self.text_processor = TextProcessor()
        self.api_client = APIClient(
            similarity_url="http://localhost:8081",
            save_url="http://localhost:8081/api/question_answers/save",
            model=model
        )
        self.context_manager = ContextManager()
        self.question_answer_service = QuestionAnswerService()
        self.command_interpreter = CommandInterpreter(
            self.api_client,
            self.question_answer_service,
            self.context_manager
        )

    def handle_command(self, command, meeting=""):
        if command:
            print(f"Pergunta recebida: {command}")
            text_response = self.command_interpreter.interpret_command(command, meeting)
            if text_response:
                print(f"Resposta: {text_response}")
                self.tts.speak_text(text_response)
                self.context_manager.add_context(command, text_response)
                return text_response
        else:
            print("Nenhum comando detectado.")
            return None

    def run(self):
        meeting = ""
        while True:
            try:
                input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
                if input_type == 'v':
                    command = self.voice_handler.capture_voice_command()
                elif input_type == 't':
                    command = self.text_handler.capture_text_command()
                else:
                    print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
                    continue

                response = self.handle_command(command, meeting)
                if response:
                    print(f"Resposta: {response}")
            except Exception as e:
                print(f"Ocorreu um erro: {e}")

if __name__ == "__main__":
    model = GenerativeModelHandler('gemini-1.5-flash')
    app = MainApp(model)
    app.run()

# voice_assistent\class_voice_assistent\prompt.py

def create_prompt(command, context, meeting):
    keywords = ["fa√ßa um resumo da √∫ltima reuni√£o.", "t√≥picos da √∫ltima reuni√£o", "resuma a √∫ltima reuni√£o", "pesquise", "pesquisar", "procure"]
    if any(keyword in command.lower() for keyword in keywords):
        return f"""
        Regras de Meeting:
        - Voc√™ √© respons√°vel por analisar, debater, sugerir e informar melhorias.
        - Resuma de forma clara e Objetiva.
        - N√£o acrescentar t√≠tulo nas respostas.

        [context]: {context}
        -------
        [meeting]: {meeting}
        -------
        [str_texto]: {command}
        """
    else:
        return f"""
        [context]: {context}
        -------
        [str_texto]: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py

class DefaultPromptGenerator:
    def generate_prompt(self, command, combined_context, meeting):
        prompt = (
            f"Comando: {command}\n"
            f"Contexto Anterior:\n{combined_context}\n"
            f"Baseie sua resposta nas informa√ß√µes acima e forne√ßa uma solu√ß√£o detalhada."
        )
        return prompt

# voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class MeetingPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting):
        return f"""
        Regras de Meeting com respostas inteligentes:
        - Responda a pergunta de [str_texto] com base nas diretrizes abaixo...
            - Voc√™ √© respons√°vel analisar com detalhes a reuni√£o de [str_meeting], e fornecer uma longa est√≥ria sobre o assunto.
            - observe os nomes das personas mencionadas no texto de meeting para aprender e melhorar a precis√£o da resposta.
            - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [str_texto]: Responda a pergunta de: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class OnlineResearchPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting, similar_context):
        return f"""
        Regras de Pesquisa Online Inteligente:
        - Utilize similar_context e fa√ßa uma pesquisa online para uma resposta mais precisa das quest√µes de [str_text]
        - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [context]: Regras B√°sicas {context}
        ------
        [similar_context]:
        Perguntas e respostas anteriores.{similar_context}
        ------
        [str_texto]: Responda seguinte pergunta: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py

from abc import ABC, abstractmethod

class PromptGenerator(ABC):
    @abstractmethod
    def generate_prompt(self, command, context, meeting, similar_context):
        pass

# voice_assistent\class_voice_assistent\question_answers_service.py

import requests
import numpy as np
from sentence_transformers import SentenceTransformer

class QuestionAnswerService:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.embedding_model = SentenceTransformer(model_name)

    def convert_text_to_embedding(self, text):
        embedding = self.embedding_model.encode(text)
        #print(f"Embedding gerado para '{text}': {embedding[0]:.16f}") # Adicionado para verificar o embedding gerado
        return embedding


# voice_assistent\class_voice_assistent\text_command_hendler.py

class TextCommandHandler:
    def capture_text_command(self):
        command = input("Digite o seu comando: ")
        return command


# voice_assistent\class_voice_assistent\text_processor.py

from bs4 import BeautifulSoup

class TextProcessor:
    def extract_values_from_json(self, data):
        if isinstance(data, dict):
            return ' '.join([str(value) for value in data.values()])
        elif isinstance(data, list):
            return ' '.join([self.extract_values_from_json(item) for item in data])
        return str(data)

    def extract_text_from_html(self, html):
        if not html.strip().startswith('<'):
            print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
            return html
        soup = BeautifulSoup(html, 'html.parser')
        text = ' '.join([p.get_text() for p in soup.find_all('p')])
        return text


# voice_assistent\class_voice_assistent\text_to_speech.py

import pyttsx3

class TextToSpeech:
    def __init__(self):
        self.engine = pyttsx3.init()

    def speak_text(self, text):
        cleaned_text = self.clean_text(text)
        self.engine.say(cleaned_text)
        self.engine.runAndWait()

    def clean_text(self, text):
        import re
        return re.sub(r'[\*\_\#]', '', text)


# voice_assistent\class_voice_assistent\voice_command_hendler.py

import speech_recognition as sr

class VoiceCommandHandler:
    def capture_voice_command(self):
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            print("Por favor, fale o seu comando:")
            try:
                audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
                print("√Åudio capturado com sucesso.")
                command = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {command}")
                return command
            except sr.WaitTimeoutError:
                print("Tempo de espera expirado. Nenhum √°udio detectado.")
                return None
            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio.")
                return None
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
                return None


# voice_assistent\config.py

# config.py
import pyttsx3
import spacy
from collections import deque

class APIConfig:
    apiKey = "API_KEY"
    url = "https://gpt-templates.saiapplications.com"
    headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")


# voice_assistent\template.py

import speech_recognition as sr
import requests
import pyttsx3
import re
from collections import deque
import spacy
import os
import webbrowser
from voice_assistent.prompt import create_prompt

# Configura√ß√µes da API
apiKey = "6UlOOoY/kkmprunma/qNDg"
url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    if isinstance(text, dict):
        text = extract_values_from_json(text)  # Extrai os valores do dicion√°rio
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

def get_text_response(prompt, context, feedback):
    data = {
        "inputs": {
            "str_texto": prompt,
            "str_contexto": context,
            "str_feedback": feedback
        }
    }
    print(f"Enviando dados para a API: {data}")
    try:
        response = requests.post(f"{url}/api/templates/6691e223802f95c2b394a8bd/execute", json=data, headers=headers)
        print(f"Status da resposta: {response.status_code}")
        if response.status_code == 200:
            try:
                response_data = response.html()  # Tente converter a resposta para JSON
                print("Resposta HTML recebida.")
                return extract_values_from_json(response_data)  # Extrai os valores do JSON
            except ValueError:
                print("A resposta n√£o est√° no formato JSON esperado. Tratando como texto simples.")
                return response.text  # Retorna o texto bruto da resposta
        else:
            print(f"Erro ao acessar a API: {response.status_code}, {response.text}")
            return None
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API: {e}")
        return None

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)


# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


User: Como posso integrar todas as aplica√ß√µes para funcionar em uma √∫nica MAIN.py ?

Streamlit. Chat de voz. converter v√≠deo para audio e audio para texto e depois salvar no banco de dados.
Assistant: Para integrar todas as aplica√ß√µes em um √∫nico `main.py`, voc√™ precisa modularizar seu c√≥digo existente e usar uma estrutura central que coordene a execu√ß√£o das diferentes partes (Streamlit chat de voz, convers√£o de v√≠deo para √°udio, √°udio para texto e salvamento no banco de dados).

Aqui est√° um esbo√ßo de como voc√™ pode abordar isso, com √™nfase na organiza√ß√£o e coordena√ß√£o das tarefas:

```python
# main.py

import streamlit as st
import os
from pathlib import Path

# Importar as fun√ß√µes e classes de cada m√≥dulo
from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from voice_assistent.class_voice_assistent.main import MainApp
from voice_assistent.class_voice_assistent.gpt_communication.gemini_gpt import GenerativeModelHandler
from transcriptions.transcriptions_config import TranscriptionConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from config.config import Config
from core.rate_limiter import RateLimiter

# 1. Configura√ß√£o Inicial
PROJECT_ROOT = Path(__file__).resolve().parent
root_path = str(PROJECT_ROOT)
print(f"Root path: {root_path}")

Config.ensure_directories()

# 2. Fun√ß√µes de Processamento
def process_videos():
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()

def process_audio():
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()

def process_transcriptions_and_embeddings(api_url):
    transcription_config = TranscriptionConfig(root_path=root_path)
    embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())
    embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    embedding_processor_wrapper.process_transcriptions()

# 3. Interface Streamlit
def main():
    st.title("Aplica√ß√µes Integradas")

    # 3.1. Sidebar com op√ß√µes
    app_mode = st.sidebar.selectbox(
        "Escolha a aplica√ß√£o:",
        ["Chat de Voz", "Converter V√≠deo para √Åudio", "Converter √Åudio para Texto", "Enviar Embeddings para o Banco de Dados"]
    )

    # 3.2. L√≥gica para cada aplica√ß√£o
    if app_mode == "Chat de Voz":
        st.header("Chat de Voz")
        model = GenerativeModelHandler('gemini-1.5-flash')
        app = MainApp(model)
        app.run()

    elif app_mode == "Converter V√≠deo para √Åudio":
        st.header("Converter V√≠deo para √Åudio")
        if st.button("Converter V√≠deos"):
            process_videos()
            st.success("V√≠deos convertidos para √°udio com sucesso!")

    elif app_mode == "Converter √Åudio para Texto":
        st.header("Converter √Åudio para Texto")
        if st.button("Converter √Åudios"):
            process_audio()
            st.success("√Åudios convertidos para texto com sucesso!")

    elif app_mode == "Enviar Embeddings para o Banco de Dados":
        st.header("Enviar Embeddings para o Banco de Dados")
        api_url = st.text_input("URL da API para enviar as transcri√ß√µes:", "http://localhost:8081/api/meetings/transcriptions")

        if st.button("Enviar Embeddings"):
            process_transcriptions_and_embeddings(api_url)
            st.success("Embeddings enviados para o banco de dados com sucesso!")

# 4. Execu√ß√£o Principal
if __name__ == "__main__":
    main()
```

### Estrutura do Projeto

-   **`main.py`**: Este √© o ponto de entrada. Ele usa Streamlit para criar uma interface que permite selecionar qual parte da aplica√ß√£o executar.

-   **`video_to_audio/`**, **`audio_to_text/`**, **`text_to_embedding/`**, **`voice_assistent/`**: Esses diret√≥rios cont√™m o c√≥digo existente de cada parte da sua aplica√ß√£o.

### Passos para Implementar

1.  **Modulariza√ß√£o:**

    *   Certifique-se de que cada parte da sua aplica√ß√£o (convers√£o de v√≠deo, convers√£o de √°udio, chat de voz) esteja bem encapsulada em fun√ß√µes ou classes reutiliz√°veis.
    *   Mova essas fun√ß√µes e classes para os respectivos m√≥dulos (arquivos `.py` dentro de seus diret√≥rios).

2.  **Integra√ß√£o no `main.py`:**

    *   Importe as fun√ß√µes e classes dos m√≥dulos.
    *   Use Streamlit para criar uma interface que permita ao usu√°rio escolher qual fun√ß√£o executar.
    *   Implemente bot√µes ou seletores para acionar as diferentes partes da aplica√ß√£o.

3.  **Gerenciamento de Depend√™ncias:**

    *   Certifique-se de que todas as depend√™ncias necess√°rias para cada parte da aplica√ß√£o estejam instaladas.  Considere usar um arquivo `requirements.txt` para listar todas as depend√™ncias.

4.  **Testes:**

    *   Teste cada parte da aplica√ß√£o individualmente para garantir que funcionem corretamente.
    *   Teste a integra√ß√£o geral para garantir que as diferentes partes possam ser executadas em sequ√™ncia ou individualmente, conforme necess√°rio.

### Pontos Chave

*   **Modulariza√ß√£o:** Dividir o c√≥digo em m√≥dulos facilita a manuten√ß√£o e reutiliza√ß√£o.
*   **Interface Streamlit:** Streamlit permite criar uma interface web simples para interagir com sua aplica√ß√£o.
*   **Gerenciamento de Estado:** Use `st.session_state` para manter o estado entre as execu√ß√µes da aplica√ß√£o Streamlit (por exemplo, se um v√≠deo foi convertido ou n√£o).
*   **Tratamento de Erros:** Implemente tratamento de erros para lidar com falhas em qualquer parte da aplica√ß√£o e fornecer feedback √∫til ao usu√°rio.
*   **Configura√ß√£o:** Utilize arquivos de configura√ß√£o (como o seu `config.py`) para armazenar caminhos de arquivos, URLs de API e outras configura√ß√µes que podem precisar ser ajustadas.

Seguindo esses passos, voc√™ deve conseguir integrar todas as suas aplica√ß√µes em um √∫nico script `main.py` com uma interface Streamlit para facilitar o uso e a demonstra√ß√£o.

User: observe em src/chat_streamlit que j√° tenho uma aplica√ß√£o que funciona como chat e consegue gerar imagem e ler imagem com OCR... atualmente s√≥ funciona por text .... quero colocar via comando de voz tbm  com a parte da aplica√ß√£o que usa Speech Recoginition
Assistant: Ok, para integrar o comando de voz ao seu `chat_streamlit.py`, voc√™ precisar√° adaptar o c√≥digo existente para incluir a funcionalidade de reconhecimento de voz e direcionar a entrada de voz para as mesmas fun√ß√µes que j√° processam o texto. Aqui est√° um guia passo a passo de como fazer isso:

**1. Importar as Bibliotecas Necess√°rias:**

Adicione as seguintes importa√ß√µes ao topo do seu arquivo `chat_streamlit.py`:

```python
import speech_recognition as sr
import threading
```

**2. Fun√ß√£o para Capturar Comando de Voz:**

Crie uma fun√ß√£o para capturar o comando de voz usando `speech_recognition`. Esta fun√ß√£o ser√° executada em uma thread separada para evitar bloquear a interface do Streamlit.

```python
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.write("Diga algo...")  # Mensagem na interface
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            command = recognizer.recognize_google(audio, language='pt-BR')
            st.write(f"Voc√™ disse: {command}")  # Mostra o comando reconhecido
            return command
        except sr.WaitTimeoutError:
            st.write("Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            st.write("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            st.write(f"Erro ao solicitar resultados: {e}")
            return None
```

**3. Adicionar um Bot√£o para Ativar o Reconhecimento de Voz:**

Adicione um bot√£o na barra lateral para iniciar a captura de voz. Esse bot√£o iniciar√° uma thread que executa a fun√ß√£o `capture_voice_command`.

```python
with st.sidebar:
    # ... (seu c√≥digo existente da barra lateral)

    if st.button("üé§ Usar Comando de Voz"):
        st.session_state.voice_command = None  # Limpa o comando anterior
        st.session_state.voice_thread = threading.Thread(target=lambda: setattr(st.session_state, 'voice_command', capture_voice_command()))
        st.session_state.voice_thread.start()
```

**4. Modificar a L√≥gica de Processamento de Mensagens:**

Modifique a l√≥gica de processamento de mensagens para verificar se h√° um comando de voz capturado. Se houver, use esse comando como entrada para a fun√ß√£o `process_message`.

```python
# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # ... (seu c√≥digo existente para determinar o placeholder)

    # Verifica se um comando de voz foi capturado
    if 'voice_command' in st.session_state and st.session_state.voice_command:
        user_input = st.session_state.voice_command
        process_message(user_input, current_image)
        st.session_state.voice_command = None  # Limpa o comando para n√£o repetir

    else:
        user_input = st.chat_input(placeholder)

        if user_input:
            # Processa a mensagem com a imagem (se houver) ou apenas texto
            process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)
```

**Explica√ß√£o das Modifica√ß√µes:**

*   **`capture_voice_command()`:** Esta fun√ß√£o captura o √°udio do microfone, tenta reconhecer a fala e retorna o comando de texto. Ela tamb√©m exibe mensagens de status na interface do Streamlit.
*   **Bot√£o "üé§ Usar Comando de Voz":** Quando este bot√£o √© clicado, ele cria e inicia uma nova thread que executa a fun√ß√£o `capture_voice_command`.  O resultado do comando de voz √© armazenado em `st.session_state.voice_command`.
*   **L√≥gica de Processamento Modificada:** A se√ß√£o de entrada de texto agora verifica se `st.session_state.voice_command` cont√©m um valor. Se sim, ele usa esse valor como a entrada do usu√°rio e chama `process_message`. Depois, ele limpa `st.session_state.voice_command` para evitar que o comando seja processado novamente.
*   **Thread:** Usar uma thread para a captura de voz √© crucial porque `recognizer.listen()` √© um m√©todo bloqueante. Sem uma thread, a interface do Streamlit ficaria congelada enquanto o √°udio √© capturado.

**Pontos Adicionais:**

*   **Permiss√µes do Microfone:** Certifique-se de que seu navegador tenha permiss√£o para acessar o microfone.
*   **Thread Safety:** Tenha cuidado com a seguran√ßa de threads ao modificar `st.session_state`. Streamlit n√£o √© inerentemente thread-safe, ent√£o evite opera√ß√µes simult√¢neas que possam causar problemas. Usar `setattr` como mostrado √© uma maneira segura de atualizar o estado.
*   **Feedback Visual:** Forne√ßa feedback visual ao usu√°rio para que saiba quando o sistema est√° gravando, processando ou aguardando um comando de voz.

Com estas modifica√ß√µes, seu `chat_streamlit.py` deve ser capaz de capturar comandos de voz e process√°-los da mesma forma que os comandos de texto. Isso adicionar√° a funcionalidade de controle por voz que voc√™ deseja.

User: eu ja tenho uma aplica√ß√£o de comando de voz dentro da pasta voice_assistent.
Assistant: Entendi. Em vez de criar uma nova fun√ß√£o de captura de voz, podemos integrar a sua aplica√ß√£o existente `voice_assistent` ao `chat_streamlit.py`. Isso envolve principalmente reutilizar as fun√ß√µes de captura e interpreta√ß√£o de comandos da sua aplica√ß√£o `voice_assistent` existente e integr√°-las na interface do Streamlit.

Aqui est√£o os passos detalhados:

**1. Importar as Fun√ß√µes Necess√°rias de `voice_assistent`:**

No topo do seu arquivo `chat_streamlit.py`, importe as fun√ß√µes que voc√™ precisa de `voice_assistent.main`:

```python
from voice_assistent.class_voice_assistent.main import MainApp
from voice_assistent.class_voice_assistent.gpt_communication.gemini_gpt import GenerativeModelHandler
import threading
import streamlit as st
```

**2. Inicializar a Aplica√ß√£o `voice_assistent`:**

Voc√™ precisar√° inicializar a aplica√ß√£o `voice_assistent` uma vez, preferencialmente fora do loop principal do Streamlit, para que n√£o seja reinicializada a cada intera√ß√£o.

```python
# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Inicializa a aplica√ß√£o de voz
@st.cache_resource
def get_voice_app():
    model = GenerativeModelHandler('gemini-1.5-flash')
    return MainApp(model)

voice_app = get_voice_app()
```

**3. Modificar o Bot√£o de Comando de Voz:**

Modifique o bot√£o na barra lateral para usar a fun√ß√£o de captura de voz da sua aplica√ß√£o `voice_assistent`. Em vez de criar uma nova thread, voc√™ chamar√° a fun√ß√£o `handle_command` da sua `voice_app` diretamente.

```python
with st.sidebar:
    # ... (seu c√≥digo existente da barra lateral)

    if st.button("üé§ Usar Comando de Voz"):
        st.session_state.voice_command = None  # Limpa o comando anterior
        st.session_state.voice_thread = threading.Thread(target=lambda: setattr(st.session_state, 'voice_command', voice_app.handle_command(voice_app.voice_handler.capture_voice_command())))
        st.session_state.voice_thread.start()
```

**4. Modificar a L√≥gica de Processamento de Mensagens:**

Modifique a l√≥gica de processamento de mensagens para verificar se h√° um comando de voz capturado. Se houver, use esse comando como entrada para a fun√ß√£o `process_message`.

```python
# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # ... (seu c√≥digo existente para determinar o placeholder)

    # Verifica se um comando de voz foi capturado
    if 'voice_command' in st.session_state and st.session_state.voice_command:
        user_input = st.session_state.voice_command
        process_message(user_input, current_image)
        st.session_state.voice_command = None  # Limpa o comando para n√£o repetir

    else:
        user_input = st.chat_input(placeholder)

        if user_input:
            # Processa a mensagem com a imagem (se houver) ou apenas texto
            process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)
```

**Explica√ß√£o das Modifica√ß√µes:**

*   **Importa√ß√£o de `MainApp`:** Importe a classe `MainApp` da sua aplica√ß√£o `voice_assistent`.
*   **Inicializa√ß√£o de `MainApp`:** Inicialize a aplica√ß√£o `MainApp` usando o modelo `GenerativeModelHandler`. Isso deve ser feito apenas uma vez.
*   **Bot√£o "üé§ Usar Comando de Voz":** Quando este bot√£o √© clicado, ele chama `voice_app.run()` para iniciar a captura de voz.
*   **L√≥gica de Processamento Modificada:** A se√ß√£o de entrada de texto agora verifica se `st.session_state.voice_command` cont√©m um valor. Se sim, ele usa esse valor como a entrada do usu√°rio e chama `process_message`. Depois, ele limpa `st.session_state.voice_command` para evitar que o comando seja processado novamente.

**Considera√ß√µes Importantes:**

*   **Cache:** Para garantir que a `MainApp` e o `GenerativeModelHandler` sejam inicializados apenas uma vez, use `@st.cache_resource`. Isso evita a reinicializa√ß√£o a cada intera√ß√£o.
*   **`handle_command`:** A fun√ß√£o `handle_command` deve retornar o texto da resposta. Este texto √© ent√£o usado como entrada para `process_message`.
*   **State Management:** O uso de `st.session_state` permite manter o estado entre as execu√ß√µes da aplica√ß√£o Streamlit.

Com estas modifica√ß√µes, seu `chat_streamlit.py` deve ser capaz de capturar comandos de voz usando a aplica√ß√£o `voice_assistent` e process√°-los da mesma forma que os comandos de texto. Isso adicionar√° a funcionalidade de controle por voz que voc√™ deseja.

User: refatore a minha aplica√ß√£o inteira com as boas pr√°ticas de POO e SOLID.
2025-04-10 20:13:35,252 [INFO] Resposta da IA (texto): ```python
# app_config\app_config.py
from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()

    def get_root_path(self):
        return str(self.ROOT_PATH)

    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py
from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None, transcription_config=None):
        super().__init__(root_path)
        self.transcription_config = transcription_config if transcription_config else TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = self.transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])

    def get_audio_input_path(self):
        return self.AUDIO_INPUT_PATH

    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# audio_to_text\audio_to_text.py
import whisper
from audio_to_text.audio_config.audio_config import AudioConfig
from abc import ABC, abstractmethod
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class IAudioProcessor(ABC):
    @abstractmethod
    def process_audio_files(self):
        pass

class AudioToConverter(IAudioProcessor):
    def __init__(self, audio_config: AudioConfig, whisper_model_name="base"):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.get_audio_input_path()
        self.TRANSCRIPTION_INPUT_PATH = audio_config.get_transcription_input_path()
        self.model = whisper.load_model(whisper_model_name)
        self.logger = logging.getLogger(__name__)

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            self.logger.info(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                self.logger.info(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, self.model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            self.logger.info(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            self.logger.error(f"Erro ao processar o arquivo {audio_file_path}: {e}", exc_info=True)

# chat_app\chat_streamlit.py
import streamlit as st
import time
from datetime import datetime
from PIL import Image
import os
import io
from dotenv import load_dotenv
import threading  # Importa o m√≥dulo threading
from google import genai
from google.genai import types

# Core Components
from chat_app.config.config import Config
from chat_app.core.handlers.gemini_handler import GeminiHandler
from chat_app.core.rate_limiter import RateLimiter

# Services
from chat_app.services.search_files import ler_todos_arquivos_python

# Submodules (Separadas para melhor organiza√ß√£o)
from chat_app.modules.image_handling import ImageHandler
from chat_app.modules.voice_input import VoiceInputHandler
from chat_app.modules.message_handling import MessageHandler
from chat_app.modules.image_generation import ImageGenerator


class ChatApp:
    def __init__(self):
        load_dotenv()  # Carrega as vari√°veis de ambiente
        Config.ensure_directories()  # Garante que os diret√≥rios necess√°rios existam

        self.rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

        self.gemini_handler = GeminiHandler("gemini-2.0-flash-exp")  # Inicializa GeminiHandler
        self.image_handler = ImageHandler()
        self.voice_input_handler = VoiceInputHandler()
        self.message_handler = MessageHandler()
        self.image_generator = ImageGenerator()

        self.initialize_session_state()
        self.load_chat_prompt()

    def initialize_session_state(self):
        """Inicializa os estados do session_state."""
        default_states = {
            "messages": [],
            "processing": False,
            "uploaded_image": None,
            "clipboard_image_preview": None,
            "clipboard_image_file": None,
            "last_message_time": 0,
            "file_uploader_key": "uploader_0",
            "generated_image": None,
            "image_prompt": None,
            "voice_command": None  # Estado para armazenar comandos de voz
        }

        for key, default_value in default_states.items():
            if key not in st.session_state:
                st.session_state[key] = default_value

    def load_chat_prompt(self):
        """Carrega o prompt do chat e adiciona o contexto do c√≥digo fonte."""
        codigo_fonte = ler_todos_arquivos_python()
        self.chat_prompt = f"{self.load_prompt_from_file()}\n\nContexto:\n\n{codigo_fonte}"

    def load_prompt_from_file(self):
        """Carrega o prompt base do arquivo."""
        try:
            with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
                return file.read().strip()
        except FileNotFoundError:
            return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

    def process_message(self, user_input, image_data=None, generated_image=None):
        """Processa a mensagem do usu√°rio (com ou sem imagem)."""
        st.session_state.processing = True  # Marca como processando para bloquear novos inputs
        st.session_state.current_prompt = user_input
        st.session_state.current_image = image_data
        st.session_state.current_generated_image = generated_image

        st.rerun()  # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento

    def execute_processing(self):
        """Executa o processamento da mensagem."""
        user_input = st.session_state.current_prompt
        image_data = st.session_state.current_image
        generated_image = st.session_state.current_generated_image

        self.rate_limiter.wait_for_slot()  # Garante que n√£o exceda o limite de requisi√ß√µes

        current_time = time.time()
        time_since_last_message = current_time - st.session_state.last_message_time
        wait_time = max(0, 2 - time_since_last_message)
        time.sleep(wait_time)

        st.session_state.last_message_time = time.time()

        img_path = None
        img_display = None

        if image_data:
            img_path, img_display = self.image_handler.save_uploaded_image(image_data)
            st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
        elif generated_image:
            img_path = self.image_handler.save_generated_image(generated_image)
            st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
        else:
            st.session_state.messages.append({"role": "user", "content": user_input})

        self.message_handler.limit_message_history(st.session_state.messages)

        full_prompt = self.chat_prompt + "\n\n"  # Start with the base prompt
        full_prompt = self.message_handler.build_full_prompt(full_prompt, st.session_state.messages, user_input)

        try:
            if img_path:
                response = self.gemini_handler.generate_content(img_path, full_prompt)
            else:
                response = self.gemini_handler.generate_content(None, full_prompt)
        except Exception as e:
            response = f"‚ùå Erro ao gerar resposta: {str(e)}"

        st.session_state.messages.append({"role": "assistant", "content": response})
        self.message_handler.limit_message_history(st.session_state.messages)

        if img_path and os.path.exists(img_path):
            os.remove(img_path)

        st.session_state.processing = False
        st.session_state.current_prompt = None
        st.session_state.current_image = None
        st.session_state.current_generated_image = None

    def run(self):
        """Fun√ß√£o principal para rodar a aplica√ß√£o Streamlit."""
        # Executa o processamento se estiver na fila
        if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
            self.execute_processing()
            st.rerun()

        # Configura√ß√£o da barra lateral
        with st.sidebar:
            st.title("Chat IA Inteligente")

            # Se√ß√£o de gera√ß√£o de imagem
            st.markdown("### Gerar Imagem")
            image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
            if st.button("Gerar Imagem"):
                if image_prompt:
                    generated_image = self.image_generator.generate_image(image_prompt)
                    if generated_image:
                        st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                        st.session_state.generated_image = None  # Limpa para n√£o exibir em cima

                        st.rerun()
                else:
                    st.warning("Por favor, digite um prompt para gerar a imagem.")

            # Se√ß√£o de imagens (sempre vis√≠vel)
            st.markdown("### Adicionar Imagem (Opcional)")
            st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

            # Layout em duas colunas para os bot√µes de imagem
            col1, col2 = st.columns(2)

            with col1:
                # Bot√£o para verificar a √°rea de transfer√™ncia
                if st.button("üìã Colar", use_container_width=True):
                    if self.image_handler.on_paste_click():
                        st.success("Imagem colada!")
                        st.rerun()
                    else:
                        st.warning("Nada encontrado.")

            with col2:
                # Bot√£o para limpar a imagem atual (se houver)
                if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
                    if st.button("üóëÔ∏è Limpar", use_container_width=True):
                        self.image_handler.clear_all_images()
                        st.rerun()
                else:
                    # Placeholder para manter o layout alinhado
                    st.write("")

            # Uploader de imagem com chave din√¢mica
            uploaded_file = st.file_uploader(
                "üì∑ Ou fa√ßa upload de imagem",
                type=["png", "jpg", "jpeg"],
                label_visibility="visible",
                key=st.session_state.file_uploader_key
            )

            # Atualiza o estado da imagem quando um arquivo √© carregado
            if uploaded_file:
                st.session_state.uploaded_image = uploaded_file
                self.image_handler.on_file_upload()
                st.success("Imagem carregada!")

            # Exibe a imagem selecionada na barra lateral
            self.image_handler.display_selected_image()

            st.markdown("---")

             # Adiciona bot√£o para comando de voz
            if st.button("üé§ Usar Comando de Voz"):
                st.session_state.voice_thread = threading.Thread(target=self.voice_input_handler.capture_voice_command)
                st.session_state.voice_thread.start()

            # Bot√£o para limpar o hist√≥rico de conversa
            if st.button("üßπ Limpar conversa", use_container_width=True):
                st.session_state.messages = []
                st.rerun()

            st.caption("Desenvolvido com Streamlit e Gemini AI")

        # Exibi√ß√£o do hist√≥rico de mensagens
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                # Se houver imagem, exiba-a (se armazenada)
                if message.get("image"):
                    st.image(message["image"], use_container_width=True)
                # Exibe o conte√∫do da mensagem (texto)
                st.markdown(message["content"])

        # Adiciona indicador de digita√ß√£o quando estiver processando
        if st.session_state.processing:
            with st.chat_message("assistant"):
                st.markdown("Gerando resposta...")

        # Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
        if not st.session_state.processing:
            # Verifica se h√° uma imagem dispon√≠vel
            current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

            # Adapta o placeholder com base na presen√ßa de imagem
            if current_image:
                placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
            else:
                placeholder = "Digite sua mensagem..."

            # Verifica se h√° um comando de voz
            if st.session_state.get('voice_command'):
                user_input = st.session_state.voice_command
                st.session_state.voice_command = None  # Limpa o comando
                self.process_message(user_input, current_image)
            else:
                user_input = st.chat_input(placeholder)

                if user_input:
                    # Processa a mensagem com a imagem (se houver) ou apenas texto
                    self.process_message(user_input, current_image)
        else:
            st.chat_input("Aguarde o processamento...", disabled=True)


if __name__ == "__main__":
    app = ChatApp()
    app.run()

# chat_app\config\config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent

    ASSETS_DIR = BASE_DIR / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR / "processed_images"
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"

    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"

    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"

    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"

    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}

    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR,
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py
from chat_app.services.gpt_services import GenerativeModelHandler
from chat_app.core.logger_config import logger
from chat_app.core.rate_limiter import RateLimiter

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py
import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py
import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0]
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py
from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from chat_app.config.config import Config
import os
from chat_app.core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from chat_app.core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py
import os
import time
import shutil
import json
from chat_app.config.config import Config
from chat_app.services.gpt_services import GenerativeModelHandler
from chat_app.services.document_service import DocumentService
from chat_app.services.markdown_service import MarkdownService
from chat_app.utils.file_utils import list_images
from chat_app.core.logger_config import logger
from chat_app.core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(
2025-04-10 20:13:35,444 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:13:35,446 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:13:35,449 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:13:35,452 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:13:35,455 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:13:35,457 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:13:35,460 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:13:35,462 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:13:35,464 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:13:35,467 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:13:35,468 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:13:35,469 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:13:35,471 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:13:35,472 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:13:35,474 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:13:35,475 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:13:35,476 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:13:35,478 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:13:35,480 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:13:35,482 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:13:35,484 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:13:35,486 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:13:35,487 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:13:35,489 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:13:35,491 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:13:35,492 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:13:35,494 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:13:35,497 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:13:35,499 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:13:35,501 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:13:35,503 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:13:35,505 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:13:35,507 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:13:35,508 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:13:35,510 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:13:35,512 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:13:35,513 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:13:35,515 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:13:35,517 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:13:35,519 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:13:35,521 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:13:35,522 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:13:35,524 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:13:35,526 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:13:35,528 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:13:35,529 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:13:35,532 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:13:35,534 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:13:35,535 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:13:35,536 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:13:35,537 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:13:35,539 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:13:35,540 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:13:35,542 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:16:50,210 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:16:50,211 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:16:50,213 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:16:50,214 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:16:50,216 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:16:50,218 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:16:50,220 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:16:50,222 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:16:50,223 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:16:50,225 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:16:50,226 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:16:50,228 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:16:50,230 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:16:50,231 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:16:50,233 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:16:50,236 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:16:50,238 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:16:50,239 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:16:50,240 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:16:50,241 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:16:50,243 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:16:50,245 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:16:50,261 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:16:50,263 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:16:50,267 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:16:50,275 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:16:50,276 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:16:50,277 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:16:50,278 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:16:50,280 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:16:50,281 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:16:50,282 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:16:50,284 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:16:50,286 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:16:50,288 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:16:50,290 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:16:50,291 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:16:50,292 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:16:50,294 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:16:50,295 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:16:50,297 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:16:50,298 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:16:50,300 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:16:50,303 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:16:50,305 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:16:50,307 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:16:50,309 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:16:50,311 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:16:50,313 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:16:50,315 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:16:50,317 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:16:50,320 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:16:50,323 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:16:50,325 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:16:50,448 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:16:50,452 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:16:50,455 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:16:50,458 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:16:50,462 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:16:50,464 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:16:50,466 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:16:50,468 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:16:50,470 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:16:50,472 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:16:50,474 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:16:50,476 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:16:50,477 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:16:50,479 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:16:50,480 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:16:50,482 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:16:50,484 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:16:50,486 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:16:50,488 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:16:50,490 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:16:50,492 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:16:50,493 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:16:50,495 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:16:50,496 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:16:50,499 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:16:50,501 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:16:50,503 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:16:50,505 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:16:50,507 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:16:50,508 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:16:50,509 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:16:50,511 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:16:50,512 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:16:50,514 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:16:50,515 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:16:50,517 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:16:50,520 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:16:50,522 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:16:50,524 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:16:50,525 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:16:50,526 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:16:50,528 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:16:50,529 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:16:50,530 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:16:50,532 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:16:50,534 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:16:50,536 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:16:50,538 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:16:50,540 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:16:50,542 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:16:50,543 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:16:50,544 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:16:50,546 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:16:50,547 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:16:50,551 [INFO] Enviando para IA - Prompt (sem imagem): Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas.

Contexto:



# app_config\app_config.py

from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()
    
    def get_root_path(self):
        return str(self.ROOT_PATH)
    
    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py

from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        transcription_config = TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])


# audio_to_text\audio_to_text.py

import whisper
from audio_to_text.audio_config.audio_config import AudioConfig

class AudioToConverter:
    def __init__(self, audio_config: AudioConfig):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.AUDIO_INPUT_PATH
        self.TRANSCRIPTION_INPUT_PATH = audio_config.TRANSCRIPTION_INPUT_PATH

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            print(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        model = whisper.load_model("base")

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                print(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            print(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            print(f"Erro ao processar o arquivo {audio_file_path}: {e}")


# chat_app\chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# chat_app\config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# chat_app\services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# chat_app\services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# chat_app\services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# chat_app\utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

# common_paths\common_paths.py

from pathlib import Path

class CommonPaths:
    def __init__(self):
        # Diret√≥rio atual do script
        self.ROOT_PATH = Path(__file__).resolve().parent

        # Defini√ß√£o dos caminhos comuns
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'output'
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.AUDIO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.TRANSCRIPTION_OUTPUT_PATH = self.ROOT_PATH / 'data'
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'data'

        # Cria√ß√£o dos diret√≥rios
        self.create_directories()

    def create_directories(self):
        self.VIDEO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.VIDEO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.TRANSCRIPTION_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)



# fundamentus_api\fundamentus\__init__.py



# fundamentus_api\fundamentus\dados_b3.py

import locale
import pandas as pd
import streamlit as st
import requests
import fundamentus
import os
import plotly.express as px
from bs4 import BeautifulSoup
from fundamentus.detalhes import get_papel
import logging

# Configura localidade
locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')

# Configura√ß√£o do layout do Streamlit
st.set_page_config(
    page_title="An√°lise de A√ß√µes",
    layout="wide",
    page_icon="üìà"
)

class Acao:
    def __init__(self, papel):
        self.papel = papel
        self.dados_fundamentais = None
        self.proventos = None
        self.detalhes = None
        self.oscilacoes = None  # Adicionando um atributo para oscila√ß√µes

    def carregar_dados_fundamentais(self):
        self.dados_fundamentais = fundamentus.get_resultado().loc[[self.papel]]  # Use colchetes duplos para garantir que seja um DataFrame
        self.remover_formatacao()

    def obter_detalhes(self):
        self.detalhes = get_papel(self.papel)
        if self.detalhes is None or self.detalhes.empty:
            logging.warning(f"Nenhum detalhe encontrado para o papel: {self.papel}")

    def obter_proventos(self):
        url = f"https://www.fundamentus.com.br/proventos.php?papel={self.papel}&tipo=2"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        tabela = soup.find('table', {'id': 'resultado'})

        if not tabela:
            return pd.DataFrame()

        dados = []
        for linha in tabela.find_all('tr')[1:]:
            colunas = linha.find_all('td')
            try:
                valor = float(colunas[1].text.strip().replace(',', '.'))
            except ValueError:
                valor = None  # Se der erro, coloca None para evitar crash

            dados.append([colunas[0].text.strip(), valor, colunas[2].text.strip()])
        
        self.proventos = pd.DataFrame(dados, columns=['Data', 'Valor', 'Tipo'])
        return self.proventos

    def obter_oscilacoes(self):
        url = f"https://www.fundamentus.com.br/detalhes.php?papel={self.papel}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        conteudo_div = soup.find('div', class_='conteudo clearfix')

        if conteudo_div is None:
            return pd.DataFrame()

        oscilacoes_data = []
        oscilacoes_section = conteudo_div.find('td', class_='nivel1', colspan='2')
        
        if oscilacoes_section:
            labels = oscilacoes_section.find_all_next('td', class_='label w1')
            dados = oscilacoes_section.find_all_next('td', class_='data w1')

            for label, dado in zip(labels, dados):
                label_text = label.get_text(strip=True)
                valor_text = dado.find('span', class_='oscil').get_text(strip=True)
                oscilacoes_data.append([label_text, valor_text])

        self.oscilacoes = pd.DataFrame(oscilacoes_data, columns=['Per√≠odo', 'Oscila√ß√£o'])
        return self.oscilacoes

    def remover_formatacao(self):
        colunas_percentuais = ['dy', 'mrgebit', 'mrgliq', 'roic', 'roe', 'c5y']
        for coluna in colunas_percentuais:
            if coluna in self.dados_fundamentais:
                try:
                    self.dados_fundamentais[coluna] = self.dados_fundamentais[coluna].astype(float)
                except ValueError as e:
                    logging.error(f"Erro ao converter coluna {coluna} para float: {e}")

    def formatar_moeda(self, valor):
        return locale.currency(valor, symbol=True, grouping=True)

class Aplicacao:
    def __init__(self):
        self.acoes = fundamentus.get_resultado()

    def ajustar_tipos_dataframe(self, df):
        for coluna in df.columns:
            if df[coluna].dtype == 'object':
                try:
                    df[coluna] = df[coluna].astype(float)
                except ValueError:
                    df[coluna] = df[coluna].astype(str)
            elif df[coluna].dtype in ['int64', 'float64']:
                df[coluna] = df[coluna].astype(float)
        return df

    def exibir_dashboard(self):
        st.sidebar.title("üìä Dashboard de An√°lise de A√ß√µes")
        st.sidebar.write("Selecione um papel para visualizar detalhes.")

        papel_selecionado = st.sidebar.selectbox("Escolha uma a√ß√£o", self.acoes.index)

        acao = Acao(papel_selecionado)
        acao.carregar_dados_fundamentais()
        acao.obter_proventos()
        acao.obter_detalhes()
        acao.obter_oscilacoes()

        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader(f"üìå Dados Fundamentais - {papel_selecionado}")
            dados_fundamentais_df = self.ajustar_tipos_dataframe(acao.dados_fundamentais.T)
            st.dataframe(dados_fundamentais_df, width=400)

        with col2:
            st.subheader("üîç Detalhes")
            if acao.detalhes is not None and not acao.detalhes.empty:
                detalhes_df = pd.DataFrame(acao.detalhes).T.reset_index()
                detalhes_df.columns = ['Descri√ß√£o', 'Valor']
                detalhes_df = self.ajustar_tipos_dataframe(detalhes_df)

                st.subheader("Tabela de Detalhes")
                st.dataframe(detalhes_df, width=800)
            else:
                st.warning("Nenhum detalhe encontrado para essa a√ß√£o.")

        col_dividendos, col_oscilacoes = st.columns([1, 2])

        with col_dividendos:
            st.subheader("üí∞ Dividendos")
            if not acao.proventos.empty:
                proventos_df = self.ajustar_tipos_dataframe(acao.proventos)
                st.write(proventos_df)

        with col_oscilacoes:
            st.subheader("üìâ Oscila√ß√µes")
            if acao.oscilacoes is not None and not acao.oscilacoes.empty:
                oscilacoes_df = self.ajustar_tipos_dataframe(acao.oscilacoes)
                st.write(oscilacoes_df)

        st.subheader("üìà Tabela Geral de A√ß√µes")
        st.dataframe(self.acoes)

# Execu√ß√£o
if __name__ == "__main__":
    app = Aplicacao()
    app.exibir_dashboard()

# fundamentus_api\setup.py

from setuptools import setup, find_packages

setup(
    name='fundamentalvision ',
    version='0.1.0',
    author='Joel FerreiraHeanna dos Reis',
    author_email='heannareis@gmail.com',
    description='Um pacote para an√°lise fundamentalista de a√ß√µes da Bolsa B3 do Brasil.',
    packages=find_packages(),
    install_requires=[
        'pandas',
        'requests',
        'beautifulsoup4',
        'streamlit',
        'plotly',
        'fundamentus'
    ],
    classifiers=[
        'Programming Language :: Python :: 3',
        'License :: OSI Approved :: MIT License',
        'Operating System :: OS Independent',
    ],
    python_requires='>=3.6',
)

# ia_generator.py

import requests
from pathlib import Path
import webbrowser
from config.common_paths import TRANSCRIPTION_OUTPUT_PATH

apiKey = "6UlOOoY/kkmprunma/qNDg"

str_personas = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'personas.txt'
str_contexto = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'contexto.txt'

url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

txt_files = list(TRANSCRIPTION_OUTPUT_PATH.glob('*.txt'))

css_styles = """
<style>
body {
    font-family: Arial, sans-serif;
    margin: 20px;
}

h1, h2, h3 {
    color: #FF8C00;
}

li, strong, p {
    color: #008000;
}

h1 {
    font-size: 24px;
    margin-bottom: 20px;
}

h2 {
    font-size: 20px;
    margin-top: 20px;
    margin-bottom: 10px;
}

ul {
    list-style-type: disc;
    margin-left: 40px;
}

li {
    margin-bottom: 10px;
}

p {
    line-height: 1.6;
}
</style>
"""

if not txt_files:
    print(f"N√£o foram encontrados arquivos .txt no diret√≥rio {TRANSCRIPTION_OUTPUT_PATH}.")
else:
    for txt_file in txt_files:
        if txt_file.is_file():
            print(f"Lendo o arquivo: {txt_file.name}")
            with open(txt_file, 'r', encoding='utf-8') as file:
                str_reuniao = file.read()

            print(f"Enviando o conte√∫do do arquivo {txt_file.name} para a API...")
            data = {
                "inputs": {
                    "str_reuniao": str_reuniao,
                    "str_personas": str_personas.read_text(encoding='utf-8'),
                    "str_contexto": str_contexto.read_text(encoding='utf-8'),
                }
            }

            response = requests.post(f"{url}/api/templates/668de04202493d3063a9d7fa/execute", json=data, headers=headers)
            if response.status_code == 200:
                print(f"Resultado para o arquivo {txt_file.name} recebido.")
                html_content = response.text
                print(response.text)

                # Incluir o CSS no conte√∫do HTML
                html_with_css = f"<html><head>{css_styles}</head><body>{html_content}</body></html>"

                # Salvar o conte√∫do HTML em um arquivo
                output_file = TRANSCRIPTION_OUTPUT_PATH / f"{txt_file.stem}_output.html"
                with open(output_file, 'w', encoding='utf-8') as html_file:
                    html_file.write(html_with_css)

                # Abrir o arquivo HTML no navegador
                webbrowser.open(f"file://{output_file.resolve()}")
            else:
                print(f"Erro ao processar o arquivo {txt_file.name}: {response.status_code}")


# main.py

from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from transcriptions.transcriptions_config import TranscriptionConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from pathlib import Path

def main():
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    root_path = str(PROJECT_ROOT)
    print(f"Root path: {root_path}")  # Para verificar se est√° correto
    api_url = "http://localhost:8081/api/meetings/transcriptions"
    
    # # Configura√ß√£o de v√≠deos
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()
    
    # # Configura√ß√£o de √°udios
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()
    
    # # Processamento de transcri√ß√µes e envio de embeddings
    # embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    # embedding_processor_wrapper.process_transcriptions()

if __name__ == "__main__":
    main()


# send_embeddings_database\embedding_config\embedding_config.py

from app_config.app_config import AppConfig

class EmbeddingConfig(AppConfig):
    def __init__(self, root_path=None, transcription_input_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = transcription_input_path
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'embeddings' / 'output'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH, self.EMBEDDING_OUTPUT_PATH])


# send_embeddings_database\verify_last_enbedding.py

import os
import numpy as np

def get_latest_file(directory):
    # Listar todos os arquivos no diret√≥rio
    files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]
    
    if not files:
        raise FileNotFoundError("Nenhum arquivo encontrado no diret√≥rio.")

    # Encontrar o arquivo mais recente
    latest_file = max(files, key=os.path.getmtime)
    return latest_file

def load_and_print_embedding(directory):
    # Obter o caminho do √∫ltimo arquivo de embedding
    embedding_file_path = get_latest_file(directory)
    
    # Carregar o embedding
    embedding = np.load(embedding_file_path)
    
    # Exibir o conte√∫do do embedding
    print("Embedding carregado:")
    print(embedding)
    print("Dimens√µes do embedding:", embedding.shape)

# Caminho do diret√≥rio de embeddings
embedding_directory = 'C:/Users/HeannarReis/Documents/bsa_atacadao/assets/embeddings/output'

# Carregar e exibir o √∫ltimo embedding
load_and_print_embedding(embedding_directory)


# test_whisper.py

from transformers import pipeline
from common_paths import CommonPaths

commmom_paths = CommonPaths()

# Fun√ß√£o para ler a transcri√ß√£o de um arquivo
def read_transcription(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
    return lines

# Fun√ß√£o para converter a pontua√ß√£o em estrelas
def score_to_stars(score):
    if score >= 0.75:
        return 5
    elif score >= 0.55:
        return 4
    elif score >= 0.35:
        return 3
    elif score >= 0.15:
        return 2
    else:
        return 1

# Inicializar o pipeline de an√°lise de sentimento
sentiment_pipeline = pipeline("sentiment-analysis", model="neuralmind/bert-base-portuguese-cased")

# Caminho para o arquivo de transcri√ß√£o
file_path = commmom_paths.TRANSCRIPTION_OUTPUT_PATH / 'feedback.txt'

# Ler a transcri√ß√£o
lines = read_transcription(file_path)

# Analisar sentimento para cada feedback
for line in lines:
    sentiment = sentiment_pipeline(line.strip())
    score = sentiment[0]['score']
    stars = score_to_stars(score)
    
    # Ajuste manual para feedbacks com aspectos positivos e negativos
    if any(word in line.lower() for word in ["mas", "por√©m", "no entanto"]):
        stars = max(1, stars - 1)  # Reduz uma estrela se houver contradi√ß√£o
    
    # Ajuste adicional baseado em palavras-chave
    positive_keywords = ["excelente", "√≥timo", "perfeito", "r√°pido", "eficiente", "satisfeito", "clara", "eficaz", "bom trabalho"]
    negative_keywords = ["ruim", "p√©ssimo", "horr√≠vel", "poderia", "n√£o resolveu", "insatisfat√≥ria", "confusa", "inadequado", "lento", "n√£o houve seguimento", "n√£o atendeu", "n√£o funcionou", "demorado"]
    
    positive_count = sum(word in line.lower() for word in positive_keywords)
    negative_count = sum(word in line.lower() for word in negative_keywords)
    
    # Ajuste de estrelas baseado na contagem de palavras-chave
    if positive_count > negative_count:
        stars = min(5, stars + 1)
    elif negative_count > positive_count:
        stars = max(1, stars - 1)
    
    print(f"Texto: {line.strip()}")
    print(f"Sentimento: {stars} estrelas")
    print(f"Pontua√ß√£o: {score:.2f}")
    print('---')


# text_to_embedding\embedding_processing.py

from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from transcriptions.transcriptions_config import TranscriptionConfig
from transcriptions.transciption_sender_database import TranscriptionSenderDatabase

class EmbeddingProcessorWrapper:
    def __init__(self, root_path, api_url):
        # Configura√ß√£o de transcri√ß√µes e embeddings
        transcription_config = TranscriptionConfig(root_path=root_path)
        embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())

        self.embedding_processor = EmbeddingProcessor(embedding_config)
        self.transcription_sender = TranscriptionSenderDatabase(api_url)
    
    def process_transcriptions(self):
        # Mostrar o diret√≥rio onde est√° procurando as transcri√ß√µes
        print(f"Diret√≥rio de entrada das transcri√ß√µes: {self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH}")
        
        # Listar todos os arquivos de transcri√ß√£o no diret√≥rio de entrada
        transcription_files = list(self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH.glob('*.txt'))
        if not transcription_files:
            print("Nenhum arquivo de transcri√ß√£o encontrado.")
        for transcription_file_path in transcription_files:
            if transcription_file_path.is_file():
                print(f"Processando arquivo: {transcription_file_path}")
                self.process_and_send_transcription(transcription_file_path)
            else:
                print(f"Arquivo n√£o encontrado: {transcription_file_path}")

    def process_and_send_transcription(self, transcription_file_path):
        try:
            # Ler a transcri√ß√£o do arquivo de texto
            with open(transcription_file_path, 'r', encoding='utf-8') as f:
                transcription_text = f.read()
                if not transcription_text:
                    print(f"Arquivo {transcription_file_path} est√° vazio.")
                    return

            # Gerar o embedding da transcri√ß√£o
            embedding = self.embedding_processor.generate_embedding(transcription_text)
            if embedding is None:
                print(f"Falha ao gerar embedding para o arquivo {transcription_file_path}.")
                return

            # Salvar o embedding em um arquivo .npy
            self.embedding_processor.save_embedding(transcription_file_path, embedding)

            # Enviar os dados para a API
            self.transcription_sender.send_transcription(transcription_text, embedding)

        except Exception as e:
            print(f"Erro ao processar o arquivo {transcription_file_path}: {e}")


# text_to_embedding\texto_to_embedding.py

from sentence_transformers import SentenceTransformer
import numpy as np

class EmbeddingProcessor:
    def __init__(self, embedding_config):
        self.embedding_config = embedding_config
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

    def generate_embedding(self, transcription_text):
        return self.embedding_model.encode(transcription_text)

    def save_embedding(self, transcription_file_path, embedding):
        embedding_file_path = self.embedding_config.EMBEDDING_OUTPUT_PATH / transcription_file_path.with_suffix('.npy').name
        np.save(embedding_file_path, embedding)
        print(f"Embedding salvo em: {embedding_file_path}")
        return embedding_file_path


# transcriptions\transciption_sender_database.py

import requests

class TranscriptionSenderDatabase:
    def __init__(self, api_url):
        self.api_url = api_url

    def send_transcription(self, transcription_text, embedding):
        data = {
            'transcriptionText': transcription_text,
            'embedding': embedding.tolist()
        }

        response = requests.post(self.api_url, json=data)

        if response.status_code == 201:
            print("Transcri√ß√£o e embedding enviados com sucesso.")
        else:
            print(f"Erro ao enviar dados: {response.status_code}")
            print("Resposta da API:")
            print(response.text)


# transcriptions\transcriptions_config.py

from app_config.app_config import AppConfig

class TranscriptionConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = self.ROOT_PATH / 'assets' / 'transcriptions' / 'input'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH])
    
    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# translate\translator_to_english.py

import speech_recognition as sr
from translate import Translator

def ouvir_e_traduzir():
    # Inicializa o reconhecedor de fala
    recognizer = sr.Recognizer()

    # Configura o tradutor
    translator = Translator(to_lang="en", from_lang="pt")

    # Usa o microfone como fonte de √°udio
    with sr.Microphone() as source:
        print("Diga algo em portugu√™s...")

        while True:
            try:
                # Escuta o √°udio do microfone
                audio = recognizer.listen(source)
                
                # Reconhece a fala usando o Google Web Speech API
                texto_portugues = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {texto_portugues}")

                # Traduz o texto para o ingl√™s
                traducao = translator.translate(texto_portugues)
                print(f"Tradu√ß√£o para o ingl√™s: {traducao}")

            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio")
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")

if __name__ == "__main__":
    try:
        ouvir_e_traduzir()
    except KeyboardInterrupt:
        print("Interrompido pelo usu√°rio")


# translate\whispert_translator.py

import whisper
import pyaudio
import numpy as np

# Inicializa o modelo Whisper
model = whisper.load_model("base")

# Configura√ß√µes de √°udio
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024

# Inicializa o PyAudio
audio = pyaudio.PyAudio()

# Abre o stream de √°udio
stream = audio.open(format=FORMAT, channels=CHANNELS,
                    rate=RATE, input=True,
                    frames_per_buffer=CHUNK)

print("Diga algo em portugu√™s...")

try:
    audio_buffer = []

    while True:
        # L√™ dados do microfone
        data = stream.read(CHUNK)
        audio_buffer.append(np.frombuffer(data, dtype=np.int16).flatten().astype(np.float32) / 32768.0)

        # Processa o √°udio a cada 5 segundos
        if len(audio_buffer) * CHUNK / RATE >= 5:
            audio_data = np.concatenate(audio_buffer)
            audio_buffer = []

            # Transcreve e traduz o √°udio usando Whisper
            result = model.transcribe(audio_data, task="translate", language="pt")

            # Exibe a tradu√ß√£o
            print(f"Tradu√ß√£o para o ingl√™s: {result['text']}")

except KeyboardInterrupt:
    print("Interrompido pelo usu√°rio")

    # Fecha o stream de √°udio
    stream.stop_stream()
    stream.close()
    audio.terminate()


# video_to_audio\video_config\video_config.py

from app_config.app_config import AppConfig

class VideoConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video' / 'input'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.create_directories([self.VIDEO_INPUT_PATH, self.VIDEO_OUTPUT_PATH])

# video_to_audio\video_to_audio.py

from moviepy import VideoFileClip
import glob
import os
from .video_config.video_config import VideoConfig

class VideoToAudioConverter:
    def __init__(self, video_config: VideoConfig):
        self.video_config = video_config

    def convert_video_to_audio(self, video_path, audio_path):
        try:
            video = VideoFileClip(video_path)
            if video.audio:
                video.audio.write_audiofile(audio_path, fps=44100)
                print(f"Convertido {video_path} para {audio_path}")
            else:
                print(f"Aviso: O v√≠deo {video_path} n√£o cont√©m √°udio!")
        except Exception as e:
            print(f"Erro ao converter {video_path}: {e}")

    def process_videos(self):
        input_directory = self.video_config.VIDEO_INPUT_PATH
        output_directory = self.video_config.VIDEO_OUTPUT_PATH

        os.makedirs(output_directory, exist_ok=True)

        # Busca qualquer arquivo de v√≠deo (formatos comuns)
        video_files = glob.glob(os.path.join(input_directory, "*.*"))  # Pega todos os arquivos

        # Filtra apenas arquivos de v√≠deo
        video_extensions = {".mp4", ".mkv", ".avi", ".mov", ".wmv", ".flv"}  
        video_files = [f for f in video_files if os.path.splitext(f)[1].lower() in video_extensions]

        if not video_files:
            print(f"Nenhum arquivo de v√≠deo encontrado em: {input_directory}")
            return

        for video_file in video_files:
            base_name = os.path.basename(video_file)
            audio_file = os.path.join(output_directory, os.path.splitext(base_name)[0] + ".wav")
            self.convert_video_to_audio(video_file, audio_file)

        print("Convers√£o de v√≠deo para √°udio conclu√≠da!")


# voice_assistent\assistent.py

import speech_recognition as sr
import pyttsx3
import re
from collections import deque
import spacy
import requests
import os
import webbrowser
from class_voice_assistent.prompt import create_prompt
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import google.generativeai as genai

# Configura√ß√µes da API
handler = genai('gemini-1.5-flash')

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

voices = engine.getProperty('voices')
engine.setProperty('rate', 180)
print("\nLista de Vozes...")
for indice, vozes in enumerate(voices):
    print(indice, vozes.name)

voz = 1
engine.setProperty('voice', voices[voz].id)

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

# Fun√ß√£o para extrair texto de HTML
def extract_text_from_html(html):
    if not html.strip().startswith('<'):
        print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
        return html
    soup = BeautifulSoup(html, 'html.parser')
    text = ' '.join([p.get_text() for p in soup.find_all('p')])
    return text

def get_text_response(prompt, context, feedback):
    # Gere o conte√∫do com base no prompt usando a classe GenerativeModelHandler
    response = handler.generate_content(prompt)
    return response

# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/api/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


# voice_assistent\class_voice_assistent\api_client.py

import requests


class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, meeting):
        try:
            response_text = self.model.generate_content(prompt, context, meeting)
            return response_text
        except Exception as e:
            print(f"Erro inesperado: {e}")
            return None

    def find_similar_embeddings(self, embedding):
        try:
            print(f"Buscando embeddings similares para: {embedding}")
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            similar_embeddings = response.json()

            # Ordenar por similaridade (assumindo que a API retorna com similaridade em ordem decrescente)
            # Remover duplicatas baseadas na pergunta
            seen_questions = set()
            unique_embeddings = []
            for embedding in similar_embeddings:
                question = embedding['question'].strip().lower()
                if question not in seen_questions:
                    unique_embeddings.append(embedding)
                    seen_questions.add(question)
            print(f"Embeddings similares √∫nicos encontrados: {unique_embeddings}")
            return unique_embeddings
        except requests.RequestException as e:
            print(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            # Converter embeddings de numpy arrays para listas
            if hasattr(question_embedding, 'tolist'):
                question_embedding = question_embedding.tolist()
            if hasattr(answer_embedding, 'tolist'):
                answer_embedding = answer_embedding.tolist()
            
            data = {
                "question": question,
                "questionEmbedding": question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding
            }
            
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                print("Pergunta e resposta salvas com sucesso.")
            else:
                print(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            print(f"Erro em save_question_answer: {e}")


    def fetch_all_contexts(self):
        try:
            response = requests.get("http://localhost:8081/api/contexts/all")
            if response.status_code == 200:
                data = response.json()
                contexts = data.get('contexts', [])
                if isinstance(contexts, list):
                    print(f"Contexto obtido da API: {contexts}")
                    return contexts
                else:
                    print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                    return []
            else:
                print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
                return []
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
            return []

    def fetch_last_meeting(self):
        try:
            response = requests.get("http://localhost:8081/api/meetings/last")
            if response.status_code == 200:
                data = response.json()
                transcription_text = data.get('transcriptionText', "")
                if isinstance(transcription_text, str):
                    print(f"Texto da transcri√ß√£o obtido da API: {transcription_text}")
                    return transcription_text
                else:
                    print(f"Erro: 'transcriptionText' n√£o √© uma string. Dados retornados: {data}")
                    return ""
            else:
                print(f"Erro ao acessar a API de reuni√µes: {response.status_code}, {response.text}")
                return ""
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de reuni√µes: {e}")
            return ""


# voice_assistent\class_voice_assistent\command_interpreter.py

import spacy
from prompt_generator.online_prompt import OnlineResearchPromptGenerator
from prompt_generator.meeting_prompt import MeetingPromptGenerator
from prompt_generator.default_prompt_generator import DefaultPromptGenerator
import re

# Carregar o modelo de linguagem natural
nlp = spacy.load("pt_core_news_sm")

class CommandInterpreter:
    def __init__(self, api_client, question_answer_service, context_manager, max_similar=3):
        self.api_client = api_client
        self.question_answer_service = question_answer_service
        self.context_manager = context_manager
        self.max_similar = max_similar  # Limite de contextos similares

    def interpret_command(self, command, meeting):
        print(f"Interpretando comando: {command}")
        contexts = self.api_client.fetch_all_contexts()
        context_str = "\n".join([context['context'] for context in contexts])

        # Gerar embedding para a pergunta e buscar embeddings similares
        question_embedding = self.question_answer_service.convert_text_to_embedding(command)
        similar_embeddings = self.api_client.find_similar_embeddings(question_embedding)

        # Filtrar para evitar respostas redundantes
        unique_responses = self._filter_unique_responses(similar_embeddings, command)
        similar_context = "\n".join([f"Pergunta: {embedding['question']}\nResposta: {embedding['answer']}" for embedding in unique_responses[:self.max_similar]])

        # Detectar tipo de comando usando regex
        if re.search(r'\b(pesquise|pesquisar|procure)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como pesquisa online.")
            response = self.get_online_research_response(command, context_str, similar_context)
        elif re.search(r'\b(contexto)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como busca de contexto.")
            response = self.get_project_response(command, meeting, context_str, similar_context)
        elif re.search(r'\b(resumo?|t√≥picos da|pontos (relevantes|principais)|an√°lise)\b.*\b(reuni√£o|√∫ltima (reuni√£o|conversa|sess√£o))\b', command, re.IGNORECASE):
            print(f"\nComando identificado como an√°lise de reuni√£o.")
            meeting = self.api_client.fetch_last_meeting()
            response = self.get_meeting_analysis_response(command, context_str, meeting)
        else:
            print(f"\nComando identificado como comando padr√£o.")
            response = self.handle_default_command(command, context_str, meeting, similar_context)

        if response:
            answer_embedding = self.question_answer_service.convert_text_to_embedding(response)
            self.api_client.save_question_answer(command, question_embedding, response, answer_embedding)
            self.context_manager.add_context(command, response)

        return response

    def _filter_unique_responses(self, similar_embeddings, current_command):
        """
        Filtra respostas semelhantes que s√£o muito similares ao comando atual para evitar redund√¢ncia.
        """
        filtered = []
        for embedding in similar_embeddings:
            if embedding['question'].lower() != current_command.lower():
                filtered.append(embedding)
        return filtered

    def handle_default_command(self, command, context_str, meeting, similar_context):
        print(f"\nTratando comando padr√£o: {command}")
        # Combinar o contexto atual com os contextos similares para enriquecer a resposta
        combined_context = f"{context_str}\n{similar_context}"
        prompt = DefaultPromptGenerator().generate_prompt(command, combined_context, meeting)
        response = self.api_client.get_text_response(prompt, combined_context, meeting)
        return response

    # M√©todos get_project_response, get_meeting_analysis_response, get_online_research_response permanecem inalterados

    def get_project_response(self, command, meeting, context_str, similar_context):
        print(f"\nGerando prompt de projeto.")
        prompt = DefaultPromptGenerator().generate_prompt(command, context_str, meeting, similar_context)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_meeting_analysis_response(self, command, context_str, meeting):
        print(f"\nGerando prompt de an√°lise de reuni√£o.")
        prompt = MeetingPromptGenerator().generate_prompt(command, context_str, meeting)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_online_research_response(self, command, context_str, similar_context):
        print(f"\nGerando prompt de pesquisa online.")
        prompt = OnlineResearchPromptGenerator().generate_prompt(command, context_str, similar_context)
        return self.api_client.get_text_response(prompt, context_str, None)


# voice_assistent\class_voice_assistent\context_manager.py

from collections import deque

class ContextManager:
    def __init__(self, maxlen=10):
        self.recent_context = deque(maxlen=maxlen)

    def add_context(self, command, response):
        self.recent_context.append((command, response))

    def get_context(self):
        return "\n".join([context for context, _ in self.recent_context])


# voice_assistent\class_voice_assistent\conversation_history.py



# voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py

import requests
import logging
import google.generativeai as genai

# Configure o logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, feedback):
        try:
            # Gerando o conte√∫do usando a nova API
            response = self.model.generate_content(prompt)
            if response and hasattr(response, 'text'):
                return prompt, response.text
            else:
                logger.error("Resposta inv√°lida da API")
                return prompt, None
        except Exception as e:
            logger.error(f"Erro em get_text_response: {e}")
            return prompt, None

    def find_similar_embeddings(self, embedding):
        try:
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            logger.info(f"Enviando dados para a API de embeddings similares: {data}")
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            logger.error(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            data = {
                "question": question,
                "questionEmbedding": question_embedding.tolist() if hasattr(question_embedding, 'tolist') else question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding.tolist() if hasattr(answer_embedding, 'tolist') else answer_embedding
            }
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                logger.info("Pergunta e resposta salvas com sucesso.")
            else:
                logger.warning(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            logger.error(f"Erro em save_question_answer: {e}")


# voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py

import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        """Carregar vari√°veis do arquivo .env"""
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        """Configurar a chave da API"""
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        """Inicializar o modelo generativo"""
        try:
            self.model = genai.GenerativeModel(self.model_name)
        except Exception as e:  
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content(self, prompt: str, context: str, meeting: str) -> str:
        """Gerar conte√∫do com base no prompt, contexto e reuni√£o"""
        try:
            # Supondo que a API espera um dicion√°rio com os par√¢metros
            request_data = f'''
                "prompt": {prompt},
                "context": {context},
                "meeting": {meeting}
            '''
            print(f"Enviando requisi√ß√£o para a API GenAI: {request_data}")

            response = self.model.generate_content(request_data)
            return response.text
        except Exception as e:
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py

import os
from dotenv import load_dotenv
from groq import Groq

# Carregar vari√°veis do arquivo .env
load_dotenv()

# Recuperar a chave da API
api_key = os.getenv("GROQ_API_KEY")

# Verificar se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API Key is missing. Please set the GROQ_API_KEY in the .env file.")

# Configurar o cliente com a chave da API
client = Groq(api_key=api_key)

# Cria√ß√£o da conclus√£o do chat
chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "De acordo com nossas conversas anteriores, o que voc√™ acha do meu uso de IA ?",
        }
    ],
    model="llama3-8b-8192",
)

print(chat_completion.choices[0].message.content)


# voice_assistent\class_voice_assistent\main.py

import os
from context_manager import ContextManager
from api_client import APIClient
from command_interpreter import CommandInterpreter
from text_command_hendler import TextCommandHandler
from text_processor import TextProcessor
from text_to_speech import TextToSpeech
from voice_command_hendler import VoiceCommandHandler
from question_answers_service import QuestionAnswerService
from gpt_communication.gemini_gpt import GenerativeModelHandler

class MainApp:
    def __init__(self, model):
        self.voice_handler = VoiceCommandHandler()
        self.text_handler = TextCommandHandler()
        self.tts = TextToSpeech()
        self.text_processor = TextProcessor()
        self.api_client = APIClient(
            similarity_url="http://localhost:8081",
            save_url="http://localhost:8081/api/question_answers/save",
            model=model
        )
        self.context_manager = ContextManager()
        self.question_answer_service = QuestionAnswerService()
        self.command_interpreter = CommandInterpreter(
            self.api_client,
            self.question_answer_service,
            self.context_manager
        )

    def handle_command(self, command, meeting=""):
        if command:
            print(f"Pergunta recebida: {command}")
            text_response = self.command_interpreter.interpret_command(command, meeting)
            if text_response:
                print(f"Resposta: {text_response}")
                self.tts.speak_text(text_response)
                self.context_manager.add_context(command, text_response)
                return text_response
        else:
            print("Nenhum comando detectado.")
            return None

    def run(self):
        meeting = ""
        while True:
            try:
                input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
                if input_type == 'v':
                    command = self.voice_handler.capture_voice_command()
                elif input_type == 't':
                    command = self.text_handler.capture_text_command()
                else:
                    print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
                    continue

                response = self.handle_command(command, meeting)
                if response:
                    print(f"Resposta: {response}")
            except Exception as e:
                print(f"Ocorreu um erro: {e}")

if __name__ == "__main__":
    model = GenerativeModelHandler('gemini-1.5-flash')
    app = MainApp(model)
    app.run()

# voice_assistent\class_voice_assistent\prompt.py

def create_prompt(command, context, meeting):
    keywords = ["fa√ßa um resumo da √∫ltima reuni√£o.", "t√≥picos da √∫ltima reuni√£o", "resuma a √∫ltima reuni√£o", "pesquise", "pesquisar", "procure"]
    if any(keyword in command.lower() for keyword in keywords):
        return f"""
        Regras de Meeting:
        - Voc√™ √© respons√°vel por analisar, debater, sugerir e informar melhorias.
        - Resuma de forma clara e Objetiva.
        - N√£o acrescentar t√≠tulo nas respostas.

        [context]: {context}
        -------
        [meeting]: {meeting}
        -------
        [str_texto]: {command}
        """
    else:
        return f"""
        [context]: {context}
        -------
        [str_texto]: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py

class DefaultPromptGenerator:
    def generate_prompt(self, command, combined_context, meeting):
        prompt = (
            f"Comando: {command}\n"
            f"Contexto Anterior:\n{combined_context}\n"
            f"Baseie sua resposta nas informa√ß√µes acima e forne√ßa uma solu√ß√£o detalhada."
        )
        return prompt

# voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class MeetingPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting):
        return f"""
        Regras de Meeting com respostas inteligentes:
        - Responda a pergunta de [str_texto] com base nas diretrizes abaixo...
            - Voc√™ √© respons√°vel analisar com detalhes a reuni√£o de [str_meeting], e fornecer uma longa est√≥ria sobre o assunto.
            - observe os nomes das personas mencionadas no texto de meeting para aprender e melhorar a precis√£o da resposta.
            - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [str_texto]: Responda a pergunta de: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class OnlineResearchPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting, similar_context):
        return f"""
        Regras de Pesquisa Online Inteligente:
        - Utilize similar_context e fa√ßa uma pesquisa online para uma resposta mais precisa das quest√µes de [str_text]
        - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [context]: Regras B√°sicas {context}
        ------
        [similar_context]:
        Perguntas e respostas anteriores.{similar_context}
        ------
        [str_texto]: Responda seguinte pergunta: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py

from abc import ABC, abstractmethod

class PromptGenerator(ABC):
    @abstractmethod
    def generate_prompt(self, command, context, meeting, similar_context):
        pass

# voice_assistent\class_voice_assistent\question_answers_service.py

import requests
import numpy as np
from sentence_transformers import SentenceTransformer

class QuestionAnswerService:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.embedding_model = SentenceTransformer(model_name)

    def convert_text_to_embedding(self, text):
        embedding = self.embedding_model.encode(text)
        #print(f"Embedding gerado para '{text}': {embedding[0]:.16f}") # Adicionado para verificar o embedding gerado
        return embedding


# voice_assistent\class_voice_assistent\text_command_hendler.py

class TextCommandHandler:
    def capture_text_command(self):
        command = input("Digite o seu comando: ")
        return command


# voice_assistent\class_voice_assistent\text_processor.py

from bs4 import BeautifulSoup

class TextProcessor:
    def extract_values_from_json(self, data):
        if isinstance(data, dict):
            return ' '.join([str(value) for value in data.values()])
        elif isinstance(data, list):
            return ' '.join([self.extract_values_from_json(item) for item in data])
        return str(data)

    def extract_text_from_html(self, html):
        if not html.strip().startswith('<'):
            print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
            return html
        soup = BeautifulSoup(html, 'html.parser')
        text = ' '.join([p.get_text() for p in soup.find_all('p')])
        return text


# voice_assistent\class_voice_assistent\text_to_speech.py

import pyttsx3

class TextToSpeech:
    def __init__(self):
        self.engine = pyttsx3.init()

    def speak_text(self, text):
        cleaned_text = self.clean_text(text)
        self.engine.say(cleaned_text)
        self.engine.runAndWait()

    def clean_text(self, text):
        import re
        return re.sub(r'[\*\_\#]', '', text)


# voice_assistent\class_voice_assistent\voice_command_hendler.py

import speech_recognition as sr

class VoiceCommandHandler:
    def capture_voice_command(self):
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            print("Por favor, fale o seu comando:")
            try:
                audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
                print("√Åudio capturado com sucesso.")
                command = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {command}")
                return command
            except sr.WaitTimeoutError:
                print("Tempo de espera expirado. Nenhum √°udio detectado.")
                return None
            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio.")
                return None
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
                return None


# voice_assistent\config.py

# config.py
import pyttsx3
import spacy
from collections import deque

class APIConfig:
    apiKey = "API_KEY"
    url = "https://gpt-templates.saiapplications.com"
    headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")


# voice_assistent\template.py

import speech_recognition as sr
import requests
import pyttsx3
import re
from collections import deque
import spacy
import os
import webbrowser
from voice_assistent.prompt import create_prompt

# Configura√ß√µes da API
apiKey = "6UlOOoY/kkmprunma/qNDg"
url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    if isinstance(text, dict):
        text = extract_values_from_json(text)  # Extrai os valores do dicion√°rio
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

def get_text_response(prompt, context, feedback):
    data = {
        "inputs": {
            "str_texto": prompt,
            "str_contexto": context,
            "str_feedback": feedback
        }
    }
    print(f"Enviando dados para a API: {data}")
    try:
        response = requests.post(f"{url}/api/templates/6691e223802f95c2b394a8bd/execute", json=data, headers=headers)
        print(f"Status da resposta: {response.status_code}")
        if response.status_code == 200:
            try:
                response_data = response.html()  # Tente converter a resposta para JSON
                print("Resposta HTML recebida.")
                return extract_values_from_json(response_data)  # Extrai os valores do JSON
            except ValueError:
                print("A resposta n√£o est√° no formato JSON esperado. Tratando como texto simples.")
                return response.text  # Retorna o texto bruto da resposta
        else:
            print(f"Erro ao acessar a API: {response.status_code}, {response.text}")
            return None
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API: {e}")
        return None

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)


# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


User: Como posso integrar todas as aplica√ß√µes para funcionar em uma √∫nica MAIN.py ?

Streamlit. Chat de voz. converter v√≠deo para audio e audio para texto e depois salvar no banco de dados.
Assistant: Para integrar todas as aplica√ß√µes em um √∫nico `main.py`, voc√™ precisa modularizar seu c√≥digo existente e usar uma estrutura central que coordene a execu√ß√£o das diferentes partes (Streamlit chat de voz, convers√£o de v√≠deo para √°udio, √°udio para texto e salvamento no banco de dados).

Aqui est√° um esbo√ßo de como voc√™ pode abordar isso, com √™nfase na organiza√ß√£o e coordena√ß√£o das tarefas:

```python
# main.py

import streamlit as st
import os
from pathlib import Path

# Importar as fun√ß√µes e classes de cada m√≥dulo
from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from voice_assistent.class_voice_assistent.main import MainApp
from voice_assistent.class_voice_assistent.gpt_communication.gemini_gpt import GenerativeModelHandler
from transcriptions.transcriptions_config import TranscriptionConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from config.config import Config
from core.rate_limiter import RateLimiter

# 1. Configura√ß√£o Inicial
PROJECT_ROOT = Path(__file__).resolve().parent
root_path = str(PROJECT_ROOT)
print(f"Root path: {root_path}")

Config.ensure_directories()

# 2. Fun√ß√µes de Processamento
def process_videos():
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()

def process_audio():
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()

def process_transcriptions_and_embeddings(api_url):
    transcription_config = TranscriptionConfig(root_path=root_path)
    embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())
    embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    embedding_processor_wrapper.process_transcriptions()

# 3. Interface Streamlit
def main():
    st.title("Aplica√ß√µes Integradas")

    # 3.1. Sidebar com op√ß√µes
    app_mode = st.sidebar.selectbox(
        "Escolha a aplica√ß√£o:",
        ["Chat de Voz", "Converter V√≠deo para √Åudio", "Converter √Åudio para Texto", "Enviar Embeddings para o Banco de Dados"]
    )

    # 3.2. L√≥gica para cada aplica√ß√£o
    if app_mode == "Chat de Voz":
        st.header("Chat de Voz")
        model = GenerativeModelHandler('gemini-1.5-flash')
        app = MainApp(model)
        app.run()

    elif app_mode == "Converter V√≠deo para √Åudio":
        st.header("Converter V√≠deo para √Åudio")
        if st.button("Converter V√≠deos"):
            process_videos()
            st.success("V√≠deos convertidos para √°udio com sucesso!")

    elif app_mode == "Converter √Åudio para Texto":
        st.header("Converter √Åudio para Texto")
        if st.button("Converter √Åudios"):
            process_audio()
            st.success("√Åudios convertidos para texto com sucesso!")

    elif app_mode == "Enviar Embeddings para o Banco de Dados":
        st.header("Enviar Embeddings para o Banco de Dados")
        api_url = st.text_input("URL da API para enviar as transcri√ß√µes:", "http://localhost:8081/api/meetings/transcriptions")

        if st.button("Enviar Embeddings"):
            process_transcriptions_and_embeddings(api_url)
            st.success("Embeddings enviados para o banco de dados com sucesso!")

# 4. Execu√ß√£o Principal
if __name__ == "__main__":
    main()
```

### Estrutura do Projeto

-   **`main.py`**: Este √© o ponto de entrada. Ele usa Streamlit para criar uma interface que permite selecionar qual parte da aplica√ß√£o executar.

-   **`video_to_audio/`**, **`audio_to_text/`**, **`text_to_embedding/`**, **`voice_assistent/`**: Esses diret√≥rios cont√™m o c√≥digo existente de cada parte da sua aplica√ß√£o.

### Passos para Implementar

1.  **Modulariza√ß√£o:**

    *   Certifique-se de que cada parte da sua aplica√ß√£o (convers√£o de v√≠deo, convers√£o de √°udio, chat de voz) esteja bem encapsulada em fun√ß√µes ou classes reutiliz√°veis.
    *   Mova essas fun√ß√µes e classes para os respectivos m√≥dulos (arquivos `.py` dentro de seus diret√≥rios).

2.  **Integra√ß√£o no `main.py`:**

    *   Importe as fun√ß√µes e classes dos m√≥dulos.
    *   Use Streamlit para criar uma interface que permita ao usu√°rio escolher qual fun√ß√£o executar.
    *   Implemente bot√µes ou seletores para acionar as diferentes partes da aplica√ß√£o.

3.  **Gerenciamento de Depend√™ncias:**

    *   Certifique-se de que todas as depend√™ncias necess√°rias para cada parte da aplica√ß√£o estejam instaladas.  Considere usar um arquivo `requirements.txt` para listar todas as depend√™ncias.

4.  **Testes:**

    *   Teste cada parte da aplica√ß√£o individualmente para garantir que funcionem corretamente.
    *   Teste a integra√ß√£o geral para garantir que as diferentes partes possam ser executadas em sequ√™ncia ou individualmente, conforme necess√°rio.

### Pontos Chave

*   **Modulariza√ß√£o:** Dividir o c√≥digo em m√≥dulos facilita a manuten√ß√£o e reutiliza√ß√£o.
*   **Interface Streamlit:** Streamlit permite criar uma interface web simples para interagir com sua aplica√ß√£o.
*   **Gerenciamento de Estado:** Use `st.session_state` para manter o estado entre as execu√ß√µes da aplica√ß√£o Streamlit (por exemplo, se um v√≠deo foi convertido ou n√£o).
*   **Tratamento de Erros:** Implemente tratamento de erros para lidar com falhas em qualquer parte da aplica√ß√£o e fornecer feedback √∫til ao usu√°rio.
*   **Configura√ß√£o:** Utilize arquivos de configura√ß√£o (como o seu `config.py`) para armazenar caminhos de arquivos, URLs de API e outras configura√ß√µes que podem precisar ser ajustadas.

Seguindo esses passos, voc√™ deve conseguir integrar todas as suas aplica√ß√µes em um √∫nico script `main.py` com uma interface Streamlit para facilitar o uso e a demonstra√ß√£o.

User: observe em src/chat_streamlit que j√° tenho uma aplica√ß√£o que funciona como chat e consegue gerar imagem e ler imagem com OCR... atualmente s√≥ funciona por text .... quero colocar via comando de voz tbm  com a parte da aplica√ß√£o que usa Speech Recoginition
Assistant: Ok, para integrar o comando de voz ao seu `chat_streamlit.py`, voc√™ precisar√° adaptar o c√≥digo existente para incluir a funcionalidade de reconhecimento de voz e direcionar a entrada de voz para as mesmas fun√ß√µes que j√° processam o texto. Aqui est√° um guia passo a passo de como fazer isso:

**1. Importar as Bibliotecas Necess√°rias:**

Adicione as seguintes importa√ß√µes ao topo do seu arquivo `chat_streamlit.py`:

```python
import speech_recognition as sr
import threading
```

**2. Fun√ß√£o para Capturar Comando de Voz:**

Crie uma fun√ß√£o para capturar o comando de voz usando `speech_recognition`. Esta fun√ß√£o ser√° executada em uma thread separada para evitar bloquear a interface do Streamlit.

```python
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.write("Diga algo...")  # Mensagem na interface
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            command = recognizer.recognize_google(audio, language='pt-BR')
            st.write(f"Voc√™ disse: {command}")  # Mostra o comando reconhecido
            return command
        except sr.WaitTimeoutError:
            st.write("Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            st.write("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            st.write(f"Erro ao solicitar resultados: {e}")
            return None
```

**3. Adicionar um Bot√£o para Ativar o Reconhecimento de Voz:**

Adicione um bot√£o na barra lateral para iniciar a captura de voz. Esse bot√£o iniciar√° uma thread que executa a fun√ß√£o `capture_voice_command`.

```python
with st.sidebar:
    # ... (seu c√≥digo existente da barra lateral)

    if st.button("üé§ Usar Comando de Voz"):
        st.session_state.voice_command = None  # Limpa o comando anterior
        st.session_state.voice_thread = threading.Thread(target=lambda: setattr(st.session_state, 'voice_command', capture_voice_command()))
        st.session_state.voice_thread.start()
```

**4. Modificar a L√≥gica de Processamento de Mensagens:**

Modifique a l√≥gica de processamento de mensagens para verificar se h√° um comando de voz capturado. Se houver, use esse comando como entrada para a fun√ß√£o `process_message`.

```python
# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # ... (seu c√≥digo existente para determinar o placeholder)

    # Verifica se um comando de voz foi capturado
    if 'voice_command' in st.session_state and st.session_state.voice_command:
        user_input = st.session_state.voice_command
        process_message(user_input, current_image)
        st.session_state.voice_command = None  # Limpa o comando para n√£o repetir

    else:
        user_input = st.chat_input(placeholder)

        if user_input:
            # Processa a mensagem com a imagem (se houver) ou apenas texto
            process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)
```

**Explica√ß√£o das Modifica√ß√µes:**

*   **`capture_voice_command()`:** Esta fun√ß√£o captura o √°udio do microfone, tenta reconhecer a fala e retorna o comando de texto. Ela tamb√©m exibe mensagens de status na interface do Streamlit.
*   **Bot√£o "üé§ Usar Comando de Voz":** Quando este bot√£o √© clicado, ele cria e inicia uma nova thread que executa a fun√ß√£o `capture_voice_command`.  O resultado do comando de voz √© armazenado em `st.session_state.voice_command`.
*   **L√≥gica de Processamento Modificada:** A se√ß√£o de entrada de texto agora verifica se `st.session_state.voice_command` cont√©m um valor. Se sim, ele usa esse valor como a entrada do usu√°rio e chama `process_message`. Depois, ele limpa `st.session_state.voice_command` para evitar que o comando seja processado novamente.
*   **Thread:** Usar uma thread para a captura de voz √© crucial porque `recognizer.listen()` √© um m√©todo bloqueante. Sem uma thread, a interface do Streamlit ficaria congelada enquanto o √°udio √© capturado.

**Pontos Adicionais:**

*   **Permiss√µes do Microfone:** Certifique-se de que seu navegador tenha permiss√£o para acessar o microfone.
*   **Thread Safety:** Tenha cuidado com a seguran√ßa de threads ao modificar `st.session_state`. Streamlit n√£o √© inerentemente thread-safe, ent√£o evite opera√ß√µes simult√¢neas que possam causar problemas. Usar `setattr` como mostrado √© uma maneira segura de atualizar o estado.
*   **Feedback Visual:** Forne√ßa feedback visual ao usu√°rio para que saiba quando o sistema est√° gravando, processando ou aguardando um comando de voz.

Com estas modifica√ß√µes, seu `chat_streamlit.py` deve ser capaz de capturar comandos de voz e process√°-los da mesma forma que os comandos de texto. Isso adicionar√° a funcionalidade de controle por voz que voc√™ deseja.

User: eu ja tenho uma aplica√ß√£o de comando de voz dentro da pasta voice_assistent.
Assistant: Entendi. Em vez de criar uma nova fun√ß√£o de captura de voz, podemos integrar a sua aplica√ß√£o existente `voice_assistent` ao `chat_streamlit.py`. Isso envolve principalmente reutilizar as fun√ß√µes de captura e interpreta√ß√£o de comandos da sua aplica√ß√£o `voice_assistent` existente e integr√°-las na interface do Streamlit.

Aqui est√£o os passos detalhados:

**1. Importar as Fun√ß√µes Necess√°rias de `voice_assistent`:**

No topo do seu arquivo `chat_streamlit.py`, importe as fun√ß√µes que voc√™ precisa de `voice_assistent.main`:

```python
from voice_assistent.class_voice_assistent.main import MainApp
from voice_assistent.class_voice_assistent.gpt_communication.gemini_gpt import GenerativeModelHandler
import threading
import streamlit as st
```

**2. Inicializar a Aplica√ß√£o `voice_assistent`:**

Voc√™ precisar√° inicializar a aplica√ß√£o `voice_assistent` uma vez, preferencialmente fora do loop principal do Streamlit, para que n√£o seja reinicializada a cada intera√ß√£o.

```python
# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Inicializa a aplica√ß√£o de voz
@st.cache_resource
def get_voice_app():
    model = GenerativeModelHandler('gemini-1.5-flash')
    return MainApp(model)

voice_app = get_voice_app()
```

**3. Modificar o Bot√£o de Comando de Voz:**

Modifique o bot√£o na barra lateral para usar a fun√ß√£o de captura de voz da sua aplica√ß√£o `voice_assistent`. Em vez de criar uma nova thread, voc√™ chamar√° a fun√ß√£o `handle_command` da sua `voice_app` diretamente.

```python
with st.sidebar:
    # ... (seu c√≥digo existente da barra lateral)

    if st.button("üé§ Usar Comando de Voz"):
        st.session_state.voice_command = None  # Limpa o comando anterior
        st.session_state.voice_thread = threading.Thread(target=lambda: setattr(st.session_state, 'voice_command', voice_app.handle_command(voice_app.voice_handler.capture_voice_command())))
        st.session_state.voice_thread.start()
```

**4. Modificar a L√≥gica de Processamento de Mensagens:**

Modifique a l√≥gica de processamento de mensagens para verificar se h√° um comando de voz capturado. Se houver, use esse comando como entrada para a fun√ß√£o `process_message`.

```python
# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # ... (seu c√≥digo existente para determinar o placeholder)

    # Verifica se um comando de voz foi capturado
    if 'voice_command' in st.session_state and st.session_state.voice_command:
        user_input = st.session_state.voice_command
        process_message(user_input, current_image)
        st.session_state.voice_command = None  # Limpa o comando para n√£o repetir

    else:
        user_input = st.chat_input(placeholder)

        if user_input:
            # Processa a mensagem com a imagem (se houver) ou apenas texto
            process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)
```

**Explica√ß√£o das Modifica√ß√µes:**

*   **Importa√ß√£o de `MainApp`:** Importe a classe `MainApp` da sua aplica√ß√£o `voice_assistent`.
*   **Inicializa√ß√£o de `MainApp`:** Inicialize a aplica√ß√£o `MainApp` usando o modelo `GenerativeModelHandler`. Isso deve ser feito apenas uma vez.
*   **Bot√£o "üé§ Usar Comando de Voz":** Quando este bot√£o √© clicado, ele chama `voice_app.run()` para iniciar a captura de voz.
*   **L√≥gica de Processamento Modificada:** A se√ß√£o de entrada de texto agora verifica se `st.session_state.voice_command` cont√©m um valor. Se sim, ele usa esse valor como a entrada do usu√°rio e chama `process_message`. Depois, ele limpa `st.session_state.voice_command` para evitar que o comando seja processado novamente.

**Considera√ß√µes Importantes:**

*   **Cache:** Para garantir que a `MainApp` e o `GenerativeModelHandler` sejam inicializados apenas uma vez, use `@st.cache_resource`. Isso evita a reinicializa√ß√£o a cada intera√ß√£o.
*   **`handle_command`:** A fun√ß√£o `handle_command` deve retornar o texto da resposta. Este texto √© ent√£o usado como entrada para `process_message`.
*   **State Management:** O uso de `st.session_state` permite manter o estado entre as execu√ß√µes da aplica√ß√£o Streamlit.

Com estas modifica√ß√µes, seu `chat_streamlit.py` deve ser capaz de capturar comandos de voz usando a aplica√ß√£o `voice_assistent` e process√°-los da mesma forma que os comandos de texto. Isso adicionar√° a funcionalidade de controle por voz que voc√™ deseja.

User: refatore a minha aplica√ß√£o inteira com as boas pr√°ticas de POO e SOLID.
Assistant: ```python
# app_config\app_config.py
from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()

    def get_root_path(self):
        return str(self.ROOT_PATH)

    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py
from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None, transcription_config=None):
        super().__init__(root_path)
        self.transcription_config = transcription_config if transcription_config else TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = self.transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])

    def get_audio_input_path(self):
        return self.AUDIO_INPUT_PATH

    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# audio_to_text\audio_to_text.py
import whisper
from audio_to_text.audio_config.audio_config import AudioConfig
from abc import ABC, abstractmethod
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class IAudioProcessor(ABC):
    @abstractmethod
    def process_audio_files(self):
        pass

class AudioToConverter(IAudioProcessor):
    def __init__(self, audio_config: AudioConfig, whisper_model_name="base"):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.get_audio_input_path()
        self.TRANSCRIPTION_INPUT_PATH = audio_config.get_transcription_input_path()
        self.model = whisper.load_model(whisper_model_name)
        self.logger = logging.getLogger(__name__)

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            self.logger.info(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                self.logger.info(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, self.model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            self.logger.info(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            self.logger.error(f"Erro ao processar o arquivo {audio_file_path}: {e}", exc_info=True)

# chat_app\chat_streamlit.py
import streamlit as st
import time
from datetime import datetime
from PIL import Image
import os
import io
from dotenv import load_dotenv
import threading  # Importa o m√≥dulo threading
from google import genai
from google.genai import types

# Core Components
from chat_app.config.config import Config
from chat_app.core.handlers.gemini_handler import GeminiHandler
from chat_app.core.rate_limiter import RateLimiter

# Services
from chat_app.services.search_files import ler_todos_arquivos_python

# Submodules (Separadas para melhor organiza√ß√£o)
from chat_app.modules.image_handling import ImageHandler
from chat_app.modules.voice_input import VoiceInputHandler
from chat_app.modules.message_handling import MessageHandler
from chat_app.modules.image_generation import ImageGenerator


class ChatApp:
    def __init__(self):
        load_dotenv()  # Carrega as vari√°veis de ambiente
        Config.ensure_directories()  # Garante que os diret√≥rios necess√°rios existam

        self.rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

        self.gemini_handler = GeminiHandler("gemini-2.0-flash-exp")  # Inicializa GeminiHandler
        self.image_handler = ImageHandler()
        self.voice_input_handler = VoiceInputHandler()
        self.message_handler = MessageHandler()
        self.image_generator = ImageGenerator()

        self.initialize_session_state()
        self.load_chat_prompt()

    def initialize_session_state(self):
        """Inicializa os estados do session_state."""
        default_states = {
            "messages": [],
            "processing": False,
            "uploaded_image": None,
            "clipboard_image_preview": None,
            "clipboard_image_file": None,
            "last_message_time": 0,
            "file_uploader_key": "uploader_0",
            "generated_image": None,
            "image_prompt": None,
            "voice_command": None  # Estado para armazenar comandos de voz
        }

        for key, default_value in default_states.items():
            if key not in st.session_state:
                st.session_state[key] = default_value

    def load_chat_prompt(self):
        """Carrega o prompt do chat e adiciona o contexto do c√≥digo fonte."""
        codigo_fonte = ler_todos_arquivos_python()
        self.chat_prompt = f"{self.load_prompt_from_file()}\n\nContexto:\n\n{codigo_fonte}"

    def load_prompt_from_file(self):
        """Carrega o prompt base do arquivo."""
        try:
            with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
                return file.read().strip()
        except FileNotFoundError:
            return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

    def process_message(self, user_input, image_data=None, generated_image=None):
        """Processa a mensagem do usu√°rio (com ou sem imagem)."""
        st.session_state.processing = True  # Marca como processando para bloquear novos inputs
        st.session_state.current_prompt = user_input
        st.session_state.current_image = image_data
        st.session_state.current_generated_image = generated_image

        st.rerun()  # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento

    def execute_processing(self):
        """Executa o processamento da mensagem."""
        user_input = st.session_state.current_prompt
        image_data = st.session_state.current_image
        generated_image = st.session_state.current_generated_image

        self.rate_limiter.wait_for_slot()  # Garante que n√£o exceda o limite de requisi√ß√µes

        current_time = time.time()
        time_since_last_message = current_time - st.session_state.last_message_time
        wait_time = max(0, 2 - time_since_last_message)
        time.sleep(wait_time)

        st.session_state.last_message_time = time.time()

        img_path = None
        img_display = None

        if image_data:
            img_path, img_display = self.image_handler.save_uploaded_image(image_data)
            st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
        elif generated_image:
            img_path = self.image_handler.save_generated_image(generated_image)
            st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
        else:
            st.session_state.messages.append({"role": "user", "content": user_input})

        self.message_handler.limit_message_history(st.session_state.messages)

        full_prompt = self.chat_prompt + "\n\n"  # Start with the base prompt
        full_prompt = self.message_handler.build_full_prompt(full_prompt, st.session_state.messages, user_input)

        try:
            if img_path:
                response = self.gemini_handler.generate_content(img_path, full_prompt)
            else:
                response = self.gemini_handler.generate_content(None, full_prompt)
        except Exception as e:
            response = f"‚ùå Erro ao gerar resposta: {str(e)}"

        st.session_state.messages.append({"role": "assistant", "content": response})
        self.message_handler.limit_message_history(st.session_state.messages)

        if img_path and os.path.exists(img_path):
            os.remove(img_path)

        st.session_state.processing = False
        st.session_state.current_prompt = None
        st.session_state.current_image = None
        st.session_state.current_generated_image = None

    def run(self):
        """Fun√ß√£o principal para rodar a aplica√ß√£o Streamlit."""
        # Executa o processamento se estiver na fila
        if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
            self.execute_processing()
            st.rerun()

        # Configura√ß√£o da barra lateral
        with st.sidebar:
            st.title("Chat IA Inteligente")

            # Se√ß√£o de gera√ß√£o de imagem
            st.markdown("### Gerar Imagem")
            image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
            if st.button("Gerar Imagem"):
                if image_prompt:
                    generated_image = self.image_generator.generate_image(image_prompt)
                    if generated_image:
                        st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                        st.session_state.generated_image = None  # Limpa para n√£o exibir em cima

                        st.rerun()
                else:
                    st.warning("Por favor, digite um prompt para gerar a imagem.")

            # Se√ß√£o de imagens (sempre vis√≠vel)
            st.markdown("### Adicionar Imagem (Opcional)")
            st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

            # Layout em duas colunas para os bot√µes de imagem
            col1, col2 = st.columns(2)

            with col1:
                # Bot√£o para verificar a √°rea de transfer√™ncia
                if st.button("üìã Colar", use_container_width=True):
                    if self.image_handler.on_paste_click():
                        st.success("Imagem colada!")
                        st.rerun()
                    else:
                        st.warning("Nada encontrado.")

            with col2:
                # Bot√£o para limpar a imagem atual (se houver)
                if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
                    if st.button("üóëÔ∏è Limpar", use_container_width=True):
                        self.image_handler.clear_all_images()
                        st.rerun()
                else:
                    # Placeholder para manter o layout alinhado
                    st.write("")

            # Uploader de imagem com chave din√¢mica
            uploaded_file = st.file_uploader(
                "üì∑ Ou fa√ßa upload de imagem",
                type=["png", "jpg", "jpeg"],
                label_visibility="visible",
                key=st.session_state.file_uploader_key
            )

            # Atualiza o estado da imagem quando um arquivo √© carregado
            if uploaded_file:
                st.session_state.uploaded_image = uploaded_file
                self.image_handler.on_file_upload()
                st.success("Imagem carregada!")

            # Exibe a imagem selecionada na barra lateral
            self.image_handler.display_selected_image()

            st.markdown("---")

             # Adiciona bot√£o para comando de voz
            if st.button("üé§ Usar Comando de Voz"):
                st.session_state.voice_thread = threading.Thread(target=self.voice_input_handler.capture_voice_command)
                st.session_state.voice_thread.start()

            # Bot√£o para limpar o hist√≥rico de conversa
            if st.button("üßπ Limpar conversa", use_container_width=True):
                st.session_state.messages = []
                st.rerun()

            st.caption("Desenvolvido com Streamlit e Gemini AI")

        # Exibi√ß√£o do hist√≥rico de mensagens
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                # Se houver imagem, exiba-a (se armazenada)
                if message.get("image"):
                    st.image(message["image"], use_container_width=True)
                # Exibe o conte√∫do da mensagem (texto)
                st.markdown(message["content"])

        # Adiciona indicador de digita√ß√£o quando estiver processando
        if st.session_state.processing:
            with st.chat_message("assistant"):
                st.markdown("Gerando resposta...")

        # Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
        if not st.session_state.processing:
            # Verifica se h√° uma imagem dispon√≠vel
            current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

            # Adapta o placeholder com base na presen√ßa de imagem
            if current_image:
                placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
            else:
                placeholder = "Digite sua mensagem..."

            # Verifica se h√° um comando de voz
            if st.session_state.get('voice_command'):
                user_input = st.session_state.voice_command
                st.session_state.voice_command = None  # Limpa o comando
                self.process_message(user_input, current_image)
            else:
                user_input = st.chat_input(placeholder)

                if user_input:
                    # Processa a mensagem com a imagem (se houver) ou apenas texto
                    self.process_message(user_input, current_image)
        else:
            st.chat_input("Aguarde o processamento...", disabled=True)


if __name__ == "__main__":
    app = ChatApp()
    app.run()

# chat_app\config\config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent

    ASSETS_DIR = BASE_DIR / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR / "processed_images"
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"

    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"

    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"

    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"

    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}

    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR,
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py
from chat_app.services.gpt_services import GenerativeModelHandler
from chat_app.core.logger_config import logger
from chat_app.core.rate_limiter import RateLimiter

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py
import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py
import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0]
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py
from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from chat_app.config.config import Config
import os
from chat_app.core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from chat_app.core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py
import os
import time
import shutil
import json
from chat_app.config.config import Config
from chat_app.services.gpt_services import GenerativeModelHandler
from chat_app.services.document_service import DocumentService
from chat_app.services.markdown_service import MarkdownService
from chat_app.utils.file_utils import list_images
from chat_app.core.logger_config import logger
from chat_app.core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(
User: Preciso garantir que seja enviado todo o c√≥digo e preciso eliminar partes redundantes e dispens√°veis sem perder funcionalidades.
2025-04-10 20:17:18,218 [INFO] Resposta da IA (texto): Ok, aqui est√° a refatora√ß√£o do c√≥digo com boas pr√°ticas de POO e SOLID, eliminando redund√¢ncias e garantindo que todas as funcionalidades sejam mantidas. O c√≥digo foi estruturado para melhorar a organiza√ß√£o e facilitar a manuten√ß√£o.

```python
# app_config\app_config.py
from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()

    def get_root_path(self):
        return str(self.ROOT_PATH)

    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py
from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None, transcription_config=None):
        super().__init__(root_path)
        self.transcription_config = transcription_config if transcription_config else TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = self.transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])

    def get_audio_input_path(self):
        return self.AUDIO_INPUT_PATH

    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# audio_to_text\audio_to_text.py
import whisper
from audio_to_text.audio_config.audio_config import AudioConfig
from abc import ABC, abstractmethod
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class IAudioProcessor(ABC):
    @abstractmethod
    def process_audio_files(self):
        pass

class AudioToConverter(IAudioProcessor):
    def __init__(self, audio_config: AudioConfig, whisper_model_name="base"):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.get_audio_input_path()
        self.TRANSCRIPTION_INPUT_PATH = audio_config.get_transcription_input_path()
        self.model = whisper.load_model(whisper_model_name)
        self.logger = logging.getLogger(__name__)

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            self.logger.info(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                self.logger.info(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, self.model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            self.logger.info(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            self.logger.error(f"Erro ao processar o arquivo {audio_file_path}: {e}", exc_info=True)

# chat_app\chat_streamlit.py
import streamlit as st
import time
from datetime import datetime
from PIL import Image
import os
import io
from dotenv import load_dotenv
import threading  # Importa o m√≥dulo threading
from google import genai
from google.genai import types

# Core Components
from chat_app.config.config import Config
from chat_app.core.handlers.gemini_handler import GeminiHandler
from chat_app.core.rate_limiter import RateLimiter

# Services
from chat_app.services.search_files import ler_todos_arquivos_python

# Submodules (Separadas para melhor organiza√ß√£o)
from chat_app.modules.image_handling import ImageHandler
from chat_app.modules.voice_input import VoiceInputHandler
from chat_app.modules.message_handling import MessageHandler
from chat_app.modules.image_generation import ImageGenerator


class ChatApp:
    def __init__(self):
        load_dotenv()  # Carrega as vari√°veis de ambiente
        Config.ensure_directories()  # Garante que os diret√≥rios necess√°rios existam

        self.rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

        self.gemini_handler = GeminiHandler("gemini-2.0-flash-exp")  # Inicializa GeminiHandler
        self.image_handler = ImageHandler(self)  # Passa a inst√¢ncia de ChatApp
        self.voice_input_handler = VoiceInputHandler(self)  # Passa a inst√¢ncia de ChatApp
        self.message_handler = MessageHandler()
        self.image_generator = ImageGenerator()

        self.initialize_session_state()
        self.load_chat_prompt()

    def initialize_session_state(self):
        """Inicializa os estados do session_state."""
        default_states = {
            "messages": [],
            "processing": False,
            "uploaded_image": None,
            "clipboard_image_preview": None,
            "clipboard_image_file": None,
            "last_message_time": 0,
            "file_uploader_key": "uploader_0",
            "generated_image": None,
            "image_prompt": None,
            "voice_command": None  # Estado para armazenar comandos de voz
        }

        for key, default_value in default_states.items():
            if key not in st.session_state:
                st.session_state[key] = default_value

    def load_chat_prompt(self):
        """Carrega o prompt do chat e adiciona o contexto do c√≥digo fonte."""
        codigo_fonte = ler_todos_arquivos_python()
        self.chat_prompt = f"{self.load_prompt_from_file()}\n\nContexto:\n\n{codigo_fonte}"

    def load_prompt_from_file(self):
        """Carrega o prompt base do arquivo."""
        try:
            with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
                return file.read().strip()
        except FileNotFoundError:
            return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

    def process_message(self, user_input, image_data=None, generated_image=None):
        """Processa a mensagem do usu√°rio (com ou sem imagem)."""
        st.session_state.processing = True  # Marca como processando para bloquear novos inputs
        st.session_state.current_prompt = user_input
        st.session_state.current_image = image_data
        st.session_state.current_generated_image = generated_image

        st.rerun()  # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento

    def execute_processing(self):
        """Executa o processamento da mensagem."""
        user_input = st.session_state.current_prompt
        image_data = st.session_state.current_image
        generated_image = st.session_state.current_generated_image

        self.rate_limiter.wait_for_slot()  # Garante que n√£o exceda o limite de requisi√ß√µes

        current_time = time.time()
        time_since_last_message = current_time - st.session_state.last_message_time
        wait_time = max(0, 2 - time_since_last_message)
        time.sleep(wait_time)

        st.session_state.last_message_time = time.time()

        img_path = None
        img_display = None

        if image_data:
            img_path, img_display = self.image_handler.save_uploaded_image(image_data)
            st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
        elif generated_image:
            img_path = self.image_handler.save_generated_image(generated_image)
            st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
        else:
            st.session_state.messages.append({"role": "user", "content": user_input})

        self.message_handler.limit_message_history(st.session_state.messages)

        full_prompt = self.chat_prompt + "\n\n"  # Start with the base prompt
        full_prompt = self.message_handler.build_full_prompt(full_prompt, st.session_state.messages, user_input)

        try:
            if img_path:
                response = self.gemini_handler.generate_content(img_path, full_prompt)
            else:
                response = self.gemini_handler.generate_content(None, full_prompt)
        except Exception as e:
            response = f"‚ùå Erro ao gerar resposta: {str(e)}"

        st.session_state.messages.append({"role": "assistant", "content": response})
        self.message_handler.limit_message_history(st.session_state.messages)

        if img_path and os.path.exists(img_path):
            os.remove(img_path)

        st.session_state.processing = False
        st.session_state.current_prompt = None
        st.session_state.current_image = None
        st.session_state.current_generated_image = None

    def run(self):
        """Fun√ß√£o principal para rodar a aplica√ß√£o Streamlit."""
        # Executa o processamento se estiver na fila
        if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
            self.execute_processing()
            st.rerun()

        # Configura√ß√£o da barra lateral
        with st.sidebar:
            st.title("Chat IA Inteligente")

            # Se√ß√£o de gera√ß√£o de imagem
            st.markdown("### Gerar Imagem")
            image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
            if st.button("Gerar Imagem"):
                if image_prompt:
                    generated_image = self.image_generator.generate_image(image_prompt)
                    if generated_image:
                        st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                        st.session_state.generated_image = None  # Limpa para n√£o exibir em cima

                        st.rerun()
                else:
                    st.warning("Por favor, digite um prompt para gerar a imagem.")

            # Se√ß√£o de imagens (sempre vis√≠vel)
            st.markdown("### Adicionar Imagem (Opcional)")
            st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

            # Layout em duas colunas para os bot√µes de imagem
            col1, col2 = st.columns(2)

            with col1:
                # Bot√£o para verificar a √°rea de transfer√™ncia
                if st.button("üìã Colar", use_container_width=True):
                    if self.image_handler.on_paste_click():
                        st.success("Imagem colada!")
                        st.rerun()
                    else:
                        st.warning("Nada encontrado.")

            with col2:
                # Bot√£o para limpar a imagem atual (se houver)
                if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
                    if st.button("üóëÔ∏è Limpar", use_container_width=True):
                        self.image_handler.clear_all_images()
                        st.rerun()
                else:
                    # Placeholder para manter o layout alinhado
                    st.write("")

            # Uploader de imagem com chave din√¢mica
            uploaded_file = st.file_uploader(
                "üì∑ Ou fa√ßa upload de imagem",
                type=["png", "jpg", "jpeg"],
                label_visibility="visible",
                key=st.session_state.file_uploader_key
            )

            # Atualiza o estado da imagem quando um arquivo √© carregado
            if uploaded_file:
                st.session_state.uploaded_image = uploaded_file
                self.image_handler.on_file_upload()
                st.success("Imagem carregada!")

            # Exibe a imagem selecionada na barra lateral
            self.image_handler.display_selected_image()

            st.markdown("---")

            # Adiciona bot√£o para comando de voz
            if st.button("üé§ Usar Comando de Voz"):
                st.session_state.voice_thread = threading.Thread(target=self.voice_input_handler.capture_voice_command)
                st.session_state.voice_thread.start()

            # Bot√£o para limpar o hist√≥rico de conversa
            if st.button("üßπ Limpar conversa", use_container_width=True):
                st.session_state.messages = []
                st.rerun()

            st.caption("Desenvolvido com Streamlit e Gemini AI")

        # Exibi√ß√£o do hist√≥rico de mensagens
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                # Se houver imagem, exiba-a (se armazenada)
                if message.get("image"):
                    st.image(message["image"], use_container_width=True)
                # Exibe o conte√∫do da mensagem (texto)
                st.markdown(message["content"])

        # Adiciona indicador de digita√ß√£o quando estiver processando
        if st.session_state.processing:
            with st.chat_message("assistant"):
                st.markdown("Gerando resposta...")

        # Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
        if not st.session_state.processing:
            # Verifica se h√° uma imagem dispon√≠vel
            current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

            # Adapta o placeholder com base na presen√ßa de imagem
            if current_image:
                placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
            else:
                placeholder = "Digite sua mensagem..."

            # Verifica se h√° um comando de voz
            if st.session_state.get('voice_command'):
                user_input = st.session_state.voice_command
                st.session_state.voice_command = None  # Limpa o comando
                self.process_message(user_input, current_image)
            else:
                user_input = st.chat_input(placeholder)

                if user_input:
                    # Processa a mensagem com a imagem (se houver) ou apenas texto
                    self.process_message(user_input, current_image)
        else:
            st.chat_input("Aguarde o processamento...", disabled=True)


if __name__ == "__main__":
    app = ChatApp()
    app.run()

# chat_app\config\config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent

    ASSETS_DIR = BASE_DIR / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR / "processed_images"
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"

    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"

    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"

    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"

    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}

    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR,
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py
from chat_app.services.gpt_services import GenerativeModelHandler
from chat_app.core.logger_config import logger
from chat_app.core.rate_limiter import RateLimiter

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py
import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py
import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0]
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py
from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from chat_app.config.config import Config
import os
from chat_app.core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from chat_app.core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py
import os
import time
import shutil
import json
from chat_app.config.config import Config
from chat_app.services.gpt_services import GenerativeModelHandler
from chat_app.services.document_service import DocumentService
from chat_app.services.markdown_service import MarkdownService
from chat_app.utils.file_utils import list_images
from chat_app.core.logger_config import logger
from chat_app.core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response
2025-04-10 20:17:18,453 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:17:18,455 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:17:18,456 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:17:18,458 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:17:18,461 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:17:18,463 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:17:18,465 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:17:18,467 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:17:18,470 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:17:18,472 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:17:18,474 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:17:18,476 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:17:18,478 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:17:18,480 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:17:18,481 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:17:18,483 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:17:18,485 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:17:18,487 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:17:18,489 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:17:18,492 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:17:18,494 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:17:18,495 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:17:18,498 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:17:18,500 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:17:18,503 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:17:18,506 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:17:18,508 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:17:18,511 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:17:18,513 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:17:18,516 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:17:18,519 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:17:18,522 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:17:18,525 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:17:18,527 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:17:18,529 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:17:18,532 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:17:18,533 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:17:18,535 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:17:18,537 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:17:18,540 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:17:18,542 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:17:18,544 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:17:18,546 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:17:18,548 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:17:18,550 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:17:18,552 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:17:18,554 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:17:18,557 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:17:18,559 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:17:18,560 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:17:18,562 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:17:18,564 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:17:18,566 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:17:18,568 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:20:56,602 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:20:56,604 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:20:56,606 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:20:56,607 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:20:56,609 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:20:56,611 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:20:56,612 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:20:56,614 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:20:56,616 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:20:56,618 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:20:56,621 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:20:56,622 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:20:56,625 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:20:56,627 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:20:56,629 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:20:56,631 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:20:56,632 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:20:56,633 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:20:56,635 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:20:56,636 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:20:56,638 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:20:56,639 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:20:56,640 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:20:56,642 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:20:56,644 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:20:56,646 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:20:56,648 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:20:56,649 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:20:56,650 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:20:56,652 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:20:56,654 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:20:56,656 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:20:56,657 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:20:56,660 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:20:56,663 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:20:56,665 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:20:56,667 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:20:56,669 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:20:56,671 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:20:56,672 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:20:56,673 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:20:56,674 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:20:56,676 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:20:56,678 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:20:56,680 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:20:56,681 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:20:56,683 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:20:56,684 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:20:56,686 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:20:56,687 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:20:56,688 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:20:56,690 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:20:56,693 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:20:56,695 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:20:56,821 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:20:56,825 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:20:56,828 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:20:56,831 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:20:56,834 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:20:56,836 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:20:56,837 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:20:56,839 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:20:56,840 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:20:56,843 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:20:56,845 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:20:56,847 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:20:56,848 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:20:56,849 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:20:56,851 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:20:56,853 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:20:56,854 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:20:56,855 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:20:56,857 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:20:56,859 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:20:56,861 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:20:56,863 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:20:56,864 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:20:56,866 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:20:56,868 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:20:56,869 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:20:56,871 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:20:56,873 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:20:56,874 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:20:56,876 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:20:56,878 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:20:56,880 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:20:56,882 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:20:56,883 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:20:56,885 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:20:56,887 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:20:56,888 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:20:56,889 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:20:56,890 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:20:56,899 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:20:56,904 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:20:56,910 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:20:56,913 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:20:56,916 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:20:56,919 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:20:56,920 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:20:56,922 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:20:56,923 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:20:56,924 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:20:56,926 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:20:56,928 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:20:56,929 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:20:56,931 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:20:56,932 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:20:56,935 [INFO] Enviando para IA - Prompt (sem imagem): Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas.

Contexto:



# app_config\app_config.py

from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()
    
    def get_root_path(self):
        return str(self.ROOT_PATH)
    
    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py

from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        transcription_config = TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])


# audio_to_text\audio_to_text.py

import whisper
from audio_to_text.audio_config.audio_config import AudioConfig

class AudioToConverter:
    def __init__(self, audio_config: AudioConfig):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.AUDIO_INPUT_PATH
        self.TRANSCRIPTION_INPUT_PATH = audio_config.TRANSCRIPTION_INPUT_PATH

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            print(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        model = whisper.load_model("base")

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                print(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            print(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            print(f"Erro ao processar o arquivo {audio_file_path}: {e}")


# chat_app\chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# chat_app\config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# chat_app\services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# chat_app\services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# chat_app\services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# chat_app\utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

# common_paths\common_paths.py

from pathlib import Path

class CommonPaths:
    def __init__(self):
        # Diret√≥rio atual do script
        self.ROOT_PATH = Path(__file__).resolve().parent

        # Defini√ß√£o dos caminhos comuns
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'output'
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.AUDIO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.TRANSCRIPTION_OUTPUT_PATH = self.ROOT_PATH / 'data'
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'data'

        # Cria√ß√£o dos diret√≥rios
        self.create_directories()

    def create_directories(self):
        self.VIDEO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.VIDEO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.TRANSCRIPTION_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)



# fundamentus_api\fundamentus\__init__.py



# fundamentus_api\fundamentus\dados_b3.py

import locale
import pandas as pd
import streamlit as st
import requests
import fundamentus
import os
import plotly.express as px
from bs4 import BeautifulSoup
from fundamentus.detalhes import get_papel
import logging

# Configura localidade
locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')

# Configura√ß√£o do layout do Streamlit
st.set_page_config(
    page_title="An√°lise de A√ß√µes",
    layout="wide",
    page_icon="üìà"
)

class Acao:
    def __init__(self, papel):
        self.papel = papel
        self.dados_fundamentais = None
        self.proventos = None
        self.detalhes = None
        self.oscilacoes = None  # Adicionando um atributo para oscila√ß√µes

    def carregar_dados_fundamentais(self):
        self.dados_fundamentais = fundamentus.get_resultado().loc[[self.papel]]  # Use colchetes duplos para garantir que seja um DataFrame
        self.remover_formatacao()

    def obter_detalhes(self):
        self.detalhes = get_papel(self.papel)
        if self.detalhes is None or self.detalhes.empty:
            logging.warning(f"Nenhum detalhe encontrado para o papel: {self.papel}")

    def obter_proventos(self):
        url = f"https://www.fundamentus.com.br/proventos.php?papel={self.papel}&tipo=2"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        tabela = soup.find('table', {'id': 'resultado'})

        if not tabela:
            return pd.DataFrame()

        dados = []
        for linha in tabela.find_all('tr')[1:]:
            colunas = linha.find_all('td')
            try:
                valor = float(colunas[1].text.strip().replace(',', '.'))
            except ValueError:
                valor = None  # Se der erro, coloca None para evitar crash

            dados.append([colunas[0].text.strip(), valor, colunas[2].text.strip()])
        
        self.proventos = pd.DataFrame(dados, columns=['Data', 'Valor', 'Tipo'])
        return self.proventos

    def obter_oscilacoes(self):
        url = f"https://www.fundamentus.com.br/detalhes.php?papel={self.papel}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        conteudo_div = soup.find('div', class_='conteudo clearfix')

        if conteudo_div is None:
            return pd.DataFrame()

        oscilacoes_data = []
        oscilacoes_section = conteudo_div.find('td', class_='nivel1', colspan='2')
        
        if oscilacoes_section:
            labels = oscilacoes_section.find_all_next('td', class_='label w1')
            dados = oscilacoes_section.find_all_next('td', class_='data w1')

            for label, dado in zip(labels, dados):
                label_text = label.get_text(strip=True)
                valor_text = dado.find('span', class_='oscil').get_text(strip=True)
                oscilacoes_data.append([label_text, valor_text])

        self.oscilacoes = pd.DataFrame(oscilacoes_data, columns=['Per√≠odo', 'Oscila√ß√£o'])
        return self.oscilacoes

    def remover_formatacao(self):
        colunas_percentuais = ['dy', 'mrgebit', 'mrgliq', 'roic', 'roe', 'c5y']
        for coluna in colunas_percentuais:
            if coluna in self.dados_fundamentais:
                try:
                    self.dados_fundamentais[coluna] = self.dados_fundamentais[coluna].astype(float)
                except ValueError as e:
                    logging.error(f"Erro ao converter coluna {coluna} para float: {e}")

    def formatar_moeda(self, valor):
        return locale.currency(valor, symbol=True, grouping=True)

class Aplicacao:
    def __init__(self):
        self.acoes = fundamentus.get_resultado()

    def ajustar_tipos_dataframe(self, df):
        for coluna in df.columns:
            if df[coluna].dtype == 'object':
                try:
                    df[coluna] = df[coluna].astype(float)
                except ValueError:
                    df[coluna] = df[coluna].astype(str)
            elif df[coluna].dtype in ['int64', 'float64']:
                df[coluna] = df[coluna].astype(float)
        return df

    def exibir_dashboard(self):
        st.sidebar.title("üìä Dashboard de An√°lise de A√ß√µes")
        st.sidebar.write("Selecione um papel para visualizar detalhes.")

        papel_selecionado = st.sidebar.selectbox("Escolha uma a√ß√£o", self.acoes.index)

        acao = Acao(papel_selecionado)
        acao.carregar_dados_fundamentais()
        acao.obter_proventos()
        acao.obter_detalhes()
        acao.obter_oscilacoes()

        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader(f"üìå Dados Fundamentais - {papel_selecionado}")
            dados_fundamentais_df = self.ajustar_tipos_dataframe(acao.dados_fundamentais.T)
            st.dataframe(dados_fundamentais_df, width=400)

        with col2:
            st.subheader("üîç Detalhes")
            if acao.detalhes is not None and not acao.detalhes.empty:
                detalhes_df = pd.DataFrame(acao.detalhes).T.reset_index()
                detalhes_df.columns = ['Descri√ß√£o', 'Valor']
                detalhes_df = self.ajustar_tipos_dataframe(detalhes_df)

                st.subheader("Tabela de Detalhes")
                st.dataframe(detalhes_df, width=800)
            else:
                st.warning("Nenhum detalhe encontrado para essa a√ß√£o.")

        col_dividendos, col_oscilacoes = st.columns([1, 2])

        with col_dividendos:
            st.subheader("üí∞ Dividendos")
            if not acao.proventos.empty:
                proventos_df = self.ajustar_tipos_dataframe(acao.proventos)
                st.write(proventos_df)

        with col_oscilacoes:
            st.subheader("üìâ Oscila√ß√µes")
            if acao.oscilacoes is not None and not acao.oscilacoes.empty:
                oscilacoes_df = self.ajustar_tipos_dataframe(acao.oscilacoes)
                st.write(oscilacoes_df)

        st.subheader("üìà Tabela Geral de A√ß√µes")
        st.dataframe(self.acoes)

# Execu√ß√£o
if __name__ == "__main__":
    app = Aplicacao()
    app.exibir_dashboard()

# fundamentus_api\setup.py

from setuptools import setup, find_packages

setup(
    name='fundamentalvision ',
    version='0.1.0',
    author='Joel FerreiraHeanna dos Reis',
    author_email='heannareis@gmail.com',
    description='Um pacote para an√°lise fundamentalista de a√ß√µes da Bolsa B3 do Brasil.',
    packages=find_packages(),
    install_requires=[
        'pandas',
        'requests',
        'beautifulsoup4',
        'streamlit',
        'plotly',
        'fundamentus'
    ],
    classifiers=[
        'Programming Language :: Python :: 3',
        'License :: OSI Approved :: MIT License',
        'Operating System :: OS Independent',
    ],
    python_requires='>=3.6',
)

# ia_generator.py

import requests
from pathlib import Path
import webbrowser
from config.common_paths import TRANSCRIPTION_OUTPUT_PATH

apiKey = "6UlOOoY/kkmprunma/qNDg"

str_personas = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'personas.txt'
str_contexto = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'contexto.txt'

url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

txt_files = list(TRANSCRIPTION_OUTPUT_PATH.glob('*.txt'))

css_styles = """
<style>
body {
    font-family: Arial, sans-serif;
    margin: 20px;
}

h1, h2, h3 {
    color: #FF8C00;
}

li, strong, p {
    color: #008000;
}

h1 {
    font-size: 24px;
    margin-bottom: 20px;
}

h2 {
    font-size: 20px;
    margin-top: 20px;
    margin-bottom: 10px;
}

ul {
    list-style-type: disc;
    margin-left: 40px;
}

li {
    margin-bottom: 10px;
}

p {
    line-height: 1.6;
}
</style>
"""

if not txt_files:
    print(f"N√£o foram encontrados arquivos .txt no diret√≥rio {TRANSCRIPTION_OUTPUT_PATH}.")
else:
    for txt_file in txt_files:
        if txt_file.is_file():
            print(f"Lendo o arquivo: {txt_file.name}")
            with open(txt_file, 'r', encoding='utf-8') as file:
                str_reuniao = file.read()

            print(f"Enviando o conte√∫do do arquivo {txt_file.name} para a API...")
            data = {
                "inputs": {
                    "str_reuniao": str_reuniao,
                    "str_personas": str_personas.read_text(encoding='utf-8'),
                    "str_contexto": str_contexto.read_text(encoding='utf-8'),
                }
            }

            response = requests.post(f"{url}/api/templates/668de04202493d3063a9d7fa/execute", json=data, headers=headers)
            if response.status_code == 200:
                print(f"Resultado para o arquivo {txt_file.name} recebido.")
                html_content = response.text
                print(response.text)

                # Incluir o CSS no conte√∫do HTML
                html_with_css = f"<html><head>{css_styles}</head><body>{html_content}</body></html>"

                # Salvar o conte√∫do HTML em um arquivo
                output_file = TRANSCRIPTION_OUTPUT_PATH / f"{txt_file.stem}_output.html"
                with open(output_file, 'w', encoding='utf-8') as html_file:
                    html_file.write(html_with_css)

                # Abrir o arquivo HTML no navegador
                webbrowser.open(f"file://{output_file.resolve()}")
            else:
                print(f"Erro ao processar o arquivo {txt_file.name}: {response.status_code}")


# main.py

from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from transcriptions.transcriptions_config import TranscriptionConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from pathlib import Path

def main():
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    root_path = str(PROJECT_ROOT)
    print(f"Root path: {root_path}")  # Para verificar se est√° correto
    api_url = "http://localhost:8081/api/meetings/transcriptions"
    
    # # Configura√ß√£o de v√≠deos
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()
    
    # # Configura√ß√£o de √°udios
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()
    
    # # Processamento de transcri√ß√µes e envio de embeddings
    # embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    # embedding_processor_wrapper.process_transcriptions()

if __name__ == "__main__":
    main()


# send_embeddings_database\embedding_config\embedding_config.py

from app_config.app_config import AppConfig

class EmbeddingConfig(AppConfig):
    def __init__(self, root_path=None, transcription_input_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = transcription_input_path
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'embeddings' / 'output'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH, self.EMBEDDING_OUTPUT_PATH])


# send_embeddings_database\verify_last_enbedding.py

import os
import numpy as np

def get_latest_file(directory):
    # Listar todos os arquivos no diret√≥rio
    files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]
    
    if not files:
        raise FileNotFoundError("Nenhum arquivo encontrado no diret√≥rio.")

    # Encontrar o arquivo mais recente
    latest_file = max(files, key=os.path.getmtime)
    return latest_file

def load_and_print_embedding(directory):
    # Obter o caminho do √∫ltimo arquivo de embedding
    embedding_file_path = get_latest_file(directory)
    
    # Carregar o embedding
    embedding = np.load(embedding_file_path)
    
    # Exibir o conte√∫do do embedding
    print("Embedding carregado:")
    print(embedding)
    print("Dimens√µes do embedding:", embedding.shape)

# Caminho do diret√≥rio de embeddings
embedding_directory = 'C:/Users/HeannarReis/Documents/bsa_atacadao/assets/embeddings/output'

# Carregar e exibir o √∫ltimo embedding
load_and_print_embedding(embedding_directory)


# test_whisper.py

from transformers import pipeline
from common_paths import CommonPaths

commmom_paths = CommonPaths()

# Fun√ß√£o para ler a transcri√ß√£o de um arquivo
def read_transcription(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
    return lines

# Fun√ß√£o para converter a pontua√ß√£o em estrelas
def score_to_stars(score):
    if score >= 0.75:
        return 5
    elif score >= 0.55:
        return 4
    elif score >= 0.35:
        return 3
    elif score >= 0.15:
        return 2
    else:
        return 1

# Inicializar o pipeline de an√°lise de sentimento
sentiment_pipeline = pipeline("sentiment-analysis", model="neuralmind/bert-base-portuguese-cased")

# Caminho para o arquivo de transcri√ß√£o
file_path = commmom_paths.TRANSCRIPTION_OUTPUT_PATH / 'feedback.txt'

# Ler a transcri√ß√£o
lines = read_transcription(file_path)

# Analisar sentimento para cada feedback
for line in lines:
    sentiment = sentiment_pipeline(line.strip())
    score = sentiment[0]['score']
    stars = score_to_stars(score)
    
    # Ajuste manual para feedbacks com aspectos positivos e negativos
    if any(word in line.lower() for word in ["mas", "por√©m", "no entanto"]):
        stars = max(1, stars - 1)  # Reduz uma estrela se houver contradi√ß√£o
    
    # Ajuste adicional baseado em palavras-chave
    positive_keywords = ["excelente", "√≥timo", "perfeito", "r√°pido", "eficiente", "satisfeito", "clara", "eficaz", "bom trabalho"]
    negative_keywords = ["ruim", "p√©ssimo", "horr√≠vel", "poderia", "n√£o resolveu", "insatisfat√≥ria", "confusa", "inadequado", "lento", "n√£o houve seguimento", "n√£o atendeu", "n√£o funcionou", "demorado"]
    
    positive_count = sum(word in line.lower() for word in positive_keywords)
    negative_count = sum(word in line.lower() for word in negative_keywords)
    
    # Ajuste de estrelas baseado na contagem de palavras-chave
    if positive_count > negative_count:
        stars = min(5, stars + 1)
    elif negative_count > positive_count:
        stars = max(1, stars - 1)
    
    print(f"Texto: {line.strip()}")
    print(f"Sentimento: {stars} estrelas")
    print(f"Pontua√ß√£o: {score:.2f}")
    print('---')


# text_to_embedding\embedding_processing.py

from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from transcriptions.transcriptions_config import TranscriptionConfig
from transcriptions.transciption_sender_database import TranscriptionSenderDatabase

class EmbeddingProcessorWrapper:
    def __init__(self, root_path, api_url):
        # Configura√ß√£o de transcri√ß√µes e embeddings
        transcription_config = TranscriptionConfig(root_path=root_path)
        embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())

        self.embedding_processor = EmbeddingProcessor(embedding_config)
        self.transcription_sender = TranscriptionSenderDatabase(api_url)
    
    def process_transcriptions(self):
        # Mostrar o diret√≥rio onde est√° procurando as transcri√ß√µes
        print(f"Diret√≥rio de entrada das transcri√ß√µes: {self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH}")
        
        # Listar todos os arquivos de transcri√ß√£o no diret√≥rio de entrada
        transcription_files = list(self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH.glob('*.txt'))
        if not transcription_files:
            print("Nenhum arquivo de transcri√ß√£o encontrado.")
        for transcription_file_path in transcription_files:
            if transcription_file_path.is_file():
                print(f"Processando arquivo: {transcription_file_path}")
                self.process_and_send_transcription(transcription_file_path)
            else:
                print(f"Arquivo n√£o encontrado: {transcription_file_path}")

    def process_and_send_transcription(self, transcription_file_path):
        try:
            # Ler a transcri√ß√£o do arquivo de texto
            with open(transcription_file_path, 'r', encoding='utf-8') as f:
                transcription_text = f.read()
                if not transcription_text:
                    print(f"Arquivo {transcription_file_path} est√° vazio.")
                    return

            # Gerar o embedding da transcri√ß√£o
            embedding = self.embedding_processor.generate_embedding(transcription_text)
            if embedding is None:
                print(f"Falha ao gerar embedding para o arquivo {transcription_file_path}.")
                return

            # Salvar o embedding em um arquivo .npy
            self.embedding_processor.save_embedding(transcription_file_path, embedding)

            # Enviar os dados para a API
            self.transcription_sender.send_transcription(transcription_text, embedding)

        except Exception as e:
            print(f"Erro ao processar o arquivo {transcription_file_path}: {e}")


# text_to_embedding\texto_to_embedding.py

from sentence_transformers import SentenceTransformer
import numpy as np

class EmbeddingProcessor:
    def __init__(self, embedding_config):
        self.embedding_config = embedding_config
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

    def generate_embedding(self, transcription_text):
        return self.embedding_model.encode(transcription_text)

    def save_embedding(self, transcription_file_path, embedding):
        embedding_file_path = self.embedding_config.EMBEDDING_OUTPUT_PATH / transcription_file_path.with_suffix('.npy').name
        np.save(embedding_file_path, embedding)
        print(f"Embedding salvo em: {embedding_file_path}")
        return embedding_file_path


# transcriptions\transciption_sender_database.py

import requests

class TranscriptionSenderDatabase:
    def __init__(self, api_url):
        self.api_url = api_url

    def send_transcription(self, transcription_text, embedding):
        data = {
            'transcriptionText': transcription_text,
            'embedding': embedding.tolist()
        }

        response = requests.post(self.api_url, json=data)

        if response.status_code == 201:
            print("Transcri√ß√£o e embedding enviados com sucesso.")
        else:
            print(f"Erro ao enviar dados: {response.status_code}")
            print("Resposta da API:")
            print(response.text)


# transcriptions\transcriptions_config.py

from app_config.app_config import AppConfig

class TranscriptionConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = self.ROOT_PATH / 'assets' / 'transcriptions' / 'input'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH])
    
    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# translate\translator_to_english.py

import speech_recognition as sr
from translate import Translator

def ouvir_e_traduzir():
    # Inicializa o reconhecedor de fala
    recognizer = sr.Recognizer()

    # Configura o tradutor
    translator = Translator(to_lang="en", from_lang="pt")

    # Usa o microfone como fonte de √°udio
    with sr.Microphone() as source:
        print("Diga algo em portugu√™s...")

        while True:
            try:
                # Escuta o √°udio do microfone
                audio = recognizer.listen(source)
                
                # Reconhece a fala usando o Google Web Speech API
                texto_portugues = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {texto_portugues}")

                # Traduz o texto para o ingl√™s
                traducao = translator.translate(texto_portugues)
                print(f"Tradu√ß√£o para o ingl√™s: {traducao}")

            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio")
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")

if __name__ == "__main__":
    try:
        ouvir_e_traduzir()
    except KeyboardInterrupt:
        print("Interrompido pelo usu√°rio")


# translate\whispert_translator.py

import whisper
import pyaudio
import numpy as np

# Inicializa o modelo Whisper
model = whisper.load_model("base")

# Configura√ß√µes de √°udio
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024

# Inicializa o PyAudio
audio = pyaudio.PyAudio()

# Abre o stream de √°udio
stream = audio.open(format=FORMAT, channels=CHANNELS,
                    rate=RATE, input=True,
                    frames_per_buffer=CHUNK)

print("Diga algo em portugu√™s...")

try:
    audio_buffer = []

    while True:
        # L√™ dados do microfone
        data = stream.read(CHUNK)
        audio_buffer.append(np.frombuffer(data, dtype=np.int16).flatten().astype(np.float32) / 32768.0)

        # Processa o √°udio a cada 5 segundos
        if len(audio_buffer) * CHUNK / RATE >= 5:
            audio_data = np.concatenate(audio_buffer)
            audio_buffer = []

            # Transcreve e traduz o √°udio usando Whisper
            result = model.transcribe(audio_data, task="translate", language="pt")

            # Exibe a tradu√ß√£o
            print(f"Tradu√ß√£o para o ingl√™s: {result['text']}")

except KeyboardInterrupt:
    print("Interrompido pelo usu√°rio")

    # Fecha o stream de √°udio
    stream.stop_stream()
    stream.close()
    audio.terminate()


# video_to_audio\video_config\video_config.py

from app_config.app_config import AppConfig

class VideoConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video' / 'input'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.create_directories([self.VIDEO_INPUT_PATH, self.VIDEO_OUTPUT_PATH])

# video_to_audio\video_to_audio.py

from moviepy import VideoFileClip
import glob
import os
from .video_config.video_config import VideoConfig

class VideoToAudioConverter:
    def __init__(self, video_config: VideoConfig):
        self.video_config = video_config

    def convert_video_to_audio(self, video_path, audio_path):
        try:
            video = VideoFileClip(video_path)
            if video.audio:
                video.audio.write_audiofile(audio_path, fps=44100)
                print(f"Convertido {video_path} para {audio_path}")
            else:
                print(f"Aviso: O v√≠deo {video_path} n√£o cont√©m √°udio!")
        except Exception as e:
            print(f"Erro ao converter {video_path}: {e}")

    def process_videos(self):
        input_directory = self.video_config.VIDEO_INPUT_PATH
        output_directory = self.video_config.VIDEO_OUTPUT_PATH

        os.makedirs(output_directory, exist_ok=True)

        # Busca qualquer arquivo de v√≠deo (formatos comuns)
        video_files = glob.glob(os.path.join(input_directory, "*.*"))  # Pega todos os arquivos

        # Filtra apenas arquivos de v√≠deo
        video_extensions = {".mp4", ".mkv", ".avi", ".mov", ".wmv", ".flv"}  
        video_files = [f for f in video_files if os.path.splitext(f)[1].lower() in video_extensions]

        if not video_files:
            print(f"Nenhum arquivo de v√≠deo encontrado em: {input_directory}")
            return

        for video_file in video_files:
            base_name = os.path.basename(video_file)
            audio_file = os.path.join(output_directory, os.path.splitext(base_name)[0] + ".wav")
            self.convert_video_to_audio(video_file, audio_file)

        print("Convers√£o de v√≠deo para √°udio conclu√≠da!")


# voice_assistent\assistent.py

import speech_recognition as sr
import pyttsx3
import re
from collections import deque
import spacy
import requests
import os
import webbrowser
from class_voice_assistent.prompt import create_prompt
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import google.generativeai as genai

# Configura√ß√µes da API
handler = genai('gemini-1.5-flash')

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

voices = engine.getProperty('voices')
engine.setProperty('rate', 180)
print("\nLista de Vozes...")
for indice, vozes in enumerate(voices):
    print(indice, vozes.name)

voz = 1
engine.setProperty('voice', voices[voz].id)

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

# Fun√ß√£o para extrair texto de HTML
def extract_text_from_html(html):
    if not html.strip().startswith('<'):
        print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
        return html
    soup = BeautifulSoup(html, 'html.parser')
    text = ' '.join([p.get_text() for p in soup.find_all('p')])
    return text

def get_text_response(prompt, context, feedback):
    # Gere o conte√∫do com base no prompt usando a classe GenerativeModelHandler
    response = handler.generate_content(prompt)
    return response

# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/api/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


# voice_assistent\class_voice_assistent\api_client.py

import requests


class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, meeting):
        try:
            response_text = self.model.generate_content(prompt, context, meeting)
            return response_text
        except Exception as e:
            print(f"Erro inesperado: {e}")
            return None

    def find_similar_embeddings(self, embedding):
        try:
            print(f"Buscando embeddings similares para: {embedding}")
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            similar_embeddings = response.json()

            # Ordenar por similaridade (assumindo que a API retorna com similaridade em ordem decrescente)
            # Remover duplicatas baseadas na pergunta
            seen_questions = set()
            unique_embeddings = []
            for embedding in similar_embeddings:
                question = embedding['question'].strip().lower()
                if question not in seen_questions:
                    unique_embeddings.append(embedding)
                    seen_questions.add(question)
            print(f"Embeddings similares √∫nicos encontrados: {unique_embeddings}")
            return unique_embeddings
        except requests.RequestException as e:
            print(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            # Converter embeddings de numpy arrays para listas
            if hasattr(question_embedding, 'tolist'):
                question_embedding = question_embedding.tolist()
            if hasattr(answer_embedding, 'tolist'):
                answer_embedding = answer_embedding.tolist()
            
            data = {
                "question": question,
                "questionEmbedding": question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding
            }
            
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                print("Pergunta e resposta salvas com sucesso.")
            else:
                print(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            print(f"Erro em save_question_answer: {e}")


    def fetch_all_contexts(self):
        try:
            response = requests.get("http://localhost:8081/api/contexts/all")
            if response.status_code == 200:
                data = response.json()
                contexts = data.get('contexts', [])
                if isinstance(contexts, list):
                    print(f"Contexto obtido da API: {contexts}")
                    return contexts
                else:
                    print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                    return []
            else:
                print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
                return []
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
            return []

    def fetch_last_meeting(self):
        try:
            response = requests.get("http://localhost:8081/api/meetings/last")
            if response.status_code == 200:
                data = response.json()
                transcription_text = data.get('transcriptionText', "")
                if isinstance(transcription_text, str):
                    print(f"Texto da transcri√ß√£o obtido da API: {transcription_text}")
                    return transcription_text
                else:
                    print(f"Erro: 'transcriptionText' n√£o √© uma string. Dados retornados: {data}")
                    return ""
            else:
                print(f"Erro ao acessar a API de reuni√µes: {response.status_code}, {response.text}")
                return ""
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de reuni√µes: {e}")
            return ""


# voice_assistent\class_voice_assistent\command_interpreter.py

import spacy
from prompt_generator.online_prompt import OnlineResearchPromptGenerator
from prompt_generator.meeting_prompt import MeetingPromptGenerator
from prompt_generator.default_prompt_generator import DefaultPromptGenerator
import re

# Carregar o modelo de linguagem natural
nlp = spacy.load("pt_core_news_sm")

class CommandInterpreter:
    def __init__(self, api_client, question_answer_service, context_manager, max_similar=3):
        self.api_client = api_client
        self.question_answer_service = question_answer_service
        self.context_manager = context_manager
        self.max_similar = max_similar  # Limite de contextos similares

    def interpret_command(self, command, meeting):
        print(f"Interpretando comando: {command}")
        contexts = self.api_client.fetch_all_contexts()
        context_str = "\n".join([context['context'] for context in contexts])

        # Gerar embedding para a pergunta e buscar embeddings similares
        question_embedding = self.question_answer_service.convert_text_to_embedding(command)
        similar_embeddings = self.api_client.find_similar_embeddings(question_embedding)

        # Filtrar para evitar respostas redundantes
        unique_responses = self._filter_unique_responses(similar_embeddings, command)
        similar_context = "\n".join([f"Pergunta: {embedding['question']}\nResposta: {embedding['answer']}" for embedding in unique_responses[:self.max_similar]])

        # Detectar tipo de comando usando regex
        if re.search(r'\b(pesquise|pesquisar|procure)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como pesquisa online.")
            response = self.get_online_research_response(command, context_str, similar_context)
        elif re.search(r'\b(contexto)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como busca de contexto.")
            response = self.get_project_response(command, meeting, context_str, similar_context)
        elif re.search(r'\b(resumo?|t√≥picos da|pontos (relevantes|principais)|an√°lise)\b.*\b(reuni√£o|√∫ltima (reuni√£o|conversa|sess√£o))\b', command, re.IGNORECASE):
            print(f"\nComando identificado como an√°lise de reuni√£o.")
            meeting = self.api_client.fetch_last_meeting()
            response = self.get_meeting_analysis_response(command, context_str, meeting)
        else:
            print(f"\nComando identificado como comando padr√£o.")
            response = self.handle_default_command(command, context_str, meeting, similar_context)

        if response:
            answer_embedding = self.question_answer_service.convert_text_to_embedding(response)
            self.api_client.save_question_answer(command, question_embedding, response, answer_embedding)
            self.context_manager.add_context(command, response)

        return response

    def _filter_unique_responses(self, similar_embeddings, current_command):
        """
        Filtra respostas semelhantes que s√£o muito similares ao comando atual para evitar redund√¢ncia.
        """
        filtered = []
        for embedding in similar_embeddings:
            if embedding['question'].lower() != current_command.lower():
                filtered.append(embedding)
        return filtered

    def handle_default_command(self, command, context_str, meeting, similar_context):
        print(f"\nTratando comando padr√£o: {command}")
        # Combinar o contexto atual com os contextos similares para enriquecer a resposta
        combined_context = f"{context_str}\n{similar_context}"
        prompt = DefaultPromptGenerator().generate_prompt(command, combined_context, meeting)
        response = self.api_client.get_text_response(prompt, combined_context, meeting)
        return response

    # M√©todos get_project_response, get_meeting_analysis_response, get_online_research_response permanecem inalterados

    def get_project_response(self, command, meeting, context_str, similar_context):
        print(f"\nGerando prompt de projeto.")
        prompt = DefaultPromptGenerator().generate_prompt(command, context_str, meeting, similar_context)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_meeting_analysis_response(self, command, context_str, meeting):
        print(f"\nGerando prompt de an√°lise de reuni√£o.")
        prompt = MeetingPromptGenerator().generate_prompt(command, context_str, meeting)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_online_research_response(self, command, context_str, similar_context):
        print(f"\nGerando prompt de pesquisa online.")
        prompt = OnlineResearchPromptGenerator().generate_prompt(command, context_str, similar_context)
        return self.api_client.get_text_response(prompt, context_str, None)


# voice_assistent\class_voice_assistent\context_manager.py

from collections import deque

class ContextManager:
    def __init__(self, maxlen=10):
        self.recent_context = deque(maxlen=maxlen)

    def add_context(self, command, response):
        self.recent_context.append((command, response))

    def get_context(self):
        return "\n".join([context for context, _ in self.recent_context])


# voice_assistent\class_voice_assistent\conversation_history.py



# voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py

import requests
import logging
import google.generativeai as genai

# Configure o logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, feedback):
        try:
            # Gerando o conte√∫do usando a nova API
            response = self.model.generate_content(prompt)
            if response and hasattr(response, 'text'):
                return prompt, response.text
            else:
                logger.error("Resposta inv√°lida da API")
                return prompt, None
        except Exception as e:
            logger.error(f"Erro em get_text_response: {e}")
            return prompt, None

    def find_similar_embeddings(self, embedding):
        try:
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            logger.info(f"Enviando dados para a API de embeddings similares: {data}")
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            logger.error(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            data = {
                "question": question,
                "questionEmbedding": question_embedding.tolist() if hasattr(question_embedding, 'tolist') else question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding.tolist() if hasattr(answer_embedding, 'tolist') else answer_embedding
            }
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                logger.info("Pergunta e resposta salvas com sucesso.")
            else:
                logger.warning(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            logger.error(f"Erro em save_question_answer: {e}")


# voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py

import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        """Carregar vari√°veis do arquivo .env"""
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        """Configurar a chave da API"""
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        """Inicializar o modelo generativo"""
        try:
            self.model = genai.GenerativeModel(self.model_name)
        except Exception as e:  
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content(self, prompt: str, context: str, meeting: str) -> str:
        """Gerar conte√∫do com base no prompt, contexto e reuni√£o"""
        try:
            # Supondo que a API espera um dicion√°rio com os par√¢metros
            request_data = f'''
                "prompt": {prompt},
                "context": {context},
                "meeting": {meeting}
            '''
            print(f"Enviando requisi√ß√£o para a API GenAI: {request_data}")

            response = self.model.generate_content(request_data)
            return response.text
        except Exception as e:
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py

import os
from dotenv import load_dotenv
from groq import Groq

# Carregar vari√°veis do arquivo .env
load_dotenv()

# Recuperar a chave da API
api_key = os.getenv("GROQ_API_KEY")

# Verificar se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API Key is missing. Please set the GROQ_API_KEY in the .env file.")

# Configurar o cliente com a chave da API
client = Groq(api_key=api_key)

# Cria√ß√£o da conclus√£o do chat
chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "De acordo com nossas conversas anteriores, o que voc√™ acha do meu uso de IA ?",
        }
    ],
    model="llama3-8b-8192",
)

print(chat_completion.choices[0].message.content)


# voice_assistent\class_voice_assistent\main.py

import os
from context_manager import ContextManager
from api_client import APIClient
from command_interpreter import CommandInterpreter
from text_command_hendler import TextCommandHandler
from text_processor import TextProcessor
from text_to_speech import TextToSpeech
from voice_command_hendler import VoiceCommandHandler
from question_answers_service import QuestionAnswerService
from gpt_communication.gemini_gpt import GenerativeModelHandler

class MainApp:
    def __init__(self, model):
        self.voice_handler = VoiceCommandHandler()
        self.text_handler = TextCommandHandler()
        self.tts = TextToSpeech()
        self.text_processor = TextProcessor()
        self.api_client = APIClient(
            similarity_url="http://localhost:8081",
            save_url="http://localhost:8081/api/question_answers/save",
            model=model
        )
        self.context_manager = ContextManager()
        self.question_answer_service = QuestionAnswerService()
        self.command_interpreter = CommandInterpreter(
            self.api_client,
            self.question_answer_service,
            self.context_manager
        )

    def handle_command(self, command, meeting=""):
        if command:
            print(f"Pergunta recebida: {command}")
            text_response = self.command_interpreter.interpret_command(command, meeting)
            if text_response:
                print(f"Resposta: {text_response}")
                self.tts.speak_text(text_response)
                self.context_manager.add_context(command, text_response)
                return text_response
        else:
            print("Nenhum comando detectado.")
            return None

    def run(self):
        meeting = ""
        while True:
            try:
                input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
                if input_type == 'v':
                    command = self.voice_handler.capture_voice_command()
                elif input_type == 't':
                    command = self.text_handler.capture_text_command()
                else:
                    print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
                    continue

                response = self.handle_command(command, meeting)
                if response:
                    print(f"Resposta: {response}")
            except Exception as e:
                print(f"Ocorreu um erro: {e}")

if __name__ == "__main__":
    model = GenerativeModelHandler('gemini-1.5-flash')
    app = MainApp(model)
    app.run()

# voice_assistent\class_voice_assistent\prompt.py

def create_prompt(command, context, meeting):
    keywords = ["fa√ßa um resumo da √∫ltima reuni√£o.", "t√≥picos da √∫ltima reuni√£o", "resuma a √∫ltima reuni√£o", "pesquise", "pesquisar", "procure"]
    if any(keyword in command.lower() for keyword in keywords):
        return f"""
        Regras de Meeting:
        - Voc√™ √© respons√°vel por analisar, debater, sugerir e informar melhorias.
        - Resuma de forma clara e Objetiva.
        - N√£o acrescentar t√≠tulo nas respostas.

        [context]: {context}
        -------
        [meeting]: {meeting}
        -------
        [str_texto]: {command}
        """
    else:
        return f"""
        [context]: {context}
        -------
        [str_texto]: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py

class DefaultPromptGenerator:
    def generate_prompt(self, command, combined_context, meeting):
        prompt = (
            f"Comando: {command}\n"
            f"Contexto Anterior:\n{combined_context}\n"
            f"Baseie sua resposta nas informa√ß√µes acima e forne√ßa uma solu√ß√£o detalhada."
        )
        return prompt

# voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class MeetingPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting):
        return f"""
        Regras de Meeting com respostas inteligentes:
        - Responda a pergunta de [str_texto] com base nas diretrizes abaixo...
            - Voc√™ √© respons√°vel analisar com detalhes a reuni√£o de [str_meeting], e fornecer uma longa est√≥ria sobre o assunto.
            - observe os nomes das personas mencionadas no texto de meeting para aprender e melhorar a precis√£o da resposta.
            - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [str_texto]: Responda a pergunta de: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class OnlineResearchPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting, similar_context):
        return f"""
        Regras de Pesquisa Online Inteligente:
        - Utilize similar_context e fa√ßa uma pesquisa online para uma resposta mais precisa das quest√µes de [str_text]
        - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [context]: Regras B√°sicas {context}
        ------
        [similar_context]:
        Perguntas e respostas anteriores.{similar_context}
        ------
        [str_texto]: Responda seguinte pergunta: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py

from abc import ABC, abstractmethod

class PromptGenerator(ABC):
    @abstractmethod
    def generate_prompt(self, command, context, meeting, similar_context):
        pass

# voice_assistent\class_voice_assistent\question_answers_service.py

import requests
import numpy as np
from sentence_transformers import SentenceTransformer

class QuestionAnswerService:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.embedding_model = SentenceTransformer(model_name)

    def convert_text_to_embedding(self, text):
        embedding = self.embedding_model.encode(text)
        #print(f"Embedding gerado para '{text}': {embedding[0]:.16f}") # Adicionado para verificar o embedding gerado
        return embedding


# voice_assistent\class_voice_assistent\text_command_hendler.py

class TextCommandHandler:
    def capture_text_command(self):
        command = input("Digite o seu comando: ")
        return command


# voice_assistent\class_voice_assistent\text_processor.py

from bs4 import BeautifulSoup

class TextProcessor:
    def extract_values_from_json(self, data):
        if isinstance(data, dict):
            return ' '.join([str(value) for value in data.values()])
        elif isinstance(data, list):
            return ' '.join([self.extract_values_from_json(item) for item in data])
        return str(data)

    def extract_text_from_html(self, html):
        if not html.strip().startswith('<'):
            print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
            return html
        soup = BeautifulSoup(html, 'html.parser')
        text = ' '.join([p.get_text() for p in soup.find_all('p')])
        return text


# voice_assistent\class_voice_assistent\text_to_speech.py

import pyttsx3

class TextToSpeech:
    def __init__(self):
        self.engine = pyttsx3.init()

    def speak_text(self, text):
        cleaned_text = self.clean_text(text)
        self.engine.say(cleaned_text)
        self.engine.runAndWait()

    def clean_text(self, text):
        import re
        return re.sub(r'[\*\_\#]', '', text)


# voice_assistent\class_voice_assistent\voice_command_hendler.py

import speech_recognition as sr

class VoiceCommandHandler:
    def capture_voice_command(self):
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            print("Por favor, fale o seu comando:")
            try:
                audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
                print("√Åudio capturado com sucesso.")
                command = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {command}")
                return command
            except sr.WaitTimeoutError:
                print("Tempo de espera expirado. Nenhum √°udio detectado.")
                return None
            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio.")
                return None
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
                return None


# voice_assistent\config.py

# config.py
import pyttsx3
import spacy
from collections import deque

class APIConfig:
    apiKey = "API_KEY"
    url = "https://gpt-templates.saiapplications.com"
    headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")


# voice_assistent\template.py

import speech_recognition as sr
import requests
import pyttsx3
import re
from collections import deque
import spacy
import os
import webbrowser
from voice_assistent.prompt import create_prompt

# Configura√ß√µes da API
apiKey = "6UlOOoY/kkmprunma/qNDg"
url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    if isinstance(text, dict):
        text = extract_values_from_json(text)  # Extrai os valores do dicion√°rio
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

def get_text_response(prompt, context, feedback):
    data = {
        "inputs": {
            "str_texto": prompt,
            "str_contexto": context,
            "str_feedback": feedback
        }
    }
    print(f"Enviando dados para a API: {data}")
    try:
        response = requests.post(f"{url}/api/templates/6691e223802f95c2b394a8bd/execute", json=data, headers=headers)
        print(f"Status da resposta: {response.status_code}")
        if response.status_code == 200:
            try:
                response_data = response.html()  # Tente converter a resposta para JSON
                print("Resposta HTML recebida.")
                return extract_values_from_json(response_data)  # Extrai os valores do JSON
            except ValueError:
                print("A resposta n√£o est√° no formato JSON esperado. Tratando como texto simples.")
                return response.text  # Retorna o texto bruto da resposta
        else:
            print(f"Erro ao acessar a API: {response.status_code}, {response.text}")
            return None
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API: {e}")
        return None

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)


# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


User: Como posso integrar todas as aplica√ß√µes para funcionar em uma √∫nica MAIN.py ?

Streamlit. Chat de voz. converter v√≠deo para audio e audio para texto e depois salvar no banco de dados.
Assistant: Para integrar todas as aplica√ß√µes em um √∫nico `main.py`, voc√™ precisa modularizar seu c√≥digo existente e usar uma estrutura central que coordene a execu√ß√£o das diferentes partes (Streamlit chat de voz, convers√£o de v√≠deo para √°udio, √°udio para texto e salvamento no banco de dados).

Aqui est√° um esbo√ßo de como voc√™ pode abordar isso, com √™nfase na organiza√ß√£o e coordena√ß√£o das tarefas:

```python
# main.py

import streamlit as st
import os
from pathlib import Path

# Importar as fun√ß√µes e classes de cada m√≥dulo
from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from voice_assistent.class_voice_assistent.main import MainApp
from voice_assistent.class_voice_assistent.gpt_communication.gemini_gpt import GenerativeModelHandler
from transcriptions.transcriptions_config import TranscriptionConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from config.config import Config
from core.rate_limiter import RateLimiter

# 1. Configura√ß√£o Inicial
PROJECT_ROOT = Path(__file__).resolve().parent
root_path = str(PROJECT_ROOT)
print(f"Root path: {root_path}")

Config.ensure_directories()

# 2. Fun√ß√µes de Processamento
def process_videos():
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()

def process_audio():
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()

def process_transcriptions_and_embeddings(api_url):
    transcription_config = TranscriptionConfig(root_path=root_path)
    embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())
    embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    embedding_processor_wrapper.process_transcriptions()

# 3. Interface Streamlit
def main():
    st.title("Aplica√ß√µes Integradas")

    # 3.1. Sidebar com op√ß√µes
    app_mode = st.sidebar.selectbox(
        "Escolha a aplica√ß√£o:",
        ["Chat de Voz", "Converter V√≠deo para √Åudio", "Converter √Åudio para Texto", "Enviar Embeddings para o Banco de Dados"]
    )

    # 3.2. L√≥gica para cada aplica√ß√£o
    if app_mode == "Chat de Voz":
        st.header("Chat de Voz")
        model = GenerativeModelHandler('gemini-1.5-flash')
        app = MainApp(model)
        app.run()

    elif app_mode == "Converter V√≠deo para √Åudio":
        st.header("Converter V√≠deo para √Åudio")
        if st.button("Converter V√≠deos"):
            process_videos()
            st.success("V√≠deos convertidos para √°udio com sucesso!")

    elif app_mode == "Converter √Åudio para Texto":
        st.header("Converter √Åudio para Texto")
        if st.button("Converter √Åudios"):
            process_audio()
            st.success("√Åudios convertidos para texto com sucesso!")

    elif app_mode == "Enviar Embeddings para o Banco de Dados":
        st.header("Enviar Embeddings para o Banco de Dados")
        api_url = st.text_input("URL da API para enviar as transcri√ß√µes:", "http://localhost:8081/api/meetings/transcriptions")

        if st.button("Enviar Embeddings"):
            process_transcriptions_and_embeddings(api_url)
            st.success("Embeddings enviados para o banco de dados com sucesso!")

# 4. Execu√ß√£o Principal
if __name__ == "__main__":
    main()
```

### Estrutura do Projeto

-   **`main.py`**: Este √© o ponto de entrada. Ele usa Streamlit para criar uma interface que permite selecionar qual parte da aplica√ß√£o executar.

-   **`video_to_audio/`**, **`audio_to_text/`**, **`text_to_embedding/`**, **`voice_assistent/`**: Esses diret√≥rios cont√™m o c√≥digo existente de cada parte da sua aplica√ß√£o.

### Passos para Implementar

1.  **Modulariza√ß√£o:**

    *   Certifique-se de que cada parte da sua aplica√ß√£o (convers√£o de v√≠deo, convers√£o de √°udio, chat de voz) esteja bem encapsulada em fun√ß√µes ou classes reutiliz√°veis.
    *   Mova essas fun√ß√µes e classes para os respectivos m√≥dulos (arquivos `.py` dentro de seus diret√≥rios).

2.  **Integra√ß√£o no `main.py`:**

    *   Importe as fun√ß√µes e classes dos m√≥dulos.
    *   Use Streamlit para criar uma interface que permita ao usu√°rio escolher qual fun√ß√£o executar.
    *   Implemente bot√µes ou seletores para acionar as diferentes partes da aplica√ß√£o.

3.  **Gerenciamento de Depend√™ncias:**

    *   Certifique-se de que todas as depend√™ncias necess√°rias para cada parte da aplica√ß√£o estejam instaladas.  Considere usar um arquivo `requirements.txt` para listar todas as depend√™ncias.

4.  **Testes:**

    *   Teste cada parte da aplica√ß√£o individualmente para garantir que funcionem corretamente.
    *   Teste a integra√ß√£o geral para garantir que as diferentes partes possam ser executadas em sequ√™ncia ou individualmente, conforme necess√°rio.

### Pontos Chave

*   **Modulariza√ß√£o:** Dividir o c√≥digo em m√≥dulos facilita a manuten√ß√£o e reutiliza√ß√£o.
*   **Interface Streamlit:** Streamlit permite criar uma interface web simples para interagir com sua aplica√ß√£o.
*   **Gerenciamento de Estado:** Use `st.session_state` para manter o estado entre as execu√ß√µes da aplica√ß√£o Streamlit (por exemplo, se um v√≠deo foi convertido ou n√£o).
*   **Tratamento de Erros:** Implemente tratamento de erros para lidar com falhas em qualquer parte da aplica√ß√£o e fornecer feedback √∫til ao usu√°rio.
*   **Configura√ß√£o:** Utilize arquivos de configura√ß√£o (como o seu `config.py`) para armazenar caminhos de arquivos, URLs de API e outras configura√ß√µes que podem precisar ser ajustadas.

Seguindo esses passos, voc√™ deve conseguir integrar todas as suas aplica√ß√µes em um √∫nico script `main.py` com uma interface Streamlit para facilitar o uso e a demonstra√ß√£o.

User: observe em src/chat_streamlit que j√° tenho uma aplica√ß√£o que funciona como chat e consegue gerar imagem e ler imagem com OCR... atualmente s√≥ funciona por text .... quero colocar via comando de voz tbm  com a parte da aplica√ß√£o que usa Speech Recoginition
Assistant: Ok, para integrar o comando de voz ao seu `chat_streamlit.py`, voc√™ precisar√° adaptar o c√≥digo existente para incluir a funcionalidade de reconhecimento de voz e direcionar a entrada de voz para as mesmas fun√ß√µes que j√° processam o texto. Aqui est√° um guia passo a passo de como fazer isso:

**1. Importar as Bibliotecas Necess√°rias:**

Adicione as seguintes importa√ß√µes ao topo do seu arquivo `chat_streamlit.py`:

```python
import speech_recognition as sr
import threading
```

**2. Fun√ß√£o para Capturar Comando de Voz:**

Crie uma fun√ß√£o para capturar o comando de voz usando `speech_recognition`. Esta fun√ß√£o ser√° executada em uma thread separada para evitar bloquear a interface do Streamlit.

```python
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.write("Diga algo...")  # Mensagem na interface
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            command = recognizer.recognize_google(audio, language='pt-BR')
            st.write(f"Voc√™ disse: {command}")  # Mostra o comando reconhecido
            return command
        except sr.WaitTimeoutError:
            st.write("Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            st.write("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            st.write(f"Erro ao solicitar resultados: {e}")
            return None
```

**3. Adicionar um Bot√£o para Ativar o Reconhecimento de Voz:**

Adicione um bot√£o na barra lateral para iniciar a captura de voz. Esse bot√£o iniciar√° uma thread que executa a fun√ß√£o `capture_voice_command`.

```python
with st.sidebar:
    # ... (seu c√≥digo existente da barra lateral)

    if st.button("üé§ Usar Comando de Voz"):
        st.session_state.voice_command = None  # Limpa o comando anterior
        st.session_state.voice_thread = threading.Thread(target=lambda: setattr(st.session_state, 'voice_command', capture_voice_command()))
        st.session_state.voice_thread.start()
```

**4. Modificar a L√≥gica de Processamento de Mensagens:**

Modifique a l√≥gica de processamento de mensagens para verificar se h√° um comando de voz capturado. Se houver, use esse comando como entrada para a fun√ß√£o `process_message`.

```python
# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # ... (seu c√≥digo existente para determinar o placeholder)

    # Verifica se um comando de voz foi capturado
    if 'voice_command' in st.session_state and st.session_state.voice_command:
        user_input = st.session_state.voice_command
        process_message(user_input, current_image)
        st.session_state.voice_command = None  # Limpa o comando para n√£o repetir

    else:
        user_input = st.chat_input(placeholder)

        if user_input:
            # Processa a mensagem com a imagem (se houver) ou apenas texto
            process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)
```

**Explica√ß√£o das Modifica√ß√µes:**

*   **`capture_voice_command()`:** Esta fun√ß√£o captura o √°udio do microfone, tenta reconhecer a fala e retorna o comando de texto. Ela tamb√©m exibe mensagens de status na interface do Streamlit.
*   **Bot√£o "üé§ Usar Comando de Voz":** Quando este bot√£o √© clicado, ele cria e inicia uma nova thread que executa a fun√ß√£o `capture_voice_command`.  O resultado do comando de voz √© armazenado em `st.session_state.voice_command`.
*   **L√≥gica de Processamento Modificada:** A se√ß√£o de entrada de texto agora verifica se `st.session_state.voice_command` cont√©m um valor. Se sim, ele usa esse valor como a entrada do usu√°rio e chama `process_message`. Depois, ele limpa `st.session_state.voice_command` para evitar que o comando seja processado novamente.
*   **Thread:** Usar uma thread para a captura de voz √© crucial porque `recognizer.listen()` √© um m√©todo bloqueante. Sem uma thread, a interface do Streamlit ficaria congelada enquanto o √°udio √© capturado.

**Pontos Adicionais:**

*   **Permiss√µes do Microfone:** Certifique-se de que seu navegador tenha permiss√£o para acessar o microfone.
*   **Thread Safety:** Tenha cuidado com a seguran√ßa de threads ao modificar `st.session_state`. Streamlit n√£o √© inerentemente thread-safe, ent√£o evite opera√ß√µes simult√¢neas que possam causar problemas. Usar `setattr` como mostrado √© uma maneira segura de atualizar o estado.
*   **Feedback Visual:** Forne√ßa feedback visual ao usu√°rio para que saiba quando o sistema est√° gravando, processando ou aguardando um comando de voz.

Com estas modifica√ß√µes, seu `chat_streamlit.py` deve ser capaz de capturar comandos de voz e process√°-los da mesma forma que os comandos de texto. Isso adicionar√° a funcionalidade de controle por voz que voc√™ deseja.

User: eu ja tenho uma aplica√ß√£o de comando de voz dentro da pasta voice_assistent.
Assistant: Entendi. Em vez de criar uma nova fun√ß√£o de captura de voz, podemos integrar a sua aplica√ß√£o existente `voice_assistent` ao `chat_streamlit.py`. Isso envolve principalmente reutilizar as fun√ß√µes de captura e interpreta√ß√£o de comandos da sua aplica√ß√£o `voice_assistent` existente e integr√°-las na interface do Streamlit.

Aqui est√£o os passos detalhados:

**1. Importar as Fun√ß√µes Necess√°rias de `voice_assistent`:**

No topo do seu arquivo `chat_streamlit.py`, importe as fun√ß√µes que voc√™ precisa de `voice_assistent.main`:

```python
from voice_assistent.class_voice_assistent.main import MainApp
from voice_assistent.class_voice_assistent.gpt_communication.gemini_gpt import GenerativeModelHandler
import threading
import streamlit as st
```

**2. Inicializar a Aplica√ß√£o `voice_assistent`:**

Voc√™ precisar√° inicializar a aplica√ß√£o `voice_assistent` uma vez, preferencialmente fora do loop principal do Streamlit, para que n√£o seja reinicializada a cada intera√ß√£o.

```python
# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Inicializa a aplica√ß√£o de voz
@st.cache_resource
def get_voice_app():
    model = GenerativeModelHandler('gemini-1.5-flash')
    return MainApp(model)

voice_app = get_voice_app()
```

**3. Modificar o Bot√£o de Comando de Voz:**

Modifique o bot√£o na barra lateral para usar a fun√ß√£o de captura de voz da sua aplica√ß√£o `voice_assistent`. Em vez de criar uma nova thread, voc√™ chamar√° a fun√ß√£o `handle_command` da sua `voice_app` diretamente.

```python
with st.sidebar:
    # ... (seu c√≥digo existente da barra lateral)

    if st.button("üé§ Usar Comando de Voz"):
        st.session_state.voice_command = None  # Limpa o comando anterior
        st.session_state.voice_thread = threading.Thread(target=lambda: setattr(st.session_state, 'voice_command', voice_app.handle_command(voice_app.voice_handler.capture_voice_command())))
        st.session_state.voice_thread.start()
```

**4. Modificar a L√≥gica de Processamento de Mensagens:**

Modifique a l√≥gica de processamento de mensagens para verificar se h√° um comando de voz capturado. Se houver, use esse comando como entrada para a fun√ß√£o `process_message`.

```python
# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # ... (seu c√≥digo existente para determinar o placeholder)

    # Verifica se um comando de voz foi capturado
    if 'voice_command' in st.session_state and st.session_state.voice_command:
        user_input = st.session_state.voice_command
        process_message(user_input, current_image)
        st.session_state.voice_command = None  # Limpa o comando para n√£o repetir

    else:
        user_input = st.chat_input(placeholder)

        if user_input:
            # Processa a mensagem com a imagem (se houver) ou apenas texto
            process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)
```

**Explica√ß√£o das Modifica√ß√µes:**

*   **Importa√ß√£o de `MainApp`:** Importe a classe `MainApp` da sua aplica√ß√£o `voice_assistent`.
*   **Inicializa√ß√£o de `MainApp`:** Inicialize a aplica√ß√£o `MainApp` usando o modelo `GenerativeModelHandler`. Isso deve ser feito apenas uma vez.
*   **Bot√£o "üé§ Usar Comando de Voz":** Quando este bot√£o √© clicado, ele chama `voice_app.run()` para iniciar a captura de voz.
*   **L√≥gica de Processamento Modificada:** A se√ß√£o de entrada de texto agora verifica se `st.session_state.voice_command` cont√©m um valor. Se sim, ele usa esse valor como a entrada do usu√°rio e chama `process_message`. Depois, ele limpa `st.session_state.voice_command` para evitar que o comando seja processado novamente.

**Considera√ß√µes Importantes:**

*   **Cache:** Para garantir que a `MainApp` e o `GenerativeModelHandler` sejam inicializados apenas uma vez, use `@st.cache_resource`. Isso evita a reinicializa√ß√£o a cada intera√ß√£o.
*   **`handle_command`:** A fun√ß√£o `handle_command` deve retornar o texto da resposta. Este texto √© ent√£o usado como entrada para `process_message`.
*   **State Management:** O uso de `st.session_state` permite manter o estado entre as execu√ß√µes da aplica√ß√£o Streamlit.

Com estas modifica√ß√µes, seu `chat_streamlit.py` deve ser capaz de capturar comandos de voz usando a aplica√ß√£o `voice_assistent` e process√°-los da mesma forma que os comandos de texto. Isso adicionar√° a funcionalidade de controle por voz que voc√™ deseja.

User: refatore a minha aplica√ß√£o inteira com as boas pr√°ticas de POO e SOLID.
Assistant: ```python
# app_config\app_config.py
from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()

    def get_root_path(self):
        return str(self.ROOT_PATH)

    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py
from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None, transcription_config=None):
        super().__init__(root_path)
        self.transcription_config = transcription_config if transcription_config else TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = self.transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])

    def get_audio_input_path(self):
        return self.AUDIO_INPUT_PATH

    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# audio_to_text\audio_to_text.py
import whisper
from audio_to_text.audio_config.audio_config import AudioConfig
from abc import ABC, abstractmethod
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class IAudioProcessor(ABC):
    @abstractmethod
    def process_audio_files(self):
        pass

class AudioToConverter(IAudioProcessor):
    def __init__(self, audio_config: AudioConfig, whisper_model_name="base"):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.get_audio_input_path()
        self.TRANSCRIPTION_INPUT_PATH = audio_config.get_transcription_input_path()
        self.model = whisper.load_model(whisper_model_name)
        self.logger = logging.getLogger(__name__)

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            self.logger.info(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                self.logger.info(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, self.model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            self.logger.info(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            self.logger.error(f"Erro ao processar o arquivo {audio_file_path}: {e}", exc_info=True)

# chat_app\chat_streamlit.py
import streamlit as st
import time
from datetime import datetime
from PIL import Image
import os
import io
from dotenv import load_dotenv
import threading  # Importa o m√≥dulo threading
from google import genai
from google.genai import types

# Core Components
from chat_app.config.config import Config
from chat_app.core.handlers.gemini_handler import GeminiHandler
from chat_app.core.rate_limiter import RateLimiter

# Services
from chat_app.services.search_files import ler_todos_arquivos_python

# Submodules (Separadas para melhor organiza√ß√£o)
from chat_app.modules.image_handling import ImageHandler
from chat_app.modules.voice_input import VoiceInputHandler
from chat_app.modules.message_handling import MessageHandler
from chat_app.modules.image_generation import ImageGenerator


class ChatApp:
    def __init__(self):
        load_dotenv()  # Carrega as vari√°veis de ambiente
        Config.ensure_directories()  # Garante que os diret√≥rios necess√°rios existam

        self.rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

        self.gemini_handler = GeminiHandler("gemini-2.0-flash-exp")  # Inicializa GeminiHandler
        self.image_handler = ImageHandler()
        self.voice_input_handler = VoiceInputHandler()
        self.message_handler = MessageHandler()
        self.image_generator = ImageGenerator()

        self.initialize_session_state()
        self.load_chat_prompt()

    def initialize_session_state(self):
        """Inicializa os estados do session_state."""
        default_states = {
            "messages": [],
            "processing": False,
            "uploaded_image": None,
            "clipboard_image_preview": None,
            "clipboard_image_file": None,
            "last_message_time": 0,
            "file_uploader_key": "uploader_0",
            "generated_image": None,
            "image_prompt": None,
            "voice_command": None  # Estado para armazenar comandos de voz
        }

        for key, default_value in default_states.items():
            if key not in st.session_state:
                st.session_state[key] = default_value

    def load_chat_prompt(self):
        """Carrega o prompt do chat e adiciona o contexto do c√≥digo fonte."""
        codigo_fonte = ler_todos_arquivos_python()
        self.chat_prompt = f"{self.load_prompt_from_file()}\n\nContexto:\n\n{codigo_fonte}"

    def load_prompt_from_file(self):
        """Carrega o prompt base do arquivo."""
        try:
            with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
                return file.read().strip()
        except FileNotFoundError:
            return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

    def process_message(self, user_input, image_data=None, generated_image=None):
        """Processa a mensagem do usu√°rio (com ou sem imagem)."""
        st.session_state.processing = True  # Marca como processando para bloquear novos inputs
        st.session_state.current_prompt = user_input
        st.session_state.current_image = image_data
        st.session_state.current_generated_image = generated_image

        st.rerun()  # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento

    def execute_processing(self):
        """Executa o processamento da mensagem."""
        user_input = st.session_state.current_prompt
        image_data = st.session_state.current_image
        generated_image = st.session_state.current_generated_image

        self.rate_limiter.wait_for_slot()  # Garante que n√£o exceda o limite de requisi√ß√µes

        current_time = time.time()
        time_since_last_message = current_time - st.session_state.last_message_time
        wait_time = max(0, 2 - time_since_last_message)
        time.sleep(wait_time)

        st.session_state.last_message_time = time.time()

        img_path = None
        img_display = None

        if image_data:
            img_path, img_display = self.image_handler.save_uploaded_image(image_data)
            st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
        elif generated_image:
            img_path = self.image_handler.save_generated_image(generated_image)
            st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
        else:
            st.session_state.messages.append({"role": "user", "content": user_input})

        self.message_handler.limit_message_history(st.session_state.messages)

        full_prompt = self.chat_prompt + "\n\n"  # Start with the base prompt
        full_prompt = self.message_handler.build_full_prompt(full_prompt, st.session_state.messages, user_input)

        try:
            if img_path:
                response = self.gemini_handler.generate_content(img_path, full_prompt)
            else:
                response = self.gemini_handler.generate_content(None, full_prompt)
        except Exception as e:
            response = f"‚ùå Erro ao gerar resposta: {str(e)}"

        st.session_state.messages.append({"role": "assistant", "content": response})
        self.message_handler.limit_message_history(st.session_state.messages)

        if img_path and os.path.exists(img_path):
            os.remove(img_path)

        st.session_state.processing = False
        st.session_state.current_prompt = None
        st.session_state.current_image = None
        st.session_state.current_generated_image = None

    def run(self):
        """Fun√ß√£o principal para rodar a aplica√ß√£o Streamlit."""
        # Executa o processamento se estiver na fila
        if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
            self.execute_processing()
            st.rerun()

        # Configura√ß√£o da barra lateral
        with st.sidebar:
            st.title("Chat IA Inteligente")

            # Se√ß√£o de gera√ß√£o de imagem
            st.markdown("### Gerar Imagem")
            image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
            if st.button("Gerar Imagem"):
                if image_prompt:
                    generated_image = self.image_generator.generate_image(image_prompt)
                    if generated_image:
                        st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                        st.session_state.generated_image = None  # Limpa para n√£o exibir em cima

                        st.rerun()
                else:
                    st.warning("Por favor, digite um prompt para gerar a imagem.")

            # Se√ß√£o de imagens (sempre vis√≠vel)
            st.markdown("### Adicionar Imagem (Opcional)")
            st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

            # Layout em duas colunas para os bot√µes de imagem
            col1, col2 = st.columns(2)

            with col1:
                # Bot√£o para verificar a √°rea de transfer√™ncia
                if st.button("üìã Colar", use_container_width=True):
                    if self.image_handler.on_paste_click():
                        st.success("Imagem colada!")
                        st.rerun()
                    else:
                        st.warning("Nada encontrado.")

            with col2:
                # Bot√£o para limpar a imagem atual (se houver)
                if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
                    if st.button("üóëÔ∏è Limpar", use_container_width=True):
                        self.image_handler.clear_all_images()
                        st.rerun()
                else:
                    # Placeholder para manter o layout alinhado
                    st.write("")

            # Uploader de imagem com chave din√¢mica
            uploaded_file = st.file_uploader(
                "üì∑ Ou fa√ßa upload de imagem",
                type=["png", "jpg", "jpeg"],
                label_visibility="visible",
                key=st.session_state.file_uploader_key
            )

            # Atualiza o estado da imagem quando um arquivo √© carregado
            if uploaded_file:
                st.session_state.uploaded_image = uploaded_file
                self.image_handler.on_file_upload()
                st.success("Imagem carregada!")

            # Exibe a imagem selecionada na barra lateral
            self.image_handler.display_selected_image()

            st.markdown("---")

             # Adiciona bot√£o para comando de voz
            if st.button("üé§ Usar Comando de Voz"):
                st.session_state.voice_thread = threading.Thread(target=self.voice_input_handler.capture_voice_command)
                st.session_state.voice_thread.start()

            # Bot√£o para limpar o hist√≥rico de conversa
            if st.button("üßπ Limpar conversa", use_container_width=True):
                st.session_state.messages = []
                st.rerun()

            st.caption("Desenvolvido com Streamlit e Gemini AI")

        # Exibi√ß√£o do hist√≥rico de mensagens
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                # Se houver imagem, exiba-a (se armazenada)
                if message.get("image"):
                    st.image(message["image"], use_container_width=True)
                # Exibe o conte√∫do da mensagem (texto)
                st.markdown(message["content"])

        # Adiciona indicador de digita√ß√£o quando estiver processando
        if st.session_state.processing:
            with st.chat_message("assistant"):
                st.markdown("Gerando resposta...")

        # Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
        if not st.session_state.processing:
            # Verifica se h√° uma imagem dispon√≠vel
            current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

            # Adapta o placeholder com base na presen√ßa de imagem
            if current_image:
                placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
            else:
                placeholder = "Digite sua mensagem..."

            # Verifica se h√° um comando de voz
            if st.session_state.get('voice_command'):
                user_input = st.session_state.voice_command
                st.session_state.voice_command = None  # Limpa o comando
                self.process_message(user_input, current_image)
            else:
                user_input = st.chat_input(placeholder)

                if user_input:
                    # Processa a mensagem com a imagem (se houver) ou apenas texto
                    self.process_message(user_input, current_image)
        else:
            st.chat_input("Aguarde o processamento...", disabled=True)


if __name__ == "__main__":
    app = ChatApp()
    app.run()

# chat_app\config\config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent

    ASSETS_DIR = BASE_DIR / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR / "processed_images"
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"

    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"

    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"

    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"

    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}

    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR,
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py
from chat_app.services.gpt_services import GenerativeModelHandler
from chat_app.core.logger_config import logger
from chat_app.core.rate_limiter import RateLimiter

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py
import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py
import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0]
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py
from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from chat_app.config.config import Config
import os
from chat_app.core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from chat_app.core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py
import os
import time
import shutil
import json
from chat_app.config.config import Config
from chat_app.services.gpt_services import GenerativeModelHandler
from chat_app.services.document_service import DocumentService
from chat_app.services.markdown_service import MarkdownService
from chat_app.utils.file_utils import list_images
from chat_app.core.logger_config import logger
from chat_app.core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(
User: Preciso garantir que seja enviado todo o c√≥digo e preciso eliminar partes redundantes e dispens√°veis sem perder funcionalidades.
Assistant: Ok, aqui est√° a refatora√ß√£o do c√≥digo com boas pr√°ticas de POO e SOLID, eliminando redund√¢ncias e garantindo que todas as funcionalidades sejam mantidas. O c√≥digo foi estruturado para melhorar a organiza√ß√£o e facilitar a manuten√ß√£o.

```python
# app_config\app_config.py
from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()

    def get_root_path(self):
        return str(self.ROOT_PATH)

    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py
from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None, transcription_config=None):
        super().__init__(root_path)
        self.transcription_config = transcription_config if transcription_config else TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = self.transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])

    def get_audio_input_path(self):
        return self.AUDIO_INPUT_PATH

    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# audio_to_text\audio_to_text.py
import whisper
from audio_to_text.audio_config.audio_config import AudioConfig
from abc import ABC, abstractmethod
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class IAudioProcessor(ABC):
    @abstractmethod
    def process_audio_files(self):
        pass

class AudioToConverter(IAudioProcessor):
    def __init__(self, audio_config: AudioConfig, whisper_model_name="base"):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.get_audio_input_path()
        self.TRANSCRIPTION_INPUT_PATH = audio_config.get_transcription_input_path()
        self.model = whisper.load_model(whisper_model_name)
        self.logger = logging.getLogger(__name__)

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            self.logger.info(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                self.logger.info(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, self.model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            self.logger.info(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            self.logger.error(f"Erro ao processar o arquivo {audio_file_path}: {e}", exc_info=True)

# chat_app\chat_streamlit.py
import streamlit as st
import time
from datetime import datetime
from PIL import Image
import os
import io
from dotenv import load_dotenv
import threading  # Importa o m√≥dulo threading
from google import genai
from google.genai import types

# Core Components
from chat_app.config.config import Config
from chat_app.core.handlers.gemini_handler import GeminiHandler
from chat_app.core.rate_limiter import RateLimiter

# Services
from chat_app.services.search_files import ler_todos_arquivos_python

# Submodules (Separadas para melhor organiza√ß√£o)
from chat_app.modules.image_handling import ImageHandler
from chat_app.modules.voice_input import VoiceInputHandler
from chat_app.modules.message_handling import MessageHandler
from chat_app.modules.image_generation import ImageGenerator


class ChatApp:
    def __init__(self):
        load_dotenv()  # Carrega as vari√°veis de ambiente
        Config.ensure_directories()  # Garante que os diret√≥rios necess√°rios existam

        self.rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

        self.gemini_handler = GeminiHandler("gemini-2.0-flash-exp")  # Inicializa GeminiHandler
        self.image_handler = ImageHandler(self)  # Passa a inst√¢ncia de ChatApp
        self.voice_input_handler = VoiceInputHandler(self)  # Passa a inst√¢ncia de ChatApp
        self.message_handler = MessageHandler()
        self.image_generator = ImageGenerator()

        self.initialize_session_state()
        self.load_chat_prompt()

    def initialize_session_state(self):
        """Inicializa os estados do session_state."""
        default_states = {
            "messages": [],
            "processing": False,
            "uploaded_image": None,
            "clipboard_image_preview": None,
            "clipboard_image_file": None,
            "last_message_time": 0,
            "file_uploader_key": "uploader_0",
            "generated_image": None,
            "image_prompt": None,
            "voice_command": None  # Estado para armazenar comandos de voz
        }

        for key, default_value in default_states.items():
            if key not in st.session_state:
                st.session_state[key] = default_value

    def load_chat_prompt(self):
        """Carrega o prompt do chat e adiciona o contexto do c√≥digo fonte."""
        codigo_fonte = ler_todos_arquivos_python()
        self.chat_prompt = f"{self.load_prompt_from_file()}\n\nContexto:\n\n{codigo_fonte}"

    def load_prompt_from_file(self):
        """Carrega o prompt base do arquivo."""
        try:
            with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
                return file.read().strip()
        except FileNotFoundError:
            return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

    def process_message(self, user_input, image_data=None, generated_image=None):
        """Processa a mensagem do usu√°rio (com ou sem imagem)."""
        st.session_state.processing = True  # Marca como processando para bloquear novos inputs
        st.session_state.current_prompt = user_input
        st.session_state.current_image = image_data
        st.session_state.current_generated_image = generated_image

        st.rerun()  # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento

    def execute_processing(self):
        """Executa o processamento da mensagem."""
        user_input = st.session_state.current_prompt
        image_data = st.session_state.current_image
        generated_image = st.session_state.current_generated_image

        self.rate_limiter.wait_for_slot()  # Garante que n√£o exceda o limite de requisi√ß√µes

        current_time = time.time()
        time_since_last_message = current_time - st.session_state.last_message_time
        wait_time = max(0, 2 - time_since_last_message)
        time.sleep(wait_time)

        st.session_state.last_message_time = time.time()

        img_path = None
        img_display = None

        if image_data:
            img_path, img_display = self.image_handler.save_uploaded_image(image_data)
            st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
        elif generated_image:
            img_path = self.image_handler.save_generated_image(generated_image)
            st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
        else:
            st.session_state.messages.append({"role": "user", "content": user_input})

        self.message_handler.limit_message_history(st.session_state.messages)

        full_prompt = self.chat_prompt + "\n\n"  # Start with the base prompt
        full_prompt = self.message_handler.build_full_prompt(full_prompt, st.session_state.messages, user_input)

        try:
            if img_path:
                response = self.gemini_handler.generate_content(img_path, full_prompt)
            else:
                response = self.gemini_handler.generate_content(None, full_prompt)
        except Exception as e:
            response = f"‚ùå Erro ao gerar resposta: {str(e)}"

        st.session_state.messages.append({"role": "assistant", "content": response})
        self.message_handler.limit_message_history(st.session_state.messages)

        if img_path and os.path.exists(img_path):
            os.remove(img_path)

        st.session_state.processing = False
        st.session_state.current_prompt = None
        st.session_state.current_image = None
        st.session_state.current_generated_image = None

    def run(self):
        """Fun√ß√£o principal para rodar a aplica√ß√£o Streamlit."""
        # Executa o processamento se estiver na fila
        if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
            self.execute_processing()
            st.rerun()

        # Configura√ß√£o da barra lateral
        with st.sidebar:
            st.title("Chat IA Inteligente")

            # Se√ß√£o de gera√ß√£o de imagem
            st.markdown("### Gerar Imagem")
            image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
            if st.button("Gerar Imagem"):
                if image_prompt:
                    generated_image = self.image_generator.generate_image(image_prompt)
                    if generated_image:
                        st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                        st.session_state.generated_image = None  # Limpa para n√£o exibir em cima

                        st.rerun()
                else:
                    st.warning("Por favor, digite um prompt para gerar a imagem.")

            # Se√ß√£o de imagens (sempre vis√≠vel)
            st.markdown("### Adicionar Imagem (Opcional)")
            st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

            # Layout em duas colunas para os bot√µes de imagem
            col1, col2 = st.columns(2)

            with col1:
                # Bot√£o para verificar a √°rea de transfer√™ncia
                if st.button("üìã Colar", use_container_width=True):
                    if self.image_handler.on_paste_click():
                        st.success("Imagem colada!")
                        st.rerun()
                    else:
                        st.warning("Nada encontrado.")

            with col2:
                # Bot√£o para limpar a imagem atual (se houver)
                if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
                    if st.button("üóëÔ∏è Limpar", use_container_width=True):
                        self.image_handler.clear_all_images()
                        st.rerun()
                else:
                    # Placeholder para manter o layout alinhado
                    st.write("")

            # Uploader de imagem com chave din√¢mica
            uploaded_file = st.file_uploader(
                "üì∑ Ou fa√ßa upload de imagem",
                type=["png", "jpg", "jpeg"],
                label_visibility="visible",
                key=st.session_state.file_uploader_key
            )

            # Atualiza o estado da imagem quando um arquivo √© carregado
            if uploaded_file:
                st.session_state.uploaded_image = uploaded_file
                self.image_handler.on_file_upload()
                st.success("Imagem carregada!")

            # Exibe a imagem selecionada na barra lateral
            self.image_handler.display_selected_image()

            st.markdown("---")

            # Adiciona bot√£o para comando de voz
            if st.button("üé§ Usar Comando de Voz"):
                st.session_state.voice_thread = threading.Thread(target=self.voice_input_handler.capture_voice_command)
                st.session_state.voice_thread.start()

            # Bot√£o para limpar o hist√≥rico de conversa
            if st.button("üßπ Limpar conversa", use_container_width=True):
                st.session_state.messages = []
                st.rerun()

            st.caption("Desenvolvido com Streamlit e Gemini AI")

        # Exibi√ß√£o do hist√≥rico de mensagens
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                # Se houver imagem, exiba-a (se armazenada)
                if message.get("image"):
                    st.image(message["image"], use_container_width=True)
                # Exibe o conte√∫do da mensagem (texto)
                st.markdown(message["content"])

        # Adiciona indicador de digita√ß√£o quando estiver processando
        if st.session_state.processing:
            with st.chat_message("assistant"):
                st.markdown("Gerando resposta...")

        # Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
        if not st.session_state.processing:
            # Verifica se h√° uma imagem dispon√≠vel
            current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

            # Adapta o placeholder com base na presen√ßa de imagem
            if current_image:
                placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
            else:
                placeholder = "Digite sua mensagem..."

            # Verifica se h√° um comando de voz
            if st.session_state.get('voice_command'):
                user_input = st.session_state.voice_command
                st.session_state.voice_command = None  # Limpa o comando
                self.process_message(user_input, current_image)
            else:
                user_input = st.chat_input(placeholder)

                if user_input:
                    # Processa a mensagem com a imagem (se houver) ou apenas texto
                    self.process_message(user_input, current_image)
        else:
            st.chat_input("Aguarde o processamento...", disabled=True)


if __name__ == "__main__":
    app = ChatApp()
    app.run()

# chat_app\config\config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent

    ASSETS_DIR = BASE_DIR / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR / "processed_images"
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"

    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"

    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"

    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"

    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}

    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR,
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py
from chat_app.services.gpt_services import GenerativeModelHandler
from chat_app.core.logger_config import logger
from chat_app.core.rate_limiter import RateLimiter

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py
import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py
import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0]
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py
from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from chat_app.config.config import Config
import os
from chat_app.core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from chat_app.core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py
import os
import time
import shutil
import json
from chat_app.config.config import Config
from chat_app.services.gpt_services import GenerativeModelHandler
from chat_app.services.document_service import DocumentService
from chat_app.services.markdown_service import MarkdownService
from chat_app.utils.file_utils import list_images
from chat_app.core.logger_config import logger
from chat_app.core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response
User: Pode enviar apenas um arquivo de cada vez, bem separado  que precisa alterar de cada vez para implementar na interface streamlit o comando de voz ??? 
2025-04-10 20:21:08,041 [INFO] Resposta da IA (texto): Ok, aqui est√° o arquivo `chat_app\chat_streamlit.py` com as modifica√ß√µes necess√°rias para integrar o comando de voz, seguindo as melhores pr√°ticas de POO e SOLID. As modifica√ß√µes est√£o concentradas e explicadas para facilitar a implementa√ß√£o.

```python
# chat_app\chat_streamlit.py
import streamlit as st
import time
from datetime import datetime
from PIL import Image
import os
import io
from dotenv import load_dotenv
import threading  # Importa o m√≥dulo threading
from google import genai
from google.genai import types

# Core Components
from chat_app.config.config import Config
from chat_app.core.handlers.gemini_handler import GeminiHandler
from chat_app.core.rate_limiter import RateLimiter

# Services
from chat_app.services.search_files import ler_todos_arquivos_python

# Submodules (Separadas para melhor organiza√ß√£o)
from chat_app.modules.image_handling import ImageHandler
from chat_app.modules.voice_input import VoiceInputHandler
from chat_app.modules.message_handling import MessageHandler
from chat_app.modules.image_generation import ImageGenerator


class ChatApp:
    def __init__(self):
        load_dotenv()  # Carrega as vari√°veis de ambiente
        Config.ensure_directories()  # Garante que os diret√≥rios necess√°rios existam

        self.rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

        self.gemini_handler = GeminiHandler("gemini-2.0-flash-exp")  # Inicializa GeminiHandler
        self.image_handler = ImageHandler(self)  # Passa a inst√¢ncia de ChatApp
        self.voice_input_handler = VoiceInputHandler(self)  # Passa a inst√¢ncia de ChatApp
        self.message_handler = MessageHandler()
        self.image_generator = ImageGenerator()

        self.initialize_session_state()
        self.load_chat_prompt()

    def initialize_session_state(self):
        """Inicializa os estados do session_state."""
        default_states = {
            "messages": [],
            "processing": False,
            "uploaded_image": None,
            "clipboard_image_preview": None,
            "clipboard_image_file": None,
            "last_message_time": 0,
            "file_uploader_key": "uploader_0",
            "generated_image": None,
            "image_prompt": None,
            "voice_command": None  # Estado para armazenar comandos de voz
        }

        for key, default_value in default_states.items():
            if key not in st.session_state:
                st.session_state[key] = default_value

    def load_chat_prompt(self):
        """Carrega o prompt do chat e adiciona o contexto do c√≥digo fonte."""
        codigo_fonte = ler_todos_arquivos_python()
        self.chat_prompt = f"{self.load_prompt_from_file()}\n\nContexto:\n\n{codigo_fonte}"

    def load_prompt_from_file(self):
        """Carrega o prompt base do arquivo."""
        try:
            with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
                return file.read().strip()
        except FileNotFoundError:
            return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

    def process_message(self, user_input, image_data=None, generated_image=None):
        """Processa a mensagem do usu√°rio (com ou sem imagem)."""
        st.session_state.processing = True  # Marca como processando para bloquear novos inputs
        st.session_state.current_prompt = user_input
        st.session_state.current_image = image_data
        st.session_state.current_generated_image = generated_image

        st.rerun()  # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento

    def execute_processing(self):
        """Executa o processamento da mensagem."""
        user_input = st.session_state.current_prompt
        image_data = st.session_state.current_image
        generated_image = st.session_state.current_generated_image

        self.rate_limiter.wait_for_slot()  # Garante que n√£o exceda o limite de requisi√ß√µes

        current_time = time.time()
        time_since_last_message = current_time - st.session_state.last_message_time
        wait_time = max(0, 2 - time_since_last_message)
        time.sleep(wait_time)

        st.session_state.last_message_time = time.time()

        img_path = None
        img_display = None

        if image_data:
            img_path, img_display = self.image_handler.save_uploaded_image(image_data)
            st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
        elif generated_image:
            img_path = self.image_handler.save_generated_image(generated_image)
            st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
        else:
            st.session_state.messages.append({"role": "user", "content": user_input})

        self.message_handler.limit_message_history(st.session_state.messages)

        full_prompt = self.chat_prompt + "\n\n"  # Start with the base prompt
        full_prompt = self.message_handler.build_full_prompt(full_prompt, st.session_state.messages, user_input)

        try:
            if img_path:
                response = self.gemini_handler.generate_content(img_path, full_prompt)
            else:
                response = self.gemini_handler.generate_content(None, full_prompt)
        except Exception as e:
            response = f"‚ùå Erro ao gerar resposta: {str(e)}"

        st.session_state.messages.append({"role": "assistant", "content": response})
        self.message_handler.limit_message_history(st.session_state.messages)

        if img_path and os.path.exists(img_path):
            os.remove(img_path)

        st.session_state.processing = False
        st.session_state.current_prompt = None
        st.session_state.current_image = None
        st.session_state.current_generated_image = None

    def run(self):
        """Fun√ß√£o principal para rodar a aplica√ß√£o Streamlit."""
        # Executa o processamento se estiver na fila
        if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
            self.execute_processing()
            st.rerun()

        # Configura√ß√£o da barra lateral
        with st.sidebar:
            st.title("Chat IA Inteligente")

            # Se√ß√£o de gera√ß√£o de imagem
            st.markdown("### Gerar Imagem")
            image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
            if st.button("Gerar Imagem"):
                if image_prompt:
                    generated_image = self.image_generator.generate_image(image_prompt)
                    if generated_image:
                        st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                        st.session_state.generated_image = None  # Limpa para n√£o exibir em cima

                        st.rerun()
                else:
                    st.warning("Por favor, digite um prompt para gerar a imagem.")

            # Se√ß√£o de imagens (sempre vis√≠vel)
            st.markdown("### Adicionar Imagem (Opcional)")
            st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

            # Layout em duas colunas para os bot√µes de imagem
            col1, col2 = st.columns(2)

            with col1:
                # Bot√£o para verificar a √°rea de transfer√™ncia
                if st.button("üìã Colar", use_container_width=True):
                    if self.image_handler.on_paste_click():
                        st.success("Imagem colada!")
                        st.rerun()
                    else:
                        st.warning("Nada encontrado.")

            with col2:
                # Bot√£o para limpar a imagem atual (se houver)
                if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
                    if st.button("üóëÔ∏è Limpar", use_container_width=True):
                        self.image_handler.clear_all_images()
                        st.rerun()
                else:
                    # Placeholder para manter o layout alinhado
                    st.write("")

            # Uploader de imagem com chave din√¢mica
            uploaded_file = st.file_uploader(
                "üì∑ Ou fa√ßa upload de imagem",
                type=["png", "jpg", "jpeg"],
                label_visibility="visible",
                key=st.session_state.file_uploader_key
            )

            # Atualiza o estado da imagem quando um arquivo √© carregado
            if uploaded_file:
                st.session_state.uploaded_image = uploaded_file
                self.image_handler.on_file_upload()
                st.success("Imagem carregada!")

            # Exibe a imagem selecionada na barra lateral
            self.image_handler.display_selected_image()

            st.markdown("---")

            # Adiciona bot√£o para comando de voz
            # Modifica√ß√£o 1: Adiciona bot√£o para ativar o comando de voz
            if st.button("üé§ Usar Comando de Voz"):
                st.session_state.voice_thread = threading.Thread(target=self.voice_input_handler.capture_voice_command)
                st.session_state.voice_thread.start()

            # Bot√£o para limpar o hist√≥rico de conversa
            if st.button("üßπ Limpar conversa", use_container_width=True):
                st.session_state.messages = []
                st.rerun()

            st.caption("Desenvolvido com Streamlit e Gemini AI")

        # Exibi√ß√£o do hist√≥rico de mensagens
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                # Se houver imagem, exiba-a (se armazenada)
                if message.get("image"):
                    st.image(message["image"], use_container_width=True)
                # Exibe o conte√∫do da mensagem (texto)
                st.markdown(message["content"])

        # Adiciona indicador de digita√ß√£o quando estiver processando
        if st.session_state.processing:
            with st.chat_message("assistant"):
                st.markdown("Gerando resposta...")

        # Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
        if not st.session_state.processing:
            # Verifica se h√° uma imagem dispon√≠vel
            current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

            # Adapta o placeholder com base na presen√ßa de imagem
            if current_image:
                placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
            else:
                placeholder = "Digite sua mensagem..."

            # Modifica√ß√£o 2: Verifica se h√° um comando de voz
            if st.session_state.get('voice_command'):
                user_input = st.session_state.voice_command
                st.session_state.voice_command = None  # Limpa o comando
                self.process_message(user_input, current_image)
            else:
                user_input = st.chat_input(placeholder)

                if user_input:
                    # Processa a mensagem com a imagem (se houver) ou apenas texto
                    self.process_message(user_input, current_image)
        else:
            st.chat_input("Aguarde o processamento...", disabled=True)


if __name__ == "__main__":
    app = ChatApp()
    app.run()
```

**Explica√ß√£o das Modifica√ß√µes:**

1.  **Importa o m√≥dulo `threading`:**

    *   Certifique-se de que o m√≥dulo `threading` est√° importado no in√≠cio do arquivo:

    ```python
    import threading
    ```

2.  **Adiciona bot√£o para comando de voz:**

    *   Adiciona um bot√£o na barra lateral para ativar o comando de voz. Este bot√£o inicia uma thread que executa a fun√ß√£o `capture_voice_command` da classe `VoiceInputHandler`.

    ```python
    with st.sidebar:
        # ... (seu c√≥digo existente da barra lateral)

        # Adiciona bot√£o para comando de voz
        if st.button("üé§ Usar Comando de Voz"):
            st.session_state.voice_thread = threading.Thread(target=self.voice_input_handler.capture_voice_command)
            st.session_state.voice_thread.start()
    ```

3.  **Verifica se h√° um comando de voz:**

    *   Modifica a l√≥gica de processamento de mensagens para verificar se h√° um comando de voz capturado em `st.session_state.voice_command`. Se houver, usa esse comando como entrada e limpa o estado para evitar repeti√ß√µes.

    ```python
    if not st.session_state.processing:
        # ... (seu c√≥digo existente para determinar o placeholder)

        # Verifica se h√° um comando de voz
        if st.session_state.get('voice_command'):
            user_input = st.session_state.voice_command
            st.session_state.voice_command = None  # Limpa o comando
            self.process_message(user_input, current_image)
        else:
            user_input = st.chat_input(placeholder)

            if user_input:
                # Processa a mensagem com a imagem (se houver) ou apenas texto
                self.process_message(user_input, current_image)
    ```

Com estas modifica√ß√µes, o arquivo `chat_streamlit.py` deve estar pronto para receber comandos de voz. Lembre-se de que os arquivos `VoiceInputHandler`, e outras classes devem estar corretamente definidos para que esta integra√ß√£o funcione.

2025-04-10 20:21:08,202 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:21:08,204 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:21:08,206 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:21:08,208 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:21:08,210 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:21:08,212 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:21:08,215 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:21:08,217 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:21:08,219 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:21:08,221 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:21:08,224 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:21:08,226 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:21:08,228 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:21:08,231 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:21:08,234 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:21:08,236 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:21:08,238 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:21:08,240 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:21:08,242 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:21:08,244 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:21:08,247 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:21:08,249 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:21:08,251 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:21:08,253 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:21:08,255 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:21:08,257 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:21:08,258 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:21:08,261 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:21:08,263 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:21:08,266 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:21:08,267 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:21:08,269 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:21:08,270 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:21:08,273 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:21:08,275 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:21:08,277 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:21:08,279 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:21:08,281 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:21:08,283 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:21:08,285 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:21:08,287 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:21:08,289 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:21:08,291 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:21:08,294 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:21:08,296 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:21:08,299 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:21:08,301 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:21:08,302 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:21:08,304 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:21:08,306 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:21:08,308 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:21:08,310 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:21:08,313 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:21:08,316 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:27:49,306 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:27:49,308 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:27:49,309 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:27:49,311 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:27:49,312 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:27:49,314 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:27:49,315 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:27:49,316 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:27:49,319 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:27:49,321 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:27:49,326 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:27:49,328 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:27:49,330 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:27:49,332 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:27:49,338 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:27:49,341 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:27:49,343 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:27:49,345 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:27:49,348 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:27:49,349 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:27:49,350 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:27:49,355 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:27:49,356 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:27:49,358 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:27:49,359 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:27:49,360 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:27:49,361 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:27:49,363 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:27:49,364 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:27:49,365 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:27:49,366 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:27:49,369 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:27:49,372 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:27:49,374 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:27:49,375 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:27:49,376 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:27:49,377 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:27:49,378 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:27:49,380 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:27:49,381 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:27:49,382 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:27:49,384 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:27:49,387 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:27:49,389 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:27:49,390 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:27:49,391 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:27:49,392 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:27:49,393 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:27:49,395 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:27:49,396 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:27:49,397 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:27:49,399 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:27:49,401 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:27:49,405 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:27:49,505 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:27:49,507 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:27:49,508 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:27:49,511 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:27:49,513 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:27:49,515 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:27:49,516 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:27:49,519 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:27:49,522 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:27:49,524 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:27:49,526 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:27:49,528 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:27:49,530 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:27:49,532 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:27:49,533 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:27:49,538 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:27:49,541 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:27:49,543 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:27:49,547 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:27:49,549 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:27:49,553 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:27:49,558 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:27:49,560 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:27:49,562 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:27:49,564 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:27:49,566 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:27:49,569 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:27:49,574 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:27:49,578 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:27:49,580 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:27:49,582 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:27:49,589 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:27:49,592 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:27:49,594 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:27:49,597 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:27:49,599 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:27:49,600 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:27:49,605 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:27:49,608 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:27:49,609 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:27:49,611 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:27:49,613 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:27:49,614 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:27:49,616 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:27:49,619 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:27:49,621 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:27:49,623 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:27:49,625 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:27:49,626 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:27:49,628 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:27:49,630 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:27:49,632 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:27:49,633 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:27:49,636 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:28:19,622 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:28:19,624 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:28:19,625 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:28:19,627 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:28:19,629 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:28:19,631 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:28:19,633 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:28:19,635 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:28:19,637 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:28:19,640 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:28:19,643 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:28:19,645 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:28:19,647 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:28:19,649 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:28:19,650 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:28:19,652 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:28:19,656 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:28:19,658 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:28:19,661 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:28:19,663 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:28:19,664 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:28:19,665 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:28:19,667 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:28:19,668 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:28:19,670 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:28:19,674 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:28:19,676 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:28:19,678 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:28:19,679 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:28:19,680 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:28:19,682 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:28:19,684 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:28:19,685 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:28:19,687 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:28:19,691 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:28:19,693 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:28:19,694 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:28:19,696 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:28:19,697 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:28:19,699 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:28:19,700 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:28:19,702 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:28:19,703 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:28:19,707 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:28:19,709 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:28:19,711 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:28:19,712 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:28:19,714 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:28:19,715 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:28:19,717 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:28:19,718 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:28:19,720 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:28:19,723 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:28:19,726 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:28:19,850 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:28:19,851 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:28:19,853 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:28:19,856 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:28:19,859 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:28:19,861 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:28:19,863 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:28:19,865 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:28:19,867 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:28:19,869 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:28:19,873 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:28:19,875 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:28:19,877 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:28:19,879 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:28:19,881 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:28:19,882 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:28:19,884 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:28:19,885 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:28:19,889 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:28:19,892 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:28:19,893 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:28:19,895 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:28:19,896 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:28:19,898 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:28:19,899 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:28:19,901 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:28:19,903 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:28:19,906 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:28:19,908 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:28:19,910 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:28:19,911 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:28:19,913 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:28:19,914 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:28:19,916 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:28:19,918 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:28:19,919 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:28:19,922 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:28:19,923 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:28:19,926 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:28:19,928 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:28:19,929 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:28:19,931 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:28:19,932 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:28:19,934 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:28:19,935 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:28:19,937 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:28:19,940 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:28:19,941 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:28:19,943 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:28:19,945 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:28:19,946 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:28:19,948 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:28:19,949 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:28:19,951 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-10 20:28:19,953 [INFO] Enviando para IA - Prompt (sem imagem): Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas.

Contexto:



# app_config\app_config.py

from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()
    
    def get_root_path(self):
        return str(self.ROOT_PATH)
    
    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py

from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        transcription_config = TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])


# audio_to_text\audio_to_text.py

import whisper
from audio_to_text.audio_config.audio_config import AudioConfig

class AudioToConverter:
    def __init__(self, audio_config: AudioConfig):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.AUDIO_INPUT_PATH
        self.TRANSCRIPTION_INPUT_PATH = audio_config.TRANSCRIPTION_INPUT_PATH

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            print(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        model = whisper.load_model("base")

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                print(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            print(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            print(f"Erro ao processar o arquivo {audio_file_path}: {e}")


# chat_app\chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# chat_app\config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# chat_app\services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# chat_app\services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# chat_app\services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# chat_app\utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

# common_paths\common_paths.py

from pathlib import Path

class CommonPaths:
    def __init__(self):
        # Diret√≥rio atual do script
        self.ROOT_PATH = Path(__file__).resolve().parent

        # Defini√ß√£o dos caminhos comuns
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'output'
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.AUDIO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.TRANSCRIPTION_OUTPUT_PATH = self.ROOT_PATH / 'data'
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'data'

        # Cria√ß√£o dos diret√≥rios
        self.create_directories()

    def create_directories(self):
        self.VIDEO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.VIDEO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.TRANSCRIPTION_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)



# fundamentus_api\fundamentus\__init__.py



# fundamentus_api\fundamentus\dados_b3.py

import locale
import pandas as pd
import streamlit as st
import requests
import fundamentus
import os
import plotly.express as px
from bs4 import BeautifulSoup
from fundamentus.detalhes import get_papel
import logging

# Configura localidade
locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')

# Configura√ß√£o do layout do Streamlit
st.set_page_config(
    page_title="An√°lise de A√ß√µes",
    layout="wide",
    page_icon="üìà"
)

class Acao:
    def __init__(self, papel):
        self.papel = papel
        self.dados_fundamentais = None
        self.proventos = None
        self.detalhes = None
        self.oscilacoes = None  # Adicionando um atributo para oscila√ß√µes

    def carregar_dados_fundamentais(self):
        self.dados_fundamentais = fundamentus.get_resultado().loc[[self.papel]]  # Use colchetes duplos para garantir que seja um DataFrame
        self.remover_formatacao()

    def obter_detalhes(self):
        self.detalhes = get_papel(self.papel)
        if self.detalhes is None or self.detalhes.empty:
            logging.warning(f"Nenhum detalhe encontrado para o papel: {self.papel}")

    def obter_proventos(self):
        url = f"https://www.fundamentus.com.br/proventos.php?papel={self.papel}&tipo=2"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        tabela = soup.find('table', {'id': 'resultado'})

        if not tabela:
            return pd.DataFrame()

        dados = []
        for linha in tabela.find_all('tr')[1:]:
            colunas = linha.find_all('td')
            try:
                valor = float(colunas[1].text.strip().replace(',', '.'))
            except ValueError:
                valor = None  # Se der erro, coloca None para evitar crash

            dados.append([colunas[0].text.strip(), valor, colunas[2].text.strip()])
        
        self.proventos = pd.DataFrame(dados, columns=['Data', 'Valor', 'Tipo'])
        return self.proventos

    def obter_oscilacoes(self):
        url = f"https://www.fundamentus.com.br/detalhes.php?papel={self.papel}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        conteudo_div = soup.find('div', class_='conteudo clearfix')

        if conteudo_div is None:
            return pd.DataFrame()

        oscilacoes_data = []
        oscilacoes_section = conteudo_div.find('td', class_='nivel1', colspan='2')
        
        if oscilacoes_section:
            labels = oscilacoes_section.find_all_next('td', class_='label w1')
            dados = oscilacoes_section.find_all_next('td', class_='data w1')

            for label, dado in zip(labels, dados):
                label_text = label.get_text(strip=True)
                valor_text = dado.find('span', class_='oscil').get_text(strip=True)
                oscilacoes_data.append([label_text, valor_text])

        self.oscilacoes = pd.DataFrame(oscilacoes_data, columns=['Per√≠odo', 'Oscila√ß√£o'])
        return self.oscilacoes

    def remover_formatacao(self):
        colunas_percentuais = ['dy', 'mrgebit', 'mrgliq', 'roic', 'roe', 'c5y']
        for coluna in colunas_percentuais:
            if coluna in self.dados_fundamentais:
                try:
                    self.dados_fundamentais[coluna] = self.dados_fundamentais[coluna].astype(float)
                except ValueError as e:
                    logging.error(f"Erro ao converter coluna {coluna} para float: {e}")

    def formatar_moeda(self, valor):
        return locale.currency(valor, symbol=True, grouping=True)

class Aplicacao:
    def __init__(self):
        self.acoes = fundamentus.get_resultado()

    def ajustar_tipos_dataframe(self, df):
        for coluna in df.columns:
            if df[coluna].dtype == 'object':
                try:
                    df[coluna] = df[coluna].astype(float)
                except ValueError:
                    df[coluna] = df[coluna].astype(str)
            elif df[coluna].dtype in ['int64', 'float64']:
                df[coluna] = df[coluna].astype(float)
        return df

    def exibir_dashboard(self):
        st.sidebar.title("üìä Dashboard de An√°lise de A√ß√µes")
        st.sidebar.write("Selecione um papel para visualizar detalhes.")

        papel_selecionado = st.sidebar.selectbox("Escolha uma a√ß√£o", self.acoes.index)

        acao = Acao(papel_selecionado)
        acao.carregar_dados_fundamentais()
        acao.obter_proventos()
        acao.obter_detalhes()
        acao.obter_oscilacoes()

        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader(f"üìå Dados Fundamentais - {papel_selecionado}")
            dados_fundamentais_df = self.ajustar_tipos_dataframe(acao.dados_fundamentais.T)
            st.dataframe(dados_fundamentais_df, width=400)

        with col2:
            st.subheader("üîç Detalhes")
            if acao.detalhes is not None and not acao.detalhes.empty:
                detalhes_df = pd.DataFrame(acao.detalhes).T.reset_index()
                detalhes_df.columns = ['Descri√ß√£o', 'Valor']
                detalhes_df = self.ajustar_tipos_dataframe(detalhes_df)

                st.subheader("Tabela de Detalhes")
                st.dataframe(detalhes_df, width=800)
            else:
                st.warning("Nenhum detalhe encontrado para essa a√ß√£o.")

        col_dividendos, col_oscilacoes = st.columns([1, 2])

        with col_dividendos:
            st.subheader("üí∞ Dividendos")
            if not acao.proventos.empty:
                proventos_df = self.ajustar_tipos_dataframe(acao.proventos)
                st.write(proventos_df)

        with col_oscilacoes:
            st.subheader("üìâ Oscila√ß√µes")
            if acao.oscilacoes is not None and not acao.oscilacoes.empty:
                oscilacoes_df = self.ajustar_tipos_dataframe(acao.oscilacoes)
                st.write(oscilacoes_df)

        st.subheader("üìà Tabela Geral de A√ß√µes")
        st.dataframe(self.acoes)

# Execu√ß√£o
if __name__ == "__main__":
    app = Aplicacao()
    app.exibir_dashboard()

# fundamentus_api\setup.py

from setuptools import setup, find_packages

setup(
    name='fundamentalvision ',
    version='0.1.0',
    author='Joel FerreiraHeanna dos Reis',
    author_email='heannareis@gmail.com',
    description='Um pacote para an√°lise fundamentalista de a√ß√µes da Bolsa B3 do Brasil.',
    packages=find_packages(),
    install_requires=[
        'pandas',
        'requests',
        'beautifulsoup4',
        'streamlit',
        'plotly',
        'fundamentus'
    ],
    classifiers=[
        'Programming Language :: Python :: 3',
        'License :: OSI Approved :: MIT License',
        'Operating System :: OS Independent',
    ],
    python_requires='>=3.6',
)

# ia_generator.py

import requests
from pathlib import Path
import webbrowser
from config.common_paths import TRANSCRIPTION_OUTPUT_PATH

apiKey = "6UlOOoY/kkmprunma/qNDg"

str_personas = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'personas.txt'
str_contexto = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'contexto.txt'

url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

txt_files = list(TRANSCRIPTION_OUTPUT_PATH.glob('*.txt'))

css_styles = """
<style>
body {
    font-family: Arial, sans-serif;
    margin: 20px;
}

h1, h2, h3 {
    color: #FF8C00;
}

li, strong, p {
    color: #008000;
}

h1 {
    font-size: 24px;
    margin-bottom: 20px;
}

h2 {
    font-size: 20px;
    margin-top: 20px;
    margin-bottom: 10px;
}

ul {
    list-style-type: disc;
    margin-left: 40px;
}

li {
    margin-bottom: 10px;
}

p {
    line-height: 1.6;
}
</style>
"""

if not txt_files:
    print(f"N√£o foram encontrados arquivos .txt no diret√≥rio {TRANSCRIPTION_OUTPUT_PATH}.")
else:
    for txt_file in txt_files:
        if txt_file.is_file():
            print(f"Lendo o arquivo: {txt_file.name}")
            with open(txt_file, 'r', encoding='utf-8') as file:
                str_reuniao = file.read()

            print(f"Enviando o conte√∫do do arquivo {txt_file.name} para a API...")
            data = {
                "inputs": {
                    "str_reuniao": str_reuniao,
                    "str_personas": str_personas.read_text(encoding='utf-8'),
                    "str_contexto": str_contexto.read_text(encoding='utf-8'),
                }
            }

            response = requests.post(f"{url}/api/templates/668de04202493d3063a9d7fa/execute", json=data, headers=headers)
            if response.status_code == 200:
                print(f"Resultado para o arquivo {txt_file.name} recebido.")
                html_content = response.text
                print(response.text)

                # Incluir o CSS no conte√∫do HTML
                html_with_css = f"<html><head>{css_styles}</head><body>{html_content}</body></html>"

                # Salvar o conte√∫do HTML em um arquivo
                output_file = TRANSCRIPTION_OUTPUT_PATH / f"{txt_file.stem}_output.html"
                with open(output_file, 'w', encoding='utf-8') as html_file:
                    html_file.write(html_with_css)

                # Abrir o arquivo HTML no navegador
                webbrowser.open(f"file://{output_file.resolve()}")
            else:
                print(f"Erro ao processar o arquivo {txt_file.name}: {response.status_code}")


# main.py

from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from transcriptions.transcriptions_config import TranscriptionConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from pathlib import Path

def main():
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    root_path = str(PROJECT_ROOT)
    print(f"Root path: {root_path}")  # Para verificar se est√° correto
    api_url = "http://localhost:8081/api/meetings/transcriptions"
    
    # # Configura√ß√£o de v√≠deos
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()
    
    # # Configura√ß√£o de √°udios
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()
    
    # # Processamento de transcri√ß√µes e envio de embeddings
    # embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    # embedding_processor_wrapper.process_transcriptions()

if __name__ == "__main__":
    main()


# send_embeddings_database\embedding_config\embedding_config.py

from app_config.app_config import AppConfig

class EmbeddingConfig(AppConfig):
    def __init__(self, root_path=None, transcription_input_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = transcription_input_path
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'embeddings' / 'output'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH, self.EMBEDDING_OUTPUT_PATH])


# send_embeddings_database\verify_last_enbedding.py

import os
import numpy as np

def get_latest_file(directory):
    # Listar todos os arquivos no diret√≥rio
    files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]
    
    if not files:
        raise FileNotFoundError("Nenhum arquivo encontrado no diret√≥rio.")

    # Encontrar o arquivo mais recente
    latest_file = max(files, key=os.path.getmtime)
    return latest_file

def load_and_print_embedding(directory):
    # Obter o caminho do √∫ltimo arquivo de embedding
    embedding_file_path = get_latest_file(directory)
    
    # Carregar o embedding
    embedding = np.load(embedding_file_path)
    
    # Exibir o conte√∫do do embedding
    print("Embedding carregado:")
    print(embedding)
    print("Dimens√µes do embedding:", embedding.shape)

# Caminho do diret√≥rio de embeddings
embedding_directory = 'C:/Users/HeannarReis/Documents/bsa_atacadao/assets/embeddings/output'

# Carregar e exibir o √∫ltimo embedding
load_and_print_embedding(embedding_directory)


# test_whisper.py

from transformers import pipeline
from common_paths import CommonPaths

commmom_paths = CommonPaths()

# Fun√ß√£o para ler a transcri√ß√£o de um arquivo
def read_transcription(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
    return lines

# Fun√ß√£o para converter a pontua√ß√£o em estrelas
def score_to_stars(score):
    if score >= 0.75:
        return 5
    elif score >= 0.55:
        return 4
    elif score >= 0.35:
        return 3
    elif score >= 0.15:
        return 2
    else:
        return 1

# Inicializar o pipeline de an√°lise de sentimento
sentiment_pipeline = pipeline("sentiment-analysis", model="neuralmind/bert-base-portuguese-cased")

# Caminho para o arquivo de transcri√ß√£o
file_path = commmom_paths.TRANSCRIPTION_OUTPUT_PATH / 'feedback.txt'

# Ler a transcri√ß√£o
lines = read_transcription(file_path)

# Analisar sentimento para cada feedback
for line in lines:
    sentiment = sentiment_pipeline(line.strip())
    score = sentiment[0]['score']
    stars = score_to_stars(score)
    
    # Ajuste manual para feedbacks com aspectos positivos e negativos
    if any(word in line.lower() for word in ["mas", "por√©m", "no entanto"]):
        stars = max(1, stars - 1)  # Reduz uma estrela se houver contradi√ß√£o
    
    # Ajuste adicional baseado em palavras-chave
    positive_keywords = ["excelente", "√≥timo", "perfeito", "r√°pido", "eficiente", "satisfeito", "clara", "eficaz", "bom trabalho"]
    negative_keywords = ["ruim", "p√©ssimo", "horr√≠vel", "poderia", "n√£o resolveu", "insatisfat√≥ria", "confusa", "inadequado", "lento", "n√£o houve seguimento", "n√£o atendeu", "n√£o funcionou", "demorado"]
    
    positive_count = sum(word in line.lower() for word in positive_keywords)
    negative_count = sum(word in line.lower() for word in negative_keywords)
    
    # Ajuste de estrelas baseado na contagem de palavras-chave
    if positive_count > negative_count:
        stars = min(5, stars + 1)
    elif negative_count > positive_count:
        stars = max(1, stars - 1)
    
    print(f"Texto: {line.strip()}")
    print(f"Sentimento: {stars} estrelas")
    print(f"Pontua√ß√£o: {score:.2f}")
    print('---')


# text_to_embedding\embedding_processing.py

from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from transcriptions.transcriptions_config import TranscriptionConfig
from transcriptions.transciption_sender_database import TranscriptionSenderDatabase

class EmbeddingProcessorWrapper:
    def __init__(self, root_path, api_url):
        # Configura√ß√£o de transcri√ß√µes e embeddings
        transcription_config = TranscriptionConfig(root_path=root_path)
        embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())

        self.embedding_processor = EmbeddingProcessor(embedding_config)
        self.transcription_sender = TranscriptionSenderDatabase(api_url)
    
    def process_transcriptions(self):
        # Mostrar o diret√≥rio onde est√° procurando as transcri√ß√µes
        print(f"Diret√≥rio de entrada das transcri√ß√µes: {self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH}")
        
        # Listar todos os arquivos de transcri√ß√£o no diret√≥rio de entrada
        transcription_files = list(self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH.glob('*.txt'))
        if not transcription_files:
            print("Nenhum arquivo de transcri√ß√£o encontrado.")
        for transcription_file_path in transcription_files:
            if transcription_file_path.is_file():
                print(f"Processando arquivo: {transcription_file_path}")
                self.process_and_send_transcription(transcription_file_path)
            else:
                print(f"Arquivo n√£o encontrado: {transcription_file_path}")

    def process_and_send_transcription(self, transcription_file_path):
        try:
            # Ler a transcri√ß√£o do arquivo de texto
            with open(transcription_file_path, 'r', encoding='utf-8') as f:
                transcription_text = f.read()
                if not transcription_text:
                    print(f"Arquivo {transcription_file_path} est√° vazio.")
                    return

            # Gerar o embedding da transcri√ß√£o
            embedding = self.embedding_processor.generate_embedding(transcription_text)
            if embedding is None:
                print(f"Falha ao gerar embedding para o arquivo {transcription_file_path}.")
                return

            # Salvar o embedding em um arquivo .npy
            self.embedding_processor.save_embedding(transcription_file_path, embedding)

            # Enviar os dados para a API
            self.transcription_sender.send_transcription(transcription_text, embedding)

        except Exception as e:
            print(f"Erro ao processar o arquivo {transcription_file_path}: {e}")


# text_to_embedding\texto_to_embedding.py

from sentence_transformers import SentenceTransformer
import numpy as np

class EmbeddingProcessor:
    def __init__(self, embedding_config):
        self.embedding_config = embedding_config
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

    def generate_embedding(self, transcription_text):
        return self.embedding_model.encode(transcription_text)

    def save_embedding(self, transcription_file_path, embedding):
        embedding_file_path = self.embedding_config.EMBEDDING_OUTPUT_PATH / transcription_file_path.with_suffix('.npy').name
        np.save(embedding_file_path, embedding)
        print(f"Embedding salvo em: {embedding_file_path}")
        return embedding_file_path


# transcriptions\transciption_sender_database.py

import requests

class TranscriptionSenderDatabase:
    def __init__(self, api_url):
        self.api_url = api_url

    def send_transcription(self, transcription_text, embedding):
        data = {
            'transcriptionText': transcription_text,
            'embedding': embedding.tolist()
        }

        response = requests.post(self.api_url, json=data)

        if response.status_code == 201:
            print("Transcri√ß√£o e embedding enviados com sucesso.")
        else:
            print(f"Erro ao enviar dados: {response.status_code}")
            print("Resposta da API:")
            print(response.text)


# transcriptions\transcriptions_config.py

from app_config.app_config import AppConfig

class TranscriptionConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = self.ROOT_PATH / 'assets' / 'transcriptions' / 'input'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH])
    
    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# translate\translator_to_english.py

import speech_recognition as sr
from translate import Translator

def ouvir_e_traduzir():
    # Inicializa o reconhecedor de fala
    recognizer = sr.Recognizer()

    # Configura o tradutor
    translator = Translator(to_lang="en", from_lang="pt")

    # Usa o microfone como fonte de √°udio
    with sr.Microphone() as source:
        print("Diga algo em portugu√™s...")

        while True:
            try:
                # Escuta o √°udio do microfone
                audio = recognizer.listen(source)
                
                # Reconhece a fala usando o Google Web Speech API
                texto_portugues = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {texto_portugues}")

                # Traduz o texto para o ingl√™s
                traducao = translator.translate(texto_portugues)
                print(f"Tradu√ß√£o para o ingl√™s: {traducao}")

            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio")
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")

if __name__ == "__main__":
    try:
        ouvir_e_traduzir()
    except KeyboardInterrupt:
        print("Interrompido pelo usu√°rio")


# translate\whispert_translator.py

import whisper
import pyaudio
import numpy as np

# Inicializa o modelo Whisper
model = whisper.load_model("base")

# Configura√ß√µes de √°udio
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024

# Inicializa o PyAudio
audio = pyaudio.PyAudio()

# Abre o stream de √°udio
stream = audio.open(format=FORMAT, channels=CHANNELS,
                    rate=RATE, input=True,
                    frames_per_buffer=CHUNK)

print("Diga algo em portugu√™s...")

try:
    audio_buffer = []

    while True:
        # L√™ dados do microfone
        data = stream.read(CHUNK)
        audio_buffer.append(np.frombuffer(data, dtype=np.int16).flatten().astype(np.float32) / 32768.0)

        # Processa o √°udio a cada 5 segundos
        if len(audio_buffer) * CHUNK / RATE >= 5:
            audio_data = np.concatenate(audio_buffer)
            audio_buffer = []

            # Transcreve e traduz o √°udio usando Whisper
            result = model.transcribe(audio_data, task="translate", language="pt")

            # Exibe a tradu√ß√£o
            print(f"Tradu√ß√£o para o ingl√™s: {result['text']}")

except KeyboardInterrupt:
    print("Interrompido pelo usu√°rio")

    # Fecha o stream de √°udio
    stream.stop_stream()
    stream.close()
    audio.terminate()


# video_to_audio\video_config\video_config.py

from app_config.app_config import AppConfig

class VideoConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video' / 'input'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.create_directories([self.VIDEO_INPUT_PATH, self.VIDEO_OUTPUT_PATH])

# video_to_audio\video_to_audio.py

from moviepy import VideoFileClip
import glob
import os
from .video_config.video_config import VideoConfig

class VideoToAudioConverter:
    def __init__(self, video_config: VideoConfig):
        self.video_config = video_config

    def convert_video_to_audio(self, video_path, audio_path):
        try:
            video = VideoFileClip(video_path)
            if video.audio:
                video.audio.write_audiofile(audio_path, fps=44100)
                print(f"Convertido {video_path} para {audio_path}")
            else:
                print(f"Aviso: O v√≠deo {video_path} n√£o cont√©m √°udio!")
        except Exception as e:
            print(f"Erro ao converter {video_path}: {e}")

    def process_videos(self):
        input_directory = self.video_config.VIDEO_INPUT_PATH
        output_directory = self.video_config.VIDEO_OUTPUT_PATH

        os.makedirs(output_directory, exist_ok=True)

        # Busca qualquer arquivo de v√≠deo (formatos comuns)
        video_files = glob.glob(os.path.join(input_directory, "*.*"))  # Pega todos os arquivos

        # Filtra apenas arquivos de v√≠deo
        video_extensions = {".mp4", ".mkv", ".avi", ".mov", ".wmv", ".flv"}  
        video_files = [f for f in video_files if os.path.splitext(f)[1].lower() in video_extensions]

        if not video_files:
            print(f"Nenhum arquivo de v√≠deo encontrado em: {input_directory}")
            return

        for video_file in video_files:
            base_name = os.path.basename(video_file)
            audio_file = os.path.join(output_directory, os.path.splitext(base_name)[0] + ".wav")
            self.convert_video_to_audio(video_file, audio_file)

        print("Convers√£o de v√≠deo para √°udio conclu√≠da!")


# voice_assistent\assistent.py

import speech_recognition as sr
import pyttsx3
import re
from collections import deque
import spacy
import requests
import os
import webbrowser
from class_voice_assistent.prompt import create_prompt
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import google.generativeai as genai

# Configura√ß√µes da API
handler = genai('gemini-1.5-flash')

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

voices = engine.getProperty('voices')
engine.setProperty('rate', 180)
print("\nLista de Vozes...")
for indice, vozes in enumerate(voices):
    print(indice, vozes.name)

voz = 1
engine.setProperty('voice', voices[voz].id)

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

# Fun√ß√£o para extrair texto de HTML
def extract_text_from_html(html):
    if not html.strip().startswith('<'):
        print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
        return html
    soup = BeautifulSoup(html, 'html.parser')
    text = ' '.join([p.get_text() for p in soup.find_all('p')])
    return text

def get_text_response(prompt, context, feedback):
    # Gere o conte√∫do com base no prompt usando a classe GenerativeModelHandler
    response = handler.generate_content(prompt)
    return response

# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/api/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


# voice_assistent\class_voice_assistent\api_client.py

import requests


class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, meeting):
        try:
            response_text = self.model.generate_content(prompt, context, meeting)
            return response_text
        except Exception as e:
            print(f"Erro inesperado: {e}")
            return None

    def find_similar_embeddings(self, embedding):
        try:
            print(f"Buscando embeddings similares para: {embedding}")
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            similar_embeddings = response.json()

            # Ordenar por similaridade (assumindo que a API retorna com similaridade em ordem decrescente)
            # Remover duplicatas baseadas na pergunta
            seen_questions = set()
            unique_embeddings = []
            for embedding in similar_embeddings:
                question = embedding['question'].strip().lower()
                if question not in seen_questions:
                    unique_embeddings.append(embedding)
                    seen_questions.add(question)
            print(f"Embeddings similares √∫nicos encontrados: {unique_embeddings}")
            return unique_embeddings
        except requests.RequestException as e:
            print(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            # Converter embeddings de numpy arrays para listas
            if hasattr(question_embedding, 'tolist'):
                question_embedding = question_embedding.tolist()
            if hasattr(answer_embedding, 'tolist'):
                answer_embedding = answer_embedding.tolist()
            
            data = {
                "question": question,
                "questionEmbedding": question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding
            }
            
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                print("Pergunta e resposta salvas com sucesso.")
            else:
                print(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            print(f"Erro em save_question_answer: {e}")


    def fetch_all_contexts(self):
        try:
            response = requests.get("http://localhost:8081/api/contexts/all")
            if response.status_code == 200:
                data = response.json()
                contexts = data.get('contexts', [])
                if isinstance(contexts, list):
                    print(f"Contexto obtido da API: {contexts}")
                    return contexts
                else:
                    print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                    return []
            else:
                print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
                return []
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
            return []

    def fetch_last_meeting(self):
        try:
            response = requests.get("http://localhost:8081/api/meetings/last")
            if response.status_code == 200:
                data = response.json()
                transcription_text = data.get('transcriptionText', "")
                if isinstance(transcription_text, str):
                    print(f"Texto da transcri√ß√£o obtido da API: {transcription_text}")
                    return transcription_text
                else:
                    print(f"Erro: 'transcriptionText' n√£o √© uma string. Dados retornados: {data}")
                    return ""
            else:
                print(f"Erro ao acessar a API de reuni√µes: {response.status_code}, {response.text}")
                return ""
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de reuni√µes: {e}")
            return ""


# voice_assistent\class_voice_assistent\command_interpreter.py

import spacy
from prompt_generator.online_prompt import OnlineResearchPromptGenerator
from prompt_generator.meeting_prompt import MeetingPromptGenerator
from prompt_generator.default_prompt_generator import DefaultPromptGenerator
import re

# Carregar o modelo de linguagem natural
nlp = spacy.load("pt_core_news_sm")

class CommandInterpreter:
    def __init__(self, api_client, question_answer_service, context_manager, max_similar=3):
        self.api_client = api_client
        self.question_answer_service = question_answer_service
        self.context_manager = context_manager
        self.max_similar = max_similar  # Limite de contextos similares

    def interpret_command(self, command, meeting):
        print(f"Interpretando comando: {command}")
        contexts = self.api_client.fetch_all_contexts()
        context_str = "\n".join([context['context'] for context in contexts])

        # Gerar embedding para a pergunta e buscar embeddings similares
        question_embedding = self.question_answer_service.convert_text_to_embedding(command)
        similar_embeddings = self.api_client.find_similar_embeddings(question_embedding)

        # Filtrar para evitar respostas redundantes
        unique_responses = self._filter_unique_responses(similar_embeddings, command)
        similar_context = "\n".join([f"Pergunta: {embedding['question']}\nResposta: {embedding['answer']}" for embedding in unique_responses[:self.max_similar]])

        # Detectar tipo de comando usando regex
        if re.search(r'\b(pesquise|pesquisar|procure)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como pesquisa online.")
            response = self.get_online_research_response(command, context_str, similar_context)
        elif re.search(r'\b(contexto)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como busca de contexto.")
            response = self.get_project_response(command, meeting, context_str, similar_context)
        elif re.search(r'\b(resumo?|t√≥picos da|pontos (relevantes|principais)|an√°lise)\b.*\b(reuni√£o|√∫ltima (reuni√£o|conversa|sess√£o))\b', command, re.IGNORECASE):
            print(f"\nComando identificado como an√°lise de reuni√£o.")
            meeting = self.api_client.fetch_last_meeting()
            response = self.get_meeting_analysis_response(command, context_str, meeting)
        else:
            print(f"\nComando identificado como comando padr√£o.")
            response = self.handle_default_command(command, context_str, meeting, similar_context)

        if response:
            answer_embedding = self.question_answer_service.convert_text_to_embedding(response)
            self.api_client.save_question_answer(command, question_embedding, response, answer_embedding)
            self.context_manager.add_context(command, response)

        return response

    def _filter_unique_responses(self, similar_embeddings, current_command):
        """
        Filtra respostas semelhantes que s√£o muito similares ao comando atual para evitar redund√¢ncia.
        """
        filtered = []
        for embedding in similar_embeddings:
            if embedding['question'].lower() != current_command.lower():
                filtered.append(embedding)
        return filtered

    def handle_default_command(self, command, context_str, meeting, similar_context):
        print(f"\nTratando comando padr√£o: {command}")
        # Combinar o contexto atual com os contextos similares para enriquecer a resposta
        combined_context = f"{context_str}\n{similar_context}"
        prompt = DefaultPromptGenerator().generate_prompt(command, combined_context, meeting)
        response = self.api_client.get_text_response(prompt, combined_context, meeting)
        return response

    # M√©todos get_project_response, get_meeting_analysis_response, get_online_research_response permanecem inalterados

    def get_project_response(self, command, meeting, context_str, similar_context):
        print(f"\nGerando prompt de projeto.")
        prompt = DefaultPromptGenerator().generate_prompt(command, context_str, meeting, similar_context)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_meeting_analysis_response(self, command, context_str, meeting):
        print(f"\nGerando prompt de an√°lise de reuni√£o.")
        prompt = MeetingPromptGenerator().generate_prompt(command, context_str, meeting)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_online_research_response(self, command, context_str, similar_context):
        print(f"\nGerando prompt de pesquisa online.")
        prompt = OnlineResearchPromptGenerator().generate_prompt(command, context_str, similar_context)
        return self.api_client.get_text_response(prompt, context_str, None)


# voice_assistent\class_voice_assistent\context_manager.py

from collections import deque

class ContextManager:
    def __init__(self, maxlen=10):
        self.recent_context = deque(maxlen=maxlen)

    def add_context(self, command, response):
        self.recent_context.append((command, response))

    def get_context(self):
        return "\n".join([context for context, _ in self.recent_context])


# voice_assistent\class_voice_assistent\conversation_history.py



# voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py

import requests
import logging
import google.generativeai as genai

# Configure o logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, feedback):
        try:
            # Gerando o conte√∫do usando a nova API
            response = self.model.generate_content(prompt)
            if response and hasattr(response, 'text'):
                return prompt, response.text
            else:
                logger.error("Resposta inv√°lida da API")
                return prompt, None
        except Exception as e:
            logger.error(f"Erro em get_text_response: {e}")
            return prompt, None

    def find_similar_embeddings(self, embedding):
        try:
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            logger.info(f"Enviando dados para a API de embeddings similares: {data}")
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            logger.error(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            data = {
                "question": question,
                "questionEmbedding": question_embedding.tolist() if hasattr(question_embedding, 'tolist') else question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding.tolist() if hasattr(answer_embedding, 'tolist') else answer_embedding
            }
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                logger.info("Pergunta e resposta salvas com sucesso.")
            else:
                logger.warning(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            logger.error(f"Erro em save_question_answer: {e}")


# voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py

import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        """Carregar vari√°veis do arquivo .env"""
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        """Configurar a chave da API"""
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        """Inicializar o modelo generativo"""
        try:
            self.model = genai.GenerativeModel(self.model_name)
        except Exception as e:  
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content(self, prompt: str, context: str, meeting: str) -> str:
        """Gerar conte√∫do com base no prompt, contexto e reuni√£o"""
        try:
            # Supondo que a API espera um dicion√°rio com os par√¢metros
            request_data = f'''
                "prompt": {prompt},
                "context": {context},
                "meeting": {meeting}
            '''
            print(f"Enviando requisi√ß√£o para a API GenAI: {request_data}")

            response = self.model.generate_content(request_data)
            return response.text
        except Exception as e:
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py

import os
from dotenv import load_dotenv
from groq import Groq

# Carregar vari√°veis do arquivo .env
load_dotenv()

# Recuperar a chave da API
api_key = os.getenv("GROQ_API_KEY")

# Verificar se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API Key is missing. Please set the GROQ_API_KEY in the .env file.")

# Configurar o cliente com a chave da API
client = Groq(api_key=api_key)

# Cria√ß√£o da conclus√£o do chat
chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "De acordo com nossas conversas anteriores, o que voc√™ acha do meu uso de IA ?",
        }
    ],
    model="llama3-8b-8192",
)

print(chat_completion.choices[0].message.content)


# voice_assistent\class_voice_assistent\main.py

import os
from context_manager import ContextManager
from api_client import APIClient
from command_interpreter import CommandInterpreter
from text_command_hendler import TextCommandHandler
from text_processor import TextProcessor
from text_to_speech import TextToSpeech
from voice_command_hendler import VoiceCommandHandler
from question_answers_service import QuestionAnswerService
from gpt_communication.gemini_gpt import GenerativeModelHandler

class MainApp:
    def __init__(self, model):
        self.voice_handler = VoiceCommandHandler()
        self.text_handler = TextCommandHandler()
        self.tts = TextToSpeech()
        self.text_processor = TextProcessor()
        self.api_client = APIClient(
            similarity_url="http://localhost:8081",
            save_url="http://localhost:8081/api/question_answers/save",
            model=model
        )
        self.context_manager = ContextManager()
        self.question_answer_service = QuestionAnswerService()
        self.command_interpreter = CommandInterpreter(
            self.api_client,
            self.question_answer_service,
            self.context_manager
        )

    def handle_command(self, command, meeting=""):
        if command:
            print(f"Pergunta recebida: {command}")
            text_response = self.command_interpreter.interpret_command(command, meeting)
            if text_response:
                print(f"Resposta: {text_response}")
                self.tts.speak_text(text_response)
                self.context_manager.add_context(command, text_response)
                return text_response
        else:
            print("Nenhum comando detectado.")
            return None

    def run(self):
        meeting = ""
        while True:
            try:
                input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
                if input_type == 'v':
                    command = self.voice_handler.capture_voice_command()
                elif input_type == 't':
                    command = self.text_handler.capture_text_command()
                else:
                    print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
                    continue

                response = self.handle_command(command, meeting)
                if response:
                    print(f"Resposta: {response}")
            except Exception as e:
                print(f"Ocorreu um erro: {e}")

if __name__ == "__main__":
    model = GenerativeModelHandler('gemini-1.5-flash')
    app = MainApp(model)
    app.run()

# voice_assistent\class_voice_assistent\prompt.py

def create_prompt(command, context, meeting):
    keywords = ["fa√ßa um resumo da √∫ltima reuni√£o.", "t√≥picos da √∫ltima reuni√£o", "resuma a √∫ltima reuni√£o", "pesquise", "pesquisar", "procure"]
    if any(keyword in command.lower() for keyword in keywords):
        return f"""
        Regras de Meeting:
        - Voc√™ √© respons√°vel por analisar, debater, sugerir e informar melhorias.
        - Resuma de forma clara e Objetiva.
        - N√£o acrescentar t√≠tulo nas respostas.

        [context]: {context}
        -------
        [meeting]: {meeting}
        -------
        [str_texto]: {command}
        """
    else:
        return f"""
        [context]: {context}
        -------
        [str_texto]: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py

class DefaultPromptGenerator:
    def generate_prompt(self, command, combined_context, meeting):
        prompt = (
            f"Comando: {command}\n"
            f"Contexto Anterior:\n{combined_context}\n"
            f"Baseie sua resposta nas informa√ß√µes acima e forne√ßa uma solu√ß√£o detalhada."
        )
        return prompt

# voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class MeetingPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting):
        return f"""
        Regras de Meeting com respostas inteligentes:
        - Responda a pergunta de [str_texto] com base nas diretrizes abaixo...
            - Voc√™ √© respons√°vel analisar com detalhes a reuni√£o de [str_meeting], e fornecer uma longa est√≥ria sobre o assunto.
            - observe os nomes das personas mencionadas no texto de meeting para aprender e melhorar a precis√£o da resposta.
            - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [str_texto]: Responda a pergunta de: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class OnlineResearchPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting, similar_context):
        return f"""
        Regras de Pesquisa Online Inteligente:
        - Utilize similar_context e fa√ßa uma pesquisa online para uma resposta mais precisa das quest√µes de [str_text]
        - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [context]: Regras B√°sicas {context}
        ------
        [similar_context]:
        Perguntas e respostas anteriores.{similar_context}
        ------
        [str_texto]: Responda seguinte pergunta: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py

from abc import ABC, abstractmethod

class PromptGenerator(ABC):
    @abstractmethod
    def generate_prompt(self, command, context, meeting, similar_context):
        pass

# voice_assistent\class_voice_assistent\question_answers_service.py

import requests
import numpy as np
from sentence_transformers import SentenceTransformer

class QuestionAnswerService:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.embedding_model = SentenceTransformer(model_name)

    def convert_text_to_embedding(self, text):
        embedding = self.embedding_model.encode(text)
        #print(f"Embedding gerado para '{text}': {embedding[0]:.16f}") # Adicionado para verificar o embedding gerado
        return embedding


# voice_assistent\class_voice_assistent\text_command_hendler.py

class TextCommandHandler:
    def capture_text_command(self):
        command = input("Digite o seu comando: ")
        return command


# voice_assistent\class_voice_assistent\text_processor.py

from bs4 import BeautifulSoup

class TextProcessor:
    def extract_values_from_json(self, data):
        if isinstance(data, dict):
            return ' '.join([str(value) for value in data.values()])
        elif isinstance(data, list):
            return ' '.join([self.extract_values_from_json(item) for item in data])
        return str(data)

    def extract_text_from_html(self, html):
        if not html.strip().startswith('<'):
            print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
            return html
        soup = BeautifulSoup(html, 'html.parser')
        text = ' '.join([p.get_text() for p in soup.find_all('p')])
        return text


# voice_assistent\class_voice_assistent\text_to_speech.py

import pyttsx3

class TextToSpeech:
    def __init__(self):
        self.engine = pyttsx3.init()

    def speak_text(self, text):
        cleaned_text = self.clean_text(text)
        self.engine.say(cleaned_text)
        self.engine.runAndWait()

    def clean_text(self, text):
        import re
        return re.sub(r'[\*\_\#]', '', text)


# voice_assistent\class_voice_assistent\voice_command_hendler.py

import speech_recognition as sr

class VoiceCommandHandler:
    def capture_voice_command(self):
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            print("Por favor, fale o seu comando:")
            try:
                audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
                print("√Åudio capturado com sucesso.")
                command = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {command}")
                return command
            except sr.WaitTimeoutError:
                print("Tempo de espera expirado. Nenhum √°udio detectado.")
                return None
            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio.")
                return None
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
                return None


# voice_assistent\config.py

# config.py
import pyttsx3
import spacy
from collections import deque

class APIConfig:
    apiKey = "API_KEY"
    url = "https://gpt-templates.saiapplications.com"
    headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")


# voice_assistent\template.py

import speech_recognition as sr
import requests
import pyttsx3
import re
from collections import deque
import spacy
import os
import webbrowser
from voice_assistent.prompt import create_prompt

# Configura√ß√µes da API
apiKey = "6UlOOoY/kkmprunma/qNDg"
url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    if isinstance(text, dict):
        text = extract_values_from_json(text)  # Extrai os valores do dicion√°rio
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

def get_text_response(prompt, context, feedback):
    data = {
        "inputs": {
            "str_texto": prompt,
            "str_contexto": context,
            "str_feedback": feedback
        }
    }
    print(f"Enviando dados para a API: {data}")
    try:
        response = requests.post(f"{url}/api/templates/6691e223802f95c2b394a8bd/execute", json=data, headers=headers)
        print(f"Status da resposta: {response.status_code}")
        if response.status_code == 200:
            try:
                response_data = response.html()  # Tente converter a resposta para JSON
                print("Resposta HTML recebida.")
                return extract_values_from_json(response_data)  # Extrai os valores do JSON
            except ValueError:
                print("A resposta n√£o est√° no formato JSON esperado. Tratando como texto simples.")
                return response.text  # Retorna o texto bruto da resposta
        else:
            print(f"Erro ao acessar a API: {response.status_code}, {response.text}")
            return None
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API: {e}")
        return None

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)


# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


User: Analise meus c√≥digos e me envie as partes que posso eliminar e os c√≥digos duplicados.
2025-04-10 20:28:25,464 [INFO] Resposta da IA (texto): Com base no seu pedido, analisei os c√≥digos fornecidos e identifiquei as seguintes partes que podem ser eliminadas e os c√≥digos duplicados:

**Partes que podem ser eliminadas:**

*   **Arquivos n√£o utilizados:**
    *   `fundamentus_api\setup.py`: Este arquivo √© usado para configurar e instalar o pacote `fundamentalvision`. Se voc√™ j√° instalou o pacote e n√£o pretende distribu√≠-lo, pode remover este arquivo.
    *   `translate\translator_to_english.py`: Este arquivo cont√©m c√≥digo para traduzir voz do portugu√™s para o ingl√™s. Se voc√™ n√£o precisa dessa funcionalidade, pode remover este arquivo.
    *    `voice_assistent\template.py`: Parece ser um modelo ou c√≥digo de teste. Se n√£o for usado, pode ser removido.
    *   `test_whisper.py`: Este arquivo parece ser um script de teste para an√°lise de sentimento usando o modelo "neuralmind/bert-base-portuguese-cased". Se voc√™ n√£o precisa dessa funcionalidade, pode remover este arquivo.
    *   `send_embeddings_database\verify_last_enbedding.py`: Este arquivo parece ser um script para carregar e imprimir o √∫ltimo embedding salvo em um diret√≥rio. Se voc√™ n√£o precisa dessa funcionalidade, pode remover este arquivo.

*   **C√≥digo comentado ou desnecess√°rio:**
    *   Em v√°rios arquivos, procure por blocos de c√≥digo comentados que n√£o s√£o mais necess√°rios e podem ser removidos.
    *   Verifique se h√° logs excessivos ou mensagens de depura√ß√£o que podem ser removidas ap√≥s a conclus√£o do desenvolvimento.

**C√≥digos duplicados:**

*   **Fun√ß√µes de extra√ß√£o de dados JSON:**
    *   As fun√ß√µes `extract_values_from_json` est√£o definidas em `voice_assistent\template.py` e `voice_assistent\class_voice_assistent\text_processor.py`. Voc√™ deve manter apenas uma defini√ß√£o dessa fun√ß√£o em um local comum e reutiliz√°-la onde for necess√°rio.
*    **Carregar vari√°veis do ambiente**
    *   O modelo de GenerativeModelHandler carrega e configura a API em `chat_app\services\gpt_services.py` e  `voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py`.

**Observa√ß√µes:**

*   Antes de eliminar qualquer c√≥digo, certifique-se de fazer um backup para evitar a perda de funcionalidades importantes.
*   Remova arquivos e partes de c√≥digo desnecess√°rias para manter o projeto organizado e eficiente.
*   Considere refatorar c√≥digos duplicados para melhorar a manuten√ß√£o e evitar erros.
2025-04-10 20:28:25,647 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-10 20:28:25,649 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-10 20:28:25,650 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-10 20:28:25,652 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-10 20:28:25,653 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-10 20:28:25,658 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-10 20:28:25,660 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-10 20:28:25,661 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-10 20:28:25,663 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-10 20:28:25,664 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-10 20:28:25,666 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-10 20:28:25,667 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-10 20:28:25,669 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-10 20:28:25,670 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-10 20:28:25,674 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-10 20:28:25,675 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-10 20:28:25,677 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-10 20:28:25,678 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-10 20:28:25,679 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-10 20:28:25,680 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-10 20:28:25,682 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-10 20:28:25,683 [INFO] Arquivo lido com sucesso: main.py
2025-04-10 20:28:25,685 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-10 20:28:25,686 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-10 20:28:25,688 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-10 20:28:25,692 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-10 20:28:25,693 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-10 20:28:25,694 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-10 20:28:25,696 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-10 20:28:25,697 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-10 20:28:25,698 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-10 20:28:25,699 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-10 20:28:25,701 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-10 20:28:25,702 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-10 20:28:25,703 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-10 20:28:25,706 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-10 20:28:25,709 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-10 20:28:25,710 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-10 20:28:25,711 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-10 20:28:25,713 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-10 20:28:25,715 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-10 20:28:25,716 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-10 20:28:25,718 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-10 20:28:25,720 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-10 20:28:25,723 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-10 20:28:25,725 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-10 20:28:25,727 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-10 20:28:25,729 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-10 20:28:25,732 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-10 20:28:25,733 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-10 20:28:25,735 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-10 20:28:25,736 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-10 20:28:25,739 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-10 20:28:25,742 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-11 10:18:06,178 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-11 10:18:06,187 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-11 10:18:06,193 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-11 10:18:06,200 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-11 10:18:06,206 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-11 10:18:06,219 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-11 10:18:06,224 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-11 10:18:06,229 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-11 10:18:06,235 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-11 10:18:06,242 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-11 10:18:06,249 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-11 10:18:06,255 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-11 10:18:06,261 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-11 10:18:06,267 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-11 10:18:06,272 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-11 10:18:06,277 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-11 10:18:06,282 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-11 10:18:06,284 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-11 10:18:06,290 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-11 10:18:06,294 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-11 10:18:06,299 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-11 10:18:06,304 [INFO] Arquivo lido com sucesso: main.py
2025-04-11 10:18:06,309 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-11 10:18:06,313 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-11 10:18:06,320 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-11 10:18:06,326 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-11 10:18:06,331 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-11 10:18:06,337 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-11 10:18:06,341 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-11 10:18:06,345 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-11 10:18:06,351 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-11 10:18:06,356 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-11 10:18:06,362 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-11 10:18:06,367 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-11 10:18:06,372 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-11 10:18:06,376 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-11 10:18:06,380 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-11 10:18:06,382 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-11 10:18:06,386 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-11 10:18:06,392 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-11 10:18:06,396 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-11 10:18:06,401 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-11 10:18:06,405 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-11 10:18:06,410 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-11 10:18:06,414 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-11 10:18:06,418 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-11 10:18:06,422 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-11 10:18:06,427 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-11 10:18:06,431 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-11 10:18:06,435 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-11 10:18:06,439 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-11 10:18:06,444 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-11 10:18:06,448 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-11 10:18:06,452 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-11 10:18:07,014 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-11 10:18:07,017 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-11 10:18:07,019 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-11 10:18:07,021 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-11 10:18:07,023 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-11 10:18:07,024 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-11 10:18:07,026 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-11 10:18:07,028 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-11 10:18:07,030 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-11 10:18:07,033 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-11 10:18:07,036 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-11 10:18:07,037 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-11 10:18:07,039 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-11 10:18:07,040 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-11 10:18:07,042 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-11 10:18:07,044 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-11 10:18:07,046 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-11 10:18:07,048 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-11 10:18:07,051 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-11 10:18:07,053 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-11 10:18:07,055 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-11 10:18:07,057 [INFO] Arquivo lido com sucesso: main.py
2025-04-11 10:18:07,058 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-11 10:18:07,061 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-11 10:18:07,063 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-11 10:18:07,065 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-11 10:18:07,068 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-11 10:18:07,070 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-11 10:18:07,071 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-11 10:18:07,073 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-11 10:18:07,076 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-11 10:18:07,077 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-11 10:18:07,079 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-11 10:18:07,082 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-11 10:18:07,084 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-11 10:18:07,086 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-11 10:18:07,089 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-11 10:18:07,091 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-11 10:18:07,092 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-11 10:18:07,094 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-11 10:18:07,096 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-11 10:18:07,098 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-11 10:18:07,101 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-11 10:18:07,103 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-11 10:18:07,105 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-11 10:18:07,107 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-11 10:18:07,109 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-11 10:18:07,110 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-11 10:18:07,112 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-11 10:18:07,113 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-11 10:18:07,116 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-11 10:18:07,119 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-11 10:18:07,120 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-11 10:18:07,123 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-11 10:18:17,680 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-11 10:18:17,682 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-11 10:18:17,684 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-11 10:18:17,686 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-11 10:18:17,688 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-11 10:18:17,690 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-11 10:18:17,691 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-11 10:18:17,692 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-11 10:18:17,694 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-11 10:18:17,695 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-11 10:18:17,697 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-11 10:18:17,698 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-11 10:18:17,700 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-11 10:18:17,702 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-11 10:18:17,703 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-11 10:18:17,705 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-11 10:18:17,707 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-11 10:18:17,709 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-11 10:18:17,711 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-11 10:18:17,713 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-11 10:18:17,715 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-11 10:18:17,718 [INFO] Arquivo lido com sucesso: main.py
2025-04-11 10:18:17,720 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-11 10:18:17,722 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-11 10:18:17,723 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-11 10:18:17,725 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-11 10:18:17,726 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-11 10:18:17,727 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-11 10:18:17,729 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-11 10:18:17,731 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-11 10:18:17,733 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-11 10:18:17,735 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-11 10:18:17,736 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-11 10:18:17,738 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-11 10:18:17,739 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-11 10:18:17,741 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-11 10:18:17,742 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-11 10:18:17,743 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-11 10:18:17,745 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-11 10:18:17,748 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-11 10:18:17,750 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-11 10:18:17,752 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-11 10:18:17,754 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-11 10:18:17,756 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-11 10:18:17,758 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-11 10:18:17,759 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-11 10:18:17,761 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-11 10:18:17,763 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-11 10:18:17,765 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-11 10:18:17,766 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-11 10:18:17,767 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-11 10:18:17,769 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-11 10:18:17,770 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-11 10:18:17,772 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-11 10:18:17,891 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-11 10:18:17,893 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-11 10:18:17,895 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-11 10:18:17,897 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-11 10:18:17,899 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-11 10:18:17,901 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-11 10:18:17,903 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-11 10:18:17,905 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-11 10:18:17,907 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-11 10:18:17,909 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-11 10:18:17,910 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-11 10:18:17,913 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-11 10:18:17,916 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-11 10:18:17,918 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-11 10:18:17,920 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-11 10:18:17,922 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-11 10:18:17,924 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-11 10:18:17,925 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-11 10:18:17,927 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-11 10:18:17,928 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-11 10:18:17,931 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-11 10:18:17,932 [INFO] Arquivo lido com sucesso: main.py
2025-04-11 10:18:17,934 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-11 10:18:17,937 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-11 10:18:17,939 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-11 10:18:17,941 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-11 10:18:17,942 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-11 10:18:17,944 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-11 10:18:17,946 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-11 10:18:17,947 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-11 10:18:17,949 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-11 10:18:17,951 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-11 10:18:17,952 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-11 10:18:17,953 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-11 10:18:17,955 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-11 10:18:17,956 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-11 10:18:17,957 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-11 10:18:17,958 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-11 10:18:17,960 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-11 10:18:17,961 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-11 10:18:17,963 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-11 10:18:17,965 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-11 10:18:17,967 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-11 10:18:17,968 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-11 10:18:17,970 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-11 10:18:17,972 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-11 10:18:17,973 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-11 10:18:17,975 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-11 10:18:17,977 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-11 10:18:17,978 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-11 10:18:17,980 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-11 10:18:17,982 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-11 10:18:17,984 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-11 10:18:17,985 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-11 10:18:18,004 [INFO] Enviando para IA - Imagem: C:\Users\jfreis\Documents\agents_ia\comandAI\assets\20250411101817_clipboard_20250411101806.png, Prompt: Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas.

Contexto:



# app_config\app_config.py

from pathlib import Path

class AppConfig:
    def __init__(self, root_path=None):
        self.ROOT_PATH = Path(root_path) if root_path else Path.cwd()
    
    def get_root_path(self):
        return str(self.ROOT_PATH)
    
    def create_directories(self, paths):
        for path in paths:
            path.mkdir(parents=True, exist_ok=True)


# audio_to_text\audio_config\audio_config.py

from app_config.app_config import AppConfig
from transcriptions.transcriptions_config import TranscriptionConfig

class AudioConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        transcription_config = TranscriptionConfig(root_path)
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.TRANSCRIPTION_INPUT_PATH = transcription_config.get_transcription_input_path()
        self.create_directories([self.AUDIO_INPUT_PATH])


# audio_to_text\audio_to_text.py

import whisper
from audio_to_text.audio_config.audio_config import AudioConfig

class AudioToConverter:
    def __init__(self, audio_config: AudioConfig):
        self.audio_config = audio_config
        self.AUDIO_INPUT_PATH = audio_config.AUDIO_INPUT_PATH
        self.TRANSCRIPTION_INPUT_PATH = audio_config.TRANSCRIPTION_INPUT_PATH

    def process_audio_files(self):
        audio_files = list(self.AUDIO_INPUT_PATH.glob('*'))

        if not audio_files:
            print(f"N√£o foram encontrados arquivos de √°udio no diret√≥rio {self.AUDIO_INPUT_PATH}.")
            return

        model = whisper.load_model("base")

        for audio_file_path in audio_files:
            if audio_file_path.is_file():
                print(f"Processando arquivo: {audio_file_path}")
                self.process_audio_file(audio_file_path, model)

    def process_audio_file(self, audio_file_path, model):
        try:
            result = model.transcribe(str(audio_file_path))

            output_file_path = self.TRANSCRIPTION_INPUT_PATH / audio_file_path.with_suffix('.txt').name

            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(result['text'])

            print(f"Transcri√ß√£o salva em: {output_file_path}")
        except Exception as e:
            print(f"Erro ao processar o arquivo {audio_file_path}: {e}")


# chat_app\chat_streamlit.py

import streamlit as st
import time
from datetime import datetime
from core.handlers.gemini_handler import GeminiHandler
from PIL import Image
import os
import io
from config.config import Config
from core.rate_limiter import RateLimiter  # Importe a classe RateLimiter
from google import genai
from google.genai import types
from dotenv import load_dotenv
from services.search_files import ler_todos_arquivos_python

# Carrega as vari√°veis de ambiente
load_dotenv()

# Inicializa RateLimiter
rate_limiter = RateLimiter(max_requests=7, period_seconds=60)

# Inicializa estados do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "clipboard_image_preview" not in st.session_state:
    st.session_state.clipboard_image_preview = None
if "clipboard_image_file" not in st.session_state:
    st.session_state.clipboard_image_file = None
if "last_message_time" not in st.session_state:
    st.session_state.last_message_time = 0
if "file_uploader_key" not in st.session_state:
    st.session_state.file_uploader_key = "uploader_0"
if "generated_image" not in st.session_state:
    st.session_state.generated_image = None
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = None

# Limite m√°ximo de mensagens no hist√≥rico
MAX_MESSAGES = 20

# Fun√ß√£o para carregar o prompt do chat
def load_chat_prompt():
    try:
        with open(Config.PROMPT_CHAT_FILE, "r", encoding="utf-8") as file:
            return file.read().strip()
    except FileNotFoundError:
        return "Voc√™ √© um assistente de IA vers√°til e √∫til. Voc√™ pode conversar sobre diversos assuntos e tamb√©m analisar imagens quando elas forem fornecidas."

# Adicione o conte√∫do dos arquivos Python como contexto
codigo_fonte = ler_todos_arquivos_python()
chat_prompt = f"{load_chat_prompt()}\n\nContexto:\n\n{codigo_fonte}"

# Inicializa GeminiHandler
@st.cache_resource
def get_gemini_handler():
    return GeminiHandler("gemini-2.0-flash-exp")

gemini_handler = get_gemini_handler()

# Fun√ß√£o para verificar e processar a √°rea de transfer√™ncia
def check_clipboard():
    try:
        from PIL import ImageGrab

        # Tenta pegar imagem da √°rea de transfer√™ncia
        img = ImageGrab.grabclipboard()

        if img is not None and isinstance(img, Image.Image):
            # Converte a imagem para bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)

            # Cria um objeto similar ao retornado pelo st.file_uploader
            class ClipboardFile:
                def __init__(self, bytes_data):
                    self.bytes_data = bytes_data
                    self.name = f"clipboard_{datetime.now().strftime('%Y%m%d%H%M%S')}.png"

                def getbuffer(self):
                    return self.bytes_data.getvalue()

            return ClipboardFile(img_byte_arr), img
        return None, None
    except Exception as e:
        st.sidebar.error(f"Erro ao acessar a √°rea de transfer√™ncia: {e}")
        return None, None

# Fun√ß√£o para resetar o uploader alterando sua chave
def reset_uploader():
    # Extrai o n√∫mero da chave atual
    current_key = st.session_state.file_uploader_key
    key_num = int(current_key.split("_")[1])
    # Gera uma nova chave incrementando o n√∫mero
    st.session_state.file_uploader_key = f"uploader_{key_num + 1}"
    # Limpa o estado do uploaded_image
    st.session_state.uploaded_image = None

# Fun√ß√£o que processa a mensagem (com ou sem imagem)
def process_message(user_input, image_data=None, generated_image=None):
    # Marca como processando para bloquear novos inputs
    st.session_state.processing = True
    st.session_state.current_prompt = user_input
    st.session_state.current_image = image_data
    st.session_state.current_generated_image = generated_image

    # For√ßa a reexecu√ß√£o para atualizar a UI e mostrar o indicador de processamento
    st.rerun()

def execute_processing():
    user_input = st.session_state.current_prompt
    image_data = st.session_state.current_image
    generated_image = st.session_state.current_generated_image

    # Garante que n√£o exceda o limite de requisi√ß√µes
    rate_limiter.wait_for_slot()  # Espera at√© que um slot esteja dispon√≠vel

    # Continua com o processamento normal
    current_time = time.time()
    time_since_last_message = current_time - st.session_state.last_message_time
    wait_time = max(0, 2 - time_since_last_message)
    time.sleep(wait_time)

    st.session_state.last_message_time = time.time()

    img_path = None
    img_display = None

    # Adiciona mensagem do usu√°rio ao hist√≥rico
    if image_data:
        os.makedirs(Config.ASSETS_DIR, exist_ok=True)
        img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{image_data.name}"
        img_path = os.path.join(Config.ASSETS_DIR, img_name)
        with open(img_path, "wb") as f:
            f.write(image_data.getbuffer())
        with Image.open(img_path) as img:
            img_display = img.copy()

        st.session_state.messages.append({"role": "user", "content": user_input, "image": img_display})
    elif generated_image:
        st.session_state.messages.append({"role": "user", "content": user_input, "image": generated_image})
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Constr√≥i o prompt completo incluindo o hist√≥rico do chat
    full_prompt = chat_prompt + "\n\n"  # Start with the base prompt

    for message in st.session_state.messages[:-1]: # Exclude the last user message
        role = message["role"]
        content = message["content"]
        full_prompt += f"{role.capitalize()}: {content}\n"

    full_prompt += f"User: {user_input}" # Add current user message

    # Processa resposta da IA
    try:
        if img_path:
            # Se tem imagem: usa o prompt espec√≠fico para imagens
            response = gemini_handler.generate_content(img_path, full_prompt)
        elif generated_image:
             # Salvando a imagem gerada para ser lida pelo GeminiHandler
             os.makedirs(Config.ASSETS_DIR, exist_ok=True)
             img_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_generated_image.png"
             img_path = os.path.join(Config.ASSETS_DIR, img_name)
             generated_image.save(img_path)

             response = gemini_handler.generate_content(img_path, full_prompt)
        else:
            # Se n√£o tem imagem: apenas conversa normal
            response = gemini_handler.generate_content(None, full_prompt)
    except Exception as e:
        response = f"‚ùå Erro ao gerar resposta: {str(e)}"

    # Adiciona resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Garante que o hist√≥rico n√£o exceda o limite
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    # Remove imagem tempor√°ria do disco ap√≥s uso
    if img_path and os.path.exists(img_path):
        os.remove(img_path)

    # Marca o processamento como conclu√≠do, mas N√ÉO limpa as imagens
    st.session_state.processing = False
    st.session_state.current_prompt = None
    st.session_state.current_image = None
    st.session_state.current_generated_image = None

# Callback quando o bot√£o de colar da √°rea de transfer√™ncia √© clicado
def on_paste_click():
    clipboard_file, clipboard_preview = check_clipboard()
    if clipboard_file and clipboard_preview:
        # Reseta o uploader para limpar o arquivo atual
        reset_uploader()
        # Define as imagens da √°rea de transfer√™ncia
        st.session_state.clipboard_image_file = clipboard_file
        st.session_state.clipboard_image_preview = clipboard_preview
        return True
    return False

# Callback quando um arquivo √© carregado
def on_file_upload():
    # Limpa qualquer imagem da √°rea de transfer√™ncia
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Callback para limpar todas as imagens
def clear_all_images():
    reset_uploader()
    st.session_state.clipboard_image_preview = None
    st.session_state.clipboard_image_file = None

# Fun√ß√£o para gerar imagem com Gemini
def generate_image(prompt):
    # Verifica se a chave da API foi carregada corretamente
    api_key = os.getenv("API_KEY_GEMINI")

    if not api_key:
        raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp-image-generation',
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                print(part.text)
            elif part.inline_data is not None:
                image = Image.open(io.BytesIO(part.inline_data.data))
                st.session_state.generated_image = image
                return image

    except Exception as e:
        st.error(f"Erro ao gerar imagem: {e}")
        return None

# Executa o processamento se estiver na fila
if st.session_state.processing and hasattr(st.session_state, 'current_prompt'):
    execute_processing()
    st.rerun()

# Configura√ß√£o da barra lateral
with st.sidebar:
    st.title("Chat IA Inteligente")

    # Se√ß√£o de gera√ß√£o de imagem
    st.markdown("### Gerar Imagem")
    image_prompt = st.text_input("Digite o prompt para gerar uma imagem:", key="image_prompt")
    if st.button("Gerar Imagem"):   
        if image_prompt:
            generated_image = generate_image(image_prompt)

            if generated_image:
                st.session_state.messages.append({"role": "assistant", "image": generated_image, "content": f"Imagem gerada com o prompt: {image_prompt}"})
                st.session_state.generated_image = None #Limpa para n√£o exibir em cima

                st.rerun()
        else:
            st.warning("Por favor, digite um prompt para gerar a imagem.")

    # Se√ß√£o de imagens (sempre vis√≠vel)
    st.markdown("### Adicionar Imagem (Opcional)")
    st.caption("Adicione uma imagem se quiser fazer perguntas sobre ela")

    # Layout em duas colunas para os bot√µes de imagem
    col1, col2 = st.columns(2)

    with col1:
        # Bot√£o para verificar a √°rea de transfer√™ncia
        if st.button("üìã Colar", use_container_width=True):
            if on_paste_click():
                st.success("Imagem colada!")
                st.rerun()
            else:
                st.warning("Nada encontrado.")

    with col2:
        # Bot√£o para limpar a imagem atual (se houver)
        if st.session_state.clipboard_image_preview or st.session_state.uploaded_image:
            if st.button("üóëÔ∏è Limpar", use_container_width=True):
                clear_all_images()
                st.rerun()
        else:
            # Placeholder para manter o layout alinhado
            st.write("")

    # Uploader de imagem com chave din√¢mica
    uploaded_file = st.file_uploader(
        "üì∑ Ou fa√ßa upload de imagem",
        type=["png", "jpg", "jpeg"],
        label_visibility="visible",
        key=st.session_state.file_uploader_key
    )

    # Atualiza o estado da imagem quando um arquivo √© carregado
    if uploaded_file:
        st.session_state.uploaded_image = uploaded_file
        on_file_upload()
        st.success("Imagem carregada!")

    # Exibe a imagem selecionada na barra lateral
    if st.session_state.clipboard_image_preview:
        st.image(st.session_state.clipboard_image_preview, use_container_width=True)
        st.caption("Imagem da √°rea de transfer√™ncia")
    elif st.session_state.uploaded_image:
        st.image(st.session_state.uploaded_image, use_container_width=True)
        st.caption("Imagem carregada")

    st.markdown("---")

    # Bot√£o para limpar o hist√≥rico de conversa
    if st.button("üßπ Limpar conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("Desenvolvido com Streamlit e Gemini AI")

# Removendo a exibi√ß√£o da imagem gerada aqui (ela ser√° exibida no hist√≥rico de mensagens)
#if st.session_state.generated_image:
#    st.image(st.session_state.generated_image, caption="Imagem Gerada", use_column_width=True)

# Exibi√ß√£o do hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Se houver imagem, exiba-a (se armazenada)
        if message.get("image"):
            st.image(message["image"], use_container_width=True)
        # Exibe o conte√∫do da mensagem (texto)
        st.markdown(message["content"])

# Adiciona indicador de digita√ß√£o quando estiver processando
if st.session_state.processing:
    with st.chat_message("assistant"):
        st.markdown("Gerando resposta...")

# Input de texto - deixe-o como √∫ltimo elemento para manter o comportamento "fixo" natural
if not st.session_state.processing:
    # Verifica se h√° uma imagem dispon√≠vel
    current_image = st.session_state.clipboard_image_file or st.session_state.uploaded_image

    # Adapta o placeholder com base na presen√ßa de imagem
    if current_image:
        placeholder = "Digite sua pergunta sobre a imagem ou qualquer outro assunto..."
    else:
        placeholder = "Digite sua mensagem..."

    user_input = st.chat_input(placeholder)

    if user_input:
        # Processa a mensagem com a imagem (se houver) ou apenas texto
        process_message(user_input, current_image)
else:
    st.chat_input("Aguarde o processamento...", disabled=True)

# chat_app\config\config.py

# src/config.py
import os
from pathlib import Path

class Config:
    BASE_DIR = Path(__file__).resolve().parent.parent.parent
    print(f"Base Directory: {BASE_DIR}")

    ASSETS_DIR = BASE_DIR.parent / "assets"

    IMAGE_GENERATED_DIR = ASSETS_DIR / "image_generated"
    PROCESSED_DIR = BASE_DIR.parent / "processed_images"
    print(PROCESSED_DIR)
    OUTPUT_DOCX = BASE_DIR / "resumo_analises_imagens.docx"
    OUTPUT_MD = BASE_DIR / "resumo_analises_imagens.md"
    
    # Caminhos para prompts din√¢micos
    PROMPT_DIR = BASE_DIR / "prompt"
    PROMPT_DOC_FILE = PROMPT_DIR / "prompt_doc.txt"
    PROMPT_CHAT_FILE = PROMPT_DIR / "prompt_chat.txt"
    
    # Configura√ß√£o de logs
    LOG_DIR = BASE_DIR / "logs"
    
    # Configura√ß√£o de hist√≥rico
    HISTORY_FILE = BASE_DIR / "historico_analises.json"
    
    # Configura√ß√£o de rate limiting
    CHAT_RATE_LIMIT = {"max_requests": 9, "period_seconds": 60}
    API_RATE_LIMIT = {"max_requests": 14, "period_seconds": 60}
    
    @classmethod
    def ensure_directories(cls):
        """Garante que todos os diret√≥rios necess√°rios existam."""
        for directory in [cls.ASSETS_DIR, cls.IMAGE_GENERATED_DIR, 
                         cls.PROCESSED_DIR, cls.LOG_DIR, cls.PROMPT_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

# chat_app\core\handlers\gemini_handler.py

from services.gpt_services import GenerativeModelHandler
from core.logger_config import logger
from core.rate_limiter import RateLimiter  # supondo que voc√™ salvou a classe acima em core/rate_limiter.py

class GeminiHandler:
    def __init__(self, model_name):
        self.handler = GenerativeModelHandler(model_name)
        self.rate_limiter = RateLimiter(max_requests=15, period_seconds=60)

    def generate_content(self, img_path, prompt):
        self.rate_limiter.wait_for_slot()  # Aguarda at√© que haja um slot dispon√≠vel

        if img_path:
            logger.info(f"Enviando para IA - Imagem: {img_path}, Prompt: {prompt}")
            return self.handler.generate_content_from_image(img_path, prompt)
        else:
            logger.info(f"Enviando para IA - Prompt (sem imagem): {prompt}")
            return self.handler.generate_content_from_text(prompt)

# chat_app\core\handlers\signal_handler.py

import signal
import sys

def handler(signum, frame):
    print("üö® Processamento interrompido pelo usu√°rio.")
    sys.exit(1)

def setup_signal_handler():
    signal.signal(signal.SIGINT, handler)

# chat_app\core\logger_config.py

# core/logger_config.py
import logging
import os
from datetime import datetime

LOG_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "..", "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = datetime.now().strftime("log_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# chat_app\core\rate_limiter.py

import time
from collections import deque
from threading import Lock

class RateLimiter:
    def __init__(self, max_requests: int, period_seconds: int):
        self.max_requests = max_requests
        self.period_seconds = period_seconds
        self.requests = deque()
        self.lock = Lock()

    def allow_request(self) -> bool:
        with self.lock:
            current_time = time.time()

            # Remove requests antigos fora da janela de tempo
            while self.requests and self.requests[0] <= current_time - self.period_seconds:
                self.requests.popleft()

            if len(self.requests) < self.max_requests:
                self.requests.append(current_time)
                return True
            else:
                return False

    def wait_for_slot(self):
        """Aguarda o pr√≥ximo slot dispon√≠vel, ajustando a espera conforme necess√°rio."""
        while not self.allow_request():
            # Calcula o tempo de espera baseado no n√∫mero de requisi√ß√µes feitas
            # tempo necess√°rio para respeitar o limite
            current_time = time.time()
            if self.requests:  # Verifica se a lista n√£o est√° vazia
                earliest_request_time = self.requests[0] 
                remaining_time = max(0, self.period_seconds - (current_time - earliest_request_time))
            else:
                remaining_time = 1  # Espera um segundo se n√£o houver requisi√ß√µes

            # Aguarda o tempo necess√°rio para garantir que a pr√≥xima requisi√ß√£o pode ser feita
            time.sleep(remaining_time)

# chat_app\services\document_service.py

from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.style import WD_STYLE_TYPE
from docx.oxml.ns import qn
from config.config import Config
import os
from core.logger_config import logger  # Importa√ß√£o correta

class DocumentService:
    def __init__(self):
        self.doc = self._load_or_create_document()
        self._setup_document_styles()

    def _load_or_create_document(self):
        if os.path.exists(Config.OUTPUT_DOCX):
            return Document(Config.OUTPUT_DOCX)
        doc = Document()
        # Configura√ß√£o inicial do documento
        title = doc.add_heading('An√°lise de Imagens com Intelig√™ncia Artificial', level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Adiciona subt√≠tulo
        subtitle = doc.add_paragraph('Relat√≥rio Gerado Automaticamente')
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle.style = 'Subtitle'

        # Adiciona uma quebra de p√°gina ap√≥s o t√≠tulo
        doc.add_page_break()

        return doc

    def _setup_document_styles(self):
        """Configura estilos personalizados para o documento"""
        styles = self.doc.styles

        # Estilo para t√≠tulo de imagem
        if 'Image Title' not in styles:
            image_title_style = styles.add_style('Image Title', WD_STYLE_TYPE.PARAGRAPH)
            font = image_title_style.font
            font.name = 'Calibri'
            font.size = Pt(16)
            font.bold = True
            font.color.rgb = RGBColor(0, 112, 192)  # Azul
            paragraph_format = image_title_style.paragraph_format
            paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER  # Centraliza o t√≠tulo
            paragraph_format.space_before = Pt(12)
            paragraph_format.space_after = Pt(6)

        # Estilo para o texto do resumo
        if 'Summary Text' not in styles:
            summary_style = styles.add_style('Summary Text', WD_STYLE_TYPE.PARAGRAPH)
            font = summary_style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            paragraph_format = summary_style.paragraph_format
            paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph_format.space_before = Pt(0)  # Reduzir o espa√ßamento antes do resumo
            paragraph_format.space_after = Pt(12)
            paragraph_format.first_line_indent = Pt(18)  # Recuo na primeira linha

    def add_image_summary(self, image_name, summary):
        image_path = os.path.join(Config.PROCESSED_DIR, image_name)
        logger.info(f"Caminho da imagem para o Word: {image_path}")  # Uso correto do logger

        # Adiciona o t√≠tulo da imagem
        p = self.doc.add_paragraph(image_name, style='Image Title')  # Adiciona o t√≠tulo antes da imagem


        # Adiciona a imagem ao documento com tamanho de p√°gina inteira
        if os.path.exists(image_path):
            paragraph = self.doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.add_run()

            # Obt√©m a largura da p√°gina
            section = self.doc.sections[0]
            page_width = section.page_width
            page_height = section.page_height

            # Calcula as margens
            left_margin = section.left_margin
            right_margin = section.right_margin

            # Calcula a largura dispon√≠vel (largura da p√°gina menos margens)
            available_width = page_width - left_margin - right_margin

            # Adiciona a imagem com a largura dispon√≠vel
            picture = run.add_picture(image_path, width=available_width)

            # Remover a linha que adiciona o par√°grafo vazio
            # self.doc.add_paragraph()

        # Formata o resumo com estilo personalizado
        clean_summary = self._clean_markdown(summary)

        # Adiciona o resumo com estilo personalizado
        p = self.doc.add_paragraph(clean_summary, style='Summary Text')

    def _add_horizontal_line(self):
        """Adiciona uma linha horizontal decorativa"""
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p_fmt = p.paragraph_format
        p_fmt.space_after = Pt(12)

        # Adiciona uma linha usando caracteres
        run = p.add_run('‚îÄ' * 50)  # 50 caracteres de linha
        run.font.color.rgb = RGBColor(192, 192, 192)  # Cinza claro

    def _clean_markdown(self, text):
        """Remove marca√ß√µes markdown do texto"""
        # Remove cabe√ßalhos markdown (###, ##, etc)
        import re
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

        # Remove marca√ß√µes de negrito e it√°lico
        text = text.replace('**', '').replace('*', '').replace('__', '').replace('_', '')

        # Remove marcadores de lista
        text = re.sub(r'^\s*[-*+]\s+', '‚Ä¢ ', text, flags=re.MULTILINE)

        return text

    def save_document(self):
        # Adiciona informa√ß√µes de rodap√©
        # section = self.doc.sections[0]
        # footer = section.footer
        # footer_para = footer.paragraphs[0]
        # footer_para.text = f"Documento gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')} | Assistente Visual Inteligente"
        # footer_para.style = self.doc.styles['Footer']

        self.doc.save(Config.OUTPUT_DOCX)

# chat_app\services\gpt_services.py

# services/gpt_services.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging
from core.logger_config import logger

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            logger.error("API Key n√£o encontrada nas vari√°veis de ambiente")
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        try:
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"Modelo Gemini '{self.model_name}' inicializado com sucesso.")
        except Exception as e:  
            logger.error(f"Erro ao inicializar o modelo: {e}")
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content_from_image(self, image_path: str, prompt: str) -> str:
        try:
            with open(image_path, "rb") as image_file:
                image_bytes = image_file.read()

            response = self.model.generate_content([
                {"mime_type": "image/png", "data": image_bytes},
                prompt
            ])

            logger.info(f"Resposta da IA (imagem): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao processar a imagem: {e}")
            raise RuntimeError(f"Erro ao processar a imagem: {e}")

    def generate_content_from_text(self, prompt: str) -> str:
        try:
            response = self.model.generate_content(prompt)
            logger.info(f"Resposta da IA (texto): {response.text}")
            return response.text
        except Exception as e:
            logger.error(f"Erro ao gerar conte√∫do: {e}")
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# chat_app\services\image_processor.py

# src/image_processor.py
import os
import time
import shutil
import json
from config.config import Config
from services.gpt_services import GenerativeModelHandler
from services.document_service import DocumentService
from services.markdown_service import MarkdownService
from utils.file_utils import list_images
from core.logger_config import logger
from core.rate_limiter import RateLimiter

class ImageProcessor:
    def __init__(self, rate_limiter: RateLimiter):
        self.gpt_handler = GenerativeModelHandler("gemini-2.0-flash-exp")
        self.document_service = DocumentService()
        self.markdown_service = MarkdownService()
        os.makedirs(Config.PROCESSED_DIR, exist_ok=True)
        self.prompt = self._load_prompt()
        self.history = []
        self.rate_limiter = rate_limiter
        self.historico_json_file = "historico_analises.json"
        self.analises_anteriores = self._carregar_historico_json()  # Carrega o hist√≥rico ao inicializar

    def _load_prompt(self):
        try:
            with open(Config.PROMPT_DOC_FILE, "r", encoding="utf-8") as file:
                prompt = file.read().strip()
                logger.info(f"Prompt carregado com sucesso: {prompt}")
                return prompt
        except FileNotFoundError:
            logger.error(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")
            raise FileNotFoundError(f"Arquivo de prompt n√£o encontrado em {Config.PROMPT_DOC_FILE}")

    def _carregar_historico_json(self):
        try:
            with open(self.historico_json_file, "r") as f:
                return json.load(f)
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []

    def _salvar_historico_json(self):
        with open(self.historico_json_file, "w") as f:
            json.dump(self.analises_anteriores, f, indent=4)

    def process_images(self):
        images = list_images(Config.ASSETS_DIR)
        if not images:
            logger.warning("Nenhuma imagem encontrada em 'assets/'.")
            return

        for idx, image_name in enumerate(images, start=1):
            logger.info(f"Processando imagem {idx}/{len(images)}: {image_name}")

            try:
                self.rate_limiter.wait_for_slot()
                summary = self._process_image(image_name)
                self.document_service.add_image_summary(image_name, summary)
                self.markdown_service.add_image_summary(image_name, summary)
                self.document_service.save_document()
                self.markdown_service.save_markdown()
                self._move_image(image_name)
                self._update_history(image_name, summary)

                # N√£o adicionar a mesma informa√ß√£o repetidas vezes
                # self.analises_anteriores.append(f"Imagem: {image_name}, Resumo: {summary}")
                # self._salvar_historico_json()

            except Exception as e:
                logger.error(f"Erro ao processar a imagem {image_name}: {e}", exc_info=True)

            time.sleep(4)
            logger.info("Preparando a pr√≥xima an√°lise...")

    def _process_image(self, image_name):
        img_path = os.path.join(Config.ASSETS_DIR, image_name)
        processed_path = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.copy2(img_path, processed_path)

        try:
            # N√£o precisa carregar o hist√≥rico a cada imagem
            # self._carregar_historico_json()

            historico_str = "\n".join([f"{entry['image_name']}: {entry['summary']}" for entry in self.history])
            prompt_com_historico = f"{self.prompt}\nHist√≥rico:\n{historico_str}\nAnalise a seguinte imagem: {image_name}"
            response_text = self.gpt_handler.generate_content_from_image(img_path, prompt_com_historico)
            logger.info(f"Resumo gerado para '{image_name}': {response_text}")
            return response_text
        except Exception as e:
            logger.error(f"Erro ao processar '{image_name}': {str(e)}")
            return f"Erro ao processar imagem: {str(e)}"

    def _move_image(self, image_name):
        origem = os.path.join(Config.ASSETS_DIR, image_name)
        destino = os.path.join(Config.PROCESSED_DIR, image_name)
        shutil.move(origem, destino)
        logger.info(f"Imagem '{image_name}' movida para '{Config.PROCESSED_DIR}'.")

    def _update_history(self, image_name, summary):
        self.history.append({"image_name": image_name, "summary": summary})
        logger.info(f"Hist√≥rico atualizado com '{image_name}'.")

    def get_history(self):
        return self.history

# chat_app\services\image_services.py

import os
from dotenv import load_dotenv
from google import genai
from PIL import Image
from io import BytesIO

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# Obt√©m a chave da API Gemini do arquivo .env
api_key = os.getenv("API_KEY_GEMINI")

# Verifica se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API_KEY_GEMINI n√£o encontrada no arquivo .env")

# Inicializa o Gemini
genai.configure(api_key=api_key)

def generate_image(prompt: str) -> Image.Image | None:
    """
    Gera uma imagem usando o modelo Gemini com base no prompt fornecido.

    Args:
        prompt (str): O prompt de texto para gerar a imagem.

    Returns:
        Image.Image | None: A imagem gerada como um objeto PIL Image ou None em caso de falha.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')
        response = model.generate_content(prompt)
        if response.prompt_feedback:
          print('Reason: {}'.format(response.prompt_feedback.block_reason))
        # Verifique se a resposta cont√©m dados de imagem
        if response.parts:
            for part in response.parts:
                if part.mime_type == 'image/png':
                    return Image.open(BytesIO(part.data))
        print(response.text)
        return None
    except Exception as e:
        print(f"Erro ao gerar imagem: {e}")
        return None

# Exemplo de uso (fora do Streamlit):
if __name__ == "__main__":
    image = generate_image("Desenhe um gato astronauta no espa√ßo sideral, estilo cartoon.")
    if image:
        image.show() # Exibe a imagem (opcional)
        image.save("gato_astronauta.png") # Salva a imagem (opcional)
    else:
        print("Falha ao gerar a imagem.")

# chat_app\services\markdown_service.py

import os
from config.config import Config

class MarkdownService:
    def __init__(self):
        self.content = []

    def add_image_summary(self, image_name, summary):
        """Adiciona uma nova imagem e resumo ao conte√∫do do Markdown."""
        image_path = f"/processed_images/{image_name}"  # Caminho relativo
        markdown_entry = f"## Imagem: {image_name}\n![{image_name}]({image_path})\n\n{summary}\n"
        self.content.append(markdown_entry)

    def save_markdown(self):
        """Salva os resumos no arquivo Markdown, garantindo que o novo conte√∫do seja anexado sem sobrescrever."""
        if not os.path.exists(Config.OUTPUT_MD):  # Se o arquivo n√£o existir, cria o cabe√ßalho
            with open(Config.OUTPUT_MD, 'w', encoding='utf-8') as f:
                f.write("# Resumo das An√°lises das Imagens\n\n")

        with open(Config.OUTPUT_MD, 'a', encoding='utf-8') as f:  # Modo 'a' (append)
            f.write("\n".join(self.content) + "\n")  # Adiciona novas entradas

        self.content = []  # Limpa a lista ap√≥s salvar para evitar duplica√ß√£o


# chat_app\services\search_files.py

import os
import glob
from pathlib import Path
from config.config import Config
import logging  # Importe o m√≥dulo de logging

# Configure o logging (voc√™ pode ajustar o n√≠vel conforme necess√°rio)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def ler_todos_arquivos_python() -> str:
    """L√™ todo o conte√∫do de todos os arquivos .py a partir de src/"""
    src_dir = Config.BASE_DIR
    conteudo_total = ""

    if not src_dir.exists():
        logging.warning(f"Diret√≥rio 'src' n√£o encontrado: {src_dir}")
        return ""

    padrao_busca = os.path.join(src_dir.as_posix(), '**', '*.py')
    arquivos = glob.glob(padrao_busca, recursive=True)

    for arquivo in sorted(arquivos):
        try:
            with open(arquivo, 'r', encoding='utf-8') as f:
                rel_path = os.path.relpath(arquivo, src_dir)
                conteudo_total += f"\n\n# {rel_path}\n\n{f.read()}"
                logging.info(f"Arquivo lido com sucesso: {rel_path}")  # Log de sucesso
        except Exception as e:
            logging.error(f"Erro ao ler o arquivo {arquivo}: {e}")  # Log de erro
            continue

    return conteudo_total

# chat_app\utils\file_utils.py

import os

def list_images(directory):
    return sorted(
        [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.getmtime(os.path.join(directory, x))
    )

# common_paths\common_paths.py

from pathlib import Path

class CommonPaths:
    def __init__(self):
        # Diret√≥rio atual do script
        self.ROOT_PATH = Path(__file__).resolve().parent

        # Defini√ß√£o dos caminhos comuns
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'output'
        self.AUDIO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.AUDIO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio'
        self.TRANSCRIPTION_OUTPUT_PATH = self.ROOT_PATH / 'data'
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'data'

        # Cria√ß√£o dos diret√≥rios
        self.create_directories()

    def create_directories(self):
        self.VIDEO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_INPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.AUDIO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.VIDEO_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
        self.TRANSCRIPTION_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)



# fundamentus_api\fundamentus\__init__.py



# fundamentus_api\fundamentus\dados_b3.py

import locale
import pandas as pd
import streamlit as st
import requests
import fundamentus
import os
import plotly.express as px
from bs4 import BeautifulSoup
from fundamentus.detalhes import get_papel
import logging

# Configura localidade
locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')

# Configura√ß√£o do layout do Streamlit
st.set_page_config(
    page_title="An√°lise de A√ß√µes",
    layout="wide",
    page_icon="üìà"
)

class Acao:
    def __init__(self, papel):
        self.papel = papel
        self.dados_fundamentais = None
        self.proventos = None
        self.detalhes = None
        self.oscilacoes = None  # Adicionando um atributo para oscila√ß√µes

    def carregar_dados_fundamentais(self):
        self.dados_fundamentais = fundamentus.get_resultado().loc[[self.papel]]  # Use colchetes duplos para garantir que seja um DataFrame
        self.remover_formatacao()

    def obter_detalhes(self):
        self.detalhes = get_papel(self.papel)
        if self.detalhes is None or self.detalhes.empty:
            logging.warning(f"Nenhum detalhe encontrado para o papel: {self.papel}")

    def obter_proventos(self):
        url = f"https://www.fundamentus.com.br/proventos.php?papel={self.papel}&tipo=2"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        tabela = soup.find('table', {'id': 'resultado'})

        if not tabela:
            return pd.DataFrame()

        dados = []
        for linha in tabela.find_all('tr')[1:]:
            colunas = linha.find_all('td')
            try:
                valor = float(colunas[1].text.strip().replace(',', '.'))
            except ValueError:
                valor = None  # Se der erro, coloca None para evitar crash

            dados.append([colunas[0].text.strip(), valor, colunas[2].text.strip()])
        
        self.proventos = pd.DataFrame(dados, columns=['Data', 'Valor', 'Tipo'])
        return self.proventos

    def obter_oscilacoes(self):
        url = f"https://www.fundamentus.com.br/detalhes.php?papel={self.papel}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return pd.DataFrame()

        soup = BeautifulSoup(response.text, 'html.parser')
        conteudo_div = soup.find('div', class_='conteudo clearfix')

        if conteudo_div is None:
            return pd.DataFrame()

        oscilacoes_data = []
        oscilacoes_section = conteudo_div.find('td', class_='nivel1', colspan='2')
        
        if oscilacoes_section:
            labels = oscilacoes_section.find_all_next('td', class_='label w1')
            dados = oscilacoes_section.find_all_next('td', class_='data w1')

            for label, dado in zip(labels, dados):
                label_text = label.get_text(strip=True)
                valor_text = dado.find('span', class_='oscil').get_text(strip=True)
                oscilacoes_data.append([label_text, valor_text])

        self.oscilacoes = pd.DataFrame(oscilacoes_data, columns=['Per√≠odo', 'Oscila√ß√£o'])
        return self.oscilacoes

    def remover_formatacao(self):
        colunas_percentuais = ['dy', 'mrgebit', 'mrgliq', 'roic', 'roe', 'c5y']
        for coluna in colunas_percentuais:
            if coluna in self.dados_fundamentais:
                try:
                    self.dados_fundamentais[coluna] = self.dados_fundamentais[coluna].astype(float)
                except ValueError as e:
                    logging.error(f"Erro ao converter coluna {coluna} para float: {e}")

    def formatar_moeda(self, valor):
        return locale.currency(valor, symbol=True, grouping=True)

class Aplicacao:
    def __init__(self):
        self.acoes = fundamentus.get_resultado()

    def ajustar_tipos_dataframe(self, df):
        for coluna in df.columns:
            if df[coluna].dtype == 'object':
                try:
                    df[coluna] = df[coluna].astype(float)
                except ValueError:
                    df[coluna] = df[coluna].astype(str)
            elif df[coluna].dtype in ['int64', 'float64']:
                df[coluna] = df[coluna].astype(float)
        return df

    def exibir_dashboard(self):
        st.sidebar.title("üìä Dashboard de An√°lise de A√ß√µes")
        st.sidebar.write("Selecione um papel para visualizar detalhes.")

        papel_selecionado = st.sidebar.selectbox("Escolha uma a√ß√£o", self.acoes.index)

        acao = Acao(papel_selecionado)
        acao.carregar_dados_fundamentais()
        acao.obter_proventos()
        acao.obter_detalhes()
        acao.obter_oscilacoes()

        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader(f"üìå Dados Fundamentais - {papel_selecionado}")
            dados_fundamentais_df = self.ajustar_tipos_dataframe(acao.dados_fundamentais.T)
            st.dataframe(dados_fundamentais_df, width=400)

        with col2:
            st.subheader("üîç Detalhes")
            if acao.detalhes is not None and not acao.detalhes.empty:
                detalhes_df = pd.DataFrame(acao.detalhes).T.reset_index()
                detalhes_df.columns = ['Descri√ß√£o', 'Valor']
                detalhes_df = self.ajustar_tipos_dataframe(detalhes_df)

                st.subheader("Tabela de Detalhes")
                st.dataframe(detalhes_df, width=800)
            else:
                st.warning("Nenhum detalhe encontrado para essa a√ß√£o.")

        col_dividendos, col_oscilacoes = st.columns([1, 2])

        with col_dividendos:
            st.subheader("üí∞ Dividendos")
            if not acao.proventos.empty:
                proventos_df = self.ajustar_tipos_dataframe(acao.proventos)
                st.write(proventos_df)

        with col_oscilacoes:
            st.subheader("üìâ Oscila√ß√µes")
            if acao.oscilacoes is not None and not acao.oscilacoes.empty:
                oscilacoes_df = self.ajustar_tipos_dataframe(acao.oscilacoes)
                st.write(oscilacoes_df)

        st.subheader("üìà Tabela Geral de A√ß√µes")
        st.dataframe(self.acoes)

# Execu√ß√£o
if __name__ == "__main__":
    app = Aplicacao()
    app.exibir_dashboard()

# fundamentus_api\setup.py

from setuptools import setup, find_packages

setup(
    name='fundamentalvision ',
    version='0.1.0',
    author='Joel FerreiraHeanna dos Reis',
    author_email='heannareis@gmail.com',
    description='Um pacote para an√°lise fundamentalista de a√ß√µes da Bolsa B3 do Brasil.',
    packages=find_packages(),
    install_requires=[
        'pandas',
        'requests',
        'beautifulsoup4',
        'streamlit',
        'plotly',
        'fundamentus'
    ],
    classifiers=[
        'Programming Language :: Python :: 3',
        'License :: OSI Approved :: MIT License',
        'Operating System :: OS Independent',
    ],
    python_requires='>=3.6',
)

# ia_generator.py

import requests
from pathlib import Path
import webbrowser
from config.common_paths import TRANSCRIPTION_OUTPUT_PATH

apiKey = "6UlOOoY/kkmprunma/qNDg"

str_personas = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'personas.txt'
str_contexto = TRANSCRIPTION_OUTPUT_PATH / 'input' / 'contexto.txt'

url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

txt_files = list(TRANSCRIPTION_OUTPUT_PATH.glob('*.txt'))

css_styles = """
<style>
body {
    font-family: Arial, sans-serif;
    margin: 20px;
}

h1, h2, h3 {
    color: #FF8C00;
}

li, strong, p {
    color: #008000;
}

h1 {
    font-size: 24px;
    margin-bottom: 20px;
}

h2 {
    font-size: 20px;
    margin-top: 20px;
    margin-bottom: 10px;
}

ul {
    list-style-type: disc;
    margin-left: 40px;
}

li {
    margin-bottom: 10px;
}

p {
    line-height: 1.6;
}
</style>
"""

if not txt_files:
    print(f"N√£o foram encontrados arquivos .txt no diret√≥rio {TRANSCRIPTION_OUTPUT_PATH}.")
else:
    for txt_file in txt_files:
        if txt_file.is_file():
            print(f"Lendo o arquivo: {txt_file.name}")
            with open(txt_file, 'r', encoding='utf-8') as file:
                str_reuniao = file.read()

            print(f"Enviando o conte√∫do do arquivo {txt_file.name} para a API...")
            data = {
                "inputs": {
                    "str_reuniao": str_reuniao,
                    "str_personas": str_personas.read_text(encoding='utf-8'),
                    "str_contexto": str_contexto.read_text(encoding='utf-8'),
                }
            }

            response = requests.post(f"{url}/api/templates/668de04202493d3063a9d7fa/execute", json=data, headers=headers)
            if response.status_code == 200:
                print(f"Resultado para o arquivo {txt_file.name} recebido.")
                html_content = response.text
                print(response.text)

                # Incluir o CSS no conte√∫do HTML
                html_with_css = f"<html><head>{css_styles}</head><body>{html_content}</body></html>"

                # Salvar o conte√∫do HTML em um arquivo
                output_file = TRANSCRIPTION_OUTPUT_PATH / f"{txt_file.stem}_output.html"
                with open(output_file, 'w', encoding='utf-8') as html_file:
                    html_file.write(html_with_css)

                # Abrir o arquivo HTML no navegador
                webbrowser.open(f"file://{output_file.resolve()}")
            else:
                print(f"Erro ao processar o arquivo {txt_file.name}: {response.status_code}")


# main.py

from video_to_audio.video_to_audio import VideoConfig, VideoToAudioConverter
from audio_to_text.audio_to_text import AudioToConverter
from audio_to_text.audio_config.audio_config import AudioConfig
from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from transcriptions.transcriptions_config import TranscriptionConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from text_to_embedding.embedding_processing import EmbeddingProcessorWrapper
from pathlib import Path

def main():
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    root_path = str(PROJECT_ROOT)
    print(f"Root path: {root_path}")  # Para verificar se est√° correto
    api_url = "http://localhost:8081/api/meetings/transcriptions"
    
    # # Configura√ß√£o de v√≠deos
    video_config = VideoConfig(root_path=root_path)
    video_processor = VideoToAudioConverter(video_config=video_config)
    video_processor.process_videos()
    
    # # Configura√ß√£o de √°udios
    audio_config = AudioConfig(root_path=root_path)
    audio_processor = AudioToConverter(audio_config=audio_config)
    audio_processor.process_audio_files()
    
    # # Processamento de transcri√ß√µes e envio de embeddings
    # embedding_processor_wrapper = EmbeddingProcessorWrapper(root_path=root_path, api_url=api_url)
    # embedding_processor_wrapper.process_transcriptions()

if __name__ == "__main__":
    main()


# send_embeddings_database\embedding_config\embedding_config.py

from app_config.app_config import AppConfig

class EmbeddingConfig(AppConfig):
    def __init__(self, root_path=None, transcription_input_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = transcription_input_path
        self.EMBEDDING_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'embeddings' / 'output'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH, self.EMBEDDING_OUTPUT_PATH])


# send_embeddings_database\verify_last_enbedding.py

import os
import numpy as np

def get_latest_file(directory):
    # Listar todos os arquivos no diret√≥rio
    files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]
    
    if not files:
        raise FileNotFoundError("Nenhum arquivo encontrado no diret√≥rio.")

    # Encontrar o arquivo mais recente
    latest_file = max(files, key=os.path.getmtime)
    return latest_file

def load_and_print_embedding(directory):
    # Obter o caminho do √∫ltimo arquivo de embedding
    embedding_file_path = get_latest_file(directory)
    
    # Carregar o embedding
    embedding = np.load(embedding_file_path)
    
    # Exibir o conte√∫do do embedding
    print("Embedding carregado:")
    print(embedding)
    print("Dimens√µes do embedding:", embedding.shape)

# Caminho do diret√≥rio de embeddings
embedding_directory = 'C:/Users/HeannarReis/Documents/bsa_atacadao/assets/embeddings/output'

# Carregar e exibir o √∫ltimo embedding
load_and_print_embedding(embedding_directory)


# test_whisper.py

from transformers import pipeline
from common_paths import CommonPaths

commmom_paths = CommonPaths()

# Fun√ß√£o para ler a transcri√ß√£o de um arquivo
def read_transcription(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
    return lines

# Fun√ß√£o para converter a pontua√ß√£o em estrelas
def score_to_stars(score):
    if score >= 0.75:
        return 5
    elif score >= 0.55:
        return 4
    elif score >= 0.35:
        return 3
    elif score >= 0.15:
        return 2
    else:
        return 1

# Inicializar o pipeline de an√°lise de sentimento
sentiment_pipeline = pipeline("sentiment-analysis", model="neuralmind/bert-base-portuguese-cased")

# Caminho para o arquivo de transcri√ß√£o
file_path = commmom_paths.TRANSCRIPTION_OUTPUT_PATH / 'feedback.txt'

# Ler a transcri√ß√£o
lines = read_transcription(file_path)

# Analisar sentimento para cada feedback
for line in lines:
    sentiment = sentiment_pipeline(line.strip())
    score = sentiment[0]['score']
    stars = score_to_stars(score)
    
    # Ajuste manual para feedbacks com aspectos positivos e negativos
    if any(word in line.lower() for word in ["mas", "por√©m", "no entanto"]):
        stars = max(1, stars - 1)  # Reduz uma estrela se houver contradi√ß√£o
    
    # Ajuste adicional baseado em palavras-chave
    positive_keywords = ["excelente", "√≥timo", "perfeito", "r√°pido", "eficiente", "satisfeito", "clara", "eficaz", "bom trabalho"]
    negative_keywords = ["ruim", "p√©ssimo", "horr√≠vel", "poderia", "n√£o resolveu", "insatisfat√≥ria", "confusa", "inadequado", "lento", "n√£o houve seguimento", "n√£o atendeu", "n√£o funcionou", "demorado"]
    
    positive_count = sum(word in line.lower() for word in positive_keywords)
    negative_count = sum(word in line.lower() for word in negative_keywords)
    
    # Ajuste de estrelas baseado na contagem de palavras-chave
    if positive_count > negative_count:
        stars = min(5, stars + 1)
    elif negative_count > positive_count:
        stars = max(1, stars - 1)
    
    print(f"Texto: {line.strip()}")
    print(f"Sentimento: {stars} estrelas")
    print(f"Pontua√ß√£o: {score:.2f}")
    print('---')


# text_to_embedding\embedding_processing.py

from send_embeddings_database.embedding_config.embedding_config import EmbeddingConfig
from text_to_embedding.texto_to_embedding import EmbeddingProcessor
from transcriptions.transcriptions_config import TranscriptionConfig
from transcriptions.transciption_sender_database import TranscriptionSenderDatabase

class EmbeddingProcessorWrapper:
    def __init__(self, root_path, api_url):
        # Configura√ß√£o de transcri√ß√µes e embeddings
        transcription_config = TranscriptionConfig(root_path=root_path)
        embedding_config = EmbeddingConfig(root_path=root_path, transcription_input_path=transcription_config.get_transcription_input_path())

        self.embedding_processor = EmbeddingProcessor(embedding_config)
        self.transcription_sender = TranscriptionSenderDatabase(api_url)
    
    def process_transcriptions(self):
        # Mostrar o diret√≥rio onde est√° procurando as transcri√ß√µes
        print(f"Diret√≥rio de entrada das transcri√ß√µes: {self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH}")
        
        # Listar todos os arquivos de transcri√ß√£o no diret√≥rio de entrada
        transcription_files = list(self.embedding_processor.embedding_config.TRANSCRIPTION_INPUT_PATH.glob('*.txt'))
        if not transcription_files:
            print("Nenhum arquivo de transcri√ß√£o encontrado.")
        for transcription_file_path in transcription_files:
            if transcription_file_path.is_file():
                print(f"Processando arquivo: {transcription_file_path}")
                self.process_and_send_transcription(transcription_file_path)
            else:
                print(f"Arquivo n√£o encontrado: {transcription_file_path}")

    def process_and_send_transcription(self, transcription_file_path):
        try:
            # Ler a transcri√ß√£o do arquivo de texto
            with open(transcription_file_path, 'r', encoding='utf-8') as f:
                transcription_text = f.read()
                if not transcription_text:
                    print(f"Arquivo {transcription_file_path} est√° vazio.")
                    return

            # Gerar o embedding da transcri√ß√£o
            embedding = self.embedding_processor.generate_embedding(transcription_text)
            if embedding is None:
                print(f"Falha ao gerar embedding para o arquivo {transcription_file_path}.")
                return

            # Salvar o embedding em um arquivo .npy
            self.embedding_processor.save_embedding(transcription_file_path, embedding)

            # Enviar os dados para a API
            self.transcription_sender.send_transcription(transcription_text, embedding)

        except Exception as e:
            print(f"Erro ao processar o arquivo {transcription_file_path}: {e}")


# text_to_embedding\texto_to_embedding.py

from sentence_transformers import SentenceTransformer
import numpy as np

class EmbeddingProcessor:
    def __init__(self, embedding_config):
        self.embedding_config = embedding_config
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

    def generate_embedding(self, transcription_text):
        return self.embedding_model.encode(transcription_text)

    def save_embedding(self, transcription_file_path, embedding):
        embedding_file_path = self.embedding_config.EMBEDDING_OUTPUT_PATH / transcription_file_path.with_suffix('.npy').name
        np.save(embedding_file_path, embedding)
        print(f"Embedding salvo em: {embedding_file_path}")
        return embedding_file_path


# transcriptions\transciption_sender_database.py

import requests

class TranscriptionSenderDatabase:
    def __init__(self, api_url):
        self.api_url = api_url

    def send_transcription(self, transcription_text, embedding):
        data = {
            'transcriptionText': transcription_text,
            'embedding': embedding.tolist()
        }

        response = requests.post(self.api_url, json=data)

        if response.status_code == 201:
            print("Transcri√ß√£o e embedding enviados com sucesso.")
        else:
            print(f"Erro ao enviar dados: {response.status_code}")
            print("Resposta da API:")
            print(response.text)


# transcriptions\transcriptions_config.py

from app_config.app_config import AppConfig

class TranscriptionConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.TRANSCRIPTION_INPUT_PATH = self.ROOT_PATH / 'assets' / 'transcriptions' / 'input'
        self.create_directories([self.TRANSCRIPTION_INPUT_PATH])
    
    def get_transcription_input_path(self):
        return self.TRANSCRIPTION_INPUT_PATH


# translate\translator_to_english.py

import speech_recognition as sr
from translate import Translator

def ouvir_e_traduzir():
    # Inicializa o reconhecedor de fala
    recognizer = sr.Recognizer()

    # Configura o tradutor
    translator = Translator(to_lang="en", from_lang="pt")

    # Usa o microfone como fonte de √°udio
    with sr.Microphone() as source:
        print("Diga algo em portugu√™s...")

        while True:
            try:
                # Escuta o √°udio do microfone
                audio = recognizer.listen(source)
                
                # Reconhece a fala usando o Google Web Speech API
                texto_portugues = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {texto_portugues}")

                # Traduz o texto para o ingl√™s
                traducao = translator.translate(texto_portugues)
                print(f"Tradu√ß√£o para o ingl√™s: {traducao}")

            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio")
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")

if __name__ == "__main__":
    try:
        ouvir_e_traduzir()
    except KeyboardInterrupt:
        print("Interrompido pelo usu√°rio")


# translate\whispert_translator.py

import whisper
import pyaudio
import numpy as np

# Inicializa o modelo Whisper
model = whisper.load_model("base")

# Configura√ß√µes de √°udio
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024

# Inicializa o PyAudio
audio = pyaudio.PyAudio()

# Abre o stream de √°udio
stream = audio.open(format=FORMAT, channels=CHANNELS,
                    rate=RATE, input=True,
                    frames_per_buffer=CHUNK)

print("Diga algo em portugu√™s...")

try:
    audio_buffer = []

    while True:
        # L√™ dados do microfone
        data = stream.read(CHUNK)
        audio_buffer.append(np.frombuffer(data, dtype=np.int16).flatten().astype(np.float32) / 32768.0)

        # Processa o √°udio a cada 5 segundos
        if len(audio_buffer) * CHUNK / RATE >= 5:
            audio_data = np.concatenate(audio_buffer)
            audio_buffer = []

            # Transcreve e traduz o √°udio usando Whisper
            result = model.transcribe(audio_data, task="translate", language="pt")

            # Exibe a tradu√ß√£o
            print(f"Tradu√ß√£o para o ingl√™s: {result['text']}")

except KeyboardInterrupt:
    print("Interrompido pelo usu√°rio")

    # Fecha o stream de √°udio
    stream.stop_stream()
    stream.close()
    audio.terminate()


# video_to_audio\video_config\video_config.py

from app_config.app_config import AppConfig

class VideoConfig(AppConfig):
    def __init__(self, root_path=None):
        super().__init__(root_path)
        self.VIDEO_INPUT_PATH = self.ROOT_PATH / 'assets' / 'video' / 'input'
        self.VIDEO_OUTPUT_PATH = self.ROOT_PATH / 'assets' / 'audio' / 'input'
        self.create_directories([self.VIDEO_INPUT_PATH, self.VIDEO_OUTPUT_PATH])

# video_to_audio\video_to_audio.py

from moviepy import VideoFileClip
import glob
import os
from .video_config.video_config import VideoConfig

class VideoToAudioConverter:
    def __init__(self, video_config: VideoConfig):
        self.video_config = video_config

    def convert_video_to_audio(self, video_path, audio_path):
        try:
            video = VideoFileClip(video_path)
            if video.audio:
                video.audio.write_audiofile(audio_path, fps=44100)
                print(f"Convertido {video_path} para {audio_path}")
            else:
                print(f"Aviso: O v√≠deo {video_path} n√£o cont√©m √°udio!")
        except Exception as e:
            print(f"Erro ao converter {video_path}: {e}")

    def process_videos(self):
        input_directory = self.video_config.VIDEO_INPUT_PATH
        output_directory = self.video_config.VIDEO_OUTPUT_PATH

        os.makedirs(output_directory, exist_ok=True)

        # Busca qualquer arquivo de v√≠deo (formatos comuns)
        video_files = glob.glob(os.path.join(input_directory, "*.*"))  # Pega todos os arquivos

        # Filtra apenas arquivos de v√≠deo
        video_extensions = {".mp4", ".mkv", ".avi", ".mov", ".wmv", ".flv"}  
        video_files = [f for f in video_files if os.path.splitext(f)[1].lower() in video_extensions]

        if not video_files:
            print(f"Nenhum arquivo de v√≠deo encontrado em: {input_directory}")
            return

        for video_file in video_files:
            base_name = os.path.basename(video_file)
            audio_file = os.path.join(output_directory, os.path.splitext(base_name)[0] + ".wav")
            self.convert_video_to_audio(video_file, audio_file)

        print("Convers√£o de v√≠deo para √°udio conclu√≠da!")


# voice_assistent\assistent.py

import speech_recognition as sr
import pyttsx3
import re
from collections import deque
import spacy
import requests
import os
import webbrowser
from class_voice_assistent.prompt import create_prompt
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import google.generativeai as genai

# Configura√ß√µes da API
handler = genai('gemini-1.5-flash')

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

voices = engine.getProperty('voices')
engine.setProperty('rate', 180)
print("\nLista de Vozes...")
for indice, vozes in enumerate(voices):
    print(indice, vozes.name)

voz = 1
engine.setProperty('voice', voices[voz].id)

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

# Fun√ß√£o para extrair texto de HTML
def extract_text_from_html(html):
    if not html.strip().startswith('<'):
        print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
        return html
    soup = BeautifulSoup(html, 'html.parser')
    text = ' '.join([p.get_text() for p in soup.find_all('p')])
    return text

def get_text_response(prompt, context, feedback):
    # Gere o conte√∫do com base no prompt usando a classe GenerativeModelHandler
    response = handler.generate_content(prompt)
    return response

# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/api/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


# voice_assistent\class_voice_assistent\api_client.py

import requests


class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, meeting):
        try:
            response_text = self.model.generate_content(prompt, context, meeting)
            return response_text
        except Exception as e:
            print(f"Erro inesperado: {e}")
            return None

    def find_similar_embeddings(self, embedding):
        try:
            print(f"Buscando embeddings similares para: {embedding}")
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            similar_embeddings = response.json()

            # Ordenar por similaridade (assumindo que a API retorna com similaridade em ordem decrescente)
            # Remover duplicatas baseadas na pergunta
            seen_questions = set()
            unique_embeddings = []
            for embedding in similar_embeddings:
                question = embedding['question'].strip().lower()
                if question not in seen_questions:
                    unique_embeddings.append(embedding)
                    seen_questions.add(question)
            print(f"Embeddings similares √∫nicos encontrados: {unique_embeddings}")
            return unique_embeddings
        except requests.RequestException as e:
            print(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            # Converter embeddings de numpy arrays para listas
            if hasattr(question_embedding, 'tolist'):
                question_embedding = question_embedding.tolist()
            if hasattr(answer_embedding, 'tolist'):
                answer_embedding = answer_embedding.tolist()
            
            data = {
                "question": question,
                "questionEmbedding": question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding
            }
            
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                print("Pergunta e resposta salvas com sucesso.")
            else:
                print(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            print(f"Erro em save_question_answer: {e}")


    def fetch_all_contexts(self):
        try:
            response = requests.get("http://localhost:8081/api/contexts/all")
            if response.status_code == 200:
                data = response.json()
                contexts = data.get('contexts', [])
                if isinstance(contexts, list):
                    print(f"Contexto obtido da API: {contexts}")
                    return contexts
                else:
                    print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                    return []
            else:
                print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
                return []
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
            return []

    def fetch_last_meeting(self):
        try:
            response = requests.get("http://localhost:8081/api/meetings/last")
            if response.status_code == 200:
                data = response.json()
                transcription_text = data.get('transcriptionText', "")
                if isinstance(transcription_text, str):
                    print(f"Texto da transcri√ß√£o obtido da API: {transcription_text}")
                    return transcription_text
                else:
                    print(f"Erro: 'transcriptionText' n√£o √© uma string. Dados retornados: {data}")
                    return ""
            else:
                print(f"Erro ao acessar a API de reuni√µes: {response.status_code}, {response.text}")
                return ""
        except requests.RequestException as e:
            print(f"Erro ao fazer requisi√ß√£o para a API de reuni√µes: {e}")
            return ""


# voice_assistent\class_voice_assistent\command_interpreter.py

import spacy
from prompt_generator.online_prompt import OnlineResearchPromptGenerator
from prompt_generator.meeting_prompt import MeetingPromptGenerator
from prompt_generator.default_prompt_generator import DefaultPromptGenerator
import re

# Carregar o modelo de linguagem natural
nlp = spacy.load("pt_core_news_sm")

class CommandInterpreter:
    def __init__(self, api_client, question_answer_service, context_manager, max_similar=3):
        self.api_client = api_client
        self.question_answer_service = question_answer_service
        self.context_manager = context_manager
        self.max_similar = max_similar  # Limite de contextos similares

    def interpret_command(self, command, meeting):
        print(f"Interpretando comando: {command}")
        contexts = self.api_client.fetch_all_contexts()
        context_str = "\n".join([context['context'] for context in contexts])

        # Gerar embedding para a pergunta e buscar embeddings similares
        question_embedding = self.question_answer_service.convert_text_to_embedding(command)
        similar_embeddings = self.api_client.find_similar_embeddings(question_embedding)

        # Filtrar para evitar respostas redundantes
        unique_responses = self._filter_unique_responses(similar_embeddings, command)
        similar_context = "\n".join([f"Pergunta: {embedding['question']}\nResposta: {embedding['answer']}" for embedding in unique_responses[:self.max_similar]])

        # Detectar tipo de comando usando regex
        if re.search(r'\b(pesquise|pesquisar|procure)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como pesquisa online.")
            response = self.get_online_research_response(command, context_str, similar_context)
        elif re.search(r'\b(contexto)\b', command, re.IGNORECASE):
            print(f"\nComando identificado como busca de contexto.")
            response = self.get_project_response(command, meeting, context_str, similar_context)
        elif re.search(r'\b(resumo?|t√≥picos da|pontos (relevantes|principais)|an√°lise)\b.*\b(reuni√£o|√∫ltima (reuni√£o|conversa|sess√£o))\b', command, re.IGNORECASE):
            print(f"\nComando identificado como an√°lise de reuni√£o.")
            meeting = self.api_client.fetch_last_meeting()
            response = self.get_meeting_analysis_response(command, context_str, meeting)
        else:
            print(f"\nComando identificado como comando padr√£o.")
            response = self.handle_default_command(command, context_str, meeting, similar_context)

        if response:
            answer_embedding = self.question_answer_service.convert_text_to_embedding(response)
            self.api_client.save_question_answer(command, question_embedding, response, answer_embedding)
            self.context_manager.add_context(command, response)

        return response

    def _filter_unique_responses(self, similar_embeddings, current_command):
        """
        Filtra respostas semelhantes que s√£o muito similares ao comando atual para evitar redund√¢ncia.
        """
        filtered = []
        for embedding in similar_embeddings:
            if embedding['question'].lower() != current_command.lower():
                filtered.append(embedding)
        return filtered

    def handle_default_command(self, command, context_str, meeting, similar_context):
        print(f"\nTratando comando padr√£o: {command}")
        # Combinar o contexto atual com os contextos similares para enriquecer a resposta
        combined_context = f"{context_str}\n{similar_context}"
        prompt = DefaultPromptGenerator().generate_prompt(command, combined_context, meeting)
        response = self.api_client.get_text_response(prompt, combined_context, meeting)
        return response

    # M√©todos get_project_response, get_meeting_analysis_response, get_online_research_response permanecem inalterados

    def get_project_response(self, command, meeting, context_str, similar_context):
        print(f"\nGerando prompt de projeto.")
        prompt = DefaultPromptGenerator().generate_prompt(command, context_str, meeting, similar_context)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_meeting_analysis_response(self, command, context_str, meeting):
        print(f"\nGerando prompt de an√°lise de reuni√£o.")
        prompt = MeetingPromptGenerator().generate_prompt(command, context_str, meeting)
        return self.api_client.get_text_response(prompt, context_str, meeting)

    def get_online_research_response(self, command, context_str, similar_context):
        print(f"\nGerando prompt de pesquisa online.")
        prompt = OnlineResearchPromptGenerator().generate_prompt(command, context_str, similar_context)
        return self.api_client.get_text_response(prompt, context_str, None)


# voice_assistent\class_voice_assistent\context_manager.py

from collections import deque

class ContextManager:
    def __init__(self, maxlen=10):
        self.recent_context = deque(maxlen=maxlen)

    def add_context(self, command, response):
        self.recent_context.append((command, response))

    def get_context(self):
        return "\n".join([context for context, _ in self.recent_context])


# voice_assistent\class_voice_assistent\conversation_history.py



# voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py

import requests
import logging
import google.generativeai as genai

# Configure o logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class APIClient:
    def __init__(self, similarity_url, save_url, model):
        self.similarity_url = similarity_url
        self.save_url = save_url
        self.model = model

    def get_text_response(self, prompt, context, feedback):
        try:
            # Gerando o conte√∫do usando a nova API
            response = self.model.generate_content(prompt)
            if response and hasattr(response, 'text'):
                return prompt, response.text
            else:
                logger.error("Resposta inv√°lida da API")
                return prompt, None
        except Exception as e:
            logger.error(f"Erro em get_text_response: {e}")
            return prompt, None

    def find_similar_embeddings(self, embedding):
        try:
            if hasattr(embedding, 'tolist'):
                embedding = embedding.tolist()
            data = embedding
            logger.info(f"Enviando dados para a API de embeddings similares: {data}")
            response = requests.post(f"{self.similarity_url}/api/question_answers/similar", json=data)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            logger.error(f"Erro em find_similar_embeddings: {e}")
            return []

    def save_question_answer(self, question, question_embedding, answer, answer_embedding):
        try:
            data = {
                "question": question,
                "questionEmbedding": question_embedding.tolist() if hasattr(question_embedding, 'tolist') else question_embedding,
                "answer": answer,
                "answerEmbedding": answer_embedding.tolist() if hasattr(answer_embedding, 'tolist') else answer_embedding
            }
            response = requests.post(self.save_url, json=data)
            response.raise_for_status()
            if response.status_code == 201:
                logger.info("Pergunta e resposta salvas com sucesso.")
            else:
                logger.warning(f"Falha ao salvar pergunta e resposta. C√≥digo de status: {response.status_code}")
        except requests.RequestException as e:
            logger.error(f"Erro em save_question_answer: {e}")


# voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py

import os
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Optional
import logging

class GenerativeModelHandler:
    def __init__(self, model_name: str):
        self.model_name: str = model_name
        self.model: Optional[genai.GenerativeModel] = None
        self.api_key: Optional[str] = None
        self._load_env_variables()
        self._configure_api()
        self._initialize_model()

    def _load_env_variables(self) -> None:
        """Carregar vari√°veis do arquivo .env"""
        load_dotenv()
        self.api_key = os.getenv('API_KEY_GEMINI')
        if not self.api_key:
            raise ValueError("API Key n√£o encontrada nas vari√°veis de ambiente")

    def _configure_api(self) -> None:
        """Configurar a chave da API"""
        genai.configure(api_key=self.api_key)

    def _initialize_model(self) -> None:
        """Inicializar o modelo generativo"""
        try:
            self.model = genai.GenerativeModel(self.model_name)
        except Exception as e:  
            raise RuntimeError(f"Erro ao inicializar o modelo: {e}")

    def generate_content(self, prompt: str, context: str, meeting: str) -> str:
        """Gerar conte√∫do com base no prompt, contexto e reuni√£o"""
        try:
            # Supondo que a API espera um dicion√°rio com os par√¢metros
            request_data = f'''
                "prompt": {prompt},
                "context": {context},
                "meeting": {meeting}
            '''
            print(f"Enviando requisi√ß√£o para a API GenAI: {request_data}")

            response = self.model.generate_content(request_data)
            return response.text
        except Exception as e:
            raise RuntimeError(f"Erro ao gerar conte√∫do: {e}")

# voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py

import os
from dotenv import load_dotenv
from groq import Groq

# Carregar vari√°veis do arquivo .env
load_dotenv()

# Recuperar a chave da API
api_key = os.getenv("GROQ_API_KEY")

# Verificar se a chave da API foi carregada corretamente
if not api_key:
    raise ValueError("API Key is missing. Please set the GROQ_API_KEY in the .env file.")

# Configurar o cliente com a chave da API
client = Groq(api_key=api_key)

# Cria√ß√£o da conclus√£o do chat
chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "De acordo com nossas conversas anteriores, o que voc√™ acha do meu uso de IA ?",
        }
    ],
    model="llama3-8b-8192",
)

print(chat_completion.choices[0].message.content)


# voice_assistent\class_voice_assistent\main.py

import os
from context_manager import ContextManager
from api_client import APIClient
from command_interpreter import CommandInterpreter
from text_command_hendler import TextCommandHandler
from text_processor import TextProcessor
from text_to_speech import TextToSpeech
from voice_command_hendler import VoiceCommandHandler
from question_answers_service import QuestionAnswerService
from gpt_communication.gemini_gpt import GenerativeModelHandler

class MainApp:
    def __init__(self, model):
        self.voice_handler = VoiceCommandHandler()
        self.text_handler = TextCommandHandler()
        self.tts = TextToSpeech()
        self.text_processor = TextProcessor()
        self.api_client = APIClient(
            similarity_url="http://localhost:8081",
            save_url="http://localhost:8081/api/question_answers/save",
            model=model
        )
        self.context_manager = ContextManager()
        self.question_answer_service = QuestionAnswerService()
        self.command_interpreter = CommandInterpreter(
            self.api_client,
            self.question_answer_service,
            self.context_manager
        )

    def handle_command(self, command, meeting=""):
        if command:
            print(f"Pergunta recebida: {command}")
            text_response = self.command_interpreter.interpret_command(command, meeting)
            if text_response:
                print(f"Resposta: {text_response}")
                self.tts.speak_text(text_response)
                self.context_manager.add_context(command, text_response)
                return text_response
        else:
            print("Nenhum comando detectado.")
            return None

    def run(self):
        meeting = ""
        while True:
            try:
                input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
                if input_type == 'v':
                    command = self.voice_handler.capture_voice_command()
                elif input_type == 't':
                    command = self.text_handler.capture_text_command()
                else:
                    print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
                    continue

                response = self.handle_command(command, meeting)
                if response:
                    print(f"Resposta: {response}")
            except Exception as e:
                print(f"Ocorreu um erro: {e}")

if __name__ == "__main__":
    model = GenerativeModelHandler('gemini-1.5-flash')
    app = MainApp(model)
    app.run()

# voice_assistent\class_voice_assistent\prompt.py

def create_prompt(command, context, meeting):
    keywords = ["fa√ßa um resumo da √∫ltima reuni√£o.", "t√≥picos da √∫ltima reuni√£o", "resuma a √∫ltima reuni√£o", "pesquise", "pesquisar", "procure"]
    if any(keyword in command.lower() for keyword in keywords):
        return f"""
        Regras de Meeting:
        - Voc√™ √© respons√°vel por analisar, debater, sugerir e informar melhorias.
        - Resuma de forma clara e Objetiva.
        - N√£o acrescentar t√≠tulo nas respostas.

        [context]: {context}
        -------
        [meeting]: {meeting}
        -------
        [str_texto]: {command}
        """
    else:
        return f"""
        [context]: {context}
        -------
        [str_texto]: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py

class DefaultPromptGenerator:
    def generate_prompt(self, command, combined_context, meeting):
        prompt = (
            f"Comando: {command}\n"
            f"Contexto Anterior:\n{combined_context}\n"
            f"Baseie sua resposta nas informa√ß√µes acima e forne√ßa uma solu√ß√£o detalhada."
        )
        return prompt

# voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class MeetingPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting):
        return f"""
        Regras de Meeting com respostas inteligentes:
        - Responda a pergunta de [str_texto] com base nas diretrizes abaixo...
            - Voc√™ √© respons√°vel analisar com detalhes a reuni√£o de [str_meeting], e fornecer uma longa est√≥ria sobre o assunto.
            - observe os nomes das personas mencionadas no texto de meeting para aprender e melhorar a precis√£o da resposta.
            - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [str_texto]: Responda a pergunta de: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py

from prompt_generator.prompt_generator import PromptGenerator

class OnlineResearchPromptGenerator(PromptGenerator):
    def generate_prompt(self, command, context, meeting, similar_context):
        return f"""
        Regras de Pesquisa Online Inteligente:
        - Utilize similar_context e fa√ßa uma pesquisa online para uma resposta mais precisa das quest√µes de [str_text]
        - N√£o acrescente t√≠tulo nas respostas.
        
        ------
        [context]: Regras B√°sicas {context}
        ------
        [similar_context]:
        Perguntas e respostas anteriores.{similar_context}
        ------
        [str_texto]: Responda seguinte pergunta: {command}
        """

# voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py

from abc import ABC, abstractmethod

class PromptGenerator(ABC):
    @abstractmethod
    def generate_prompt(self, command, context, meeting, similar_context):
        pass

# voice_assistent\class_voice_assistent\question_answers_service.py

import requests
import numpy as np
from sentence_transformers import SentenceTransformer

class QuestionAnswerService:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.embedding_model = SentenceTransformer(model_name)

    def convert_text_to_embedding(self, text):
        embedding = self.embedding_model.encode(text)
        #print(f"Embedding gerado para '{text}': {embedding[0]:.16f}") # Adicionado para verificar o embedding gerado
        return embedding


# voice_assistent\class_voice_assistent\text_command_hendler.py

class TextCommandHandler:
    def capture_text_command(self):
        command = input("Digite o seu comando: ")
        return command


# voice_assistent\class_voice_assistent\text_processor.py

from bs4 import BeautifulSoup

class TextProcessor:
    def extract_values_from_json(self, data):
        if isinstance(data, dict):
            return ' '.join([str(value) for value in data.values()])
        elif isinstance(data, list):
            return ' '.join([self.extract_values_from_json(item) for item in data])
        return str(data)

    def extract_text_from_html(self, html):
        if not html.strip().startswith('<'):
            print("Aviso: A entrada parece um caminho de arquivo, n√£o um conte√∫do HTML.")
            return html
        soup = BeautifulSoup(html, 'html.parser')
        text = ' '.join([p.get_text() for p in soup.find_all('p')])
        return text


# voice_assistent\class_voice_assistent\text_to_speech.py

import pyttsx3

class TextToSpeech:
    def __init__(self):
        self.engine = pyttsx3.init()

    def speak_text(self, text):
        cleaned_text = self.clean_text(text)
        self.engine.say(cleaned_text)
        self.engine.runAndWait()

    def clean_text(self, text):
        import re
        return re.sub(r'[\*\_\#]', '', text)


# voice_assistent\class_voice_assistent\voice_command_hendler.py

import speech_recognition as sr

class VoiceCommandHandler:
    def capture_voice_command(self):
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            print("Por favor, fale o seu comando:")
            try:
                audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
                print("√Åudio capturado com sucesso.")
                command = recognizer.recognize_google(audio, language='pt-BR')
                print(f"Voc√™ disse: {command}")
                return command
            except sr.WaitTimeoutError:
                print("Tempo de espera expirado. Nenhum √°udio detectado.")
                return None
            except sr.UnknownValueError:
                print("N√£o foi poss√≠vel entender o √°udio.")
                return None
            except sr.RequestError as e:
                print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
                return None


# voice_assistent\config.py

# config.py
import pyttsx3
import spacy
from collections import deque

class APIConfig:
    apiKey = "API_KEY"
    url = "https://gpt-templates.saiapplications.com"
    headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")


# voice_assistent\template.py

import speech_recognition as sr
import requests
import pyttsx3
import re
from collections import deque
import spacy
import os
import webbrowser
from voice_assistent.prompt import create_prompt

# Configura√ß√µes da API
apiKey = "6UlOOoY/kkmprunma/qNDg"
url = "https://gpt-templates.saiapplications.com"
headers = {"X-Api-Key": apiKey}

# Inicializa√ß√£o do motor de texto para voz
engine = pyttsx3.init()

# Inicializa o contexto como uma deque para manter as √∫ltimas intera√ß√µes
recent_context = deque(maxlen=10)

# Inicializa√ß√£o do modelo de linguagem
nlp = spacy.load("pt_core_news_sm")

# Fun√ß√£o para capturar e processar comandos de voz
def capture_voice_command():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Por favor, fale o seu comando:")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            print("√Åudio capturado com sucesso.")
            command = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Voc√™ disse: {command}")
            return command
        except sr.WaitTimeoutError:
            print("Tempo de espera expirado. Nenhum √°udio detectado.")
            return None
        except sr.UnknownValueError:
            print("N√£o foi poss√≠vel entender o √°udio.")
            return None
        except sr.RequestError as e:
            print(f"Erro ao solicitar resultados do servi√ßo de reconhecimento de fala; {e}")
            return None

# Fun√ß√£o para capturar comandos de texto
def capture_text_command():
    command = input("Digite o seu comando: ")
    return command

# Fun√ß√£o para converter texto em fala
def speak_text(text):
    if isinstance(text, dict):
        text = extract_values_from_json(text)  # Extrai os valores do dicion√°rio
    cleaned_text = clean_text(text)
    engine.say(cleaned_text)
    engine.runAndWait()

# Fun√ß√£o para remover caracteres especiais do texto
def clean_text(text):
    return re.sub(r'[\*\_]', '', text)

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)

def get_text_response(prompt, context, feedback):
    data = {
        "inputs": {
            "str_texto": prompt,
            "str_contexto": context,
            "str_feedback": feedback
        }
    }
    print(f"Enviando dados para a API: {data}")
    try:
        response = requests.post(f"{url}/api/templates/6691e223802f95c2b394a8bd/execute", json=data, headers=headers)
        print(f"Status da resposta: {response.status_code}")
        if response.status_code == 200:
            try:
                response_data = response.html()  # Tente converter a resposta para JSON
                print("Resposta HTML recebida.")
                return extract_values_from_json(response_data)  # Extrai os valores do JSON
            except ValueError:
                print("A resposta n√£o est√° no formato JSON esperado. Tratando como texto simples.")
                return response.text  # Retorna o texto bruto da resposta
        else:
            print(f"Erro ao acessar a API: {response.status_code}, {response.text}")
            return None
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API: {e}")
        return None

# Fun√ß√£o para extrair valores do JSON
def extract_values_from_json(data):
    if isinstance(data, dict):
        return ' '.join([str(value) for value in data.values()])
    elif isinstance(data, list):
        return ' '.join([extract_values_from_json(item) for item in data])
    return str(data)


# Fun√ß√£o para consultar todos os contextos da API
def fetch_all_contexts():
    try:
        response = requests.get("http://localhost:8081/contexts/all")
        # Verifica o status da resposta
        if response.status_code == 200:
            data = response.json()  # Obtemos o JSON completo

            # Imprime o JSON completo para verificar o retorno bruto
            print(f"Dados brutos da API: {data}")

            # Acessa a lista de contextos e imprime o tipo de dados
            contexts = data.get('contexts', [])
            print(f"Tipo de dados de 'contexts': {type(contexts)}")
            
            if isinstance(contexts, list):  # Verificamos se √© uma lista
                context_str = "\n".join([context['context'] for context in contexts])
                print(f"Contexto obtido da API: {context_str}")  # Adiciona um print para verificar o contexto
                return contexts  # Retorna a lista completa de contextos
            else:
                print(f"Erro: 'contexts' n√£o √© uma lista. Dados retornados: {data}")
                return []
        else:
            print(f"Erro ao acessar a API de contextos: {response.status_code}, {response.text}")
            return []
    except requests.RequestException as e:
        print(f"Erro ao fazer requisi√ß√£o para a API de contextos: {e}")
        return []

# Fun√ß√£o para interpretar comandos e delegar tarefas
def interpret_command(command, feedback):
    # Atualiza o contexto com base na API antes de elaborar a resposta
    contexts = fetch_all_contexts()
    
    doc = nlp(command)
    if "abrir" in command:
        if "navegador" in command:
            webbrowser.open("http://www.google.com")
            return "Abrindo navegador"
        elif "arquivo" in command or "pasta" in command:
            # Extraia o nome do arquivo ou pasta do comando
            for token in doc:
                if token.pos_ == "NOUN":
                    path = token.text
                    if os.path.exists(path):
                        os.startfile(path)
                        return f"Abrindo {path}"
                    else:
                        return f"Arquivo ou pasta {path} n√£o encontrado"
    elif any(keyword in command.lower() for keyword in ["fa√ßa an√°lise", "sentimento", "feedbacks", "feedback"]):
        return get_feedback_analysis_response(command, feedback)
    elif any(keyword in command.lower() for keyword in ["pesquise", "pesquisar", "procure"]):
        return get_online_research_response(command)
    else:
        context_str = "\n".join([context['context'] for context in contexts])  # Converter o contexto para string
        return get_project_response(command, context_str, feedback)

# Fun√ß√£o para responder perguntas sobre o projeto
def get_project_response(command, context, feedback):
    prompt = create_prompt(command, context, feedback)
    print(f"Prompt enviado para a API GPT: {prompt}")  # Adiciona um print para verificar o prompt
    return get_text_response(prompt, context, feedback)

# Fun√ß√£o para fazer pesquisas online
def get_online_research_response(command):
    prompt = create_prompt(command, "", "")
    return get_text_response(prompt, "", "")

# Fun√ß√£o para an√°lise de feedbacks
def get_feedback_analysis_response(command, feedback):
    prompt = create_prompt(command, "", feedback)
    return get_text_response(prompt, "", feedback)

# Loop principal para intera√ß√£o cont√≠nua, incluindo o contexto
def main():
    feedback = ""  # Inicializa o feedback como uma string vazia
    while True:
        input_type = input("Voc√™ quer usar voz ou texto? (v/t): ").strip().lower()
        if input_type == 'v':
            command = capture_voice_command()
        elif input_type == 't':
            command = capture_text_command()
        else:
            print("Op√ß√£o inv√°lida. Por favor, escolha 'v' para voz ou 't' para texto.")
            continue

        if command:
            text_response = interpret_command(command, feedback)
            if text_response:
                print(f"Resposta: {text_response}")
                speak_text(text_response)
                # Adiciona a intera√ß√£o recente ao contexto
                recent_context.append((command, text_response))
        else:
            print("Nenhum comando detectado. Aguardando novamente...")
            continue

if __name__ == "__main__":
    main()


User: Analise meus c√≥digos e me envie as partes que posso eliminar e os c√≥digos duplicados.
Assistant: Com base no seu pedido, analisei os c√≥digos fornecidos e identifiquei as seguintes partes que podem ser eliminadas e os c√≥digos duplicados:

**Partes que podem ser eliminadas:**

*   **Arquivos n√£o utilizados:**
    *   `fundamentus_api\setup.py`: Este arquivo √© usado para configurar e instalar o pacote `fundamentalvision`. Se voc√™ j√° instalou o pacote e n√£o pretende distribu√≠-lo, pode remover este arquivo.
    *   `translate\translator_to_english.py`: Este arquivo cont√©m c√≥digo para traduzir voz do portugu√™s para o ingl√™s. Se voc√™ n√£o precisa dessa funcionalidade, pode remover este arquivo.
    *    `voice_assistent\template.py`: Parece ser um modelo ou c√≥digo de teste. Se n√£o for usado, pode ser removido.
    *   `test_whisper.py`: Este arquivo parece ser um script de teste para an√°lise de sentimento usando o modelo "neuralmind/bert-base-portuguese-cased". Se voc√™ n√£o precisa dessa funcionalidade, pode remover este arquivo.
    *   `send_embeddings_database\verify_last_enbedding.py`: Este arquivo parece ser um script para carregar e imprimir o √∫ltimo embedding salvo em um diret√≥rio. Se voc√™ n√£o precisa dessa funcionalidade, pode remover este arquivo.

*   **C√≥digo comentado ou desnecess√°rio:**
    *   Em v√°rios arquivos, procure por blocos de c√≥digo comentados que n√£o s√£o mais necess√°rios e podem ser removidos.
    *   Verifique se h√° logs excessivos ou mensagens de depura√ß√£o que podem ser removidas ap√≥s a conclus√£o do desenvolvimento.

**C√≥digos duplicados:**

*   **Fun√ß√µes de extra√ß√£o de dados JSON:**
    *   As fun√ß√µes `extract_values_from_json` est√£o definidas em `voice_assistent\template.py` e `voice_assistent\class_voice_assistent\text_processor.py`. Voc√™ deve manter apenas uma defini√ß√£o dessa fun√ß√£o em um local comum e reutiliz√°-la onde for necess√°rio.
*    **Carregar vari√°veis do ambiente**
    *   O modelo de GenerativeModelHandler carrega e configura a API em `chat_app\services\gpt_services.py` e  `voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py`.

**Observa√ß√µes:**

*   Antes de eliminar qualquer c√≥digo, certifique-se de fazer um backup para evitar a perda de funcionalidades importantes.
*   Remova arquivos e partes de c√≥digo desnecess√°rias para manter o projeto organizado e eficiente.
*   Considere refatorar c√≥digos duplicados para melhorar a manuten√ß√£o e evitar erros.
User: Fa√ßa um resumo do chamado dessa imagem.
2025-04-11 10:18:21,166 [INFO] Resposta da IA (imagem): Com certeza. O chamado na imagem relata um problema com o pedido de compra 302165 (PR2900473), onde a equipe de TI informa que n√£o consegue cadastrar o PIP devido a um erro no tipo de patrim√¥nio que sai do Ariba. √â mencionado que a esp√©cie, subesp√©cie e tipo de patrim√¥nio est√£o errados, e que essa combina√ß√£o n√£o existe no cadastro do portal. Aparentemente, algu√©m precisa corrigir as informa√ß√µes no Ariba para que o pedido possa prosseguir.

2025-04-11 10:18:21,267 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-11 10:18:21,270 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-11 10:18:21,272 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-11 10:18:21,273 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-11 10:18:21,275 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-11 10:18:21,277 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-11 10:18:21,278 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-11 10:18:21,279 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-11 10:18:21,281 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-11 10:18:21,283 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-11 10:18:21,285 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-11 10:18:21,286 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-11 10:18:21,288 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-11 10:18:21,290 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-11 10:18:21,291 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-11 10:18:21,293 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-11 10:18:21,294 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-11 10:18:21,295 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-11 10:18:21,297 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-11 10:18:21,298 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-11 10:18:21,300 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-11 10:18:21,301 [INFO] Arquivo lido com sucesso: main.py
2025-04-11 10:18:21,303 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-11 10:18:21,305 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-11 10:18:21,306 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-11 10:18:21,308 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-11 10:18:21,310 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-11 10:18:21,311 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-11 10:18:21,313 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-11 10:18:21,314 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-11 10:18:21,316 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-11 10:18:21,318 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-11 10:18:21,320 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-11 10:18:21,321 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-11 10:18:21,323 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-11 10:18:21,325 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-11 10:18:21,327 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-11 10:18:21,328 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-11 10:18:21,330 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-11 10:18:21,334 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-11 10:18:21,336 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-11 10:18:21,338 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-11 10:18:21,340 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-11 10:18:21,341 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-11 10:18:21,343 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-11 10:18:21,344 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-11 10:18:21,346 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-11 10:18:21,348 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-11 10:18:21,350 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-11 10:18:21,351 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-11 10:18:21,353 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-11 10:18:21,354 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-11 10:18:21,355 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-11 10:18:21,357 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-11 10:27:06,993 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-11 10:27:06,994 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-11 10:27:06,996 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-11 10:27:06,997 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-11 10:27:06,999 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-11 10:27:07,001 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-11 10:27:07,003 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-11 10:27:07,005 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-11 10:27:07,007 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-11 10:27:07,008 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-11 10:27:07,009 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-11 10:27:07,011 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-11 10:27:07,013 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-11 10:27:07,015 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-11 10:27:07,017 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-11 10:27:07,019 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-11 10:27:07,023 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-11 10:27:07,025 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-11 10:27:07,026 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-11 10:27:07,028 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-11 10:27:07,029 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-11 10:27:07,030 [INFO] Arquivo lido com sucesso: main.py
2025-04-11 10:27:07,032 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-11 10:27:07,033 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-11 10:27:07,034 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-11 10:27:07,036 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-11 10:27:07,039 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-11 10:27:07,040 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-11 10:27:07,041 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-11 10:27:07,043 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-11 10:27:07,044 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-11 10:27:07,046 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-11 10:27:07,047 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-11 10:27:07,048 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-11 10:27:07,050 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-11 10:27:07,051 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-11 10:27:07,053 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-11 10:27:07,054 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-11 10:27:07,056 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-11 10:27:07,057 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-11 10:27:07,059 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-11 10:27:07,060 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-11 10:27:07,062 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-11 10:27:07,064 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-11 10:27:07,065 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-11 10:27:07,067 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-11 10:27:07,068 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-11 10:27:07,070 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-11 10:27:07,071 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-11 10:27:07,072 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-11 10:27:07,074 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-11 10:27:07,075 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-11 10:27:07,076 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-11 10:27:07,078 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
2025-04-11 10:27:07,188 [INFO] Arquivo lido com sucesso: app_config\app_config.py
2025-04-11 10:27:07,193 [INFO] Arquivo lido com sucesso: audio_to_text\audio_config\audio_config.py
2025-04-11 10:27:07,196 [INFO] Arquivo lido com sucesso: audio_to_text\audio_to_text.py
2025-04-11 10:27:07,198 [INFO] Arquivo lido com sucesso: chat_app\chat_streamlit.py
2025-04-11 10:27:07,200 [INFO] Arquivo lido com sucesso: chat_app\config\config.py
2025-04-11 10:27:07,202 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\gemini_handler.py
2025-04-11 10:27:07,205 [INFO] Arquivo lido com sucesso: chat_app\core\handlers\signal_handler.py
2025-04-11 10:27:07,207 [INFO] Arquivo lido com sucesso: chat_app\core\logger_config.py
2025-04-11 10:27:07,212 [INFO] Arquivo lido com sucesso: chat_app\core\rate_limiter.py
2025-04-11 10:27:07,213 [INFO] Arquivo lido com sucesso: chat_app\services\document_service.py
2025-04-11 10:27:07,215 [INFO] Arquivo lido com sucesso: chat_app\services\gpt_services.py
2025-04-11 10:27:07,218 [INFO] Arquivo lido com sucesso: chat_app\services\image_processor.py
2025-04-11 10:27:07,220 [INFO] Arquivo lido com sucesso: chat_app\services\image_services.py
2025-04-11 10:27:07,222 [INFO] Arquivo lido com sucesso: chat_app\services\markdown_service.py
2025-04-11 10:27:07,224 [INFO] Arquivo lido com sucesso: chat_app\services\search_files.py
2025-04-11 10:27:07,226 [INFO] Arquivo lido com sucesso: chat_app\utils\file_utils.py
2025-04-11 10:27:07,227 [INFO] Arquivo lido com sucesso: common_paths\common_paths.py
2025-04-11 10:27:07,229 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\__init__.py
2025-04-11 10:27:07,230 [INFO] Arquivo lido com sucesso: fundamentus_api\fundamentus\dados_b3.py
2025-04-11 10:27:07,232 [INFO] Arquivo lido com sucesso: fundamentus_api\setup.py
2025-04-11 10:27:07,234 [INFO] Arquivo lido com sucesso: ia_generator.py
2025-04-11 10:27:07,235 [INFO] Arquivo lido com sucesso: main.py
2025-04-11 10:27:07,237 [INFO] Arquivo lido com sucesso: send_embeddings_database\embedding_config\embedding_config.py
2025-04-11 10:27:07,239 [INFO] Arquivo lido com sucesso: send_embeddings_database\verify_last_enbedding.py
2025-04-11 10:27:07,241 [INFO] Arquivo lido com sucesso: test_whisper.py
2025-04-11 10:27:07,244 [INFO] Arquivo lido com sucesso: text_to_embedding\embedding_processing.py
2025-04-11 10:27:07,246 [INFO] Arquivo lido com sucesso: text_to_embedding\texto_to_embedding.py
2025-04-11 10:27:07,247 [INFO] Arquivo lido com sucesso: transcriptions\transciption_sender_database.py
2025-04-11 10:27:07,248 [INFO] Arquivo lido com sucesso: transcriptions\transcriptions_config.py
2025-04-11 10:27:07,249 [INFO] Arquivo lido com sucesso: translate\translator_to_english.py
2025-04-11 10:27:07,251 [INFO] Arquivo lido com sucesso: translate\whispert_translator.py
2025-04-11 10:27:07,252 [INFO] Arquivo lido com sucesso: video_to_audio\video_config\video_config.py
2025-04-11 10:27:07,255 [INFO] Arquivo lido com sucesso: video_to_audio\video_to_audio.py
2025-04-11 10:27:07,257 [INFO] Arquivo lido com sucesso: voice_assistent\assistent.py
2025-04-11 10:27:07,259 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\api_client.py
2025-04-11 10:27:07,261 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\command_interpreter.py
2025-04-11 10:27:07,263 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\context_manager.py
2025-04-11 10:27:07,265 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\conversation_history.py
2025-04-11 10:27:07,267 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_api_client.py
2025-04-11 10:27:07,269 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\gemini_gpt.py
2025-04-11 10:27:07,272 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\gpt_communication\groq._gpt.py
2025-04-11 10:27:07,274 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\main.py
2025-04-11 10:27:07,275 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt.py
2025-04-11 10:27:07,277 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\default_prompt_generator.py
2025-04-11 10:27:07,279 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\meeting_prompt.py
2025-04-11 10:27:07,281 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\online_prompt.py
2025-04-11 10:27:07,282 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\prompt_generator\prompt_generator.py
2025-04-11 10:27:07,283 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\question_answers_service.py
2025-04-11 10:27:07,285 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_command_hendler.py
2025-04-11 10:27:07,287 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_processor.py
2025-04-11 10:27:07,288 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\text_to_speech.py
2025-04-11 10:27:07,290 [INFO] Arquivo lido com sucesso: voice_assistent\class_voice_assistent\voice_command_hendler.py
2025-04-11 10:27:07,291 [INFO] Arquivo lido com sucesso: voice_assistent\config.py
2025-04-11 10:27:07,293 [INFO] Arquivo lido com sucesso: voice_assistent\template.py
